{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp text.modeling.seq2seq.translation\n",
    "# |default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | nbflags skip_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "> The `text.modeling.seq2seq.translation` module contains custom models, custom splitters, etc... translation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import inspect, torch, warnings\n",
    "from typing import Callable, Dict, List, Optional, Union\n",
    "\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import (\n",
    "    DataBlock,\n",
    "    ColReader,\n",
    "    ItemGetter,\n",
    "    ColSplitter,\n",
    "    RandomSplitter,\n",
    ")\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastcore.all import *\n",
    "from transformers import AutoModelForSeq2SeqLM, PreTrainedModel\n",
    "from transformers.utils import logging as hf_logging\n",
    "\n",
    "from blurr.text.data.seq2seq.core import (\n",
    "    Seq2SeqBatchTokenizeTransform,\n",
    "    Seq2SeqTextBlock,\n",
    "    default_text_gen_kwargs,\n",
    ")\n",
    "from blurr.text.modeling.core import BaseModelCallback, BaseModelWrapper, Blearner\n",
    "from blurr.text.modeling.seq2seq.core import (\n",
    "    Seq2SeqMetricsCallback,\n",
    "    blurr_seq2seq_splitter,\n",
    ")\n",
    "from blurr.text.utils import get_hf_objects\n",
    "from blurr.utils import PreCalculatedCrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.6.3\n",
      "transformers: 4.18.0\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "import ast, os, inspect, pdb\n",
    "from functools import reduce\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, ranger, OptimWrapper, params\n",
    "from fastcore.test import *\n",
    "from nbdev import nbdev_export\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.text.utils import BlurrText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# silence all the HF warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "NLP = BlurrText()\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "# |cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "The objective in translation is to generate a representation of a given text in another style. For example, we may want to translate German into English or modern English into old English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da97a12933574e3ca2ecc5251b5c570a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8097850b753e4b448eb959ecba38e69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97796f82047b4b6e95a3f0291992db75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wmt16/de-en (download: 1.57 GiB, generated: 1.28 GiB, post-processed: Unknown size, total: 2.85 GiB) to /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8cd4cddfe040368bcf002b56223ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1d4b8f371c47b2b40834a6da537298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/658M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7270c31ee0646fa803010a2aafd9ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/919M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15924a412d34836b900efcdea05db46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/75.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51740a419ef4b74aa4a6e764a81b033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/38.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9ada72e9404f8ab09aec06191a8a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184b9f3bc69a4fa1b67262d638b919b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb2d3b116b94da488b1bfac24859e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating examples from: %s europarl_v7\n",
      "Generating examples from: %s commoncrawl\n",
      "Generating examples from: %s newscommentary_v11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e968e66a7f13466eaf0255d622233e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating examples from: %s newstest2015\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6797494dce0b425cba30bffc8e1fa396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating examples from: %s newstest2016\n",
      "Dataset wmt16 downloaded and prepared to /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tada se dio stanovništva preselio uz samu obalu - Pristan, gdje je i nastao Novi grad početkom XX vijeka.</td>\n",
       "      <td>In that period the majority of the population moved close to the seaside, where the first sea port was founded at the beginning of the 20th century, and later a new city was built.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Dieses Video ist nicht verfügbar loger\" bitch, daß das Böse, der sein Video auf YouTube hochgeladen hatte nearsyx?</td>\n",
       "      <td>\"This video is no loger available\" that evil bitch, who had uploaded his video on youtube nearsyx?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    de  \\\n",
       "0            Tada se dio stanovništva preselio uz samu obalu - Pristan, gdje je i nastao Novi grad početkom XX vijeka.   \n",
       "1  \"Dieses Video ist nicht verfügbar loger\" bitch, daß das Böse, der sein Video auf YouTube hochgeladen hatte nearsyx?   \n",
       "\n",
       "                                                                                                                                                                                     en  \n",
       "0  In that period the majority of the population moved close to the seaside, where the first sea port was founded at the beginning of the 20th century, and later a new city was built.  \n",
       "1                                                                                    \"This video is no loger available\" that evil bitch, who had uploaded his video on youtube nearsyx?  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"wmt16\", \"de-en\", split=\"train\")\n",
    "dataset = dataset.shuffle(seed=32).select(range(1200))\n",
    "wmt_df = pd.DataFrame(dataset[\"translation\"], columns=[\"de\", \"en\"])\n",
    "len(wmt_df)\n",
    "wmt_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmppp9i08el\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573157b76dbe48fc9055ed18d3b90922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json in cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\n",
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmpes7wybva\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95d190385fd48218118eb4b793df134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/tokenizer_config.json in cache at /home/wgilliam/.cache/huggingface/transformers/3bb44a3386cfbb9cb18134066610daf2447a07f2f56a14bed4ef1ffee714851c.ab636688faaa6513d9a830ea57bdb7081f0dda90f9de5e3c857a239f0cc406e7\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/3bb44a3386cfbb9cb18134066610daf2447a07f2f56a14bed4ef1ffee714851c.ab636688faaa6513d9a830ea57bdb7081f0dda90f9de5e3c857a239f0cc406e7\n",
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/source.spm not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmpmmic75d1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7397c4ac9b45648937d7a50eaca8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/source.spm in cache at /home/wgilliam/.cache/huggingface/transformers/97f9ac1f9bf6b0e421cdf322cd4243cf20650839545200bf6b513ad03c168c8c.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/97f9ac1f9bf6b0e421cdf322cd4243cf20650839545200bf6b513ad03c168c8c.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587\n",
      "https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target.spm not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmp_780e_84\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0a65ebfe2748e0b6d43665b94dafbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/750k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target.spm in cache at /home/wgilliam/.cache/huggingface/transformers/1c5dd1c09c6117b6da35a0bfc70dee4e4852bd9f1e019474ccd80f98014806b5.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/1c5dd1c09c6117b6da35a0bfc70dee4e4852bd9f1e019474ccd80f98014806b5.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79\n",
      "https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmp9veehttl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcd2fa7e2d34755b40db7caacd49e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/vocab.json in cache at /home/wgilliam/.cache/huggingface/transformers/135ba2ed81322da617731039edec94c1b10b121b5499ea1bcdd7e60040cf4913.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/135ba2ed81322da617731039edec94c1b10b121b5499ea1bcdd7e60040cf4913.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/source.spm from cache at /home/wgilliam/.cache/huggingface/transformers/97f9ac1f9bf6b0e421cdf322cd4243cf20650839545200bf6b513ad03c168c8c.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target.spm from cache at /home/wgilliam/.cache/huggingface/transformers/1c5dd1c09c6117b6da35a0bfc70dee4e4852bd9f1e019474ccd80f98014806b5.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/135ba2ed81322da617731039edec94c1b10b121b5499ea1bcdd7e60040cf4913.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target_vocab.json from cache at None\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/3bb44a3386cfbb9cb18134066610daf2447a07f2f56a14bed4ef1ffee714851c.ab636688faaa6513d9a830ea57bdb7081f0dda90f9de5e3c857a239f0cc406e7\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/special_tokens_map.json from cache at None\n",
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmp4evxfupq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c542b2df269749568e1e7be26fa2e075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/284M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin in cache at /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514\n",
      "loading weights file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-de-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('marian',\n",
       " transformers.models.marian.tokenization_marian.MarianTokenizer,\n",
       " transformers.models.marian.configuration_marian.MarianConfig,\n",
       " transformers.models.marian.modeling_marian.MarianMTModel)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "    pretrained_model_name, model_cls=model_cls\n",
    ")\n",
    "hf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = (Seq2SeqTextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=ColReader(\"de\"),\n",
    "    get_y=ColReader(\"en\"),\n",
    "    splitter=RandomSplitter(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(wmt_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 168]), torch.Size([2, 140]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0][\"input_ids\"].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In▁Erwägung▁nachstehender▁Gründe▁sollte das▁Europäische▁Parlament▁keinerlei▁Doppelmoral tolerieren. Indessen und um▁politischen Druck auf▁Journalisten▁auszuüben, die▁Korruptionsfälle aufdecken, die in▁Verbindung mit▁hochrangigen▁Beamten und▁regieren</td>\n",
       "      <td>'whereas the European Parliament shall not accept double standards; whereas, in order to put political pressure on journalists disclosing corruption cases linked to high-ranking officials and ruling party politicians, the Government administration in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Es▁ist▁jetzt▁wirklich an der Zeit,▁daß nicht▁nur in▁bezug auf den▁Jahreswirtschaftsbericht und die▁wirtschaftspolitischen▁Leitlinien,▁nein,▁auch in▁bezug auf die▁gesamten▁Fragen zum▁Verfahren zur▁Feststellung des▁übermäßigen▁Defizits und▁auch in▁bezu</td>\n",
       "      <td>It really is time for the European Parliament to be given a codecision right that is consistent with the further democratic development of this European Union; that right must apply not just to the annual economic report and the economic policy guide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=250, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7beb5d148b34d4496f891d212ec9b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7bc8ec150b434480d25087e9134558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169965edb296470483b72c004d109cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f463405d2274fe8820e98b404ec1b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq2seq_metrics = {\n",
    "    \"bleu\": {\"returns\": \"bleu\"},\n",
    "    \"meteor\": {\"returns\": \"meteor\"},\n",
    "    \"sacrebleu\": {\"returns\": \"score\"},\n",
    "}\n",
    "\n",
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=PreCalculatedCrossEntropyLoss(),  # CrossEntropyLossFlat()\n",
    "    cbs=learn_cbs,\n",
    "    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    ")\n",
    "\n",
    "# learn = learn.to_native_fp16() #.to_fp16()\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BaseModelWrapper (Input shape: 2 x 168)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     2 x 140 x 512       \n",
       "Embedding                                 29747712   False     \n",
       "Embedding                                 29747712   False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 512             \n",
       "MarianSinusoidalPositionalEmbedding                      262144     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "SiLUActivation                                                 \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "SiLUActivation                                                 \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "SiLUActivation                                                 \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "SiLUActivation                                                 \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "SiLUActivation                                                 \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "Linear                                    262656     False     \n",
       "LayerNorm                                 1024       True      \n",
       "SiLUActivation                                                 \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 2048      \n",
       "Linear                                    1050624    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 168 x 512       \n",
       "Linear                                    1049088    False     \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Embedding                                 29747712   False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 512             \n",
       "MarianSinusoidalPositionalEmbedding                      262144     False     \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "SiLUActivation                                                 \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "SiLUActivation                                                 \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "SiLUActivation                                                 \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "SiLUActivation                                                 \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "SiLUActivation                                                 \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "SiLUActivation                                                 \n",
       "LayerNorm                                 1024       True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "Linear                                    262656     True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 2048      \n",
       "Linear                                    1050624    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 512       \n",
       "Linear                                    1049088    True      \n",
       "LayerNorm                                 1024       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 140 x 58101     \n",
       "Linear                                    29747712   False     \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 163,653,632\n",
       "Total trainable params: 25,236,480\n",
       "Total non-trainable params: 138,417,152\n",
       "\n",
       "Optimizer used: functools.partial(<function Adam>)\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - BaseModelCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | output: false\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([]), torch.Size([2, 140, 58101]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "\n",
    "len(preds), preds[\"loss\"].shape, preds[\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 168]), 2, torch.Size([2, 140]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0][\"input_ids\"].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=3.981071640737355e-05, steep=6.309573450380412e-07, valley=5.248074739938602e-05, slide=7.585775892948732e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# |slow\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.088453</td>\n",
       "      <td>2.097524</td>\n",
       "      <td>0.295524</td>\n",
       "      <td>0.543777</td>\n",
       "      <td>28.882930</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a `@typedispatch`ed implementation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Schließen die▁vorgeschlagenen▁Anwendungszwecke▁Empfehlungen über die▁Bekämpfung von oder den▁Schutz▁gegen▁Organismen ein, die▁unter den in der▁vorgesehenen▁Anwendungsregion▁herrschenden▁Bedingungen in▁bezug auf▁Landwirtschaft,▁Pflanzenschutz und Umwelt -▁einschließlich der▁Witterungsverhältnisse - nach den▁Erfahrungen und dem▁wissenschaftlichen▁Erkenntnisstand nicht▁als▁schädlich▁gelten, oder▁ist▁davon▁auszugehen,▁daß die▁anderen▁Wirkungen▁unter▁diesen▁Bedingungen den▁beabsichtigten▁Zweck nicht</td>\n",
       "      <td>Where relevant, yield response when the product is used and reduction of loss in storage must be quantitatively and/or qualitatively similar to those resulting from the use of suitable reference products. If no suitable reference product exists, the plant protection product must be shown to give a consistent and defined quantitative and/or qualitative benefit in terms of yield response and reduction of loss in storage under the agricultural, plant health and environmental (including climatic) co</td>\n",
       "      <td>[Where the proposed uses include recommendations on the control of or protection against organisms which are not considered to be harmful under the conditions prevailing in the intended application region in respect of agriculture, plant health and the environment, including climatic conditions, in the light of experience and scientific knowledge, or where it is assumed that the other effects do not meet the intended purpose under such conditions, no authorisation shall be granted for such uses., That is why we have listened to you and asked you to introduce a further transparent consultation procedure on the Anti-Counterfeiting Agreement (ACTA) to ensure that the European Parliament and the citizens represented by this Parliament are regularly and comprehensively informed about the progress of the negotiations, while respecting the confidentiality clauses that you have just explained to us about the agreement.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "We add here `Learner.blurr_translate` method to bring the results inline with the format returned via Hugging Face's pipeline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': ['I like to drink beer',\n",
       "   'I like to drink beer.',\n",
       "   'I like drinking beer']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_de, key=\"translation_texts\", num_return_sequences=3)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@patch\n",
    "def blurr_translate(self: Learner, inp, **kwargs):\n",
    "    preds = self.blurr_generate(inp, key=\"translation_texts\", **kwargs)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': ['I like to drink beer',\n",
       "   'I like to drink beer.',\n",
       "   'I like drinking beer']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_translate(test_de, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Using fast.ai `Learner.export` and `load_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = \"translation_export\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = None\n",
    "learn.export(fname=f\"{export_fname}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': 'I like to drink beer'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_translate(test_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BlearnerForTranslation` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForTranslation(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    def predict(self, text, **kwargs):\n",
    "        return self.blurr_translate(text, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(cls):\n",
    "        return AutoModelForSeq2SeqLM\n",
    "\n",
    "    @classmethod\n",
    "    def _add_t5_prefix(cls, inp, src_lang_name, trg_lang_name):\n",
    "        return f\"translate {src_lang_name} to {trg_lang_name}: {inp}\"\n",
    "\n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        seq2seq_metrics = {\n",
    "            \"bleu\": {\"returns\": \"bleu\"},\n",
    "            \"meteor\": {\"returns\": \"meteor\"},\n",
    "            \"sacrebleu\": {\"returns\": \"score\"},\n",
    "        }\n",
    "\n",
    "        return Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(\n",
    "        cls,\n",
    "        # Your raw dataset. Supports DataFrames, Hugging Face Datasets, as well as file paths\n",
    "        # to .csv, .xlsx, .xls, and .jsonl files\n",
    "        data: Union[pd.DataFrame, Path, str, List[Dict]],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The language of your source (inputs)\n",
    "        src_lang_name: str = \"English\",\n",
    "        # The attribute/column of your source language texts\n",
    "        src_lang_attr: str = \"src_lang\",\n",
    "        # The attribute/column of your target language texts\n",
    "        trg_lang_name: str = \"English\",\n",
    "        # The attribute/column of your target language texts (this is what you want to predict)\n",
    "        trg_lang_attr: str = \"trg_lang\",\n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length: Union[int, str] = None,\n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length: Union[int, str] = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Optional[Callable] = None,\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs: dict = {},\n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs: dict = {},\n",
    "    ):\n",
    "        # if we get a path/str then we're loading something like a .csv file\n",
    "        if isinstance(data, Path) or isinstance(data, str):\n",
    "            content_type = mimetypes.guess_type(data)[0]\n",
    "            if (\n",
    "                content_type\n",
    "                == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
    "            ):\n",
    "                data = pd.read_excel(data)\n",
    "            elif content_type == \"text/csv\":\n",
    "                data = pd.read_csv(data)\n",
    "            elif content_type == \"application/json\":\n",
    "                data = pd.read_json(data, orient=\"records\")\n",
    "            else:\n",
    "                raise ValueError(\"'data' must be a .xlsx, .xls, .csv, or .jsonl file\")\n",
    "\n",
    "            data = pd.read_csv(data)\n",
    "\n",
    "        # infer our datablock splitter if None\n",
    "        if dblock_splitter is None:\n",
    "            dblock_splitter = (\n",
    "                ColSplitter() if hasattr(data, \"is_valid\") else RandomSplitter()\n",
    "            )\n",
    "\n",
    "        # we need to find the architecture to ensure \"mbart\" specific tokenizer kwargs are included\n",
    "        model_cls = cls.get_model_cls()\n",
    "        model = model_cls.from_pretrained(pretrained_model_name_or_path)\n",
    "        hf_arch = model.__module__.split(\".\")[2]\n",
    "\n",
    "        if hf_arch == \"mbart\":\n",
    "            hf_tok_kwargs = {\n",
    "                **{\"src_lang\": \"en_XX\", \"tgt_lang\": \"en_XX\"},\n",
    "                **hf_tok_kwargs,\n",
    "            }\n",
    "\n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "            pretrained_model_name_or_path,\n",
    "            model_cls=model_cls,\n",
    "            tokenizer_kwargs=hf_tok_kwargs,\n",
    "        )\n",
    "\n",
    "        # update text generation kwargs\n",
    "        text_gen_kwargs = {\n",
    "            **text_gen_kwargs,\n",
    "            **default_text_gen_kwargs(hf_config, hf_model, task=\"translation\"),\n",
    "        }\n",
    "\n",
    "        # not all \"translation\" parameters are for the model.generate method ... remove them here\n",
    "        generate_func_args = list(\n",
    "            inspect.signature(hf_model.generate).parameters.keys()\n",
    "        )\n",
    "        for k in text_gen_kwargs.copy():\n",
    "            if k not in generate_func_args:\n",
    "                del text_gen_kwargs[k]\n",
    "\n",
    "        # update our text generation kwargs for mbart\n",
    "        if hf_arch == \"mbart\":\n",
    "            text_gen_kwargs = {**{\"decoder_start_token_id\": \"en_XX\"}, **text_gen_kwargs}\n",
    "\n",
    "        # build dblock, dls, and default metrics (optional)\n",
    "        get_x = Pipeline(funcs=[ColReader(src_lang_attr)])\n",
    "        get_y = ItemGetter(trg_lang_attr)\n",
    "\n",
    "        if hf_arch == \"t5\":\n",
    "            get_x.add(\n",
    "                partial(\n",
    "                    cls._add_t5_prefix,\n",
    "                    src_lang_name=src_lang_name,\n",
    "                    trg_lang_name=trg_lang_name,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "            hf_arch,\n",
    "            hf_config,\n",
    "            hf_tokenizer,\n",
    "            hf_model,\n",
    "            max_length=max_length,\n",
    "            max_target_length=max_target_length,\n",
    "            text_gen_kwargs=text_gen_kwargs,\n",
    "        )\n",
    "\n",
    "        blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "        dblock = DataBlock(\n",
    "            blocks=blocks, get_x=get_x, get_y=get_y, splitter=dblock_splitter\n",
    "        )\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        learner_kwargs[\"splitter\"] = learner_kwargs.pop(\n",
    "            \"splitter\", partial(blurr_seq2seq_splitter, arch=hf_arch)\n",
    "        )\n",
    "        learner_kwargs[\"loss_func\"] = learner_kwargs.pop(\n",
    "            \"loss_func\", PreCalculatedCrossEntropyLoss()\n",
    "        )\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-de-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/source.spm from cache at /home/wgilliam/.cache/huggingface/transformers/97f9ac1f9bf6b0e421cdf322cd4243cf20650839545200bf6b513ad03c168c8c.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target.spm from cache at /home/wgilliam/.cache/huggingface/transformers/1c5dd1c09c6117b6da35a0bfc70dee4e4852bd9f1e019474ccd80f98014806b5.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/135ba2ed81322da617731039edec94c1b10b121b5499ea1bcdd7e60040cf4913.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target_vocab.json from cache at None\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/3bb44a3386cfbb9cb18134066610daf2447a07f2f56a14bed4ef1ffee714851c.ab636688faaa6513d9a830ea57bdb7081f0dda90f9de5e3c857a239f0cc406e7\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/special_tokens_map.json from cache at None\n",
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-de-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "learn = BlearnerForTranslation.from_data(\n",
    "    wmt_df,\n",
    "    \"Helsinki-NLP/opus-mt-de-en\",\n",
    "    src_lang_name=\"German\",\n",
    "    src_lang_attr=\"de\",\n",
    "    trg_lang_name=\"English\",\n",
    "    trg_lang_attr=\"en\",\n",
    "    dl_kwargs={\"bs\": 2},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.014099</td>\n",
       "      <td>2.172663</td>\n",
       "      <td>0.307334</td>\n",
       "      <td>0.537191</td>\n",
       "      <td>29.823626</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_cb = BlearnerForTranslation.get_metrics_cb()\n",
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=[metrics_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(IT) Herr▁Präsident, Herr▁Kommissar,▁meine▁Damen und Herren, so▁genau▁wie die▁Entschließung mit dem▁Titel \"Naturkatastrophen\", die von der▁Fraktion der▁Europäischen▁Volkspartei (Christdemokraten)▁vorgelegt wurde,▁ist,▁würde▁ich▁gerne▁trotzdem die▁Aufmerksamkeit auf▁einige▁Punkte▁lenken, die▁heute▁Abend▁angesprochen▁wurden, die▁aber nicht in der▁Entschließung zum▁Thema▁gemacht▁werden, und die▁Gegenstand▁meiner▁Änderungsvorschläge▁sind.</td>\n",
       "      <td>(IT) Mr President, Commissioner, ladies and gentlemen, as accurate as the resolution entitled 'Natural disasters', tabled by the Group of the European People's Party (Christian Democrats), is, I would nonetheless like to draw attention to some points</td>\n",
       "      <td>[(IT) Mr President, Commissioner, ladies and gentlemen, just as the resolution on natural disasters presented by the Group of the European People's Party (Christian Democrats), I would like to draw attention to some of the points raised this evening, which are not dealt with in the resolution, and which are the subject of my amendments., This Parliament has always been an example and a champion in the defence of human rights, and at this critical time it must prove that it is not doing a common cause with a corrupt dictator in full decline and that it will allow itself to be carried away by the collaboration of some Members who have always been manipulated by this dictatorship.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de = \"Ich trinke gerne Bier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_texts': 'I like to drink beer'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_translate(test_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_texts': 'I like to drink beer'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_fname = \"translation_export\"\n",
    "\n",
    "learn.metrics = None\n",
    "learn = learn.to_fp32()\n",
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_generate(test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained **translation models** below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained translation models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BartForConditionalGeneration',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'LEDForConditionalGeneration',\n",
       " 'M2M100ForConditionalGeneration',\n",
       " 'MBartForConditionalGeneration',\n",
       " 'MT5ForConditionalGeneration',\n",
       " 'PLBartForConditionalGeneration',\n",
       " 'PegasusForConditionalGeneration',\n",
       " 'ProphetNetForConditionalGeneration',\n",
       " 'Speech2TextForConditionalGeneration',\n",
       " 'T5ForConditionalGeneration',\n",
       " 'XLMProphetNetForConditionalGeneration']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    model_type\n",
    "    for model_type in NLP.get_models(task=\"ConditionalGeneration\")\n",
    "    if (not model_type.startswith(\"TF\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    \"facebook/bart-base\",\n",
    "    \"facebook/wmt19-de-en\",  # FSMT\n",
    "    \"Helsinki-NLP/opus-mt-de-en\",  # MarianMT\n",
    "    #'sshleifer/tiny-mbart',\n",
    "    #'google/mt5-small',\n",
    "    \"t5-small\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)\n",
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f/cache-8fc54b133c8c43b7.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"wmt16\", \"de-en\", split=\"train\")\n",
    "dataset = dataset.shuffle(seed=32).select(range(1200))\n",
    "wmt_df = pd.DataFrame(dataset[\"translation\"], columns=[\"de\", \"en\"])\n",
    "len(wmt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/facebook/bart-base/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/43978bdeaa326572886b44fcfed82f932f76571095ce31973e51c3da8ccade7f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/facebook/bart-base/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/3c167ed8af56e6605eeb794b63a79d65d85e6708c9b04408d41946337030f5cd.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/facebook/bart-base/resolve/main/tokenizer.json from cache at /home/wgilliam/.cache/huggingface/transformers/a878fcd69bba037c9b1b227f4213579ae43d0aaa9374e167bc6c5f41b1cfeb30.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "loading file https://huggingface.co/facebook/bart-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/facebook/bart-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/facebook/bart-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/facebook/bart-base/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/486355ec722ef05fd480e999d4c763be56549ae930f6a3742ee721a5d2a05647.f2f355ad2775769afc60592b43a46d72ca548375e3a1d65f381a751e711cbadd\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich habe das Glück hier zu stehen, als schwuler Mann - und wenn ich für mich beschlossen habe, schwul zu sein, ist es nicht interessant, dass jemand anderes offensichtlich für sich bestimmt, heterosexuell zu sein? - Kampf für die Gleichstellung, nicht nur für schwule Männer und Lesben und Bisexuelle und Transgender, sondern</td>\n",
       "      <td>I stand here fortunate, as a gay man - and if I chose to be gay, is it not interesting that one obviously therefore chooses to be heterosexual? - fighting for equality, not just for gay men and lesbians and bisexuals and transgender people, but for</td>\n",
       "      <td>[ Ich habe das Glück hier zu stehen, als sch,  schriftlich. - (EL) Der Bericht macht buchstä]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/wmt19-de-en ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/facebook/wmt19-de-en/resolve/main/config.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmpg94k7zk0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbd2e8c796549818a51a2b7cce00943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/825 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/facebook/wmt19-de-en/resolve/main/config.json in cache at /home/wgilliam/.cache/huggingface/transformers/232d5f8320861ff995f0ce707c380004bfb69ec2d6d426a4f067451b766c0035.0390a2ce5c4c6411e268f30e31322ecdef9eb2ba49fda94dfc5a76d67a9b0000\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/232d5f8320861ff995f0ce707c380004bfb69ec2d6d426a4f067451b766c0035.0390a2ce5c4c6411e268f30e31322ecdef9eb2ba49fda94dfc5a76d67a9b0000\n",
      "loading configuration file https://huggingface.co/facebook/wmt19-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/232d5f8320861ff995f0ce707c380004bfb69ec2d6d426a4f067451b766c0035.0390a2ce5c4c6411e268f30e31322ecdef9eb2ba49fda94dfc5a76d67a9b0000\n",
      "Model config FSMTConfig {\n",
      "  \"_name_or_path\": \"facebook/wmt19-de-en\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"FSMTForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": null,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": 2,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"fsmt_decoder\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": null,\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.18.0\",\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"vocab_size\": 42024\n",
      "  },\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.2,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 8192,\n",
      "  \"encoder_layerdrop\": 0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"langs\": [\n",
      "    \"de\",\n",
      "    \"en\"\n",
      "  ],\n",
      "  \"length_penalty\": 1.1,\n",
      "  \"max_length\": 200,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"fsmt\",\n",
      "  \"num_beams\": 5,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"src_vocab_size\": 42024,\n",
      "  \"tgt_vocab_size\": 42024,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": null,\n",
      "  \"use_cache\": true\n",
      "}\n",
      "\n",
      "https://huggingface.co/facebook/wmt19-de-en/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmpuog48dx0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f614512441534865bfd992dd1088f6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/67.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/facebook/wmt19-de-en/resolve/main/tokenizer_config.json in cache at /home/wgilliam/.cache/huggingface/transformers/ee37018c2659c8edff30fa5786a4086e37a183385772707b5477ba4411a61d92.bb240727cbb831795b3c665b2c7805e92ca85dab184cd839ea0408af6dcfecae\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/ee37018c2659c8edff30fa5786a4086e37a183385772707b5477ba4411a61d92.bb240727cbb831795b3c665b2c7805e92ca85dab184cd839ea0408af6dcfecae\n",
      "loading configuration file https://huggingface.co/facebook/wmt19-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/232d5f8320861ff995f0ce707c380004bfb69ec2d6d426a4f067451b766c0035.0390a2ce5c4c6411e268f30e31322ecdef9eb2ba49fda94dfc5a76d67a9b0000\n",
      "Model config FSMTConfig {\n",
      "  \"_name_or_path\": \"facebook/wmt19-de-en\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"FSMTForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": null,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": 2,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"fsmt_decoder\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": null,\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.18.0\",\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"vocab_size\": 42024\n",
      "  },\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.2,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 8192,\n",
      "  \"encoder_layerdrop\": 0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"langs\": [\n",
      "    \"de\",\n",
      "    \"en\"\n",
      "  ],\n",
      "  \"length_penalty\": 1.1,\n",
      "  \"max_length\": 200,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"fsmt\",\n",
      "  \"num_beams\": 5,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"src_vocab_size\": 42024,\n",
      "  \"tgt_vocab_size\": 42024,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": null,\n",
      "  \"use_cache\": true\n",
      "}\n",
      "\n",
      "https://huggingface.co/facebook/wmt19-de-en/resolve/main/vocab-src.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmpu9udm5ff\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208b2b789a8c48b0b9749345c4f74e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/829k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/facebook/wmt19-de-en/resolve/main/vocab-src.json in cache at /home/wgilliam/.cache/huggingface/transformers/389f8ccd1a7283e9f4d04e2059faba3e29a5092e5209dd1f061904e2b72f2e5f.26ba0023c6adfdb30f5b481eb41adbaa8ec26dc4b98e42d321b9deb99433e90f\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/389f8ccd1a7283e9f4d04e2059faba3e29a5092e5209dd1f061904e2b72f2e5f.26ba0023c6adfdb30f5b481eb41adbaa8ec26dc4b98e42d321b9deb99433e90f\n",
      "https://huggingface.co/facebook/wmt19-de-en/resolve/main/vocab-tgt.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmpqq4yhgn2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5640b65805634359b2be3832eec4ccfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/829k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/facebook/wmt19-de-en/resolve/main/vocab-tgt.json in cache at /home/wgilliam/.cache/huggingface/transformers/31bb587b1089489d525c2ba4fdb7ed2017e242a7ee9f927049d2d472e2cb1ec9.26ba0023c6adfdb30f5b481eb41adbaa8ec26dc4b98e42d321b9deb99433e90f\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/31bb587b1089489d525c2ba4fdb7ed2017e242a7ee9f927049d2d472e2cb1ec9.26ba0023c6adfdb30f5b481eb41adbaa8ec26dc4b98e42d321b9deb99433e90f\n",
      "https://huggingface.co/facebook/wmt19-de-en/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmpkmtx9c4f\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c68eca87d641f49c6b91570e5dc7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/308k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/facebook/wmt19-de-en/resolve/main/merges.txt in cache at /home/wgilliam/.cache/huggingface/transformers/b6b9d991e26bd9421ae2696ba763560cece0fd7ef9f3a3b3be3e71436c0a30e9.7b3379be52fb43e75807d326f0244c93e52304616f437ba5a8d2ee3995704bb4\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/b6b9d991e26bd9421ae2696ba763560cece0fd7ef9f3a3b3be3e71436c0a30e9.7b3379be52fb43e75807d326f0244c93e52304616f437ba5a8d2ee3995704bb4\n",
      "loading file https://huggingface.co/facebook/wmt19-de-en/resolve/main/vocab-src.json from cache at /home/wgilliam/.cache/huggingface/transformers/389f8ccd1a7283e9f4d04e2059faba3e29a5092e5209dd1f061904e2b72f2e5f.26ba0023c6adfdb30f5b481eb41adbaa8ec26dc4b98e42d321b9deb99433e90f\n",
      "loading file https://huggingface.co/facebook/wmt19-de-en/resolve/main/vocab-tgt.json from cache at /home/wgilliam/.cache/huggingface/transformers/31bb587b1089489d525c2ba4fdb7ed2017e242a7ee9f927049d2d472e2cb1ec9.26ba0023c6adfdb30f5b481eb41adbaa8ec26dc4b98e42d321b9deb99433e90f\n",
      "loading file https://huggingface.co/facebook/wmt19-de-en/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/b6b9d991e26bd9421ae2696ba763560cece0fd7ef9f3a3b3be3e71436c0a30e9.7b3379be52fb43e75807d326f0244c93e52304616f437ba5a8d2ee3995704bb4\n",
      "loading file https://huggingface.co/facebook/wmt19-de-en/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/facebook/wmt19-de-en/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/facebook/wmt19-de-en/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/ee37018c2659c8edff30fa5786a4086e37a183385772707b5477ba4411a61d92.bb240727cbb831795b3c665b2c7805e92ca85dab184cd839ea0408af6dcfecae\n",
      "loading configuration file https://huggingface.co/facebook/wmt19-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/232d5f8320861ff995f0ce707c380004bfb69ec2d6d426a4f067451b766c0035.0390a2ce5c4c6411e268f30e31322ecdef9eb2ba49fda94dfc5a76d67a9b0000\n",
      "Model config FSMTConfig {\n",
      "  \"_name_or_path\": \"facebook/wmt19-de-en\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"FSMTForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": null,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"bos_token_id\": 2,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"fsmt_decoder\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": null,\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.18.0\",\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"vocab_size\": 42024\n",
      "  },\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.2,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 8192,\n",
      "  \"encoder_layerdrop\": 0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"langs\": [\n",
      "    \"de\",\n",
      "    \"en\"\n",
      "  ],\n",
      "  \"length_penalty\": 1.1,\n",
      "  \"max_length\": 200,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"fsmt\",\n",
      "  \"num_beams\": 5,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"src_vocab_size\": 42024,\n",
      "  \"tgt_vocab_size\": 42024,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": null,\n",
      "  \"use_cache\": true\n",
      "}\n",
      "\n",
      "https://huggingface.co/facebook/wmt19-de-en/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmphznq5uhg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d650fe0c3f4d91b0fff4f16d3a7032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/facebook/wmt19-de-en/resolve/main/pytorch_model.bin in cache at /home/wgilliam/.cache/huggingface/transformers/a46524d41cad7f1854ca313a0ca48f73081df4a0dc4be12d6a7d8d74f3f2b4ff.99fcb44889d54158876b90cc6822bfb973ef7f5725865f17a84c60394ebcb225\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/a46524d41cad7f1854ca313a0ca48f73081df4a0dc4be12d6a7d8d74f3f2b4ff.99fcb44889d54158876b90cc6822bfb973ef7f5725865f17a84c60394ebcb225\n",
      "loading weights file https://huggingface.co/facebook/wmt19-de-en/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/a46524d41cad7f1854ca313a0ca48f73081df4a0dc4be12d6a7d8d74f3f2b4ff.99fcb44889d54158876b90cc6822bfb973ef7f5725865f17a84c60394ebcb225\n",
      "All model checkpoint weights were used when initializing FSMTForConditionalGeneration.\n",
      "\n",
      "All the weights of FSMTForConditionalGeneration were initialized from the model checkpoint at facebook/wmt19-de-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use FSMTForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tfsmt\n",
      "tokenizer:\tFSMTTokenizer\n",
      "model:\t\tFSMTForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich habe das Glück hier zu stehen, als schwuler Mann - und wenn ich für mich beschlossen habe, schwul zu sein, ist es nicht interessant, dass jemand anderes offensichtlich für sich bestimmt, heterosexuell zu sein? - Kampf für die Gleichstellung, nicht nur für schwule Männer und Lesben und Bisexuelle und Transgender, sondern für Menschen auf Grund ihres Alters, ihrer Religion, ihres Glauben, ihres Geschlechts, alles, was als Unterschied wahrgenommen wird und verwendet werden könnte, um ihnen die</td>\n",
       "      <td>I stand here fortunate, as a gay man - and if I chose to be gay, is it not interesting that one obviously therefore chooses to be heterosexual? - fighting for equality, not just for gay men and lesbians and bisexuals and transgender people, but for p</td>\n",
       "      <td>[I am lucky enough to be standing here as a gay man - and if I have decided for myself to be gay, isn't it interesting that someone else obviously chooses to be heterosexual? - fighting for equality, not just for gay men and lesbians and bisexuals and transgenders, but for people because of their age, their religion, their faith, their gender, anything that is perceived as difference and could be used to deprive them of equality., If we bear in mind the enormous amount of work that we will have to carry out together over the next few years - the German Presidency is not enough, we should not expect miracles from the Germans, and I say this also to my own Presidency, which is coming - then we all know that we must reform the key players, the institutions.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Helsinki-NLP/opus-mt-de-en ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/source.spm from cache at /home/wgilliam/.cache/huggingface/transformers/97f9ac1f9bf6b0e421cdf322cd4243cf20650839545200bf6b513ad03c168c8c.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target.spm from cache at /home/wgilliam/.cache/huggingface/transformers/1c5dd1c09c6117b6da35a0bfc70dee4e4852bd9f1e019474ccd80f98014806b5.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/135ba2ed81322da617731039edec94c1b10b121b5499ea1bcdd7e60040cf4913.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target_vocab.json from cache at None\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/3bb44a3386cfbb9cb18134066610daf2447a07f2f56a14bed4ef1ffee714851c.ab636688faaa6513d9a830ea57bdb7081f0dda90f9de5e3c857a239f0cc406e7\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/special_tokens_map.json from cache at None\n",
      "loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      58100\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 58100,\n",
      "  \"decoder_vocab_size\": 58101,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 58100,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 58101\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-de-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tmarian\n",
      "tokenizer:\tMarianTokenizer\n",
      "model:\t\tMarianMTModel\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In▁Erwägung▁nachstehender▁Gründe▁sollte das▁Europäische▁Parlament▁keinerlei▁Doppelmoral tolerieren. Indessen und um▁politischen Druck auf▁Journalisten▁auszuüben, die▁Korruptionsfälle aufdecken, die in▁Verbindung mit▁hochrangigen▁Beamten und▁regierenden▁Politikern der▁Partei▁stehen, hat die▁ungarische Staatsverwaltung vor Kurzem▁Schritte▁eingeleitet, um▁Strafverfahren▁gegen▁derartige▁Vertreter der Medien▁anzustrengen -▁nämlich▁gegen▁Herrn Tamás Pindroch, den▁Journalisten von Magyar Hírlap -,▁wob</td>\n",
       "      <td>'whereas the European Parliament shall not accept double standards; whereas, in order to put political pressure on journalists disclosing corruption cases linked to high-ranking officials and ruling party politicians, the Government administration in</td>\n",
       "      <td>[\"The European Parliament should not tolerate any double standards, however, and in order to exert political pressure on journalists to expose the corruption cases associated with high-ranking officials and political leaders of the Party, the Hungarian State Administration has recently taken steps to bring criminal proceedings against such representatives of the media - namely Mr Tamás Pindroch, the journalist of Magyar Hírlap -, bearing in mind in particular that criminal proceedings have been launched against those journalists who have been investigating scandals involving senior former members of the European Parliament., This is not intended to deny the importance of traditional energy sources - and I could do so all the less at the moment when Algerian gas comes to Spain and from Spain to Portugal and to the rest of Europe via such an important construction as the gas pipeline linking Algeria to our continent and our Union via Morocco, but of course the emphasis this report places on renewable and sustainable energy sources and energy saving is very much applauded.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "https://huggingface.co/t5-small/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmp0rul851d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08099428b6d4459a1efa2fea6b2a0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/t5-small/resolve/main/tokenizer.json in cache at /home/wgilliam/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\n",
      "loading file https://huggingface.co/t5-small/resolve/main/spiece.model from cache at /home/wgilliam/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\n",
      "loading file https://huggingface.co/t5-small/resolve/main/tokenizer.json from cache at /home/wgilliam/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\n",
      "loading file https://huggingface.co/t5-small/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/t5-small/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/t5-small/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "https://huggingface.co/t5-small/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmpwmeakd9y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4588ea269e08457abd91f62baed61a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/t5-small/resolve/main/pytorch_model.bin in cache at /home/wgilliam/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\n",
      "creating metadata file for /home/wgilliam/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\n",
      "loading weights file https://huggingface.co/t5-small/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>translate German to English: Die Zunahme der Gewalttätigkeiten bei nationalen und internationalen Sportveranstaltungen resultiert nicht aus dem Fehlen von Informationsnetzen und ausreichenden Unterdrückungsmechanismen, sondern ist auf die Kommerzialisierung des Sports, die damit zusammenhängenden enormen wirtschaftlichen Interessen, die Förderung eines desorientierenden'sportlichen' Geistes des Fanatismus (Fußballrowdytums) sowie die Propagierung einer Psychologie der Gewalt insbesondere unter d</td>\n",
       "      <td>The increase in violent clashes at national and international sporting events is not due to a lack of information networks or adequate suppression mechanisms; it is due to the commercialisation of sport, the huge financial interests tied up in it, th</td>\n",
       "      <td>[Die Zunahme der Gewalttätigkeiten bei nationalen und internationalen Sportveranstaltungen resultiert nicht, Zudem haben wir unser Augenmerk auf das Erfordernis einer größtmöglichen Harmonisierung]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# |slow\n",
    "# | output: false\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "bsz = 2\n",
    "inp_seq_sz = 128\n",
    "trg_seq_sz = 128\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error = None\n",
    "\n",
    "    print(f\"=== {model_name} ===\\n\")\n",
    "\n",
    "    hf_tok_kwargs = {}\n",
    "    if model_name == \"sshleifer/tiny-mbart\":\n",
    "        hf_tok_kwargs[\"src_lang\"], hf_tok_kwargs[\"tgt_lang\"] = \"de_DE\", \"en_XX\"\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "        model_name, model_cls=model_cls, tokenizer_kwargs=hf_tok_kwargs\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n\"\n",
    "    )\n",
    "\n",
    "    # 1. build your DataBlock\n",
    "    text_gen_kwargs = default_text_gen_kwargs(hf_config, hf_model, task=\"translation\")\n",
    "\n",
    "    def add_t5_prefix(inp):\n",
    "        return f\"translate German to English: {inp}\" if (hf_arch == \"t5\") else inp\n",
    "\n",
    "    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "        hf_arch,\n",
    "        hf_config,\n",
    "        hf_tokenizer,\n",
    "        hf_model,\n",
    "        padding=\"max_length\",\n",
    "        max_length=inp_seq_sz,\n",
    "        max_target_length=trg_seq_sz,\n",
    "        text_gen_kwargs=text_gen_kwargs,\n",
    "    )\n",
    "\n",
    "    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "    dblock = DataBlock(\n",
    "        blocks=blocks,\n",
    "        get_x=Pipeline([ColReader(\"de\"), add_t5_prefix]),\n",
    "        get_y=ColReader(\"en\"),\n",
    "        splitter=RandomSplitter(),\n",
    "    )\n",
    "\n",
    "    dls = dblock.dataloaders(wmt_df, bs=bsz)\n",
    "    b = dls.one_batch()\n",
    "\n",
    "    # 2. build your Learner\n",
    "    seq2seq_metrics = {}\n",
    "\n",
    "    model = BaseModelWrapper(hf_model)\n",
    "    fit_cbs = [\n",
    "        ShortEpochCallback(0.05, short_valid=True),\n",
    "        Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics),\n",
    "    ]\n",
    "\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        opt_func=ranger,\n",
    "        loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "        cbs=[BaseModelCallback],\n",
    "        splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    "    ).to_fp16()\n",
    "\n",
    "    learn.create_opt()\n",
    "    learn.freeze()\n",
    "\n",
    "    # 3. Run your tests\n",
    "    try:\n",
    "        print(\"*** TESTING DataLoaders ***\\n\")\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0][\"input_ids\"]), bsz)\n",
    "        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, inp_seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        #         print('*** TESTING One pass through the model ***')\n",
    "        #         preds = learn.model(b[0])\n",
    "        #         test_eq(preds[1].shape[0], bsz)\n",
    "        #         test_eq(preds[1].shape[2], hf_config.vocab_size)\n",
    "\n",
    "        print(\"*** TESTING Training/Results ***\")\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n",
    "\n",
    "        test_results.append(\n",
    "            (\n",
    "                hf_arch,\n",
    "                type(hf_tokenizer).__name__,\n",
    "                type(hf_model).__name__,\n",
    "                \"PASSED\",\n",
    "                \"\",\n",
    "            )\n",
    "        )\n",
    "        learn.show_results(\n",
    "            learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250\n",
    "        )\n",
    "    except Exception as err:\n",
    "        test_results.append(\n",
    "            (\n",
    "                hf_arch,\n",
    "                type(hf_tokenizer).__name__,\n",
    "                type(hf_model).__name__,\n",
    "                \"FAILED\",\n",
    "                err,\n",
    "            )\n",
    "        )\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fsmt</td>\n",
       "      <td>FSMTTokenizer</td>\n",
       "      <td>FSMTForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marian</td>\n",
       "      <td>MarianTokenizer</td>\n",
       "      <td>MarianMTModel</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>T5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# |slow\n",
    "# | echo: false\n",
    "test_results_df = pd.DataFrame(\n",
    "    test_results, columns=[\"arch\", \"tokenizer\", \"model_name\", \"result\", \"error\"]\n",
    ")\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_callbacks.ipynb.\n",
      "Converted 00_utils.ipynb.\n",
      "Converted 01_text-callbacks.ipynb.\n",
      "Converted 01_text-utils.ipynb.\n",
      "Converted 11_text-data-core.ipynb.\n",
      "Converted 11_text-modeling-core.ipynb.\n",
      "Converted 12_text-data-language-modeling.ipynb.\n",
      "Converted 12_text-modeling-language-modeling.ipynb.\n",
      "Converted 13_text-data-token-classification.ipynb.\n",
      "Converted 13_text-modeling-token-classification.ipynb.\n",
      "Converted 14_text-data-question-answering.ipynb.\n",
      "Converted 14_text-modeling-question-answering.ipynb.\n",
      "Converted 20_text-data-seq2seq-core.ipynb.\n",
      "Converted 20_text-modeling-seq2seq-core.ipynb.\n",
      "Converted 21_text-data-seq2seq-summarization.ipynb.\n",
      "Converted 21_text-modeling-seq2seq-summarization.ipynb.\n",
      "Converted 22_text-data-seq2seq-translation.ipynb.\n",
      "Converted 22_text-modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_text-examples-high-level-api.ipynb.\n",
      "Converted 99b_text-examples-glue.ipynb.\n",
      "Converted 99c_text-examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_text-examples-multilabel.ipynb.\n",
      "Converted 99e_text-examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
