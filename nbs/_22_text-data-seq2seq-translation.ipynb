{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp text.data.seq2seq.translation\n",
    "# |default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | nbflags skip_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> The `text.data.seq2seq.translation` module contains the bits required to use the fastai DataBlock API and/or mid-level data processing pipelines to organize your data for translation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import warnings\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset\n",
    "from fastai.data.block import DataBlock\n",
    "from transformers import AutoModelForSeq2SeqLM, PreTrainedTokenizerBase\n",
    "from transformers.utils import logging as hf_logging\n",
    "\n",
    "from blurr.text.data.seq2seq.core import (\n",
    "    Seq2SeqBatchTokenizeTransform,\n",
    "    Seq2SeqPreprocessor,\n",
    "    Seq2SeqTextBlock,\n",
    ")\n",
    "from blurr.text.utils import get_hf_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.6\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "import os, ast, pdb\n",
    "from functools import reduce\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.data.transforms import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastcore.all import *\n",
    "from fastcore.test import *\n",
    "from nbdev import nbdev_export\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.text.utils import BlurrText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# silence all the HF warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "NLP = BlurrText()\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "# |cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll use a subset of `wmt16` to demonstrate how to configure your BLURR for translation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation'],\n",
       "    num_rows: 45489\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset = load_dataset(\"wmt16\", \"de-en\", split=\"train[:1%]\")\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['translation'])\n",
      "{'translation': {'de': 'Wiederaufnahme der Sitzungsperiode', 'en': 'Resumption of the session'}}\n"
     ]
    }
   ],
   "source": [
    "print(raw_dataset[0].keys())\n",
    "print(raw_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45489\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wiederaufnahme der Sitzungsperiode</td>\n",
       "      <td>Resumption of the session</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.</td>\n",
       "      <td>I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                           de  \\\n",
       "0                                                                                                                                                                                          Wiederaufnahme der Sitzungsperiode   \n",
       "1  Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.   \n",
       "\n",
       "                                                                                                                                                                                                                en  \n",
       "0                                                                                                                                                                                        Resumption of the session  \n",
       "1  I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmt_df = pd.DataFrame(raw_dataset[\"translation\"], columns=[\"de\", \"en\"])\n",
    "\n",
    "print(len(wmt_df))\n",
    "wmt_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bart',\n",
       " transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,\n",
       " transformers.models.bart.configuration_bart.BartConfig,\n",
       " transformers.models.bart.modeling_bart.BartForConditionalGeneration)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "    pretrained_model_name, model_cls=model_cls\n",
    ")\n",
    "hf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Starting with version 2.0, BLURR provides a preprocessing base class that can be used to build task specific pre-processed datasets from pandas DataFrames or Hugging Face Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TranslationPreprocessor` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class TranslationPreprocessor(Seq2SeqPreprocessor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # A Hugging Face tokenizer\n",
    "        hf_tokenizer: PreTrainedTokenizerBase,\n",
    "        # The number of examples to process at a time\n",
    "        batch_size: int = 1000,\n",
    "        # The unique identifier in the dataset\n",
    "        id_attr: Optional[str] = None,\n",
    "        # The attribute holding the text to translate\n",
    "        text_attr: str = \"original_text\",\n",
    "        # The maximum length (# of tokens) allowed for inputs. Will default to the max length allowed\n",
    "        # by the model if not provided\n",
    "        max_input_tok_length: Optional[int] = None,\n",
    "        # The attribute holding the summary\n",
    "        target_text_attr: str = \"translated_text\",\n",
    "        # The maximum length (# of tokens) allowed for targets\n",
    "        max_target_tok_length: Optional[int] = None,\n",
    "        # The attribute that should be created if your are processing individual training and validation\n",
    "        # datasets into a single dataset, and will indicate to which each example is associated\n",
    "        is_valid_attr: Optional[str] = \"is_valid\",\n",
    "        # Tokenization kwargs that will be applied with calling the tokenizer\n",
    "        tok_kwargs: dict = {},\n",
    "    ):\n",
    "        # we need to use the offset mappings to get back at the raw text from its tokenized representation\n",
    "        tok_kwargs = {**tok_kwargs, \"return_offsets_mapping\": True}\n",
    "\n",
    "        super().__init__(\n",
    "            hf_tokenizer,\n",
    "            batch_size,\n",
    "            text_attr,\n",
    "            max_input_tok_length,\n",
    "            target_text_attr,\n",
    "            max_target_tok_length,\n",
    "            is_valid_attr,\n",
    "            tok_kwargs,\n",
    "        )\n",
    "\n",
    "        self.id_attr = id_attr\n",
    "\n",
    "    def process_df(\n",
    "        self, training_df: pd.DataFrame, validation_df: Optional[pd.DataFrame] = None\n",
    "    ):\n",
    "        df = super().process_df(training_df, validation_df)\n",
    "\n",
    "        # process df in mini-batches\n",
    "        final_df = pd.DataFrame()\n",
    "        for g, batch_df in df.groupby(np.arange(len(df)) // self.batch_size):\n",
    "            final_df = final_df.append(self._process_df_batch(batch_df))\n",
    "\n",
    "        final_df.reset_index(drop=True, inplace=True)\n",
    "        return final_df\n",
    "\n",
    "    def process_hf_dataset(\n",
    "        self, training_ds: Dataset, validation_ds: Optional[Dataset] = None\n",
    "    ):\n",
    "        ds = super().process_hf_dataset(training_ds, validation_ds)\n",
    "        return Dataset.from_pandas(self.process_df(pd.DataFrame(ds)))\n",
    "\n",
    "    # ----- utility methods -----\n",
    "    def _process_df_batch(self, batch_df):\n",
    "        batch_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # grab our inputs and targets batch encoding objects\n",
    "        inputs, targets = self._tokenize_function(batch_df.to_dict(orient=\"list\"))\n",
    "\n",
    "        # add are processed text and target texts to the batched DataFrame\n",
    "        for txt_seq_idx, (txt_attr, batch_enc) in enumerate(\n",
    "            zip([self.text_attr, self.target_text_attr], [inputs, targets])\n",
    "        ):\n",
    "            if txt_attr is None:\n",
    "                break\n",
    "\n",
    "            char_idxs = []\n",
    "            for idx, offset_mapping in enumerate(batch_enc[\"offset_mapping\"]):\n",
    "                text_offsets = [\n",
    "                    offset_mapping[i]\n",
    "                    for i, seq_id in enumerate(batch_enc.sequence_ids(idx))\n",
    "                ]\n",
    "                char_idxs.append([min(text_offsets)[0], max(text_offsets)[1]])\n",
    "\n",
    "            batch_df = pd.concat(\n",
    "                [\n",
    "                    batch_df,\n",
    "                    pd.DataFrame(\n",
    "                        char_idxs,\n",
    "                        columns=[\n",
    "                            f\"{txt_attr}_start_char_idx\",\n",
    "                            f\"{txt_attr}_end_char_idx\",\n",
    "                        ],\n",
    "                    ),\n",
    "                ],\n",
    "                axis=1,\n",
    "            )\n",
    "            batch_df.insert(\n",
    "                0,\n",
    "                f\"proc_{txt_attr}\",\n",
    "                batch_df.apply(\n",
    "                    lambda r: r[txt_attr][\n",
    "                        r[f\"{txt_attr}_start_char_idx\"] : r[f\"{txt_attr}_end_char_idx\"]\n",
    "                        + 1\n",
    "                    ],\n",
    "                    axis=1,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        return batch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class can be used for preprocessing translation tasks, and includes a `proc_{your_text_attr}` and `proc_{target_text_attr}` attributes containing your modified input and target texts as a result of tokenization (e.g., if you specify a `max_length` the `proc_{your_text_attr}` may contain truncated text). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proc_en</th>\n",
       "      <th>proc_de</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>de_start_char_idx</th>\n",
       "      <th>de_end_char_idx</th>\n",
       "      <th>en_start_char_idx</th>\n",
       "      <th>en_end_char_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resumption of the session</td>\n",
       "      <td>Wiederaufnahme der Sitzungsperiode</td>\n",
       "      <td>Wiederaufnahme der Sitzungsperiode</td>\n",
       "      <td>Resumption of the session</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.</td>\n",
       "      <td>Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.</td>\n",
       "      <td>Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.</td>\n",
       "      <td>I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.</td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                           proc_en  \\\n",
       "0                                                                                                                                                                                        Resumption of the session   \n",
       "1  I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.   \n",
       "\n",
       "                                                                                                                                                                                                                      proc_de  \\\n",
       "0                                                                                                                                                                                          Wiederaufnahme der Sitzungsperiode   \n",
       "1  Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.   \n",
       "\n",
       "                                                                                                                                                                                                                           de  \\\n",
       "0                                                                                                                                                                                          Wiederaufnahme der Sitzungsperiode   \n",
       "1  Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.   \n",
       "\n",
       "                                                                                                                                                                                                                en  \\\n",
       "0                                                                                                                                                                                        Resumption of the session   \n",
       "1  I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.   \n",
       "\n",
       "   de_start_char_idx  de_end_char_idx  en_start_char_idx  en_end_char_idx  \n",
       "0                  0               34                  0               25  \n",
       "1                  0              218                  0              207  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = TranslationPreprocessor(\n",
    "    hf_tokenizer,\n",
    "    text_attr=\"de\",\n",
    "    target_text_attr=\"en\",\n",
    "    max_input_tok_length=128,\n",
    "    max_target_tok_length=128,\n",
    ")\n",
    "proc_df = preprocessor.process_df(wmt_df)\n",
    "proc_df.columns, len(proc_df)\n",
    "proc_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch-Time Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Get your Hugging Face objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "    pretrained_model_name, model_cls=model_cls\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Step 2: Create your `DataBlock`\n",
    "\n",
    "Two lines!  Notice we pass in `noop` for our targets (e.g. our summaries) because the batch transform will take care of both out inputs and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = (Seq2SeqTextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=ColReader(\"de\"),\n",
    "    get_y=ColReader(\"en\"),\n",
    "    splitter=RandomSplitter(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dblock.summary(wmt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Build your `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(wmt_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([4, 483]), torch.Size([4, 86]), torch.Size([4, 86]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    0,  2223,    13,  1402,  4723,    89,   189,    28, 16855,   111,\n",
       "            38,   524,  2053,  4010,     9,     5,  2788,  4755,  1293,     6,\n",
       "           147,     5,  1492,     9,  9813,   696,  4685,   372,  2212,   111,\n",
       "             5,  3038,    40,    28, 10142,    13,   258,     5,   796,  1332,\n",
       "             8,  1625,     4,   286,     5,   796,  1332,     6,   142,     5,\n",
       "          7147,     9,    10,   481,   721,   443,    40,  3155,    24,     7,\n",
       "          9648,     5,  2621, 10153,   532,    56,    11,  4938,  1048,   137,\n",
       "             5, 13783,  1288,   376,    88,  1370,     6,  3329,    92,  2919,\n",
       "          1616,    13,   796,   451,     4,     2], device='cuda:1'),\n",
       " tensor([    0,  2223,    13,  1402,  4723,    89,   189,    28, 16855,   111,\n",
       "            38,   524,  2053,  4010,     9,     5,  2788,  4755,  1293,     6,\n",
       "           147,     5,  1492,     9,  9813,   696,  4685,   372,  2212,   111,\n",
       "             5,  3038,    40,    28, 10142,    13,   258,     5,   796,  1332,\n",
       "             8,  1625,     4,   286,     5,   796,  1332,     6,   142,     5,\n",
       "          7147,     9,    10,   481,   721,   443,    40,  3155,    24,     7,\n",
       "          9648,     5,  2621, 10153,   532,    56,    11,  4938,  1048,   137,\n",
       "             5, 13783,  1288,   376,    88,  1370,     6,  3329,    92,  2919,\n",
       "          1616,    13,   796,   451,     4,     2], device='cuda:1'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][\"labels\"][0], b[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; Was nun die Ergebnisse der Verhandlungen über die Anwendung der Artikel 3, 4, 5, 6 und 12 des Interimsabkommens bezüglich Warenhandel, öffentlicher Aufträge, Wettbewerb, Konsultationsmechanismen bei Fragen des geistigen Eigentums und Beilegung vo</td>\n",
       "      <td>Although for certain sectors there may be flaws - I am thinking specifically of the textiles sector, where the rules of origin issue causes great concern - the effects will be beneficial for both the European Union and Mexico. For the European Union</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; Die allgemeine Ausrichtung der umgesetzten Wirtschaftspolitik, der Stabilitätspakt sowie die strengen Konvergenzprogramme, die der Beschäftigung empfindlich schaden und Beschäftigungsfähigkeit sowie Flexibilität der Arbeitsverhältnisse und Arbeit</td>\n",
       "      <td>The general lines of the implemented economic policy, the Stability Pact and the strict convergence programmes, which are a constant menace to employment and which promote employability and the flexibilisation of labour relations, and the organisati</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=250, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a preprocessed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1a: Get your Hugging Face objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "    pretrained_model_name, model_cls=model_cls\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1b. Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TranslationPreprocessor(\n",
    "    hf_tokenizer,\n",
    "    text_attr=\"de\",\n",
    "    target_text_attr=\"en\",\n",
    "    max_input_tok_length=128,\n",
    "    max_target_tok_length=128,\n",
    ")\n",
    "proc_df = preprocessor.process_df(wmt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Create your `DataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = (Seq2SeqTextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=ColReader(\"proc_de\"),\n",
    "    get_y=ColReader(\"proc_en\"),\n",
    "    splitter=RandomSplitter(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Build your `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(proc_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([4, 129]), torch.Size([4, 83]), torch.Size([4, 83]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; Hierbei denke ich an systematische Dokumentation und Informationsbeschaffung, professionelle Formen der Beobachtung, die Entwicklung von Aufklärungsaktionen, die Verwendung von Geldern zur Unterstützung der demokratischen Kräfte in dem betreffend</td>\n",
       "      <td>The following spring to mind in this respect: the systematic collation of documentation and information, professional forms of observation, the development of information campaigns, the use of cash to support democratic forces in the country concern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; Eine letzte Bemerkung: Die durch die Struktur des Internet bedingte permanente Verfügbarkeit von Sexuellem im ausschließlich anonymisierten privaten Bereich und die Tatsache, daß der sexuelle Mißbrauch der öffentlichen und damit der sozialen Kont</td>\n",
       "      <td>One final comment: the permanent availability of sexual material in the exclusively anonymous private sphere, which is conditioned by the structure of the Internet, and the attendant fact that sexual abuse is removed from public and, hence, social c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=250, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The purpose of the following tests is to ensure as much as possible, that the core DataBlock code above works for the pretrained **translation models** below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained translation models you are working with ... and if any of your pretrained summarization models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BartForConditionalGeneration',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'LEDForConditionalGeneration',\n",
       " 'M2M100ForConditionalGeneration',\n",
       " 'MBartForConditionalGeneration',\n",
       " 'MT5ForConditionalGeneration',\n",
       " 'PegasusForConditionalGeneration',\n",
       " 'ProphetNetForConditionalGeneration',\n",
       " 'Speech2TextForConditionalGeneration',\n",
       " 'T5ForConditionalGeneration',\n",
       " 'XLMProphetNetForConditionalGeneration']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    model_type\n",
    "    for model_type in NLP.get_models(task=\"ConditionalGeneration\")\n",
    "    if (not model_type.startswith(\"TF\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    \"facebook/bart-base\",\n",
    "    \"facebook/wmt19-de-en\",  # FSMT\n",
    "    \"Helsinki-NLP/opus-mt-de-en\",  # MarianMT\n",
    "    \"sshleifer/tiny-mbart\",\n",
    "    \"google/mt5-small\",\n",
    "    \"t5-small\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"./\")\n",
    "wmt_df = pd.DataFrame(raw_dataset[\"translation\"], columns=[\"de\", \"en\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; Bericht (A5-0089/2000) von Frau Rühle im Namen des Ausschusses für Haushaltskontrolle über den Aufschub des Beschlusses zur Entlastung der Kommission für die Haushaltsführung des sechsten, siebten und achten Europäischen Entwicklungsfonds für das Haushaltsjahr 1998 (KOM(1999) 227 - C5-0003/1999 - 1999/2004(&lt;/s&gt;</td>\n",
       "      <td>Report (A5-0089/2000) by Mr Rühle, on behalf of the Committee on Budgetary Control, on postponement of the decision concerning discharge to the Commission in respect of the financial management of the sixth, seventh and eighth European Development Funds for the 1998 financial year (COM(1999) 227 - C5­0003/1999 - 1999/2004(DEC)); on granting discharge to the European Foundation for the Improvement of Living and Working Conditions, Dublin, for the 1998 financial year (C5-0150/2000 - 2000/2094(DEC)); on granting discharge to the European Centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; Wesentliche Pfeiler, die ein Fundament dafür schaffen könnten, sind unserer Meinung nach die Aufnahme eines materiell abgesicherten Kapitels über den Fremdenverkehr im Rahmen der Reform, das auch die Rechtsgrundlage für den Sektor darstellt, die Herausbildung einer EU-weiten Fremdenverkehrspolitik, die den Sektor fördert, ohne das Funktion&lt;/s&gt;</td>\n",
       "      <td>In our view, the axes which could create a basis for its support are: the addition of material capital for tourism in the new review which will also constitute a legal base for the sector, the framing of a Community tourism policy to support the sector without disturbing the operation of the tourism market, coordination of the tourism policy with other, parallel Community policies which affect it directly or indirectly, a study of the sector, and the adoption of medium and long-term measures to enhance the competitiveness of tourism as a product.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/wmt19-de-en ===\n",
      "\n",
      "architecture:\tfsmt\n",
      "tokenizer:\tFSMTTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Was nun die Ergebnisse der Verhandlungen über die Anwendung der Artikel 3, 4, 5, 6 und 12 des Interimsabkommens bezüglich Warenhandel, öffentlicher Aufträge, Wettbewerb, Konsultationsmechanismen bei Fragen des geistigen Eigentums und Beilegung von Streitigkeiten betrifft, so gilt festzuhalten, daß wir das vorgesehene Maßnahmenpaket für ein gutes Abkommen halten, auch wenn es für bestimmte Sektoren mit Nachteilen verbunden ist - ich denke im einzelnen an die Textilindustrie, die sich insbesondere wegen der Ursprungsregeln Sorgen macht -, ein Abkommen, das sowohl der Europäischen Union als auch Mexiko &lt;/s&gt;</td>\n",
       "      <td>Although for certain sectors there may be flaws - I am thinking specifically of the textiles sector, where the rules of origin issue causes great concern - the effects will be beneficial for both the European Union and Mexico. For the European Union, because the establishment of a free trade area will enable it to rebuild the presence Member States had in Mexican markets before the NAFTA agreement came into force, involving new expansion opportunities for European companies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Herr Präsident, ich habe auch für die Entschließung zu der Mitteilung der Kommission \"Strategie für den europäischen Binnenmarkt\" gestimmt, obwohl in ihrem Text die Stellungnahme, die Herr Medina Ortega im Namen des Ausschusses für Beschäftigung und soziale Angelegenheiten erarbeitet hat, nicht enthalten ist. Dort heißt es auf Seite 20 wörtlich: \"Unter dem Aspekt der sozialen Sicherheit erfordert das Ideal der Integration die Einführung einer europäischen Sozialversicherung,\" - ich wiederhole, einer europäischen Sozialversicherung - \"die das gegenwärtige System der Harmonisierung der nationalen Systeme ablöst\". &lt;/s&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;</td>\n",
       "      <td>Mr President, I also voted for the Communication: \"The strategy for Europe's internal market\", despite the fact that the text did not include the opinion drafted by Mr Medina Ortega on behalf of the Committee on Employment and Social Affairs, page 20 of which states that from the point of view of social security, the ideal of supplementary pensions requires the creation of a genuine European social security system - and I repeat, European social security system - to replace the current approach, which is based on the harmonisation of national systems.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Helsinki-NLP/opus-mt-de-en ===\n",
      "\n",
      "architecture:\tmarian\n",
      "tokenizer:\tMarianTokenizer\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Was nun die▁Ergebnisse der▁Verhandlungen über die▁Anwendung der Artikel 3, 4, 5, 6 und 12 des Interimsabkommens▁bezüglich▁Warenhandel,▁öffentlicher▁Aufträge,▁Wettbewerb,▁Konsultationsmechanismen▁bei▁Fragen des▁geistigen▁Eigentums und▁Beilegung von▁Streitigkeiten▁betrifft, so▁gilt▁festzuhalten,▁daß wir das▁vorgesehene▁Maßnahmenpaket für ein▁gutes▁Abkommen▁halten,▁auch▁wenn es für▁bestimmte▁Sektoren mit▁Nachteilen▁verbunden▁ist -▁ich▁denke im▁einzelnen an die▁Textilindustrie, die sich▁insbesondere▁wegen der▁Ursprungsregeln▁Sorgen▁macht -, ein▁Abkommen, das▁sowohl der▁Europäischen Union▁als▁auch▁Mexiko▁Vorteile▁bringen▁wird: Für die▁Europäische Union,▁weil die▁Schaffung▁einer▁Freihandelszone es den▁Mitgliedstaaten▁ermöglichen▁wird, auf</td>\n",
       "      <td>Although for certain sectors there may be flaws - I am thinking specifically of the textiles sector, where the rules of origin issue causes great concern - the effects will be beneficial for both the European Union and Mexico. For the European Union, because the establishment of a free trade area will enable it to rebuild the presence Member States had in Mexican markets before the NAFTA agreement came into force, involving new expansion opportunities for European companies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁Unserer▁Meinung nach▁kommt▁oberste▁Priorität der▁wirtschafts- und▁sozialpolitische Agenda zu, die das einschließt, was in▁Ihren▁Prioritäten▁auch▁Lebensqualität▁genannt▁wird, das▁heißt, die▁Rechte der▁Bürger▁als▁Verbraucher und▁auch▁als▁Personen.▁Dabei▁geht es um▁Fragen, die wir▁immer▁wieder▁als▁gegeben▁voraussetzen,▁aber nicht▁genügend▁herausstellen, zum▁Beispiel um das▁europäische▁Sozialmodell und▁seine▁Anpassung an▁neue▁Gegebenheiten, um die▁Verbraucherrechte und den▁Schutz der Umwelt▁sowie um eine▁nachhaltige▁Entwicklung.&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;</td>\n",
       "      <td>We understand that the first priority is the economic and social agenda, which also includes what is known as 'quality of life' priorities, that is to say, the rights of citizens as consumers and as people, in relation to those questions which we always talk about, but never give sufficient priority to, that is, the European social model and its adaptation to the new circumstances, consumer rights, respect for the environment and sustainable development.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sshleifer/tiny-mbart ===\n",
      "\n",
      "architecture:\tmbart\n",
      "tokenizer:\tMBartTokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Was nun die Ergebnisse der Verhandlungen über die Anwendung der Artikel 3, 4, 5, 6 und 12 des Interimsabkommens bezüglich Warenhandel, öffentlicher Aufträge, Wettbewerb, Konsultationsmechanismen bei Fragen des geistigen Eigentums und Beilegung von Streitigkeiten betrifft, so gilt festzuhalten, daß wir das vorgesehene Maßnahmenpaket für ein gutes Abkommen halten, auch wenn es für bestimmte Sektoren mit Nachteilen verbunden ist - ich denke im einzelnen an die Textilindustrie, die sich insbesondere wegen der Ursprungsregeln Sorgen macht -, ein Abkommen, das sowohl der Europäischen&lt;/s&gt;de_DE</td>\n",
       "      <td>Although for certain sectors there may be flaws - I am thinking specifically of the textiles sector, where the rules of origin issue causes great concern - the effects will be beneficial for both the European Union and Mexico. For the European Union, because the establishment of a free trade area will enable it to rebuild the presence Member States had in Mexican markets before the NAFTA agreement came into force, involving new expansion opportunities for European companies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dasselbe gilt für das europäische Patent, dessen Verkauf uns ebenfalls nicht gelingen wird; ferner für die Ausschreibungsnormen, für den Kapitalmarkt; auch für die Früchte der Koordinierung der Sozialpolitik, denn es ist sinnlos, große Mobilitätsmöglichkeiten ins Auge zu fassen, erfolgreiche Programme wie ERASMUS oder SOKRATES zur Erhöhung der Mobilität durchzuführen, wenn wir dann Regelungen für die soziale Sicherheit haben, die dieser Mobilität nicht förderlich sind.&lt;/s&gt;de_DE&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;&lt;pad&gt;</td>\n",
       "      <td>The same applies to the Community patent - for we will not be able to sell that either - to procurement rules and the capital market and to the beginnings of the coordination of social security, because there is no point in us dreaming up great expectations of mobility or developing such successful programmes as ERASMUS or SOCRATES to make people more mobile, if our social security rules do not then support this mobility.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mt5-small ===\n",
      "\n",
      "architecture:\tmt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Was nun die Ergebnisse der Verhandlungen über die Anwendung der Artikel 3, 4, 5, 6 und 12 des Interimsabkommens bezüglich Warenhandel, öffentlicher Aufträge, Wettbewerb, Konsultationsmechanismen bei Fragen des geistigen Eigentums und Beilegung von Streitigkeiten betrifft, so gilt festzuhalten, daß wir das vorgesehene Maßnahmenpaket für ein gutes Abkommen halten, auch wenn es für bestimmte Sektoren mit Nachteilen verbunden ist - ich denke im einzelnen an die Textilindustrie, die sich insbesonder&lt;/s&gt;</td>\n",
       "      <td>Although for certain sectors there may be flaws - I am thinking specifically of the textiles sector, where the rules of origin issue causes great concern - the effects will be beneficial for both the European Union and Mexico. For the European Union, because the establishment of a free trade area will enable it to rebuild the presence Member States had in Mexican markets before the NAFTA agreement came into force, involving new expansion opportunities for European companies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wie Frau Abgeordnete Anna Terrón in ihrer Wortmeldung gesagt hat, bezeichnet das Jahr 1999 im Bereich der Justiz und der inneren Angelegenheiten ein Jahr großer Erwartungen. Erwartungen, die sich mit dem Inkrafttreten des Vertrags von Amsterdam konkretisieren, Erwartungen, die sich mit den Schlußfolgerungen des Rates von Tampere konkretisieren, aber auch Erwartungen, bei denen es darauf ankommt, daß sie sich ab diesem Jahr in konkreten Handlungen und Leistungen niederschlagen, und in diesem Sinne sind wir uns alle&lt;/s&gt;</td>\n",
       "      <td>As Mrs Terrón i Cusí said in her speech, 1999 was a year of great expectations in the field of justice and home affairs - an expectation realised with the coming into force of the Treaty of Amsterdam, an expectation realised with the conclusions of the Tampere Council, and a fundamental expectation, as from this year, that will be realised in the form of specific actions.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n",
      "architecture:\tt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>translate German to English: Was nun die Ergebnisse der Verhandlungen über die Anwendung der Artikel 3, 4, 5, 6 und 12 des Interimsabkommens bezüglich Warenhandel, öffentlicher Aufträge, Wettbewerb, Konsultationsmechanismen bei Fragen des geistigen Eigentums und Beilegung von Streitigkeiten betrifft, so gilt festzuhalten, daß wir das vorgesehene Maßnahmenpaket für ein gutes Abkommen halten, auch wenn es für bestimmte Sektoren mit Nachteilen verbunden ist - ich denke im einzelnen an die Textilindustrie,&lt;/s&gt;</td>\n",
       "      <td>Although for certain sectors there may be flaws - I am thinking specifically of the textiles sector, where the rules of origin issue causes great concern - the effects will be beneficial for both the European Union and Mexico. For the European Union, because the establishment of a free trade area will enable it to rebuild the presence Member States had in Mexican markets before the NAFTA agreement came into force, involving new expansion opportunities for European companies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>translate German to English: Das beweist unter anderem, daß der Tourismus gar nicht das Erdöl der Armen ist, weil er enorme Investitionen in Strukturen, Infrastrukturen, Unternehmertum, Berufswesen, soziale Leistungen und Ausbildung erfordert; daß die Tourismusindustrie von grundlegender Bedeutung für das Gleichgewicht in vielen Regionen ist, weil sie direkte Quelle von Beschäftigung ist und einen Markt für viele lokale Produktionsaktivitäten bietet, nämlich Landwirtschaft, Kleinindustrie und Handwerk, Verkehr, Dienstleistungen, Handel, Bildung; &lt;/s&gt;</td>\n",
       "      <td>This reminds us that tourism cannot be regarded as the poor countries' petroleum industry, because it requires huge investment in structures, infrastructures, entrepreneurship, professional expertise, social services and training; that the tourist industry is essential for the equilibrium of many regions as it provides a direct source of employment and a market for all local productive activities: agriculture, small firms in the industrial and craft sector, transport, services, retail sector, training, etc; that the development of the Community' s tourist industry is closely linked to its sustainability with regard to the Community objectives; that the varied geography and historical, cultural and environmental</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# |slow\n",
    "# | output: false\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "bsz = 2\n",
    "seq_sz = 128\n",
    "trg_seq_sz = 128\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error = None\n",
    "\n",
    "    print(f\"=== {model_name} ===\\n\")\n",
    "\n",
    "    hf_tok_kwargs = {}\n",
    "    if model_name == \"sshleifer/tiny-mbart\":\n",
    "        hf_tok_kwargs[\"src_lang\"], hf_tok_kwargs[\"tgt_lang\"] = \"de_DE\", \"en_XX\"\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "        model_name, model_cls=model_cls, tokenizer_kwargs=hf_tok_kwargs\n",
    "    )\n",
    "\n",
    "    print(f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\n\")\n",
    "\n",
    "    # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "    if hf_tokenizer.pad_token is None:\n",
    "        hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "        hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "        hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "        hf_arch,\n",
    "        hf_config,\n",
    "        hf_tokenizer,\n",
    "        hf_model,\n",
    "        padding=\"max_length\",\n",
    "        max_length=seq_sz,\n",
    "        max_target_length=trg_seq_sz,\n",
    "    )\n",
    "\n",
    "    def add_t5_prefix(inp):\n",
    "        return f\"translate German to English: {inp}\" if (hf_arch == \"t5\") else inp\n",
    "\n",
    "    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "    dblock = DataBlock(\n",
    "        blocks=blocks,\n",
    "        get_x=Pipeline([ColReader(\"de\"), add_t5_prefix]),\n",
    "        get_y=ColReader(\"en\"),\n",
    "        splitter=RandomSplitter(),\n",
    "    )\n",
    "\n",
    "    dls = dblock.dataloaders(wmt_df, bs=bsz)\n",
    "    b = dls.one_batch()\n",
    "\n",
    "    try:\n",
    "        print(\"*** TESTING DataLoaders ***\\n\")\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0][\"input_ids\"]), bsz)\n",
    "        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "        test_eq(b[1].shape, torch.Size([bsz, trg_seq_sz]))\n",
    "\n",
    "        if hasattr(hf_tokenizer, \"add_prefix_space\"):\n",
    "            test_eq(hf_tokenizer.add_prefix_space, True)\n",
    "\n",
    "        test_results.append(\n",
    "            (hf_arch, type(hf_tokenizer).__name__, model_name, \"PASSED\", \"\")\n",
    "        )\n",
    "        dls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=1000)\n",
    "\n",
    "    except Exception as err:\n",
    "        test_results.append(\n",
    "            (hf_arch, type(hf_tokenizer).__name__, model_name, \"FAILED\", err)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>facebook/bart-base</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fsmt</td>\n",
       "      <td>FSMTTokenizer</td>\n",
       "      <td>facebook/wmt19-de-en</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marian</td>\n",
       "      <td>MarianTokenizer</td>\n",
       "      <td>Helsinki-NLP/opus-mt-de-en</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mbart</td>\n",
       "      <td>MBartTokenizerFast</td>\n",
       "      <td>sshleifer/tiny-mbart</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mt5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>google/mt5-small</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>t5-small</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# |slow\n",
    "# | echo: false\n",
    "test_results_df = pd.DataFrame(\n",
    "    test_results, columns=[\"arch\", \"tokenizer\", \"model_name\", \"result\", \"error\"]\n",
    ")\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_callbacks.ipynb.\n",
      "Converted 00_utils.ipynb.\n",
      "Converted 01_text-callbacks.ipynb.\n",
      "Converted 01_text-utils.ipynb.\n",
      "Converted 11_text-data-core.ipynb.\n",
      "Converted 11_text-modeling-core.ipynb.\n",
      "Converted 12_text-data-language-modeling.ipynb.\n",
      "Converted 12_text-modeling-language-modeling.ipynb.\n",
      "Converted 13_text-data-token-classification.ipynb.\n",
      "Converted 13_text-modeling-token-classification.ipynb.\n",
      "Converted 14_text-data-question-answering.ipynb.\n",
      "Converted 14_text-modeling-question-answering.ipynb.\n",
      "Converted 20_text-data-seq2seq-core.ipynb.\n",
      "Converted 20_text-modeling-seq2seq-core.ipynb.\n",
      "Converted 21_text-data-seq2seq-summarization.ipynb.\n",
      "Converted 21_text-modeling-seq2seq-summarization.ipynb.\n",
      "Converted 22_text-data-seq2seq-translation.ipynb.\n",
      "Converted 22_text-modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_text-examples-high-level-api.ipynb.\n",
      "Converted 99b_text-examples-glue.ipynb.\n",
      "Converted 99c_text-examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_text-examples-multilabel.ipynb.\n",
      "Converted 99e_text-examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
