{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text: Data Core\n",
    "\n",
    "> The `text.data.core` module contains the core bits required to use fast.ai's low-level and/or mid-level APIs to define `Datasets`, build `DataLoaders` for training transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp text.data.core\n",
    "# |default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "from __future__ import annotations\n",
    "\n",
    "import gc, importlib, sys, traceback\n",
    "\n",
    "from accelerate.logging import get_logger\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "from fastai.callback.all import *\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.data.block import TransformBlock\n",
    "from fastai.data.transforms import TfmdDL\n",
    "from fastai.text.data import SortedDL\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    PretrainedConfig,\n",
    "    PreTrainedTokenizerBase,\n",
    "    PreTrainedModel,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from transformers import logging as hf_logging\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "from blurr.utils import clean_memory, get_hf_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "import pdb\n",
    "from fastai.data.transforms import DataLoader, DataLoaders, Datasets, ItemTransform\n",
    "from fastai.losses import BaseLoss, BCEWithLogitsLossFlat\n",
    "from datasets import concatenate_datasets, load_dataset, Value\n",
    "from fastai.data.block import CategoryBlock, ColReader, ColSplitter, DataBlock, FuncSplitter, MultiCategoryBlock\n",
    "from fastcore.test import *\n",
    "import nbdev\n",
    "\n",
    "from blurr.utils import print_versions, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |export\n",
    "# silence all the HF warnings and load environment variables\n",
    "warnings.simplefilter(\"ignore\")\n",
    "hf_logging.set_verbosity_error()\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #0: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "# |notest\n",
    "torch.cuda.set_device(0)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.13.1\n",
      "fastai: 2.7.11\n",
      "transformers: 4.26.1\n"
     ]
    }
   ],
   "source": [
    "# | echo: false\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll use a subset of `imdb` to demonstrate how to configure your BLURR for sequence classification tasks. **BLURR** is designed to work with Hugging Face `Dataset` and/or pandas `DataFrame` objects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0607ec8e05ac48169550ebaba53226da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 200\n",
      "1000 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you want to watch a movie and feel good about watching it, then Tigerland is the film for you. I love this movie from top to bottom. This movie's picture-perfect scenes look so real; it's almost like a documentary of something that happened in real life but with drama. Boy, I tell you... REAL drama they actually real \"fought\" in one of the scenes (get the DVD listen to the commentary its not obvious). I see this film as a bunch of desperate young men trying to escape an ill-fated destiny, after watching Saving Private Ryan I have an a appreciation of what an \"ill-fated destiny\" is and k...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm giving ten out of ten it's one of the best movies ever. Absolutely smashed, stunned and dazed by the whole picture, marvellous playing of Jason Statham, Ray Liotta and all the crew, amazing plot... Just look into yourself and pluck up your courage to admit-it touched your soul, because it's strange, but there are all the answers you've been ever looking for... The very best, mr. Ritchie! THE VERY BEST EVER. Those who were looking for a simple figtings and skirmish keep yelling they are disappointed. But there are lots of shallow movies in Hollywood nowadays, you can't remember what it ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is the first time I'm writing a comment on a movie on IMDb. but i had to write it for this one. its 3 hrs of unadulterated torture. from the starting u get the idea that the movie is gonna be bad. the acting is pathetic. I'm a big fan of Ajay devgan (loved him in bhagat singh) but he is at his worst in this movie. amitabh seems to have worked hard for this one, but somehow the fear is missing. prashant raj is a non actor. and the most irritating part of the movie is nisha kothari. i have no clue why the director took her in this movie. the background score is repetitive. somehow i fel...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Level One, Horror.&lt;br /&gt;&lt;br /&gt;When I saw this film for the first time at 10, I knew it would give me nightmares. It did. Surprisingly, as I recall, it was the sound as much as the sight of the monster that caused them.&lt;br /&gt;&lt;br /&gt;Level Two, Psychoanalytic Theory.&lt;br /&gt;&lt;br /&gt;Later as an adult, I saw the story for what it was: What if the savage, unrestrained instincts we all repress became manifest.&lt;br /&gt;&lt;br /&gt;Level Three, Pure Science Fiction.&lt;br /&gt;&lt;br /&gt;The best way plausibly to realize the plot's \"What if\" is through the science fiction genre. This is pure science fiction, not the \"cowbo...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caught this film at the Arizona International Film Festival. I wasn't expecting a lot (though the festival's director told me it was one of the best films submitted). Five minutes into it I was sold. Shot in B &amp; W on a shoestring budget, this film is hilarious. The acting is solid, the writing is solid and the look of the film is solid. The acting is probably the biggest revelation, since most films shot on low budgets tend to have amateur or stagey acting. Not this one. It features one of the most convincing, endearing and funny portrayals of a character with Tourette's Syndrome I've ever...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  If you want to watch a movie and feel good about watching it, then Tigerland is the film for you. I love this movie from top to bottom. This movie's picture-perfect scenes look so real; it's almost like a documentary of something that happened in real life but with drama. Boy, I tell you... REAL drama they actually real \"fought\" in one of the scenes (get the DVD listen to the commentary its not obvious). I see this film as a bunch of desperate young men trying to escape an ill-fated destiny, after watching Saving Private Ryan I have an a appreciation of what an \"ill-fated destiny\" is and k...   \n",
       "1  I'm giving ten out of ten it's one of the best movies ever. Absolutely smashed, stunned and dazed by the whole picture, marvellous playing of Jason Statham, Ray Liotta and all the crew, amazing plot... Just look into yourself and pluck up your courage to admit-it touched your soul, because it's strange, but there are all the answers you've been ever looking for... The very best, mr. Ritchie! THE VERY BEST EVER. Those who were looking for a simple figtings and skirmish keep yelling they are disappointed. But there are lots of shallow movies in Hollywood nowadays, you can't remember what it ...   \n",
       "2  this is the first time I'm writing a comment on a movie on IMDb. but i had to write it for this one. its 3 hrs of unadulterated torture. from the starting u get the idea that the movie is gonna be bad. the acting is pathetic. I'm a big fan of Ajay devgan (loved him in bhagat singh) but he is at his worst in this movie. amitabh seems to have worked hard for this one, but somehow the fear is missing. prashant raj is a non actor. and the most irritating part of the movie is nisha kothari. i have no clue why the director took her in this movie. the background score is repetitive. somehow i fel...   \n",
       "3  Level One, Horror.<br /><br />When I saw this film for the first time at 10, I knew it would give me nightmares. It did. Surprisingly, as I recall, it was the sound as much as the sight of the monster that caused them.<br /><br />Level Two, Psychoanalytic Theory.<br /><br />Later as an adult, I saw the story for what it was: What if the savage, unrestrained instincts we all repress became manifest.<br /><br />Level Three, Pure Science Fiction.<br /><br />The best way plausibly to realize the plot's \"What if\" is through the science fiction genre. This is pure science fiction, not the \"cowbo...   \n",
       "4  Caught this film at the Arizona International Film Festival. I wasn't expecting a lot (though the festival's director told me it was one of the best films submitted). Five minutes into it I was sold. Shot in B & W on a shoestring budget, this film is hilarious. The acting is solid, the writing is solid and the look of the film is solid. The acting is probably the biggest revelation, since most films shot on low budgets tend to have amateur or stagey acting. Not this one. It features one of the most convincing, endearing and funny portrayals of a character with Tourette's Syndrome I've ever...   \n",
       "\n",
       "   label  is_valid  \n",
       "0      1     False  \n",
       "1      1     False  \n",
       "2      0     False  \n",
       "3      1     False  \n",
       "4      1     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dsd = load_dataset(\"imdb\", split=[\"train\", \"test\"])\n",
    "\n",
    "# build HF `Dataset` objects\n",
    "train_ds = imdb_dsd[0].add_column(\"is_valid\", [False] * len(imdb_dsd[0])).shuffle().select(range(1000))\n",
    "valid_ds = imdb_dsd[1].add_column(\"is_valid\", [True] * len(imdb_dsd[1])).shuffle().select(range(200))\n",
    "imdb_ds = concatenate_datasets([train_ds, valid_ds])\n",
    "\n",
    "# build a `DataFrame` representation as well\n",
    "imdb_df = pd.DataFrame(imdb_ds)\n",
    "\n",
    "print(len(train_ds), len(valid_ds))\n",
    "print(len(imdb_df[imdb_df[\"is_valid\"] == False]), len(imdb_df[imdb_df[\"is_valid\"] == True]))\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = imdb_dsd[0].features[\"label\"].names\n",
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset civil_comments (/home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b30758429d49a49ef26674e5428459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745c81372e4e4e59b17f1c2ecf802e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe3423a9aae41698d93f4f42b86f366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53f2ca6080349408c8e9c4731d716f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc339ff82e874d278e21a93199cfe445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 200\n",
      "1000 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m looking. I don’t see “all the Trump lovers who see nothing wrong with maiming animals”.  I don’t know which is more ridiculous; the original comment or your defense of it.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Numbers?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Guess that commenter has not updated the goal posts. Remember how they kept baiting people with the \"no evidence of hacking\" the election, even though it was only the right wing talking about this.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“My fingers are long and beautiful, as, has been well-documented, are various other parts of my body.” You find this acceptable by a presidential candidate? More people need to hear and read this egomaniac's trash. They'll make their own mind in spite of those who choose to limit access to the whole story and blame political correctness.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If anyone questions incompetence of .gov --- look no further than this article! SADDDDDDD\\n\\nLower Quality &amp; Higher Price = SADDDDDDDD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                  text  \\\n",
       "0                                                                                                                                                                      I’m looking. I don’t see “all the Trump lovers who see nothing wrong with maiming animals”.  I don’t know which is more ridiculous; the original comment or your defense of it.   \n",
       "1                                                                                                                                                                                                                                                                                                                                             Numbers?   \n",
       "2                                                                                                                                                Guess that commenter has not updated the goal posts. Remember how they kept baiting people with the \"no evidence of hacking\" the election, even though it was only the right wing talking about this.   \n",
       "3  “My fingers are long and beautiful, as, has been well-documented, are various other parts of my body.” You find this acceptable by a presidential candidate? More people need to hear and read this egomaniac's trash. They'll make their own mind in spite of those who choose to limit access to the whole story and blame political correctness.   \n",
       "4                                                                                                                                                                                                               If anyone questions incompetence of .gov --- look no further than this article! SADDDDDDD\\n\\nLower Quality & Higher Price = SADDDDDDDD   \n",
       "\n",
       "   toxicity  severe_toxicity  obscene  threat  insult  identity_attack  \\\n",
       "0         1                0        0       0       1                0   \n",
       "1         0                0        0       0       0                0   \n",
       "2         0                0        0       0       0                0   \n",
       "3         0                0        0       0       0                0   \n",
       "4         0                0        0       0       0                0   \n",
       "\n",
       "   sexual_explicit  is_valid  \n",
       "0                0     False  \n",
       "1                0     False  \n",
       "2                0     False  \n",
       "3                0     False  \n",
       "4                0     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "civil_dsd = load_dataset(\"civil_comments\", split=[\"train\", \"validation\"])\n",
    "\n",
    "# round the floats\n",
    "civil_labels = [\"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\", \"sexual_explicit\"]\n",
    "\n",
    "\n",
    "def round_targs(example):\n",
    "    for lbl in civil_labels:\n",
    "        example[lbl] = np.round(example[lbl])\n",
    "    return example\n",
    "\n",
    "\n",
    "# convert floats to ints\n",
    "def fix_dtypes(ds):\n",
    "    new_features = ds.features.copy()\n",
    "    for lbl in civil_labels:\n",
    "        new_features[lbl] = Value(\"int32\")\n",
    "    return ds.cast(new_features)\n",
    "\n",
    "\n",
    "# build HF `Dataset` objects\n",
    "civil_train_ds = civil_dsd[0].add_column(\"is_valid\", [False] * len(civil_dsd[0])).shuffle().select(range(1000))\n",
    "civil_train_ds = civil_train_ds.map(round_targs)\n",
    "civil_train_ds = fix_dtypes(civil_train_ds)\n",
    "\n",
    "civil_valid_ds = civil_dsd[1].add_column(\"is_valid\", [True] * len(civil_dsd[1])).shuffle().select(range(200))\n",
    "civil_valid_ds = civil_valid_ds.map(round_targs)\n",
    "civil_valid_ds = fix_dtypes(civil_valid_ds)\n",
    "\n",
    "civil_ds = concatenate_datasets([civil_train_ds, civil_valid_ds])\n",
    "\n",
    "# build a `DataFrame` representation as well\n",
    "civil_df = pd.DataFrame(civil_ds)\n",
    "\n",
    "print(len(civil_train_ds), len(civil_valid_ds))\n",
    "print(len(civil_df[civil_df[\"is_valid\"] == False]), len(civil_df[civil_df[\"is_valid\"] == True]))\n",
    "civil_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base API\n",
    "\n",
    "A base collation function that works with a variety of input formats and pads inputs on-the-fly at batch time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def get_task_hf_objects(pretrained_model_name: str, labels: list = [\"neg\", \"pos\"], verbose: bool = False):\n",
    "    model_cls = AutoModelForSequenceClassification\n",
    "    n_labels = len(labels)\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "        pretrained_model_name, model_cls=model_cls, config_kwargs={\"num_labels\": n_labels}\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)\n",
    "\n",
    "        print(\"=== config ===\")\n",
    "        print(f\"# of labels:\\t{hf_config.num_labels}\")\n",
    "        print(\"\")\n",
    "        print(\"=== tokenizer ===\")\n",
    "        print(f\"Vocab size:\\t\\t{hf_tokenizer.vocab_size}\")\n",
    "        print(f\"Max # of tokens:\\t{hf_tokenizer.model_max_length}\")\n",
    "        print(f\"Attributes expected by model in forward pass:\\t{hf_tokenizer.model_input_names}\")\n",
    "\n",
    "    return hf_arch, hf_config, hf_tokenizer, hf_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TextCollatorWithPadding` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@dataclass\n",
    "class TextCollatorWithPadding:\n",
    "    def __init__(\n",
    "        self,\n",
    "        # A Hugging Face tokenizer\n",
    "        hf_tokenizer: PreTrainedTokenizerBase,\n",
    "        # The abbreviation/name of your Hugging Face transformer architecture (e.b., bert, bart, etc..)\n",
    "        hf_arch: str = None,\n",
    "        # A specific configuration instance you want to use\n",
    "        hf_config: PretrainedConfig = None,\n",
    "        # A Hugging Face model\n",
    "        hf_model: PreTrainedModel = None,\n",
    "        # The number of inputs expected by your model\n",
    "        n_inp: int = 1,\n",
    "        # Defaults to use Hugging Face's DataCollatorWithPadding(tokenizer=hf_tokenizer)\n",
    "        data_collator_cls: type = DataCollatorWithPadding,\n",
    "        # kwyargs specific for the instantiation of the `data_collator`\n",
    "        data_collator_kwargs: dict = {},\n",
    "    ):\n",
    "        store_attr()\n",
    "        self.hf_tokenizer = data_collator_kwargs.pop(\"tokenizer\", self.hf_tokenizer)\n",
    "        self.data_collator = data_collator_cls(tokenizer=self.hf_tokenizer, **data_collator_kwargs)\n",
    "\n",
    "    def __call__(self, features):\n",
    "        features = L(features)\n",
    "        inputs, labels, targs = [], [], []\n",
    "\n",
    "        # features contain dictionaries\n",
    "        if isinstance(features[0], dict):\n",
    "            feature_keys = list(features[0].keys())\n",
    "            inputs = [self._build_inputs_d(features, feature_keys)]\n",
    "\n",
    "            input_labels = self._build_input_labels(features, feature_keys)\n",
    "            if input_labels is not None:\n",
    "                labels, targs = [input_labels], [input_labels.clone()]\n",
    "        # features contains tuples, each of which can contain multiple inputs and/or targets\n",
    "        elif isinstance(features[0], tuple):\n",
    "            for f_idx in range(self.n_inp):\n",
    "                feature_keys = list(features[0][f_idx].keys())\n",
    "                inputs.append(self._build_inputs_d(features.itemgot(f_idx), feature_keys))\n",
    "\n",
    "                input_labels = self._build_input_labels(features.itemgot(f_idx), feature_keys)\n",
    "                labels.append(input_labels if input_labels is not None else [])\n",
    "\n",
    "            targs = [self._proc_targets(list(features.itemgot(f_idx))) for f_idx in range(self.n_inp, len(features[0]))]\n",
    "\n",
    "        return self._build_batch(inputs, labels, targs)\n",
    "\n",
    "    # ----- utility methods -----\n",
    "\n",
    "    # to build the inputs dictionary\n",
    "    def _build_inputs_d(self, features, feature_keys):\n",
    "        return {fwd_arg: list(features.attrgot(fwd_arg)) for fwd_arg in self.hf_tokenizer.model_input_names if fwd_arg in feature_keys}\n",
    "\n",
    "    # to build the input \"labels\"\n",
    "    def _build_input_labels(self, features, feature_keys):\n",
    "        if \"label\" in feature_keys:\n",
    "            labels = list(features.attrgot(\"label\"))\n",
    "            return self._proc_targets(labels)\n",
    "        return None\n",
    "\n",
    "    # used to give the labels/targets the right shape\n",
    "    def _proc_targets(self, targs):\n",
    "        if is_listy(targs[0]):\n",
    "            targs = torch.stack([tensor(lbls) for lbls in targs])\n",
    "        elif isinstance(targs[0], torch.Tensor) and len(targs[0].size()) > 0:\n",
    "            targs = torch.stack(targs)\n",
    "        else:\n",
    "            targs = torch.tensor(targs)\n",
    "\n",
    "        return targs\n",
    "\n",
    "    # will properly assemble are batch given a list of inputs, labels, and targets\n",
    "    def _build_batch(self, inputs, labels, targs):\n",
    "        batch = []\n",
    "\n",
    "        for input, input_labels in zip(inputs, labels):\n",
    "            input_d = dict(self.data_collator(input))\n",
    "            if len(input_labels) > 0:\n",
    "                input_d[\"labels\"] = input_labels\n",
    "            batch.append(input_d)\n",
    "\n",
    "        for targ in targs:\n",
    "            batch.append(targ)\n",
    "\n",
    "        return tuplify(batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base API: Examples\n",
    "\n",
    "This section demonstrates how you can use standard `Dataset` objects (PyTorch and Hugging Face) to build PyTorch `DataLoader`s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t2\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", labels, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: `torch.utils.data.Dataset`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train|Validation examples:  1000 200\n",
      "{'text': ['If you want to watch a movie and feel good about watching it, then Tigerland is the film for you. I love this movie from top to bottom. This movie\\'s picture-perfect scenes look so real; it\\'s almost like a documentary of something that happened in real life but with drama. Boy, I tell you... REAL drama they actually real \"fought\" in one of the scenes (get the DVD listen to the commentary its not obvious). I see this film as a bunch of desperate young men trying to escape an ill-fated destiny, after watching Saving Private Ryan I have an a appreciation of what an \"ill-fated destiny\" is and know exactly how the men in the film feel. I see this movie as a crossbreed between \"Stand By Me\" and \"Saving Private Ryan.\" What do men do when they are with a situation that\\'s \"hard pressed\" in real life? Some men go crazy, some men cry, some men through fists, others do drugs, some randomly sleep with hookers ruthlessly trying to eradicate the meaning of love from their life, some try drink the pain away, some jump off buildings or bridges, some feel guilty and others feel so much agony it makes them so sick they collapse - physically. This movie has all those desperate emotions rolled into one ball. But don\\'t get me wrong its not depressing movie, its realistic, its a very very humorous movie, the cocky and funny Bozz (Collin\\'s Character) lights it all up, and on top of that there are about 5 female actresses in the movie; I\\'ll let you figure out what their in there for! With dialogue, war/action sequences, picture perfect scenes along with appropriate music; this movie has it all, like I said: from top to bottom. I don\\'t why Tigerland is heavily under-credited. The best thing about owning the movie is that on the cover it says in big bold writing \"The best film of the year,\" and it absolutely falls nothing short of that. Keep the rare gems coming Hollywood, 10/10.', \"I'm giving ten out of ten it's one of the best movies ever. Absolutely smashed, stunned and dazed by the whole picture, marvellous playing of Jason Statham, Ray Liotta and all the crew, amazing plot... Just look into yourself and pluck up your courage to admit-it touched your soul, because it's strange, but there are all the answers you've been ever looking for... The very best, mr. Ritchie! THE VERY BEST EVER. Those who were looking for a simple figtings and skirmish keep yelling they are disappointed. But there are lots of shallow movies in Hollywood nowadays, you can't remember what it was about the next day you had seen it. On the contrary, Revolver is unique, I could have hardly expected it's possible to portray such a clear and genius picture of myself, of everyone who was to watch it. Absolutely unsurpassed, astounding, dazzling... One can get insight watching this, I have no doubt about that. Actually, no words can express my admiration... I'm still wondering how it was possible to shoot such a movie after years of giddy Hollywood rubbish we had been watching. Thank you from all heart, it's simply the best.\"], 'label': [1, 1], 'is_valid': [False, False]}\n",
      "\n",
      "['If you want to watch a movie and feel good about watching it, then Tigerland is the film for you. I love this movie from top to bottom. This movie\\'s picture-perfect scenes look so real; it\\'s almost like a documentary of something that happened in real life but with drama. Boy, I tell you... REAL drama they actually real \"fought\" in one of the scenes (get the DVD listen to the commentary its not obvious). I see this film as a bunch of desperate young men trying to escape an ill-fated destiny, after watching Saving Private Ryan I have an a appreciation of what an \"ill-fated destiny\" is and know exactly how the men in the film feel. I see this movie as a crossbreed between \"Stand By Me\" and \"Saving Private Ryan.\" What do men do when they are with a situation that\\'s \"hard pressed\" in real life? Some men go crazy, some men cry, some men through fists, others do drugs, some randomly sleep with hookers ruthlessly trying to eradicate the meaning of love from their life, some try drink the pain away, some jump off buildings or bridges, some feel guilty and others feel so much agony it makes them so sick they collapse - physically. This movie has all those desperate emotions rolled into one ball. But don\\'t get me wrong its not depressing movie, its realistic, its a very very humorous movie, the cocky and funny Bozz (Collin\\'s Character) lights it all up, and on top of that there are about 5 female actresses in the movie; I\\'ll let you figure out what their in there for! With dialogue, war/action sequences, picture perfect scenes along with appropriate music; this movie has it all, like I said: from top to bottom. I don\\'t why Tigerland is heavily under-credited. The best thing about owning the movie is that on the cover it says in big bold writing \"The best film of the year,\" and it absolutely falls nothing short of that. Keep the rare gems coming Hollywood, 10/10.', \"I'm giving ten out of ten it's one of the best movies ever. Absolutely smashed, stunned and dazed by the whole picture, marvellous playing of Jason Statham, Ray Liotta and all the crew, amazing plot... Just look into yourself and pluck up your courage to admit-it touched your soul, because it's strange, but there are all the answers you've been ever looking for... The very best, mr. Ritchie! THE VERY BEST EVER. Those who were looking for a simple figtings and skirmish keep yelling they are disappointed. But there are lots of shallow movies in Hollywood nowadays, you can't remember what it was about the next day you had seen it. On the contrary, Revolver is unique, I could have hardly expected it's possible to portray such a clear and genius picture of myself, of everyone who was to watch it. Absolutely unsurpassed, astounding, dazzling... One can get insight watching this, I have no doubt about that. Actually, no words can express my admiration... I'm still wondering how it was possible to shoot such a movie after years of giddy Hollywood rubbish we had been watching. Thank you from all heart, it's simply the best.\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train|Validation examples: \", len(train_ds), len(valid_ds))\n",
    "\n",
    "print(train_ds[:2])\n",
    "print(\"\")\n",
    "print(train_ds[\"text\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91b59bb181046fc92a31b2d69da017a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dcef72b96b84d9db6253d09b4a36a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the dataset\n",
    "def tokenize_func(example):\n",
    "    return hf_tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "proc_train_ds = train_ds.map(tokenize_func, batched=True)\n",
    "proc_train_ds.set_format(\"torch\", columns=hf_tokenizer.model_input_names + [\"label\"])\n",
    "\n",
    "proc_valid_ds = valid_ds.map(tokenize_func, batched=True)\n",
    "proc_valid_ds.set_format(\"torch\", columns=hf_tokenizer.model_input_names + [\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our PyTorch Dataset class\n",
    "class HFTextClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, hf_tokenizer):\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.hf_tokenizer = hf_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.hf_dataset[idx]\n",
    "        return item\n",
    "\n",
    "\n",
    "# build our PyTorch training and validation Datasets\n",
    "pt_proc_train_ds = HFTextClassificationDataset(proc_train_ds, hf_tokenizer=hf_tokenizer)\n",
    "pt_proc_valid_ds = HFTextClassificationDataset(proc_valid_ds, hf_tokenizer=hf_tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build your fastai `DataLoaders` from Pytorch `DataLoader` objects\n",
    "batch_size = 4\n",
    "data_collator = TextCollatorWithPadding(hf_tokenizer)\n",
    "train_dl = torch.utils.data.DataLoader(pt_proc_train_ds, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
    "valid_dl = torch.utils.data.DataLoader(pt_proc_valid_ds, batch_size=batch_size * 2, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 25\n",
      "2\n",
      "\n",
      "[CLS] Only the chosen ones will appreciate the quality of the story and character design of this movie. Superior ancients that dwell in the lands of lore far beyond any average human creature's understanding. This movie pulls the adventure genre into a unique centrifugal magical force of fantasy unto thee mystical crystals of chalice. Stories come and go, but the idea for a good story is to think positive, not negative thoughts. To create a good versus evil battle like never before. Embracing an impounding shimmering process that keeps imagination glowing in one dimension and out the other. Striking a quick flash of energy that transports a human to another world.[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "\n",
      "tensor([1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dl), len(valid_dl))\n",
    "\n",
    "b = next(iter(train_dl))\n",
    "print(len(b))\n",
    "print(\"\")\n",
    "print(hf_tokenizer.decode(b[0][\"input_ids\"][0][:200]))\n",
    "print(\"\")\n",
    "print(b[1])\n",
    "\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOPE: Won't work with PyTorch DataLoaders\n",
    "# AttributeError: 'DataLoader' object has no attribute 'show_batch'\n",
    "# dls.show_batch(dataloaders=dls, max_n=2, trunc_at=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilabel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t7\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", civil_labels, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: `torch.utils.data.Dataset`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train|Validation examples:  1000 200\n",
      "{'text': ['I’m looking. I don’t see “all the Trump lovers who see nothing wrong with maiming animals”.  I don’t know which is more ridiculous; the original comment or your defense of it.', 'Numbers?'], 'toxicity': [1, 0], 'severe_toxicity': [0, 0], 'obscene': [0, 0], 'threat': [0, 0], 'insult': [1, 0], 'identity_attack': [0, 0], 'sexual_explicit': [0, 0], 'is_valid': [False, False]}\n",
      "\n",
      "['I’m looking. I don’t see “all the Trump lovers who see nothing wrong with maiming animals”.  I don’t know which is more ridiculous; the original comment or your defense of it.', 'Numbers?']\n"
     ]
    }
   ],
   "source": [
    "print(\"Train|Validation examples: \", len(civil_train_ds), len(civil_valid_ds))\n",
    "\n",
    "print(civil_train_ds[:2])\n",
    "print(\"\")\n",
    "print(civil_train_ds[\"text\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda55e0c6ad3401692fdb9902cff87a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c5eac065af473eb7bd9cd9c8a18c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the dataset\n",
    "def tokenize_func(example):\n",
    "    return hf_tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "proc_civil_train_ds = civil_train_ds.map(tokenize_func, batched=True)\n",
    "proc_civil_train_ds.set_format(\"torch\", columns=hf_tokenizer.model_input_names + civil_labels)\n",
    "\n",
    "proc_civil_valid_ds = civil_valid_ds.map(tokenize_func, batched=True)\n",
    "proc_civil_valid_ds.set_format(\"torch\", columns=hf_tokenizer.model_input_names + civil_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our PyTorch Dataset class\n",
    "class HFTextMultilabelClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset, hf_tokenizer, labels):\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.hf_tokenizer = hf_tokenizer\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.hf_dataset[idx]\n",
    "        item[\"label\"] = [item[lbl] for lbl in self.labels]\n",
    "        return item\n",
    "\n",
    "\n",
    "# build our PyTorch training and validation Datasets\n",
    "pt_proc_civil_train_ds = HFTextMultilabelClassificationDataset(proc_civil_train_ds, hf_tokenizer=hf_tokenizer, labels=civil_labels)\n",
    "pt_proc_civil_valid_ds = HFTextMultilabelClassificationDataset(proc_civil_valid_ds, hf_tokenizer=hf_tokenizer, labels=civil_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build your fastai `DataLoaders` from Pytorch `DataLoader` objects\n",
    "batch_size = 4\n",
    "data_collator = TextCollatorWithPadding(hf_tokenizer)\n",
    "train_dl = torch.utils.data.DataLoader(pt_proc_civil_train_ds, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
    "valid_dl = torch.utils.data.DataLoader(pt_proc_civil_valid_ds, batch_size=batch_size * 2, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 25\n",
      "2\n",
      "\n",
      "[CLS] No, the very source you provided says otherwise. Same place I copied the above numbers from. Alaska Dept of Labor. First page under the table of contents, labeled 'highlights'. Quote: \"The oil industry had 6,728 nonresident and 11,751 resident workers in 2015. Nonresidents were 36.4 percent, up from 35.1 per- cent in 2014.\" Quote: \"• The percentage of nonresidents working in oil and gas rose from 35.1 percent to 36.4 percent. (See Exhibit 6.)\" Quote: \" Nonresidents earned 33.8 percent of total wages, up from 32.2 percent in 2014.\" Nice try, but some folks actually double check.[SEP]\n",
      "\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dl), len(valid_dl))\n",
    "\n",
    "b = next(iter(train_dl))\n",
    "print(len(b))\n",
    "print(\"\")\n",
    "print(hf_tokenizer.decode(b[0][\"input_ids\"][0][:200]))\n",
    "print(\"\")\n",
    "print(b[1])\n",
    "\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t2\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", labels, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: `Datasets`\n",
    "\n",
    "We'll use the Hugging Face `Dataset` objects created in *Setup*, but these could just as well be instances of `torch.utils.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train|Validation examples:  1000 200\n",
      "{'text': ['If you want to watch a movie and feel good about watching it, then Tigerland is the film for you. I love this movie from top to bottom. This movie\\'s picture-perfect scenes look so real; it\\'s almost like a documentary of something that happened in real life but with drama. Boy, I tell you... REAL drama they actually real \"fought\" in one of the scenes (get the DVD listen to the commentary its not obvious). I see this film as a bunch of desperate young men trying to escape an ill-fated destiny, after watching Saving Private Ryan I have an a appreciation of what an \"ill-fated destiny\" is and know exactly how the men in the film feel. I see this movie as a crossbreed between \"Stand By Me\" and \"Saving Private Ryan.\" What do men do when they are with a situation that\\'s \"hard pressed\" in real life? Some men go crazy, some men cry, some men through fists, others do drugs, some randomly sleep with hookers ruthlessly trying to eradicate the meaning of love from their life, some try drink the pain away, some jump off buildings or bridges, some feel guilty and others feel so much agony it makes them so sick they collapse - physically. This movie has all those desperate emotions rolled into one ball. But don\\'t get me wrong its not depressing movie, its realistic, its a very very humorous movie, the cocky and funny Bozz (Collin\\'s Character) lights it all up, and on top of that there are about 5 female actresses in the movie; I\\'ll let you figure out what their in there for! With dialogue, war/action sequences, picture perfect scenes along with appropriate music; this movie has it all, like I said: from top to bottom. I don\\'t why Tigerland is heavily under-credited. The best thing about owning the movie is that on the cover it says in big bold writing \"The best film of the year,\" and it absolutely falls nothing short of that. Keep the rare gems coming Hollywood, 10/10.', \"I'm giving ten out of ten it's one of the best movies ever. Absolutely smashed, stunned and dazed by the whole picture, marvellous playing of Jason Statham, Ray Liotta and all the crew, amazing plot... Just look into yourself and pluck up your courage to admit-it touched your soul, because it's strange, but there are all the answers you've been ever looking for... The very best, mr. Ritchie! THE VERY BEST EVER. Those who were looking for a simple figtings and skirmish keep yelling they are disappointed. But there are lots of shallow movies in Hollywood nowadays, you can't remember what it was about the next day you had seen it. On the contrary, Revolver is unique, I could have hardly expected it's possible to portray such a clear and genius picture of myself, of everyone who was to watch it. Absolutely unsurpassed, astounding, dazzling... One can get insight watching this, I have no doubt about that. Actually, no words can express my admiration... I'm still wondering how it was possible to shoot such a movie after years of giddy Hollywood rubbish we had been watching. Thank you from all heart, it's simply the best.\"], 'label': [1, 1], 'is_valid': [False, False]}\n",
      "\n",
      "['If you want to watch a movie and feel good about watching it, then Tigerland is the film for you. I love this movie from top to bottom. This movie\\'s picture-perfect scenes look so real; it\\'s almost like a documentary of something that happened in real life but with drama. Boy, I tell you... REAL drama they actually real \"fought\" in one of the scenes (get the DVD listen to the commentary its not obvious). I see this film as a bunch of desperate young men trying to escape an ill-fated destiny, after watching Saving Private Ryan I have an a appreciation of what an \"ill-fated destiny\" is and know exactly how the men in the film feel. I see this movie as a crossbreed between \"Stand By Me\" and \"Saving Private Ryan.\" What do men do when they are with a situation that\\'s \"hard pressed\" in real life? Some men go crazy, some men cry, some men through fists, others do drugs, some randomly sleep with hookers ruthlessly trying to eradicate the meaning of love from their life, some try drink the pain away, some jump off buildings or bridges, some feel guilty and others feel so much agony it makes them so sick they collapse - physically. This movie has all those desperate emotions rolled into one ball. But don\\'t get me wrong its not depressing movie, its realistic, its a very very humorous movie, the cocky and funny Bozz (Collin\\'s Character) lights it all up, and on top of that there are about 5 female actresses in the movie; I\\'ll let you figure out what their in there for! With dialogue, war/action sequences, picture perfect scenes along with appropriate music; this movie has it all, like I said: from top to bottom. I don\\'t why Tigerland is heavily under-credited. The best thing about owning the movie is that on the cover it says in big bold writing \"The best film of the year,\" and it absolutely falls nothing short of that. Keep the rare gems coming Hollywood, 10/10.', \"I'm giving ten out of ten it's one of the best movies ever. Absolutely smashed, stunned and dazed by the whole picture, marvellous playing of Jason Statham, Ray Liotta and all the crew, amazing plot... Just look into yourself and pluck up your courage to admit-it touched your soul, because it's strange, but there are all the answers you've been ever looking for... The very best, mr. Ritchie! THE VERY BEST EVER. Those who were looking for a simple figtings and skirmish keep yelling they are disappointed. But there are lots of shallow movies in Hollywood nowadays, you can't remember what it was about the next day you had seen it. On the contrary, Revolver is unique, I could have hardly expected it's possible to portray such a clear and genius picture of myself, of everyone who was to watch it. Absolutely unsurpassed, astounding, dazzling... One can get insight watching this, I have no doubt about that. Actually, no words can express my admiration... I'm still wondering how it was possible to shoot such a movie after years of giddy Hollywood rubbish we had been watching. Thank you from all heart, it's simply the best.\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train|Validation examples: \", len(train_ds), len(valid_ds))\n",
    "\n",
    "print(train_ds[:2])\n",
    "print(\"\")\n",
    "print(train_ds[\"text\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-04ed63f6cc01230b.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9965e072b3234038a65b0767380e82dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'is_valid', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 1000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label', 'is_valid', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# tokenize the dataset\n",
    "def tokenize_func(example):\n",
    "    return hf_tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "proc_train_ds = train_ds.map(tokenize_func, batched=True)\n",
    "proc_train_ds.set_format(\"torch\", columns=hf_tokenizer.model_input_names + [\"label\"])\n",
    "\n",
    "proc_valid_ds = valid_ds.map(tokenize_func, batched=True)\n",
    "proc_valid_ds.set_format(\"torch\", columns=hf_tokenizer.model_input_names + [\"label\"])\n",
    "\n",
    "print(proc_train_ds)\n",
    "print(proc_valid_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build your fastai `DataLoaders` from Pytorch `DataLoader` objects\n",
    "batch_size = 4\n",
    "data_collator = TextCollatorWithPadding(hf_tokenizer)\n",
    "train_dl = torch.utils.data.DataLoader(proc_train_ds, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
    "valid_dl = torch.utils.data.DataLoader(proc_valid_ds, batch_size=batch_size * 2, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 25\n",
      "2\n",
      "\n",
      "[CLS] What was the worst movie of 2003? \"Cat in the Hat?\" \"Gigli?\" Mais non! I propose that it was this atrocious little film from earlier in the year. Badly written, badly edited, and (if I may be so bold) badly acted, \"The Order\" is the black hole of film - a movie so dense not even the slightest bit of entertainment could escape from its event horizon of suck. It isn't even accidentally funny, like (for example) \"Showgirls.\"<br /><br />You know that the producers are assuming that their audience isn't going to be very smart. They renamed the movie, originally titled \"The Sin Eaters,\" because they figured Americans were too stupid to understand what a sin eater was, even though they go to great lengths to explain what a sin eater is in the movie. Instead, they figure an utterly generic title and a picture of Heath Ledger looking sullen are more than\n",
      "\n",
      "tensor([0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dl), len(valid_dl))\n",
    "\n",
    "b = next(iter(train_dl))\n",
    "print(len(b))\n",
    "print(\"\")\n",
    "print(hf_tokenizer.decode(b[0][\"input_ids\"][0][:200]))\n",
    "print(\"\")\n",
    "print(b[1])\n",
    "\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t7\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", civil_labels, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: `Datasets`\n",
    "\n",
    "We'll use the Hugging Face `Dataset` objects created in *Setup*, but these could just as well be instances of `torch.utils.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train|Validation examples:  1000 200\n",
      "{'text': ['I’m looking. I don’t see “all the Trump lovers who see nothing wrong with maiming animals”.  I don’t know which is more ridiculous; the original comment or your defense of it.', 'Numbers?'], 'toxicity': [1, 0], 'severe_toxicity': [0, 0], 'obscene': [0, 0], 'threat': [0, 0], 'insult': [1, 0], 'identity_attack': [0, 0], 'sexual_explicit': [0, 0], 'is_valid': [False, False]}\n",
      "\n",
      "['I’m looking. I don’t see “all the Trump lovers who see nothing wrong with maiming animals”.  I don’t know which is more ridiculous; the original comment or your defense of it.', 'Numbers?']\n"
     ]
    }
   ],
   "source": [
    "print(\"Train|Validation examples: \", len(civil_train_ds), len(civil_valid_ds))\n",
    "\n",
    "print(civil_train_ds[:2])\n",
    "print(\"\")\n",
    "print(civil_train_ds[\"text\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf329369349f4530a0986ea1a78690ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e27d6b946d945d4a7b1dd37fab02bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack', 'sexual_explicit', 'is_valid', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
      "    num_rows: 1000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'toxicity', 'severe_toxicity', 'obscene', 'threat', 'insult', 'identity_attack', 'sexual_explicit', 'is_valid', 'input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# tokenize the dataset\n",
    "def tokenize_func(example):\n",
    "    updated_example = dict(hf_tokenizer(example[\"text\"], truncation=True))\n",
    "    labels = torch.stack([tensor(example[lbl]) for lbl in civil_labels], dim=-1)\n",
    "    updated_example[\"label\"] = labels\n",
    "\n",
    "    return updated_example\n",
    "\n",
    "\n",
    "proc_civil_train_ds = civil_train_ds.map(tokenize_func, batched=True)\n",
    "# proc_civil_train_ds.set_format(\"torch\", columns=hf_tokenizer.model_input_names + [\"label\"])\n",
    "\n",
    "proc_civil_valid_ds = civil_valid_ds.map(tokenize_func, batched=True, batch_size=4)\n",
    "# proc_civil_valid_ds.set_format(\"torch\", columns=hf_tokenizer.model_input_names + [\"label\"])\n",
    "\n",
    "print(proc_civil_train_ds)\n",
    "print(proc_civil_valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build your fastai `DataLoaders` from Pytorch `DataLoader` objects\n",
    "batch_size = 4\n",
    "data_collator = TextCollatorWithPadding(hf_tokenizer)\n",
    "train_dl = torch.utils.data.DataLoader(proc_civil_train_ds, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
    "valid_dl = torch.utils.data.DataLoader(proc_civil_valid_ds, batch_size=batch_size * 2, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 25\n",
      "2\n",
      "\n",
      "[CLS] CTE is common knowledge and they even had a major motion picture about it. Would you expect the coach to tell his players on the first day of practice that \"there may be germs on the shower room floor\"? It is time to end football and boxing.[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dl), len(valid_dl))\n",
    "\n",
    "b = next(iter(train_dl))\n",
    "print(len(b))\n",
    "print(\"\")\n",
    "print(hf_tokenizer.decode(b[0][\"input_ids\"][0][:200]))\n",
    "print(\"\")\n",
    "print(b[1])\n",
    "\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-Level API\n",
    "\n",
    "This section demonstrates how you can migrate from using PyTorch/Hugging Face to fast.ai `Datasets` and `DataLoaders` to recapture much of the fast.ai specific features unavailable when using basic PyTorch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TextInput` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class TextInput(TensorBase):\n",
    "    \"\"\"The base represenation of your inputs; used by the various fastai `show` methods\"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TextInput` object is returned from the decodes method of `BatchDecodeTransform` as a means to customize `@typedispatch`ed functions like `DataLoaders.show_batch` and `Learner.show_results`. The value will the your \"input_ids\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BatchDecodeTransform` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class BatchDecodeTransform(Transform):\n",
    "    \"\"\"A class used to cast your inputs as `input_return_type` for fastai `show` methods\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # A Hugging Face tokenizer (not required if passing in an instance of `BatchTokenizeTransform` to `before_batch_tfm`)\n",
    "        hf_tokenizer: PreTrainedTokenizerBase,\n",
    "        # The abbreviation/name of your Hugging Face transformer architecture (not required if passing in an instance of `BatchTokenizeTransform` to `before_batch_tfm`)\n",
    "        hf_arch: str = None,\n",
    "        # A Hugging Face configuration object (not required if passing in an instance of `BatchTokenizeTransform` to `before_batch_tfm`)\n",
    "        hf_config: PretrainedConfig = None,\n",
    "        # A Hugging Face model (not required if passing in an instance of `BatchTokenizeTransform` to `before_batch_tfm`)\n",
    "        hf_model: PreTrainedModel = None,\n",
    "        # Used by typedispatched show methods\n",
    "        input_return_type: type = TextInput,\n",
    "        # Any other keyword arguments\n",
    "        **kwargs,\n",
    "    ):\n",
    "        store_attr()\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def decodes(self, items: dict):\n",
    "        \"\"\"Returns the proper object and data for show related fastai methods\"\"\"\n",
    "        return self.input_return_type(items[\"input_ids\"])\n",
    "\n",
    "        # inps = self.input_return_type(items[0][\"input_ids\"])\n",
    "        # # inps = self.input_return_type(items[0][0])\n",
    "        # if len(items) > 1:\n",
    "        #     return inps, *items[1:]\n",
    "        # else:\n",
    "        #     labels = items[0].get(\"labels\", [None] * items[0][\"input_ids\"])\n",
    "        #     return inps, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of fastai 2.1.5, before batch transforms no longer have a `decodes` method ... and so, I've introduced a standard batch transform here, `BatchDecodeTransform`, (one that occurs \"after\" the batch has been created) that will do the decoding for us."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility classes and methods \n",
    "\n",
    "These methods are use internally for getting blurr transforms associated to your `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def get_blurr_tfm(\n",
    "    # A list of transforms (e.g., dls.after_batch, dls.before_batch, etc...)\n",
    "    tfms_list: Pipeline,\n",
    "    # The transform to find\n",
    "    tfm_class: Transform = BatchDecodeTransform,\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a fastai DataLoaders batch transforms, this method can be used to get at a transform\n",
    "    instance used in your Blurr DataBlock\n",
    "    \"\"\"\n",
    "    return next(filter(lambda el: issubclass(type(el), tfm_class), tfms_list), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ohmeow/blurr/blob/dev-3.0.0 #master/blurr/text/data/core.py#L190){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_blurr_tfm\n",
       "\n",
       ">      get_blurr_tfm (tfms_list:fastcore.transform.Pipeline,\n",
       ">                     tfm_class:fastcore.transform.Transform=<class\n",
       ">                     '__main__.BatchDecodeTransform'>)\n",
       "\n",
       "Given a fastai DataLoaders batch transforms, this method can be used to get at a transform\n",
       "instance used in your Blurr DataBlock\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| tfms_list | Pipeline |  | A list of transforms (e.g., dls.after_batch, dls.before_batch, etc...) |\n",
       "| tfm_class | Transform | BatchDecodeTransform | The transform to find |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ohmeow/blurr/blob/dev-3.0.0 #master/blurr/text/data/core.py#L190){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_blurr_tfm\n",
       "\n",
       ">      get_blurr_tfm (tfms_list:fastcore.transform.Pipeline,\n",
       ">                     tfm_class:fastcore.transform.Transform=<class\n",
       ">                     '__main__.BatchDecodeTransform'>)\n",
       "\n",
       "Given a fastai DataLoaders batch transforms, this method can be used to get at a transform\n",
       "instance used in your Blurr DataBlock\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| tfms_list | Pipeline |  | A list of transforms (e.g., dls.after_batch, dls.before_batch, etc...) |\n",
       "| tfm_class | Transform | BatchDecodeTransform | The transform to find |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbdev.show_doc(get_blurr_tfm, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def first_blurr_tfm(\n",
    "    # Your fast.ai `DataLoaders\n",
    "    dls: DataLoaders,\n",
    "    # The Blurr transforms to look for in order\n",
    "    tfms: list[Transform] = [BatchDecodeTransform],\n",
    "):\n",
    "    \"\"\"\n",
    "    This convenience method will find the first Blurr transform required for methods such as\n",
    "    `show_batch` and `show_results`. The returned transform should have everything you need to properly\n",
    "    decode and 'show' your Hugging Face inputs/targets\n",
    "    \"\"\"\n",
    "    for tfm in tfms:\n",
    "        found_tfm = get_blurr_tfm(dls.before_batch, tfm_class=tfm)\n",
    "        if found_tfm:\n",
    "            return found_tfm\n",
    "\n",
    "        found_tfm = get_blurr_tfm(dls.after_batch, tfm_class=tfm)\n",
    "        if found_tfm:\n",
    "            return found_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ohmeow/blurr/blob/dev-3.0.0 #master/blurr/text/data/core.py#L203){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### first_blurr_tfm\n",
       "\n",
       ">      first_blurr_tfm (dls:fastai.data.core.DataLoaders,\n",
       ">                       tfms:list[fastcore.transform.Transform]=[<class\n",
       ">                       '__main__.BatchDecodeTransform'>])\n",
       "\n",
       "This convenience method will find the first Blurr transform required for methods such as\n",
       "`show_batch` and `show_results`. The returned transform should have everything you need to properly\n",
       "decode and 'show' your Hugging Face inputs/targets\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| dls | DataLoaders |  | Your fast.ai `DataLoaders |\n",
       "| tfms | list[Transform] | [<class '__main__.BatchDecodeTransform'>] | The Blurr transforms to look for in order |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ohmeow/blurr/blob/dev-3.0.0 #master/blurr/text/data/core.py#L203){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### first_blurr_tfm\n",
       "\n",
       ">      first_blurr_tfm (dls:fastai.data.core.DataLoaders,\n",
       ">                       tfms:list[fastcore.transform.Transform]=[<class\n",
       ">                       '__main__.BatchDecodeTransform'>])\n",
       "\n",
       "This convenience method will find the first Blurr transform required for methods such as\n",
       "`show_batch` and `show_results`. The returned transform should have everything you need to properly\n",
       "decode and 'show' your Hugging Face inputs/targets\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| dls | DataLoaders |  | Your fast.ai `DataLoaders |\n",
       "| tfms | list[Transform] | [<class '__main__.BatchDecodeTransform'>] | The Blurr transforms to look for in order |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbdev.show_doc(first_blurr_tfm, title_level=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `show_batch` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@typedispatch\n",
    "def show_batch(\n",
    "    # This typedispatched `show_batch` will be called for `TextInput` typed inputs\n",
    "    x: TextInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # Your `DataLoaders`. This is required so as to get at the Hugging Face objects for\n",
    "    # decoding them into something understandable\n",
    "    dataloaders,\n",
    "    # Your `show_batch` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_batch`\n",
    "    **kwargs,\n",
    "):\n",
    "    # grab our tokenizer\n",
    "    tfm = first_blurr_tfm(dataloaders)\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "\n",
    "    # if we've included our labels list, we'll use it to look up the value of our target(s)\n",
    "    trg_labels = tfm.kwargs[\"labels\"] if (\"labels\" in tfm.kwargs) else None\n",
    "    if trg_labels is None and dataloaders.vocab is not None:\n",
    "        trg_labels = dataloaders.vocab\n",
    "\n",
    "    res = L()\n",
    "    n_inp = dataloaders.n_inp\n",
    "\n",
    "    n_samples = min(max_n, dataloaders.bs)\n",
    "    for idx in range(n_samples):\n",
    "        input_ids = x[idx]\n",
    "        rets = [hf_tokenizer.decode(input_ids, skip_special_tokens=True)[:trunc_at]]\n",
    "\n",
    "        sample = samples[idx] if samples is not None else None\n",
    "        for item_idx, item in enumerate(sample[n_inp:]):\n",
    "            label = y[item_idx] if y is not None else item\n",
    "\n",
    "            if torch.is_tensor(label):\n",
    "                label = list(label.numpy()) if len(label.size()) > 0 else label.item()\n",
    "\n",
    "            if is_listy(label):\n",
    "                trg = [trg_labels[int(idx)] for idx, val in enumerate(label) if (val == 1)] if trg_labels else label\n",
    "            else:\n",
    "                trg = trg_labels[int(item)] if trg_labels else item\n",
    "\n",
    "            rets.append(trg)\n",
    "        res.append(tuplify(rets))\n",
    "\n",
    "    cols = [\"text\"] + [\"target\" if (i == 0) else f\"target_{i}\" for i in range(len(res[0]) - n_inp)]\n",
    "    display_df(pd.DataFrame(res, columns=cols)[:max_n])\n",
    "    return ctxs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TextDataLoader` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@delegates()\n",
    "class TextDataLoader(TfmdDL):\n",
    "    \"\"\"\n",
    "    A transformed `DataLoader` that works with Blurr.\n",
    "    From the fastai docs: A `TfmDL` is described as \"a DataLoader that creates Pipeline from a list of Transforms\n",
    "    for the callbacks `after_item`, `before_batch` and `after_batch`. As a result, it can decode or show a processed batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # A standard PyTorch Dataset\n",
    "        dataset: torch.utils.data.dataset.Dataset | Datasets,\n",
    "        # A Hugging Face tokenizer (not required if passing in an instance of `BatchTokenizeTransform` to `before_batch_tfm`)\n",
    "        hf_tokenizer: PreTrainedTokenizerBase,\n",
    "        # The abbreviation/name of your Hugging Face transformer architecture (not required if passing in an \\\n",
    "        # instance of `BatchTokenizeTransform` to `before_batch_tfm`)\n",
    "        hf_arch: str = None,\n",
    "        # A Hugging Face configuration object (not required if passing in an  \\\n",
    "        # instance of `BatchTokenizeTransform` to `before_batch_tfm`)\n",
    "        hf_config: PretrainedConfig = None,\n",
    "        # A Hugging Face model (not required if passing in an instance of `BatchTokenizeTransform` to `before_batch_tfm`)\n",
    "        hf_model: PreTrainedModel = None,\n",
    "        # An instance of `TextCollatorWithPadding` or equivalent (defaults to `BlurrBatchCreator`)\n",
    "        text_collator: TextCollatorWithPadding = None,\n",
    "        # The batch_tfm used to decode Blurr batches (defaults to `BatchDecodeTransform`)\n",
    "        batch_decode_tfm: BatchDecodeTransform = None,\n",
    "        # Used by typedispatched show methods\n",
    "        input_return_type: type = TextInput,\n",
    "        # Keyword arguments to be applied to your `batch_decode_tfm`\n",
    "        batch_decode_kwargs: dict = {},\n",
    "        # Keyword arguments to be applied to `BlurrDataLoader`\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # define what happens when a batch is created (e.g., this is where collation happens)\n",
    "        if \"create_batch\" in kwargs:\n",
    "            kwargs.pop(\"create_batch\")\n",
    "        if not text_collator:\n",
    "            text_collator = TextCollatorWithPadding(hf_tokenizer, hf_arch, hf_config, hf_model)\n",
    "\n",
    "        # define the transform applied after the batch is created (used of show methods)\n",
    "        if \"after_batch\" in kwargs:\n",
    "            kwargs.pop(\"after_batch\")\n",
    "        if not batch_decode_tfm:\n",
    "            batch_decode_tfm = BatchDecodeTransform(\n",
    "                hf_tokenizer,\n",
    "                hf_arch,\n",
    "                hf_config,\n",
    "                hf_model,\n",
    "                input_return_type,\n",
    "                **batch_decode_kwargs.copy(),\n",
    "            )\n",
    "\n",
    "        super().__init__(\n",
    "            dataset=dataset,\n",
    "            create_batch=text_collator,\n",
    "            after_batch=batch_decode_tfm,\n",
    "            **kwargs,\n",
    "        )\n",
    "        store_attr()\n",
    "\n",
    "    def new(\n",
    "        self,\n",
    "        # A standard PyTorch and fastai dataset\n",
    "        dataset: Union[torch.utils.data.dataset.Dataset, Datasets] = None,\n",
    "        # The class you want to create an instance of (will be \"self\" if None)\n",
    "        cls: type = None,\n",
    "        #  Any additional keyword arguments you want to pass to the __init__ method of `cls`\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        We have to override the new method in order to add back the Hugging Face objects in this factory\n",
    "        method (called for example in places like `show_results`). With the exception of the additions to the kwargs\n",
    "        dictionary, the code below is pulled from the `DataLoaders.new` method as is.\n",
    "        \"\"\"\n",
    "        # we need to add these arguments back in (these, after_batch, and create_batch will go in as kwargs)\n",
    "        kwargs[\"hf_arch\"] = self.hf_arch\n",
    "        kwargs[\"hf_config\"] = self.hf_config\n",
    "        kwargs[\"hf_tokenizer\"] = self.hf_tokenizer\n",
    "        kwargs[\"hf_model\"] = self.hf_model\n",
    "\n",
    "        kwargs[\"text_collator\"] = self.text_collator\n",
    "        kwargs[\"batch_decode_tfm\"] = self.batch_decode_tfm\n",
    "        kwargs[\"batch_decode_kwargs\"] = self.batch_decode_kwargs\n",
    "\n",
    "        return super().new(dataset, cls, **kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sorted_dl_func` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def sorted_dl_func(\n",
    "    example,\n",
    "    # A Hugging Face tokenizer\n",
    "    hf_tokenizer: PreTrainedTokenizerBase,\n",
    "    # The `is_split_into_words` argument applied to your `hf_tokenizer` during tokenization. \\\n",
    "    # Set this to 'True' if your inputs are pre-tokenized (not numericalized)\n",
    "    is_split_into_words: bool = False,\n",
    "    # Any other keyword arguments you want to include during tokenization\n",
    "    tok_kwargs: dict = {},\n",
    "):\n",
    "    \"\"\"This method is used by the `SortedDL` to ensure your dataset is sorted *after* tokenization\"\"\"\n",
    "    txt = None\n",
    "    if isinstance(example[0], dict):\n",
    "        if \"input_ids\" in example[0]:\n",
    "            # if inputs are pretokenized\n",
    "            return len(example[0][\"input_ids\"])\n",
    "        else:\n",
    "            txt = example[0][\"text\"]\n",
    "    else:\n",
    "        txt = example[0]\n",
    "\n",
    "    return len(txt) if is_split_into_words else len(hf_tokenizer.tokenize(txt, **tok_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/ohmeow/blurr/blob/dev-3.0.0 #master/blurr/text/data/core.py#L379){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sorted_dl_func\n",
       "\n",
       ">      sorted_dl_func (example, hf_tokenizer:transformers.tokenization_utils_bas\n",
       ">                      e.PreTrainedTokenizerBase,\n",
       ">                      is_split_into_words:bool=False, tok_kwargs:dict={})\n",
       "\n",
       "This method is used by the `SortedDL` to ensure your dataset is sorted *after* tokenization\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| example |  |  |  |\n",
       "| hf_tokenizer | PreTrainedTokenizerBase |  | A Hugging Face tokenizer |\n",
       "| is_split_into_words | bool | False | The `is_split_into_words` argument applied to your `hf_tokenizer` during tokenization. \\<br>Set this to 'True' if your inputs are pre-tokenized (not numericalized) |\n",
       "| tok_kwargs | dict | {} | Any other keyword arguments you want to include during tokenization |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/ohmeow/blurr/blob/dev-3.0.0 #master/blurr/text/data/core.py#L379){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sorted_dl_func\n",
       "\n",
       ">      sorted_dl_func (example, hf_tokenizer:transformers.tokenization_utils_bas\n",
       ">                      e.PreTrainedTokenizerBase,\n",
       ">                      is_split_into_words:bool=False, tok_kwargs:dict={})\n",
       "\n",
       "This method is used by the `SortedDL` to ensure your dataset is sorted *after* tokenization\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| example |  |  |  |\n",
       "| hf_tokenizer | PreTrainedTokenizerBase |  | A Hugging Face tokenizer |\n",
       "| is_split_into_words | bool | False | The `is_split_into_words` argument applied to your `hf_tokenizer` during tokenization. \\<br>Set this to 'True' if your inputs are pre-tokenized (not numericalized) |\n",
       "| tok_kwargs | dict | {} | Any other keyword arguments you want to include during tokenization |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbdev.show_doc(sorted_dl_func, title_level=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-Level API: Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using fast.ai `Datasets` and `DataLoaders`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t2\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", labels, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: `Datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ab64f77b3d42b9b26ecb9ba0dca9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the dataset\n",
    "def tokenize_func(example):\n",
    "    return hf_tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "proc_imdb_ds = imdb_ds.map(tokenize_func, batched=True)\n",
    "proc_imdb_ds.set_format(\"torch\", columns=hf_tokenizer.model_input_names + [\"label\"])\n",
    "\n",
    "# turn Arrow into DataFrame (`ColSplitter` only works with `DataFrame`s)\n",
    "train_df = pd.DataFrame(proc_imdb_ds)\n",
    "train_df.head()\n",
    "\n",
    "# define dataset splitter\n",
    "splitter = ColSplitter(\"is_valid\")\n",
    "splits = splitter(imdb_df)\n",
    "\n",
    "\n",
    "# define how we want to build our inputs and targets\n",
    "def _build_inputs(example):\n",
    "    return {fwd_arg_name: example[fwd_arg_name] for fwd_arg_name in hf_tokenizer.model_input_names if fwd_arg_name in list(example.keys())}\n",
    "\n",
    "\n",
    "def _build_targets(example):\n",
    "    return example[\"label\"]\n",
    "\n",
    "\n",
    "# create our fastai `Datasets` object\n",
    "dsets = Datasets(items=train_df, splits=splits, tfms=[[_build_inputs], _build_targets], n_inp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in train|validation datasets:  1000 200\n",
      "Items in each example: 2\n",
      "Example inputs: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Example target(s): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Items in train|validation datasets: \", len(dsets.train), len(dsets.valid))\n",
    "\n",
    "example = dsets.valid[0]\n",
    "# example\n",
    "\n",
    "print(f\"Items in each example: {len(example)}\")\n",
    "print(f\"Example inputs: {list(example[0].keys())}\")\n",
    "print(f\"Example target(s): {example[1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = TextCollatorWithPadding(hf_tokenizer)\n",
    "sort_func = partial(sorted_dl_func, hf_tokenizer=hf_tokenizer)\n",
    "\n",
    "dls = dsets.dataloaders(\n",
    "    batch_size=4,\n",
    "    create_batch=data_collator,\n",
    "    dl_type=partial(SortedDL, sort_func=sort_func),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 50\n",
      "2\n",
      "\n",
      "[CLS] I felt duty bound to watch the 1983 Timothy Dalton / Zelah Clarke adaptation of \"Jane Eyre,\" because I'd just written an article about the 2006 BBC \"Jane Eyre\" for TheScreamOnline.<br /><br />So, I approached watching this the way I'd approach doing homework.<br /><br />I was irritated at first. The lighting in this version is bad. Everyone / everything is washed out in a bright white klieg light that, in some scenes, casts shadows on the wall behind the characters.<br /><br />And the sound is poorly recorded. I felt like I was listening to a high school play.<br /><br />And the pancake make-up is way too heavy.<br /><br />And the sets don't fully convey the Gothic mood of the novel. They are too fussy, too Martha Stewart. I just can'\n",
      "\n",
      "tensor([1, 1, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(len(dls.train), len(dls.valid))\n",
    "\n",
    "b = next(iter(dls.train))\n",
    "print(len(b))\n",
    "print(\"\")\n",
    "print(hf_tokenizer.decode(b[0][\"input_ids\"][0][:200]))\n",
    "print(\"\")\n",
    "print(b[1])\n",
    "\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t7\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", civil_labels, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: `Datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2687f37acd43d4a6128b8e2cbd176e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the dataset\n",
    "def tokenize_func(example):\n",
    "    updated_example = dict(hf_tokenizer(example[\"text\"], truncation=True))\n",
    "    labels = torch.stack([tensor(example[lbl]) for lbl in civil_labels], dim=-1)\n",
    "    updated_example[\"label\"] = labels\n",
    "\n",
    "    return updated_example\n",
    "\n",
    "\n",
    "proc_civil_ds = civil_ds.map(tokenize_func, batched=True)\n",
    "proc_civil_ds.set_format(\"torch\", columns=hf_tokenizer.model_input_names + [\"label\"])\n",
    "\n",
    "# turn Arrow into DataFrame (`ColSplitter` only works with `DataFrame`s)\n",
    "train_df = pd.DataFrame(proc_civil_ds)\n",
    "train_df.head()\n",
    "\n",
    "# define dataset splitter\n",
    "splitter = ColSplitter(\"is_valid\")\n",
    "splits = splitter(civil_df)\n",
    "\n",
    "\n",
    "# define how we want to build our inputs and targets\n",
    "def _build_inputs(example):\n",
    "    return {fwd_arg_name: example[fwd_arg_name] for fwd_arg_name in hf_tokenizer.model_input_names if fwd_arg_name in list(example.keys())}\n",
    "\n",
    "\n",
    "def _build_targets(example):\n",
    "    return example[\"label\"]\n",
    "\n",
    "\n",
    "# create our fastai `Datasets` object\n",
    "dsets = Datasets(items=train_df, splits=splits, tfms=[[_build_inputs], _build_targets], n_inp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in train|validation datasets:  1000 200\n",
      "Items in each example: 2\n",
      "Example inputs: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Example target(s): tensor([0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(\"Items in train|validation datasets: \", len(dsets.train), len(dsets.valid))\n",
    "\n",
    "example = dsets.valid[0]\n",
    "# example\n",
    "\n",
    "print(f\"Items in each example: {len(example)}\")\n",
    "print(f\"Example inputs: {list(example[0].keys())}\")\n",
    "print(f\"Example target(s): {example[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = TextCollatorWithPadding(hf_tokenizer)\n",
    "sort_func = partial(sorted_dl_func, hf_tokenizer=hf_tokenizer)\n",
    "dls = dsets.dataloaders(\n",
    "    batch_size=4,\n",
    "    create_batch=data_collator,\n",
    "    dl_type=partial(SortedDL, sort_func=sort_func),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 50\n",
      "2\n",
      "\n",
      "[CLS] \"Brass In Pocket\" By The Pretenders (really) Got brass in pocket Got bottle, I'm gonna use it Intention, I feel inventive Gonna make you, make you, make you notice Got motion, restrained emotion Been driving Detroit leaning No reason, just seems so pleasing Gonna make you, make you, make you notice Gonna use my arms Gonna use my legs Gonna use my style Gonna use my side step Gonna use my fingers Gonna use my, my, my imagination 'Cause I gonna make you see There's nobody else here No one like me I'm special so special I gotta have some of your attention give it to me Got rhythm I can't miss a beat Got new skank it's so reet Got something I'm winking at you Gonna make you, make you, make you notice 'Cause I gonna make you see There's nobody else here No one like me I'm special, so special I gotta have some of your attention Give it to\n",
      "\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(len(dls.train), len(dls.valid))\n",
    "\n",
    "b = next(iter(dls.train))\n",
    "print(len(b))\n",
    "print(\"\")\n",
    "print(hf_tokenizer.decode(b[0][\"input_ids\"][0][:200]))\n",
    "print(\"\")\n",
    "print(b[1])\n",
    "\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `BatchDecodeTransform` and `TextDataLoader`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t2\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", labels, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: `Dataset`s\n",
    "\n",
    "We'll use the Hugging Face `Dataset` objects created in *Setup*, but these could just as well be instances of `torch.utils.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-63830ebfef2f9de8.arrow\n"
     ]
    }
   ],
   "source": [
    "# tokenize the dataset\n",
    "def tokenize_func(example):\n",
    "    return hf_tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "proc_imdb_ds = imdb_ds.map(tokenize_func, batched=True)\n",
    "# proc_imdb_ds.set_format(\"torch\", columns=hf_tokenizer.model_input_names + [\"label\"])\n",
    "\n",
    "\n",
    "# define dataset splitter\n",
    "def _split_func(example):\n",
    "    return example[\"is_valid\"] == True\n",
    "\n",
    "\n",
    "splitter = FuncSplitter(_split_func)\n",
    "splits = splitter(proc_imdb_ds)\n",
    "\n",
    "\n",
    "# define how we want to build our inputs and targets\n",
    "def _build_inputs(example):\n",
    "    return {fwd_arg_name: example[fwd_arg_name] for fwd_arg_name in hf_tokenizer.model_input_names if fwd_arg_name in list(example.keys())}\n",
    "\n",
    "\n",
    "def _build_targets(example):\n",
    "    return example[\"label\"]\n",
    "\n",
    "\n",
    "# create our fastai `Datasets` object\n",
    "dsets = Datasets(items=proc_imdb_ds, splits=splits, tfms=[[_build_inputs], _build_targets], n_inp=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = train_ds.features[\"label\"].names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "trn_dl = TextDataLoader(\n",
    "    dsets.train,\n",
    "    hf_tokenizer,\n",
    "    batch_decode_kwargs={\"labels\": label_names},\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_dl = TextDataLoader(\n",
    "    dsets.valid,\n",
    "    hf_tokenizer,\n",
    "    batch_decode_kwargs={\"labels\": label_names},\n",
    "    batch_size=batch_size * 2,\n",
    ")\n",
    "\n",
    "dls = DataLoaders(trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 25\n",
      "2\n",
      "\n",
      "[CLS] But it does have some good action and a plot that is somewhat interesting. Nevsky acts like a body builder and he isn't all that attractive, in fact, IMO, he is UGLY. ( his acting skills lack everything! ) Sascha is played very well by Joanna Pacula, but she needed more lines than she was given, her character needed to be developed. There are way too many men in this story, there is zero romance, too much action, and way too dumb of an ending. It is very violent. I did however love the scenery, this movie takes you all over the world, and that is a bonus. I also liked how it had some stuff about the mafia in it, not too much or too little, but enough that it got my attention. The actors needed to be more handsome...The biggest problem I had was that Nevsky was just too normal, not sexy enough. I think for most guys, Sascha will be hot enough,\n",
      "\n",
      "tensor([0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(len(dls.train), len(dls.valid))\n",
    "\n",
    "b = dls.train.one_batch()\n",
    "print(len(b))\n",
    "print(\"\")\n",
    "print(hf_tokenizer.decode(b[0][\"input_ids\"][0][:200]))\n",
    "print(\"\")\n",
    "print(b[1])\n",
    "\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A young girl surviving as a prostitute.&lt;br /&gt;&lt;br /&gt;A cheap hustler who wants to get the big score.&lt;br /&gt;&lt;br /&gt;They meet each other in Thailand. You may think by the opening titles it's going to be a violent movie but it is also a story of love with two persons in their own struggle to get the money for a better way of life. This film feels like an essay sometimes because of its changes of images, but still refreshing. This story is also about Eros and Thanatos. \"It's not an original joke but it is well told\" says a character and that also applies to this one: We've seen the story but this way we see it. Thailand appears in hot tones, the photograph going from one colored to a multicolored place. And it captures the city as the cage of this imperfect persons. There is also a good use of the</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This film is mesmerizing in its beauty and creativity. An artist's profound vision, his art that springs intuitively from its natural source brings us an inspiring Hosanna, blending his creations with trees, white water dashing against rocks, fields and rain...Andy Goldsworthy makes the viewer feel joy in being alive, aware that we are all made of the clay of this glorious earth. He doesn't spare us his occasional frustration, but on the whole we see the miracle in joining art with nature. Credit also goes of course to the filmmaker, Thomas Riedelsheimer, who directed, photographed and edited the movie with incredible sensibility and perfect timing.&lt;br /&gt;&lt;br /&gt;If you have any feeling for beauty, nature and art...do not miss this fantastic film!</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t7\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", civil_labels, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: `Dataset`s\n",
    "\n",
    "We'll use the Hugging Face `Dataset` objects created in *Setup*, but these could just as well be instances of `torch.utils.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab/cache-0f2b47a24c3c8441.arrow\n"
     ]
    }
   ],
   "source": [
    "# tokenize the dataset\n",
    "def tokenize_func(example):\n",
    "    updated_example = dict(hf_tokenizer(example[\"text\"], truncation=True))\n",
    "    labels = torch.stack([tensor(example[lbl]) for lbl in civil_labels], dim=-1)\n",
    "    updated_example[\"label\"] = labels\n",
    "\n",
    "    return updated_example\n",
    "\n",
    "\n",
    "proc_civil_ds = civil_ds.map(tokenize_func, batched=True)\n",
    "# proc_imdb_ds.set_format(\"torch\", columns=hf_tokenizer.model_input_names + [\"label\"])\n",
    "\n",
    "\n",
    "# define dataset splitter\n",
    "def _split_func(example):\n",
    "    return example[\"is_valid\"] == True\n",
    "\n",
    "\n",
    "splitter = FuncSplitter(_split_func)\n",
    "splits = splitter(proc_civil_ds)\n",
    "\n",
    "\n",
    "# define how we want to build our inputs and targets\n",
    "def _build_inputs(example):\n",
    "    return {fwd_arg_name: example[fwd_arg_name] for fwd_arg_name in hf_tokenizer.model_input_names if fwd_arg_name in list(example.keys())}\n",
    "\n",
    "\n",
    "def _build_targets(example):\n",
    "    return example[\"label\"]\n",
    "\n",
    "\n",
    "# create our fastai `Datasets` object\n",
    "dsets = Datasets(items=proc_civil_ds, splits=splits, tfms=[[_build_inputs], _build_targets], n_inp=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "trn_dl = TextDataLoader(\n",
    "    dsets.train,\n",
    "    hf_tokenizer,\n",
    "    batch_decode_kwargs={\"labels\": civil_labels},\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_dl = TextDataLoader(\n",
    "    dsets.valid,\n",
    "    hf_tokenizer,\n",
    "    batch_decode_kwargs={\"labels\": civil_labels},\n",
    "    batch_size=batch_size * 2,\n",
    ")\n",
    "\n",
    "dls = DataLoaders(trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 25\n",
      "2\n",
      "\n",
      "[CLS] 1 termer Cory Gardner. He sat that at the Koch retreat eating fine steak and caviar, listening to how much money would be sent to him if he doesn't listen to the voters.[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(len(dls.train), len(dls.valid))\n",
    "\n",
    "b = dls.train.one_batch()\n",
    "print(len(b))\n",
    "print(\"\")\n",
    "print(hf_tokenizer.decode(b[0][\"input_ids\"][0][:200]))\n",
    "print(\"\")\n",
    "print(b[1])\n",
    "\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm sorry, Mike. Until you correct the ones calling others names, the ones attempting to bully with sarcasm, untruth, downright lies, the ones who merely put down those with whom they disagree...and hide behind smiley faces - you don't really have the right to try to correct me. Nor can I help that others perceive my disagreement with them as offensive. It is amazing, is it not, that there are those with whom pleasant conversation between me and them is not only possible, but typical - even though disagreeing. If you \"perceive\" something else - perhaps try reading the comments I am responding to. Now. This conversation? I said nothing offensive. All I did was point out an inconvenient truth concerning semantics and a concerted effort to demonize pro-life people. You did not address that at all.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Don227, maybe you need to think his comment through a little more thoroughly. Bears tend to avoid cities and places where people are - thus the reason for the low incidence of bear attacks. If a bear _is_ in the city, the odds of an attack go up drastically. The police acted properly. Wild animals are unpredictable. The police couldn't simply ignore the animal and hope no one was hurt.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is great news! So much for the pot heads and their supporters saying pot doesn't affect one's thinking. The court says anyone with a pot card can't own a gun or ammo. Who say's there's only bad news in the paper? The funny part is many got pot cards just to get around pot laws. Now it's come back to bite them big time!</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Same-sex marriages are legal in Canada. Any data on women sexually assaulting other women?</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-Level API\n",
    "\n",
    "BLURR's mid-level API provides a way to build your `DataLoaders` using fast.ai's mid-level `DataBlock` API.  \n",
    "\n",
    "BLURR supports three ways of doing this in the mid-level API: \n",
    "\n",
    "1. Using pre-tokenized data (the traditional approach)\n",
    "\n",
    "2. batch-time tokenization (the default approach in previous versions of blurr)\n",
    "\n",
    "2. item-time tokenization (e.g., to apply tokenization on individual items as they are pulled from their respective `Dataset`)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BatchTokenizeTransform` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class BatchTokenizeTransform(Transform):\n",
    "    \"\"\"\n",
    "    Handles everything you need to assemble a mini-batch of inputs and targets, as well as\n",
    "    decode the dictionary produced as a byproduct of the tokenization process in the `encodes` method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # The abbreviation/name of your Hugging Face transformer architecture (e.b., bert, bart, etc..)\n",
    "        hf_arch: str,\n",
    "        # A specific configuration instance you want to use\n",
    "        hf_config: PretrainedConfig,\n",
    "        # A Hugging Face tokenizer\n",
    "        hf_tokenizer: PreTrainedTokenizerBase,\n",
    "        # A Hugging Face model\n",
    "        hf_model: PreTrainedModel,\n",
    "        # To control whether the \"labels\" are included in your inputs. If they are, the loss will be calculated in \\\n",
    "        # the model's forward function and you can simply use `PreCalculatedLoss` as your `Learner`'s loss function to use it\n",
    "        include_labels: bool = True,\n",
    "        # The token ID that should be ignored when calculating the loss\n",
    "        ignore_token_id: int = CrossEntropyLossFlat().ignore_index,\n",
    "        # To control the length of the padding/truncation. It can be an integer or None, \\\n",
    "        # in which case it will default to the maximum length the model can accept. \\\n",
    "        # If the model has no specific maximum input length, truncation/padding to max_length is deactivated. \\\n",
    "        # See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)\n",
    "        max_length: int = None,\n",
    "        # To control the `padding` applied to your `hf_tokenizer` during tokenization. \\\n",
    "        # If None, will default to 'False' or 'do_not_pad'. \\\n",
    "        # See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)\n",
    "        padding: bool | str = True,\n",
    "        # To control `truncation` applied to your `hf_tokenizer` during tokenization. \\\n",
    "        # If None, will default to 'False' or 'do_not_truncate'. \\\n",
    "        # See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation)\n",
    "        truncation: bool | str = True,\n",
    "        # The `is_split_into_words` argument applied to your `hf_tokenizer` during tokenization. \\\n",
    "        # Set this to 'True' if your inputs are pre-tokenized (not numericalized) \\\n",
    "        is_split_into_words: bool = False,\n",
    "        # Any other keyword arguments you want included when using your `hf_tokenizer` to tokenize your inputs\n",
    "        tok_kwargs: dict = {},\n",
    "        # Keyword arguments to apply to `BatchTokenizeTransform`\n",
    "        **kwargs,\n",
    "    ):\n",
    "        store_attr()\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def encodes(self, samples, return_batch_encoding=False):\n",
    "        \"\"\"\n",
    "        This method peforms on-the-fly, batch-time tokenization of your data. In other words, your raw inputs\n",
    "        are tokenized as needed for each mini-batch of data rather than requiring pre-tokenization of your full\n",
    "        dataset ahead of time.\n",
    "        \"\"\"\n",
    "        samples = L(samples)\n",
    "\n",
    "        # grab inputs\n",
    "        is_dict = isinstance(samples[0][0], dict)\n",
    "        test_inp = samples[0][0][\"text\"] if is_dict else samples[0][0]\n",
    "\n",
    "        if is_listy(test_inp) and not self.is_split_into_words:\n",
    "            if is_dict:\n",
    "                inps = [(item[\"text\"][0], item[\"text\"][1]) for item in samples.itemgot(0).items]\n",
    "            else:\n",
    "                inps = list(zip(samples.itemgot(0, 0), samples.itemgot(0, 1)))\n",
    "        else:\n",
    "            inps = [item[\"text\"] for item in samples.itemgot(0).items] if is_dict else samples.itemgot(0).items\n",
    "\n",
    "        inputs = self.hf_tokenizer(\n",
    "            inps,\n",
    "            max_length=self.max_length,\n",
    "            padding=self.padding,\n",
    "            truncation=self.truncation,\n",
    "            is_split_into_words=self.is_split_into_words,\n",
    "            return_tensors=\"pt\",\n",
    "            **self.tok_kwargs,\n",
    "        )\n",
    "\n",
    "        d_keys = inputs.keys()\n",
    "\n",
    "        # update the samples with tokenized inputs (e.g. input_ids, attention_mask, etc...), as well as extra information\n",
    "        # if the inputs is a dictionary.\n",
    "        # (< 2.0.0): updated_samples = [(*[{k: inputs[k][idx] for k in d_keys}], *sample[1:]) for idx, sample in enumerate(samples)]\n",
    "        updated_samples = []\n",
    "        for idx, sample in enumerate(samples):\n",
    "            inps = {k: inputs[k][idx] for k in d_keys}\n",
    "            if is_dict:\n",
    "                inps = {\n",
    "                    **inps,\n",
    "                    **{k: v for k, v in sample[0].items() if k not in [\"text\"]},\n",
    "                }\n",
    "\n",
    "            trgs = sample[1:]\n",
    "            if self.include_labels and len(trgs) > 0:\n",
    "                inps[\"labels\"] = trgs[0]\n",
    "\n",
    "            updated_samples.append((*[inps], *trgs))\n",
    "\n",
    "        if return_batch_encoding:\n",
    "            return updated_samples, inputs\n",
    "\n",
    "        return updated_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by this [article](https://docs.fast.ai/tutorial.transformers.html), `BatchTokenizeTransform` inputs can come in as raw **text**, **a list of words** (e.g., tasks like Named Entity Recognition (NER), where you want to predict the label of each token), or as a **dictionary** that includes extra information you want to use during post-processing.\n",
    "\n",
    "**On-the-fly Batch-Time Tokenization**: \n",
    "\n",
    "Part of the inspiration for this derives from the mechanics of Hugging Face tokenizers, in particular it can return a collated mini-batch of data given a list of sequences. As such, the collating required for our inputs can be done during tokenization ***before*** our batch transforms run in a `before_batch_tfms` transform (where we get a list of examples)! This allows users of BLURR to have everything done dynamically at batch-time without prior preprocessing with at least four potential benefits:\n",
    "1. Less code\n",
    "2. Faster mini-batch creation\n",
    "3. Less RAM utilization and time spent tokenizing beforehand (this really helps with very large datasets)\n",
    "4. Flexibility"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ItemTokenizeTransform` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class ItemTokenizeTransform(ItemTransform):\n",
    "    split_idx = None\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # A Hugging Face configuration object\n",
    "        hf_config: PretrainedConfig = None,\n",
    "        # A Hugging Face tokenizer\n",
    "        hf_tokenizer: PreTrainedTokenizerBase = None,\n",
    "        # Any keyword arguments you want your Hugging Face tokenizer to use during tokenization\n",
    "        tok_kwargs: dict = {},\n",
    "        # Any keyword arguments you want applied to `ItemTokenizeTransform`\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        store_attr()\n",
    "\n",
    "        if tok_kwargs.get(\"truncation\", None) is None:\n",
    "            tok_kwargs[\"truncation\"] = True\n",
    "        if tok_kwargs.get(\"max_length\", None) is None:\n",
    "            tok_kwargs[\"max_length\"] = True\n",
    "\n",
    "    def encodes(self, txt, **kwargs):\n",
    "        inputs = self.hf_tokenizer(txt, **self.tok_kwargs)\n",
    "        return dict(inputs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TextBlock` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "class TextBlock(TransformBlock):\n",
    "    \"\"\"The core `TransformBlock` to prepare your inputs for training in Blurr with fastai's `DataBlock` API\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # The abbreviation/name of your Hugging Face transformer architecture (not required if passing in an \\\n",
    "        # instance of `BatchTokenizeTransform` to `before_batch_tfm`)\n",
    "        hf_arch: str = None,\n",
    "        # A Hugging Face configuration object (not required if passing in an \\\n",
    "        # instance of `BatchTokenizeTransform` to `before_batch_tfm`)\n",
    "        hf_config: PretrainedConfig = None,\n",
    "        # A Hugging Face tokenizer (not required if passing in an \\\n",
    "        # instance of `BatchTokenizeTransform` to `before_batch_tfm`)\n",
    "        hf_tokenizer: PreTrainedTokenizerBase = None,\n",
    "        # A Hugging Face model (not required if passing in an \\\n",
    "        # instance of `BatchTokenizeTransform` to `before_batch_tfm`)\n",
    "        hf_model: PreTrainedModel = None,\n",
    "        # Any transforms to apply when getting an item from a dataset (useufl for item-time tokenization)\n",
    "        type_tfms: list[ItemTokenizeTransform] = None,\n",
    "        # The \"before_batch\" transform you want to use if tokenizing your raw data on the fly (optional)\n",
    "        tokenize_tfm: Transform = None,\n",
    "        # The batch_tfm you want to decode your inputs into a type that can be used in the fastai show methods, \\\n",
    "        # (defaults to BatchDecodeTransform)\n",
    "        batch_decode_tfm: BatchDecodeTransform = None,\n",
    "        # To control whether the \"labels\" are included in your inputs. If they are, the loss will be calculated in \\\n",
    "        # the model's forward function and you can simply use `PreCalculatedLoss` as your `Learner`'s loss function to use it\n",
    "        include_labels: bool = True,\n",
    "        # The `is_split_into_words` argument applied to your `hf_tokenizer` during tokenization. \\\n",
    "        # Set this to `True` if your inputs are pre-tokenized (not numericalized)\n",
    "        is_split_into_words: bool = False,\n",
    "        # The return type your decoded inputs should be cast too (used by methods such as `show_batch`)\n",
    "        input_return_type: type = TextInput,\n",
    "        # The type of `DataLoader` you want created (defaults to `SortedDL`)\n",
    "        dl_type: DataLoader = None,\n",
    "        # Any keyword arguments you want applied to your `batch_decode_tfm` (will be set as a fastai `batch_tfms`)\n",
    "        batch_decode_kwargs: dict = {},\n",
    "        # Any keyword arguments you want your Hugging Face tokenizer to use during tokenization\n",
    "        tok_kwargs: dict = {},\n",
    "        # Any keyword arguments you want to have applied with generating text\n",
    "        text_gen_kwargs: dict = {},\n",
    "        # Any keyword arguments you want applied to `TextBlock`\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if (not all([hf_arch, hf_config, hf_tokenizer, hf_model])) and tokenize_tfm is None:\n",
    "            raise ValueError(\"You must supply an hf_arch, hf_config, hf_tokenizer, hf_model -or- a tokenize_tfm\")\n",
    "\n",
    "        # if we are using a transform to tokenize our inputs, grab the HF objects from it\n",
    "        if tokenize_tfm is not None:\n",
    "            hf_arch = getattr(tokenize_tfm, \"hf_arch\", hf_arch)\n",
    "            hf_config = getattr(tokenize_tfm, \"hf_config\", hf_config)\n",
    "            hf_tokenizer = getattr(tokenize_tfm, \"hf_tokenizer\", hf_tokenizer)\n",
    "            hf_model = getattr(tokenize_tfm, \"hf_model\", hf_model)\n",
    "            is_split_into_words = getattr(tokenize_tfm, \"is_split_into_words\", is_split_into_words)\n",
    "            include_labels = getattr(tokenize_tfm, \"include_labels\", include_labels)\n",
    "\n",
    "        # configure our batch decode transform (used by show_batch/results methods)\n",
    "        if batch_decode_tfm is None:\n",
    "            batch_decode_tfm = BatchDecodeTransform(\n",
    "                hf_arch=hf_arch,\n",
    "                hf_config=hf_config,\n",
    "                hf_tokenizer=hf_tokenizer,\n",
    "                hf_model=hf_model,\n",
    "                input_return_type=input_return_type,\n",
    "                **batch_decode_kwargs.copy(),\n",
    "            )\n",
    "\n",
    "        # default to SortedDL using our custom sort function if no `dl_type` is specified\n",
    "        if dl_type is None:\n",
    "            dl_sort_func = partial(\n",
    "                sorted_dl_func, hf_tokenizer=hf_tokenizer, is_split_into_words=is_split_into_words, tok_kwargs=tok_kwargs.copy()\n",
    "            )\n",
    "            dl_type = partial(SortedDL, sort_func=dl_sort_func)\n",
    "\n",
    "        # build our custom `TransformBlock`\n",
    "        data_collator = TextCollatorWithPadding(hf_tokenizer)\n",
    "        dl_kwargs = {\"create_batch\": data_collator} if tokenize_tfm is None else {\"before_batch\": tokenize_tfm}\n",
    "        return super().__init__(dl_type=dl_type, dls_kwargs=dl_kwargs, type_tfms=type_tfms, batch_tfms=batch_decode_tfm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-Level API: Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretokenized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t2\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", labels, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Step 2: `DataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define DataBlock splitter\n",
    "def _split_func(example):\n",
    "    return example[\"is_valid\"] == True\n",
    "\n",
    "\n",
    "splitter = FuncSplitter(_split_func)\n",
    "\n",
    "\n",
    "# define how we want to build our targets\n",
    "# note: we don't need to define how to build our inputs because we're using an HF `Dataset` in this example\n",
    "def get_y(example):\n",
    "    return example[\"label\"]\n",
    "\n",
    "\n",
    "# define the DataBlock\n",
    "txt_block = TextBlock(\n",
    "    hf_arch=hf_arch, hf_config=hf_config, hf_tokenizer=hf_tokenizer, hf_model=hf_model, batch_decode_kwargs={\"labels\": label_names}\n",
    ")\n",
    "\n",
    "blocks = (txt_block, CategoryBlock)\n",
    "dblock = DataBlock(blocks=blocks, get_y=get_y, splitter=splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-63830ebfef2f9de8.arrow\n"
     ]
    }
   ],
   "source": [
    "# tokenize the HF dataset\n",
    "def tokenize_func(example):\n",
    "    return hf_tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "proc_imdb_ds = imdb_ds.map(tokenize_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(proc_imdb_ds, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, torch.Size([4, 1481]), 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), len(b[0][\"input_ids\"]), b[0][\"input_ids\"].shape, len(b[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the actual types represented by our batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I felt duty bound to watch the 1983 Timothy Dalton / Zelah Clarke adaptation of \"Jane Eyre,\" because I'd just written an article about the 2006 BBC \"Jane Eyre\" for TheScreamOnline.&lt;br /&gt;&lt;br /&gt;So, I approached watching this the way I'd approach doing homework.&lt;br /&gt;&lt;br /&gt;I was irritated at first. The lighting in this version is bad. Everyone / everything is washed out in a bright white klieg light that, in some scenes, casts shadows on the wall behind the characters.&lt;br /&gt;&lt;br /&gt;And the sound is p</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I waited until the 4th of July to write this because... well... because it just feels right to be doing it on this day.&lt;br /&gt;&lt;br /&gt;In 1924 D.W. Griffith needed a hit, he had not had a big one since ORPHANS OF THE STORM (1921). He'd been working steadily since then but his movies had been smaller in scope and had failed to hit the right chord with audiences. He was planning a film about Patrick Henry when he was contacted by members of the Daughters of the American Revolution (DAR) who asked if h</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t7\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# | output: false\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", civil_labels, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Step 2: `DataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define DataBlock splitter\n",
    "def _split_func(example):\n",
    "    return example[\"is_valid\"] == True\n",
    "\n",
    "\n",
    "splitter = FuncSplitter(_split_func)\n",
    "\n",
    "\n",
    "# define how we want to build our targets\n",
    "# note: we don't need to define how to build our inputs because we're using an HF `Dataset` in this example\n",
    "def get_y(example):\n",
    "    return example[\"label\"]\n",
    "\n",
    "\n",
    "# define the DataBlock\n",
    "txt_block = TextBlock(\n",
    "    hf_arch=hf_arch, hf_config=hf_config, hf_tokenizer=hf_tokenizer, hf_model=hf_model, batch_decode_kwargs={\"labels\": label_names}\n",
    ")\n",
    "\n",
    "blocks = (txt_block, MultiCategoryBlock(encoded=True, vocab=civil_labels))\n",
    "dblock = DataBlock(blocks=blocks, get_y=get_y, splitter=splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab/cache-0f2b47a24c3c8441.arrow\n"
     ]
    }
   ],
   "source": [
    "# tokenize the dataset\n",
    "def tokenize_func(example):\n",
    "    updated_example = dict(hf_tokenizer(example[\"text\"], truncation=True))\n",
    "    labels = torch.stack([tensor(example[lbl]) for lbl in civil_labels], dim=-1)\n",
    "    updated_example[\"label\"] = labels\n",
    "\n",
    "    return updated_example\n",
    "\n",
    "\n",
    "proc_civil_ds = civil_ds.map(tokenize_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(proc_civil_ds, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([4, 237]), torch.Size([4, 7]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), b[0][\"input_ids\"].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the actual types represented by our batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Brass In Pocket\" By The Pretenders (really) Got brass in pocket Got bottle, I'm gonna use it Intention, I feel inventive Gonna make you, make you, make you notice Got motion, restrained emotion Been driving Detroit leaning No reason, just seems so pleasing Gonna make you, make you, make you notice Gonna use my arms Gonna use my legs Gonna use my style Gonna use my side step Gonna use my fingers Gonna use my, my, my imagination 'Cause I gonna make you see There's nobody else here No one like me</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wrong, wrong, wrong and wrong. These results are a total disaster for the Dems. The old saying \"be careful of what you wish for\" applies 100%. All this does is set up the Dems and the Fake News for crushing disaster in 2018. Their hopes have been raised to unrealistic expectations which will be dashed. Consider: 1) Dems ran a corporate Clinton-approved \"Republican-light\" candidate. This will encourage them to run more of the same type of candidates in 2018 and 2020. This strategy did not work in</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch-Time Tokenization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t2\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# | output: false\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", labels, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Step 2: `DataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_tfm = BatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model)\n",
    "\n",
    "blocks = (\n",
    "    TextBlock(tokenize_tfm=tokenize_tfm, batch_decode_kwargs={\"labels\": label_names}),\n",
    "    CategoryBlock,\n",
    ")\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=ColReader(\"text\"),\n",
    "    get_y=ColReader(\"label\"),\n",
    "    splitter=ColSplitter(),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(imdb_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, torch.Size([4, 1481]), 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), len(b[0][\"input_ids\"]), b[0][\"input_ids\"].shape, len(b[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the actual types represented by our batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I felt duty bound to watch the 1983 Timothy Dalton / Zelah Clarke adaptation of \"Jane Eyre,\" because I'd just written an article about the 2006 BBC \"Jane Eyre\" for TheScreamOnline.&lt;br /&gt;&lt;br /&gt;So, I approached watching this the way I'd approach doing homework.&lt;br /&gt;&lt;br /&gt;I was irritated at first. The lighting in this version is bad. Everyone / everything is washed out in a bright white klieg light that, in some scenes, casts shadows on the wall behind the characters.&lt;br /&gt;&lt;br /&gt;And the sound is p</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MYRA BRECKINRIDGE is one of those rare films that established its place in film history immediately. Praise for the film was absolutely nonexistent, even from the people involved in making it. This film was loathed from day one. While every now and then one will come across some maverick who will praise the film on philosophical grounds (aggressive feminism or the courage to tackle the issue of transgenderism), the film has not developed a cult following like some notorious flops do. It's not ha</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t7\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# | output: false\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", civil_labels, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Step 2: `DataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_tfm = BatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model)\n",
    "\n",
    "blocks = (TextBlock(tokenize_tfm=tokenize_tfm), MultiCategoryBlock(encoded=True, vocab=civil_labels))\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(civil_labels), splitter=ColSplitter())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(civil_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([4, 237]), torch.Size([4, 7]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), b[0][\"input_ids\"].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the actual types represented by our batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Brass In Pocket\" By The Pretenders (really) Got brass in pocket Got bottle, I'm gonna use it Intention, I feel inventive Gonna make you, make you, make you notice Got motion, restrained emotion Been driving Detroit leaning No reason, just seems so pleasing Gonna make you, make you, make you notice Gonna use my arms Gonna use my legs Gonna use my style Gonna use my side step Gonna use my fingers Gonna use my, my, my imagination 'Cause I gonna make you see There's nobody else here No one like me</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't cherry-pick, Greenleaf. On my linked website which you hate so much, I've got a LOT of graphs that demonstrate that the alleged \"predictions\" from the sources you consider'reputable' have used... cherry-picked data, tossed out data that don't agree with their theses and beliefs and, \"to a man\" have NOT accurately forecast ANY of the temperature changes that the MainScream media and Warmites claim to be true. Yep, you can deny \"Deniers\" all you want, but the real scientific, REPEATABLE, U</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-Time Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t2\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# | output: false\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", labels, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Step 2: `DataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = ItemTokenizeTransform(hf_config=hf_config, hf_tokenizer=hf_tokenizer)\n",
    "tfm.split_idx = 0\n",
    "\n",
    "tfm2 = ItemTokenizeTransform(hf_config=hf_config, hf_tokenizer=hf_tokenizer)\n",
    "tfm2.split_idx = 1\n",
    "\n",
    "blocks = (\n",
    "    TextBlock(hf_arch=hf_arch, hf_config=hf_config, hf_tokenizer=hf_tokenizer, hf_model=hf_model, type_tfms=[tfm, tfm2]),\n",
    "    CategoryBlock,\n",
    ")\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=ColReader(\"text\"),\n",
    "    get_y=ColReader(\"label\"),\n",
    "    splitter=ColSplitter(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(imdb_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, torch.Size([4, 1481]), 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), len(b[0][\"input_ids\"]), b[0][\"input_ids\"].shape, len(b[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the actual types represented by our batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I felt duty bound to watch the 1983 Timothy Dalton / Zelah Clarke adaptation of \"Jane Eyre,\" because I'd just written an article about the 2006 BBC \"Jane Eyre\" for TheScreamOnline.&lt;br /&gt;&lt;br /&gt;So, I approached watching this the way I'd approach doing homework.&lt;br /&gt;&lt;br /&gt;I was irritated at first. The lighting in this version is bad. Everyone / everything is washed out in a bright white klieg light that, in some scenes, casts shadows on the wall behind the characters.&lt;br /&gt;&lt;br /&gt;And the sound is p</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WARNING: POSSIBLE SPOILERS (but not really - keep reading). Ahhh, there are so many reasons to become utterly addicted to this spoof gem that I won't have room to list them all. The opening credits set the playful scene with kitsch late 1950s cartoon stills; an enchanting Peres 'Prez' Prado mambo theme which appears to be curiously uncredited (but his grunts are unmistakable, and no-one else did them); and with familiar cast names, including Kathy Najimi a full year before she hit with Sister Ac</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: HF objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== config ===\n",
      "# of labels:\t7\n",
      "\n",
      "=== tokenizer ===\n",
      "Vocab size:\t\t128000\n",
      "Max # of tokens:\t1000000000000000019884624838656\n",
      "Attributes expected by model in forward pass:\t['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# | output: false\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_task_hf_objects(\"microsoft/deberta-v3-small\", civil_labels, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Step 2: `DataBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = ItemTokenizeTransform(hf_config=hf_config, hf_tokenizer=hf_tokenizer)\n",
    "tfm.split_idx = 0\n",
    "\n",
    "tfm2 = ItemTokenizeTransform(hf_config=hf_config, hf_tokenizer=hf_tokenizer)\n",
    "tfm2.split_idx = 1\n",
    "\n",
    "blocks = (\n",
    "    TextBlock(hf_arch=hf_arch, hf_config=hf_config, hf_tokenizer=hf_tokenizer, hf_model=hf_model, type_tfms=[tfm, tfm2]),\n",
    "    MultiCategoryBlock(encoded=True, vocab=civil_labels),\n",
    ")\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=ColReader(\"text\"),\n",
    "    get_y=ColReader(civil_labels),\n",
    "    splitter=ColSplitter(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(civil_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([4, 237]), torch.Size([4, 7]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "len(b), b[0][\"input_ids\"].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the actual types represented by our batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Brass In Pocket\" By The Pretenders (really) Got brass in pocket Got bottle, I'm gonna use it Intention, I feel inventive Gonna make you, make you, make you notice Got motion, restrained emotion Been driving Detroit leaning No reason, just seems so pleasing Gonna make you, make you, make you notice Gonna use my arms Gonna use my legs Gonna use my style Gonna use my side step Gonna use my fingers Gonna use my, my, my imagination 'Cause I gonna make you see There's nobody else here No one like me</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have a solution.....let all the younger Gen Y become fireman so they can enjoy the egregious benefits that is offered in this profession, including, 24 hr shifts X 7 days per month that include sleeping, eating on the taxpayer and watching the Leafs LOts of time to work for cash......I have actually reported on scoundrel working in the neighbourhood undercutting bonafide workers by 10 bucks an hour....just because he can as he makes over 100K in his parttime job. Benefits galore Why pay 100 an</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |echo:false\n",
    "try:\n",
    "    del dls, hf_model\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    clean_memory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the core DataBlock code above works for **all** pretrained sequence classification models available in Hugging Face.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained classification models you are working with ... and if any of your pretrained sequence classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
