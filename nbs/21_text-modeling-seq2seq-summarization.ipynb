{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp text.modeling.seq2seq.summarization\n",
    "# |default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | nbflags skip_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "> The `text.modeling.seq2seq.summarization` module contains custom models, custom splitters, etc... summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import inspect, torch, warnings\n",
    "from typing import Callable, Dict, List, Optional, Union\n",
    "\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import (\n",
    "    DataBlock,\n",
    "    ColReader,\n",
    "    ItemGetter,\n",
    "    ColSplitter,\n",
    "    RandomSplitter,\n",
    ")\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastcore.all import *\n",
    "from transformers import AutoModelForSeq2SeqLM, PreTrainedModel\n",
    "from transformers.utils import logging as hf_logging\n",
    "\n",
    "from blurr.text.data.seq2seq.core import (\n",
    "    Seq2SeqBatchTokenizeTransform,\n",
    "    Seq2SeqTextBlock,\n",
    "    default_text_gen_kwargs,\n",
    ")\n",
    "from blurr.text.modeling.core import BaseModelCallback, BaseModelWrapper, Blearner\n",
    "from blurr.text.modeling.seq2seq.core import (\n",
    "    Seq2SeqMetricsCallback,\n",
    "    blurr_seq2seq_splitter,\n",
    ")\n",
    "from blurr.text.utils import get_hf_objects\n",
    "from blurr.utils import PreCalculatedCrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.6.3\n",
      "transformers: 4.18.0\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "import ast, os, inspect, pdb\n",
    "from functools import reduce\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, ranger, OptimWrapper, params\n",
    "from fastcore.test import *\n",
    "from nbdev import nbdev_export\n",
    "from nbdev.showdoc import show_doc\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.text.utils import BlurrText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# silence all the HF warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "hf_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "NLP = BlurrText()\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "# |cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "The objective of summarization is to generate a concise and accurate representation of a much larger body of text.  For example, we may want to summarize an article in a single sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/wgilliam/.cache/huggingface/datasets/ccdv___cnn_dailymail/3.0.0/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...</td>\n",
       "      <td>Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .</td>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...</td>\n",
       "      <td>Usain Bolt wins third gold of world championship .\\nAnchors Jamaica to 4x100m relay victory .\\nEighth gold at the championships for Bolt .\\nJamaica double up in women's 4x100m relay .</td>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   article  \\\n",
       "0  It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...   \n",
       "1  (CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                  highlights  \\\n",
       "0  Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .   \n",
       "1                                                                                                                    Usain Bolt wins third gold of world championship .\\nAnchors Jamaica to 4x100m relay victory .\\nEighth gold at the championships for Bolt .\\nJamaica double up in women's 4x100m relay .   \n",
       "\n",
       "                                         id  \n",
       "0  0001d1afc246a7964130f43ae940af6bc6c57f01  \n",
       "1  0002095e55fcbd3a2f366d9bf92a95433dc305ef  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ccdv/cnn_dailymail\", \"3.0.0\", split=\"train[:1000]\")\n",
    "cnndm_df = pd.DataFrame(dataset)\n",
    "cnndm_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "\n",
    "# pretrained_model_name = \"t5-small\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name,\n",
    "#                                                                   model_cls=T5ForConditionalGeneration)\n",
    "\n",
    "# pretrained_model_name = \"google/pegasus-cnn_dailymail\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name,\n",
    "#                                                                   model_cls=PegasusForConditionalGeneration)\n",
    "\n",
    "# pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name,\n",
    "#                                                                   model_cls=BartForConditionalGeneration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/c457182dd3c47e71636dfe957c948acf12fd6b1d17d3e16a69f9bd731f340157.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
      "loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/1917cd1903f32920951797d984eff6fb9707c20aa7c0eba679d033d5d5dbc7d3.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/41a44e7ad55ba42aa9abd4697be8ff844b95c3f33ad59ceb5059b263caf581fe.67d01b18f2079bd75eac0b2f2e7235768c7f26bd728e7a855a1c5acae01a91a8\n",
      "loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/b3a80b0a1380627404ab7beeafae5a22d57a6caee6d637757be7b02319a26d37.a3aeae96c9bbfd0fad6832e6f41a23b7f17b292daca2c554b8064433b145e921\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-6-6.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('bart',\n",
       " transformers.models.bart.configuration_bart.BartConfig,\n",
       " transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,\n",
       " transformers.models.bart.modeling_bart.BartForConditionalGeneration)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"sshleifer/distilbart-cnn-6-6\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "    pretrained_model_name, model_cls=BartForConditionalGeneration\n",
    ")\n",
    "\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen_kwargs = {}\n",
    "if hf_arch in [\"bart\", \"t5\"]:\n",
    "    text_gen_kwargs = {\n",
    "        **hf_config.task_specific_params[\"summarization\"],\n",
    "        **{\"max_length\": 30, \"min_length\": 10},\n",
    "    }\n",
    "\n",
    "# not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "for k in text_gen_kwargs.copy():\n",
    "    if k not in generate_func_args:\n",
    "        del text_gen_kwargs[k]\n",
    "\n",
    "if hf_arch == \"mbart\":\n",
    "    text_gen_kwargs[\"decoder_start_token_id\"] = hf_tokenizer.get_vocab()[\"en_XX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_kwargs = {}\n",
    "if hf_arch == \"mbart\":\n",
    "    tok_kwargs[\"src_lang\"], tok_kwargs[\"tgt_lang\"] = \"en_XX\", \"en_XX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "    hf_arch,\n",
    "    hf_config,\n",
    "    hf_tokenizer,\n",
    "    hf_model,\n",
    "    max_length=256,\n",
    "    max_target_length=130,\n",
    "    tok_kwargs=tok_kwargs,\n",
    "    text_gen_kwargs=text_gen_kwargs,\n",
    ")\n",
    "\n",
    "blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=ColReader(\"article\"),\n",
    "    get_y=ColReader(\"highlights\"),\n",
    "    splitter=RandomSplitter(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(cnndm_df, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 256]), torch.Size([2, 75]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0][\"input_ids\"].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; (CNN) -- When Ji Yeqing awakened, she was already in the recovery room. Chinese authorities had dragged her out of her home and down four flights of stairs, she said, restraining and beating her husband as he tried to come to her aid. They whisked her into a clinic, held her down on a bed and forced her to undergo an abortion. Her offense? Becoming pregnant with a second child, in violation of China's one-child policy. \"After the abortion, I felt empty, as if something was scooped out of me,\" Ji told a congressional panel in September. \"My husband and I had been so excited for our new baby. Now suddenly all that hope and joy and excitement disappeared.... I was very depressed and despondent. For a long time, whenever I thought about my lost child, I would cry.\" As she lay unconscious, she said, an IUD to prevent future pregnancies was inserted. The issue of forced abortions -- and in some cases, forced sterilizations -- in China has seized the spotlight in recent days with news of escaped activist Chen Guangcheng. Chen, a blind, self-taught lawyer, rose to fame in the late 1990s because of his advocacy for what he calls victims&lt;/s&gt;</td>\n",
       "      <td>China's one-child policy results in forced abortions and sterilizations, activists say.\\nWomen tell of emotional and physical consequences from the procedures.\\nActivist Chen Guangcheng works to advocate for victims of such practices.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; (CNN) -- The generation of gays and lesbians that literally created the modern LGBT movement -- from the heroes of the 1969 Stonewall riots to their slightly younger friends -- is at, or nearing, retirement age. That used to mean the beginning of an extremely difficult time in an LGBT person's life. But as gay baby boomers find more acceptance in mainstream society and continue to do what they've always done -- push to make a better world for the LGBT community -- their retirement options are slowly improving. That is, if they decide to retire at all. \"The notion of retirement has never been a part of my vocabulary,\" said Bob Witeck, CEO and co-founder of Witeck Communications. Nearly 61, Witeck has put some thought into what he should do with his strategic public relations and marketing firm as he gets older. Like many friends his age who are also entrepreneurs, he plans to keep working. \"Because I run a business, as I get older I can change the intensity of my engagement in the kinds of work I take on,\" Witeck said. \"I know I'm lucky that way, and I'm lucky in my personal life as well. My husband is 50, so I have a younger man to help me&lt;/s&gt;</td>\n",
       "      <td>LGBT baby boomers changed the visibility of the gay community.\\nAs they approach retirement, they face different obstacles than their straight counterparts.\\nWithout marriage equality, same-sex couples may face financial hardships.\\nAdvocates say the situation is slowly improving.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_metrics = {\n",
    "    \"rouge\": {\n",
    "        \"compute_kwargs\": {\n",
    "            \"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "            \"use_stemmer\": True,\n",
    "        },\n",
    "        \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "    },\n",
    "    \"bertscore\": {\n",
    "        \"compute_kwargs\": {\"lang\": \"en\"},\n",
    "        \"returns\": [\"precision\", \"recall\", \"f1\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    cbs=learn_cbs,\n",
    "    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    ")\n",
    "\n",
    "# learn = learn.to_native_fp16() #.to_fp16()\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BaseModelWrapper (Input shape: 2 x 256)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     2 x 69 x 1024       \n",
       "Embedding                                 51470336   False     \n",
       "Embedding                                 51470336   False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1024            \n",
       "BartLearnedPositionalEmbedding                      1050624    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "GELUActivation                                                 \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "GELUActivation                                                 \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "GELUActivation                                                 \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "GELUActivation                                                 \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "GELUActivation                                                 \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "Linear                                    1049600    False     \n",
       "LayerNorm                                 2048       True      \n",
       "GELUActivation                                                 \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 4096      \n",
       "Linear                                    4198400    False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 256 x 1024      \n",
       "Linear                                    4195328    False     \n",
       "LayerNorm                                 2048       True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Embedding                                 51470336   False     \n",
       "____________________________________________________________________________\n",
       "                     2 x 1024            \n",
       "BartLearnedPositionalEmbedding                      1050624    False     \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "GELUActivation                                                 \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "GELUActivation                                                 \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "GELUActivation                                                 \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "GELUActivation                                                 \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "GELUActivation                                                 \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "GELUActivation                                                 \n",
       "LayerNorm                                 2048       True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "Linear                                    1049600    True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 4096       \n",
       "Linear                                    4198400    True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 1024       \n",
       "Linear                                    4195328    True      \n",
       "LayerNorm                                 2048       True      \n",
       "LayerNorm                                 2048       True      \n",
       "____________________________________________________________________________\n",
       "                     2 x 69 x 50264      \n",
       "Linear                                    51470336   False     \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 384,344,064\n",
       "Total trainable params: 100,808,704\n",
       "Total non-trainable params: 283,535,360\n",
       "\n",
       "Optimizer used: functools.partial(<function Adam>)\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - BaseModelCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | output: false\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([]), torch.Size([2, 59, 50264]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "\n",
    "len(preds), preds[\"loss\"].shape, preds[\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 256]), 2, torch.Size([2, 59]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0][\"input_ids\"].shape, len(b[1]), b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=4.786300996784121e-05, steep=6.309573450380412e-07, valley=6.30957365501672e-05, slide=1.4454397387453355e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.306568</td>\n",
       "      <td>2.146496</td>\n",
       "      <td>0.296782</td>\n",
       "      <td>0.124385</td>\n",
       "      <td>0.222347</td>\n",
       "      <td>0.275367</td>\n",
       "      <td>0.892347</td>\n",
       "      <td>0.865695</td>\n",
       "      <td>0.878717</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\n",
      "All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a `@typedispatch`ed implementation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN Student News) -- January 13, 2011. Download PDF maps related to today's show:. • Arizona • Australia. Transcript. THIS IS A RUSH TRANSCRIPT. THIS COPY MAY NOT BE IN ITS FINAL FORM AND MAY BE UPDATED. CARL AZUZ, CNN STUDENT NEWS ANCHOR: A problem that won't be solved, even if the solution is clear. The story and the reasons, leading off today's broadcast of CNN Student News! My name is Carl Azuz! First Up: Winter Storm Woes. AZUZ: Florida is the only state in the union without snow on the g</td>\n",
       "      <td>A winter storm slams the northeastern United States.\\nThe U.S. House of Representatives condemns the Arizona shooting.\\nMassive floods leave vast areas of Australia underwater.\\nUse the Daily Discussion to help students understand today's featured news</td>\n",
       "      <td>[ Find out how a storm system iced out the southeast . Use the Daily Discussion to help students understand today's featured news stories,  Jeb Bush and Mitt Romney are putting pressure on New Jersey Gov. Chris Christie .\\nBush has been a well-liked figure]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "We add here `Learner.blurr_summarize` method to bring the results inline with the format returned via Hugging Face's pipeline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': [\" 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the armed robbers' vehicles .\",\n",
       "   \" 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the robbers' vehicles .\",\n",
       "   \" 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\"]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(\n",
    "    test_article, key=\"summary_texts\", num_return_sequences=3\n",
    ")\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@patch\n",
    "def blurr_summarize(self: Learner, inp, **kwargs):\n",
    "    preds = self.blurr_generate(inp, key=\"summary_texts\", **kwargs)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': [\" 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the armed robbers' vehicles .\",\n",
       "   \" 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the robbers' vehicles .\",\n",
       "   \" 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\"]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_summarize(test_article, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Using fast.ai `Learner.export` and `load_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = \"summarize_export\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = None\n",
    "learn.export(fname=f\"{export_fname}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': ' 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_summarize(test_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BlearnerForSummarization` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForSummarization(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    def predict(self, text, **kwargs):\n",
    "        return self.blurr_summarize(text, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(cls):\n",
    "        return AutoModelForSeq2SeqLM\n",
    "\n",
    "    @classmethod\n",
    "    def _add_t5_prefix(cls, inp):\n",
    "        return f\"summarize: {inp}\"\n",
    "\n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        seq2seq_metrics = {\n",
    "            \"rouge\": {\n",
    "                \"compute_kwargs\": {\n",
    "                    \"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "                    \"use_stemmer\": True,\n",
    "                },\n",
    "                \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "            },\n",
    "            \"bertscore\": {\n",
    "                \"compute_kwargs\": {\"lang\": \"en\"},\n",
    "                \"returns\": [\"precision\", \"recall\", \"f1\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "        return Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(\n",
    "        cls,\n",
    "        # Your raw dataset. Supports DataFrames, Hugging Face Datasets, as well as file paths\n",
    "        # to .csv, .xlsx, .xls, and .jsonl files\n",
    "        data: Union[pd.DataFrame, Path, str, List[Dict]],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your target (summarized) text\n",
    "        summary_attr: str = \"summary\",\n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length: Union[int, str] = None,\n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length: Union[int, str] = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Optional[Callable] = None,\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs: dict = {},\n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs: dict = {},\n",
    "    ):\n",
    "        # if we get a path/str then we're loading something like a .csv file\n",
    "        if isinstance(data, Path) or isinstance(data, str):\n",
    "            content_type = mimetypes.guess_type(data)[0]\n",
    "            if (\n",
    "                content_type\n",
    "                == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
    "            ):\n",
    "                data = pd.read_excel(data)\n",
    "            elif content_type == \"text/csv\":\n",
    "                data = pd.read_csv(data)\n",
    "            elif content_type == \"application/json\":\n",
    "                data = pd.read_json(data, orient=\"records\")\n",
    "            else:\n",
    "                raise ValueError(\"'data' must be a .xlsx, .xls, .csv, or .jsonl file\")\n",
    "\n",
    "            data = pd.read_csv(data)\n",
    "\n",
    "        # infer our datablock splitter if None\n",
    "        if dblock_splitter is None:\n",
    "            dblock_splitter = (\n",
    "                ColSplitter() if hasattr(data, \"is_valid\") else RandomSplitter()\n",
    "            )\n",
    "\n",
    "        # we need to find the architecture to ensure \"mbart\" specific tokenizer kwargs are included\n",
    "        model_cls = cls.get_model_cls()\n",
    "        model = model_cls.from_pretrained(pretrained_model_name_or_path)\n",
    "        hf_arch = model.__module__.split(\".\")[2]\n",
    "\n",
    "        if hf_arch == \"mbart\":\n",
    "            hf_tok_kwargs = {\n",
    "                **{\"src_lang\": \"en_XX\", \"tgt_lang\": \"en_XX\"},\n",
    "                **hf_tok_kwargs,\n",
    "            }\n",
    "\n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "            pretrained_model_name_or_path,\n",
    "            model_cls=model_cls,\n",
    "            tokenizer_kwargs=hf_tok_kwargs,\n",
    "        )\n",
    "\n",
    "        # update text generation kwargs\n",
    "        text_gen_kwargs = {\n",
    "            **text_gen_kwargs,\n",
    "            **default_text_gen_kwargs(hf_config, hf_model, task=\"summarization\"),\n",
    "        }\n",
    "\n",
    "        # not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "        generate_func_args = list(\n",
    "            inspect.signature(hf_model.generate).parameters.keys()\n",
    "        )\n",
    "        for k in text_gen_kwargs.copy():\n",
    "            if k not in generate_func_args:\n",
    "                del text_gen_kwargs[k]\n",
    "\n",
    "        # update our text generation kwargs for mbart\n",
    "        if hf_arch == \"mbart\":\n",
    "            text_gen_kwargs = {**{\"decoder_start_token_id\": \"en_XX\"}, **text_gen_kwargs}\n",
    "\n",
    "        # define getters\n",
    "        get_x = Pipeline(funcs=[ItemGetter(text_attr)])\n",
    "        get_y = ItemGetter(summary_attr)\n",
    "\n",
    "        if hf_arch == \"t5\":\n",
    "            get_x.add(cls._add_t5_prefix)\n",
    "\n",
    "        # define our DataBlock and DataLoaders\n",
    "        batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "            hf_arch,\n",
    "            hf_config,\n",
    "            hf_tokenizer,\n",
    "            hf_model,\n",
    "            max_length=max_length,\n",
    "            max_target_length=max_target_length,\n",
    "            text_gen_kwargs=text_gen_kwargs,\n",
    "        )\n",
    "\n",
    "        blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "        dblock = DataBlock(\n",
    "            blocks=blocks, get_x=get_x, get_y=get_y, splitter=dblock_splitter\n",
    "        )\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        learner_kwargs[\"splitter\"] = learner_kwargs.pop(\n",
    "            \"splitter\", partial(blurr_seq2seq_splitter, arch=hf_arch)\n",
    "        )\n",
    "        learner_kwargs[\"loss_func\"] = learner_kwargs.pop(\n",
    "            \"loss_func\", PreCalculatedCrossEntropyLoss()\n",
    "        )\n",
    "\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/b3a80b0a1380627404ab7beeafae5a22d57a6caee6d637757be7b02319a26d37.a3aeae96c9bbfd0fad6832e6f41a23b7f17b292daca2c554b8064433b145e921\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-6-6.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/c457182dd3c47e71636dfe957c948acf12fd6b1d17d3e16a69f9bd731f340157.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
      "loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/1917cd1903f32920951797d984eff6fb9707c20aa7c0eba679d033d5d5dbc7d3.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/41a44e7ad55ba42aa9abd4697be8ff844b95c3f33ad59ceb5059b263caf581fe.67d01b18f2079bd75eac0b2f2e7235768c7f26bd728e7a855a1c5acae01a91a8\n",
      "loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"replacing_rate\": 0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"student_decoder_layers\": null,\n",
      "  \"student_encoder_layers\": null,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/b3a80b0a1380627404ab7beeafae5a22d57a6caee6d637757be7b02319a26d37.a3aeae96c9bbfd0fad6832e6f41a23b7f17b292daca2c554b8064433b145e921\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-6-6.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "learn = BlearnerForSummarization.from_data(\n",
    "    cnndm_df,\n",
    "    \"sshleifer/distilbart-cnn-6-6\",\n",
    "    text_attr=\"article\",\n",
    "    summary_attr=\"highlights\",\n",
    "    max_length=256,\n",
    "    max_target_length=130,\n",
    "    dblock_splitter=RandomSplitter(),\n",
    "    dl_kwargs={\"bs\": 2},\n",
    ").to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.217999</td>\n",
       "      <td>2.165818</td>\n",
       "      <td>0.363228</td>\n",
       "      <td>0.142654</td>\n",
       "      <td>0.249067</td>\n",
       "      <td>0.338458</td>\n",
       "      <td>0.879375</td>\n",
       "      <td>0.888943</td>\n",
       "      <td>0.884054</td>\n",
       "      <td>02:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\n",
      "All the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=[BlearnerForSummarization.get_metrics_cb()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- When Ji Yeqing awakened, she was already in the recovery room. Chinese authorities had dragged her out of her home and down four flights of stairs, she said, restraining and beating her husband as he tried to come to her aid. They whisked her into a clinic, held her down on a bed and forced her to undergo an abortion. Her offense? Becoming pregnant with a second child, in violation of China's one-child policy. \"After the abortion, I felt empty, as if something was scooped out of me,\" J</td>\n",
       "      <td>China's one-child policy results in forced abortions and sterilizations, activists say.\\nWomen tell of emotional and physical consequences from the procedures.\\nActivist Chen Guangcheng works to advocate for victims of such practices.</td>\n",
       "      <td>[ Ji Yeqing says she was forced to have an abortion in violation of China's one-child policy .\\nShe says she felt \"empty\" after the abortion .\\nThe issue of forced abortions in China has seized the spotlight in recent days .\\nIn some cases, forced sterilizations are used to prevent future pregnancies .,  Malala Yousufzai was shot in the neck by Taliban militants on Tuesday .\\nMalala is recovering after surgeons worked for three hours to remove a bullet lodged in her neck .\\nAn angry chorus of voices in social media, on the street, and over the airwaves decries the attack .\\nThe 14-year-old is a defiant blogger .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': [\" 10 men raid Swiss casino in early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the armed robbers' vehicles .\",\n",
       "   \" 10 men raid Swiss casino in early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the robbers' vehicles .\",\n",
       "   \" 10 men raid Swiss casino in early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the robbers' vehicles .\\n\"]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(test_article, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': \" 10 men raid Swiss casino in early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the armed robbers' vehicles .\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_fname = \"summarize_export\"\n",
    "\n",
    "learn.metrics = None\n",
    "learn = learn.to_fp32()\n",
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_summarize(test_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained **summarization models** below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained summarization models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BartForConditionalGeneration',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'LEDForConditionalGeneration',\n",
       " 'M2M100ForConditionalGeneration',\n",
       " 'MBartForConditionalGeneration',\n",
       " 'MT5ForConditionalGeneration',\n",
       " 'PLBartForConditionalGeneration',\n",
       " 'PegasusForConditionalGeneration',\n",
       " 'ProphetNetForConditionalGeneration',\n",
       " 'Speech2TextForConditionalGeneration',\n",
       " 'T5ForConditionalGeneration',\n",
       " 'XLMProphetNetForConditionalGeneration']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |hide\n",
    "[\n",
    "    model_type\n",
    "    for model_type in NLP.get_models(task=\"ConditionalGeneration\")\n",
    "    if (not model_type.startswith(\"TF\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "pretrained_model_names = [\n",
    "    \"facebook/bart-base\",\n",
    "    #'facebook/blenderbot_small-90M',\n",
    "    \"allenai/led-base-16384\",\n",
    "    \"sshleifer/tiny-mbart\",\n",
    "    \"google/mt5-small\",\n",
    "    \"sshleifer/distill-pegasus-cnn-16-4\",\n",
    "    \"t5-small\",\n",
    "    #'microsoft/prophetnet-large-uncased',\n",
    "    #'microsoft/xprophetnet-large-wiki100-cased', # XLMProphetNet\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/wgilliam/.cache/huggingface/datasets/ccdv___cnn_dailymail/3.0.0/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...</td>\n",
       "      <td>Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .</td>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...</td>\n",
       "      <td>Usain Bolt wins third gold of world championship .\\nAnchors Jamaica to 4x100m relay victory .\\nEighth gold at the championships for Bolt .\\nJamaica double up in women's 4x100m relay .</td>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   article  \\\n",
       "0  It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...   \n",
       "1  (CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                  highlights  \\\n",
       "0  Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .   \n",
       "1                                                                                                                    Usain Bolt wins third gold of world championship .\\nAnchors Jamaica to 4x100m relay victory .\\nEighth gold at the championships for Bolt .\\nJamaica double up in women's 4x100m relay .   \n",
       "\n",
       "                                         id  \n",
       "0  0001d1afc246a7964130f43ae940af6bc6c57f01  \n",
       "1  0002095e55fcbd3a2f366d9bf92a95433dc305ef  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |hide\n",
    "dataset = load_dataset(\"ccdv/cnn_dailymail\", \"3.0.0\", split=\"train[:1000]\")\n",
    "cnndm_df = pd.DataFrame(dataset)\n",
    "cnndm_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/facebook/bart-base/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/43978bdeaa326572886b44fcfed82f932f76571095ce31973e51c3da8ccade7f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/facebook/bart-base/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/3c167ed8af56e6605eeb794b63a79d65d85e6708c9b04408d41946337030f5cd.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/facebook/bart-base/resolve/main/tokenizer.json from cache at /home/wgilliam/.cache/huggingface/transformers/a878fcd69bba037c9b1b227f4213579ae43d0aaa9374e167bc6c5f41b1cfeb30.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "loading file https://huggingface.co/facebook/bart-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/facebook/bart-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/facebook/bart-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/facebook/bart-base/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/486355ec722ef05fd480e999d4c763be56549ae930f6a3742ee721a5d2a05647.f2f355ad2775769afc60592b43a46d72ca548375e3a1d65f381a751e711cbadd\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- Was it George Zimmerman or Trayvon Martin who screamed for help the night the 17-year-old Martin was shot dead? That could depend on which mother the jury believes. Both Zimmerman's and Martin's mothers expressed no hesitation Friday in separate court appearances as to whose panicked voice is heard screaming during</td>\n",
       "      <td>NEW: A defense lawyer says other evidence, not the 911 call, will determine the case.\\nNEW: A lawyer for Martin's family says he thinks the jury will find Zimmerman guilty.</td>\n",
       "      <td>[(CNN) -- Was it George Zimmerman or Trayvon Martin who screamed for help the night the 17-year-old Martin was shot dead,  (CNN) -- The hostage crisis in eastern Algeria is over, but the questions remain. Among them, exactly how many people are unaccount]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/led-base-16384 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/allenai/led-base-16384/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/ec844bead6f5bbcd6ac727b57e595c2ba40b0970f91cb923423773f72fe1702f.898baac75d55d484b1b1de95b8ab791987c78591acf36ce6131b56d0d2d26af7\n",
      "Model config LEDConfig {\n",
      "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"LEDForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_window\": [\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_decoder_position_embeddings\": 1024,\n",
      "  \"max_encoder_position_embeddings\": 16384,\n",
      "  \"model_type\": \"led\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/led-base-16384/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/ec844bead6f5bbcd6ac727b57e595c2ba40b0970f91cb923423773f72fe1702f.898baac75d55d484b1b1de95b8ab791987c78591acf36ce6131b56d0d2d26af7\n",
      "Model config LEDConfig {\n",
      "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"LEDForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_window\": [\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_decoder_position_embeddings\": 1024,\n",
      "  \"max_encoder_position_embeddings\": 16384,\n",
      "  \"model_type\": \"led\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/4fb25bb1f9a942a2e2930029211b4a7deaeb18b62f6e5ce6d59730c90da51373.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
      "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/087e8f4306cbf22e21907929074344a3b0a46bd680a118eb6267cd5a2bcec5b2.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/special_tokens_map.json from cache at /home/wgilliam/.cache/huggingface/transformers/05da652a7fca41c1c18027c1201e473217bb373e370d1283e3de49d5880cbf0c.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0\n",
      "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/86288ba22bce9550d76e9b26722ee92ae5921ae9285ccbc2904e9a5ad7199b73.cfc08f03f72cde495bd6b3dd3252bca130b3437de370856d084d1453c58b6fea\n",
      "loading configuration file https://huggingface.co/allenai/led-base-16384/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/ec844bead6f5bbcd6ac727b57e595c2ba40b0970f91cb923423773f72fe1702f.898baac75d55d484b1b1de95b8ab791987c78591acf36ce6131b56d0d2d26af7\n",
      "Model config LEDConfig {\n",
      "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"LEDForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_window\": [\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_decoder_position_embeddings\": 1024,\n",
      "  \"max_encoder_position_embeddings\": 16384,\n",
      "  \"model_type\": \"led\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/led-base-16384/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/ec844bead6f5bbcd6ac727b57e595c2ba40b0970f91cb923423773f72fe1702f.898baac75d55d484b1b1de95b8ab791987c78591acf36ce6131b56d0d2d26af7\n",
      "Model config LEDConfig {\n",
      "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"LEDForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_window\": [\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024,\n",
      "    1024\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_decoder_position_embeddings\": 1024,\n",
      "  \"max_encoder_position_embeddings\": 16384,\n",
      "  \"model_type\": \"led\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/allenai/led-base-16384/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/c8f7e4603efbc329ce921b34057d78880dead50f45b2a1648b3a06ca6eb17f51.201222b06d46289037a8dccc57548abc8eb81ba042d3762214ac15c9691ff8c7\n",
      "All model checkpoint weights were used when initializing LEDForConditionalGeneration.\n",
      "\n",
      "All the weights of LEDForConditionalGeneration were initialized from the model checkpoint at allenai/led-base-16384.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LEDForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tled\n",
      "tokenizer:\tLEDTokenizerFast\n",
      "model:\t\tLEDForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 64 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- London may be the center of attention this summer, but venture beyond the Olympic Stadium and you'll find the real British Isles, a world of ancient thatched cottages, monumental castles, elegant university towns and jagged peaks. You won't have to travel far to see why the British</td>\n",
       "      <td>In the Cotswolds, visit elegant mansions, graceful churches and atmospheric pubs.\\nGowned cyclists ride the streets of Cambridge while academics debate.\\nDon't skip the snow-</td>\n",
       "      <td>[(CNN) -- London may be the center of attention this summer, but venture beyond the, Washington (CNN) -- The sister of presidential assailant John Hinckley Jr. testified Tuesday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sshleifer/tiny-mbart ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/sshleifer/tiny-mbart/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/5fd8333015b256440e1b6fbf2d5f86a4868a39440a89554475ee8d1c616d9e56.5b830f48cd63bb457b6ea960d512d839da5b4c30ee8b6998c04977316c32b2f0\n",
      "Model config MBartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/tiny-mbart\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 2,\n",
      "  \"decoder_attention_heads\": 1,\n",
      "  \"decoder_ffn_dim\": 4,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 1,\n",
      "  \"encoder_ffn_dim\": 4,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"mbart\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 2,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250027\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/sshleifer/tiny-mbart/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/5fd8333015b256440e1b6fbf2d5f86a4868a39440a89554475ee8d1c616d9e56.5b830f48cd63bb457b6ea960d512d839da5b4c30ee8b6998c04977316c32b2f0\n",
      "Model config MBartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/tiny-mbart\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 2,\n",
      "  \"decoder_attention_heads\": 1,\n",
      "  \"decoder_ffn_dim\": 4,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 1,\n",
      "  \"encoder_ffn_dim\": 4,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"mbart\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 2,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250027\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/sshleifer/tiny-mbart/resolve/main/sentencepiece.bpe.model from cache at /home/wgilliam/.cache/huggingface/transformers/13a2c62c1dabc5357bc38b0694f5829f3db0708d51f1a0f07734f62cc0a825a0.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
      "loading file https://huggingface.co/sshleifer/tiny-mbart/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/sshleifer/tiny-mbart/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/sshleifer/tiny-mbart/resolve/main/special_tokens_map.json from cache at /home/wgilliam/.cache/huggingface/transformers/33fa7894ab257a74cede3060dca6d2fc609918785e80160f6c057723ece47292.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n",
      "loading file https://huggingface.co/sshleifer/tiny-mbart/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/e9c580e6446c42ed20fb148206f2a9bd75a825278ffa029df063682077d45bb6.67d01b18f2079bd75eac0b2f2e7235768c7f26bd728e7a855a1c5acae01a91a8\n",
      "loading configuration file https://huggingface.co/sshleifer/tiny-mbart/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/5fd8333015b256440e1b6fbf2d5f86a4868a39440a89554475ee8d1c616d9e56.5b830f48cd63bb457b6ea960d512d839da5b4c30ee8b6998c04977316c32b2f0\n",
      "Model config MBartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/tiny-mbart\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 2,\n",
      "  \"decoder_attention_heads\": 1,\n",
      "  \"decoder_ffn_dim\": 4,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 1,\n",
      "  \"encoder_ffn_dim\": 4,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"mbart\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 2,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250027\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/sshleifer/tiny-mbart/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/5fd8333015b256440e1b6fbf2d5f86a4868a39440a89554475ee8d1c616d9e56.5b830f48cd63bb457b6ea960d512d839da5b4c30ee8b6998c04977316c32b2f0\n",
      "Model config MBartConfig {\n",
      "  \"_name_or_path\": \"sshleifer/tiny-mbart\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 2,\n",
      "  \"decoder_attention_heads\": 1,\n",
      "  \"decoder_ffn_dim\": 4,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 1,\n",
      "  \"encoder_ffn_dim\": 4,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"mbart\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 2,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250027\n",
      "}\n",
      "\n",
      "Assigning ['ar_AR', 'cs_CZ', 'de_DE', 'en_XX', 'es_XX', 'et_EE', 'fi_FI', 'fr_XX', 'gu_IN', 'hi_IN', 'it_IT', 'ja_XX', 'kk_KZ', 'ko_KR', 'lt_LT', 'lv_LV', 'my_MM', 'ne_NP', 'nl_XX', 'ro_RO', 'ru_RU', 'si_LK', 'tr_TR', 'vi_VN', 'zh_CN'] to the additional_special_tokens key of the tokenizer\n",
      "loading weights file https://huggingface.co/sshleifer/tiny-mbart/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/d6eec704737db03a21a794f08b07fcbb71d855562a992cfb1be6193b37a7ff68.61ce63751e40ea882dd1a22b6c9303b954b81ec69d631ab0541750fd856720be\n",
      "All model checkpoint weights were used when initializing MBartForConditionalGeneration.\n",
      "\n",
      "All the weights of MBartForConditionalGeneration were initialized from the model checkpoint at sshleifer/tiny-mbart.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MBartForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tmbart\n",
      "tokenizer:\tMBartTokenizerFast\n",
      "model:\t\tMBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- A spate of deadly shootings during anti-drug operations in Honduras -- including two in which U.S. agents killed suspects -- is linked to an aggressive new strategy to disrupt a preferred corridor for traffickers. Operation Anvil, as the multinational</td>\n",
       "      <td>Six people have been killed in three incidents over the past two months in Honduras. The incidents happened during the course of Operation Anvil, a joint Honduran-U.</td>\n",
       "      <td>[เข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไป, เข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไปเข้าไป]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mt5-small ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/mt5-small/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n",
      "Model config MT5Config {\n",
      "  \"_name_or_path\": \"google/mt5-small\",\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 1024,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 8,\n",
      "  \"num_heads\": 6,\n",
      "  \"num_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/mt5-small/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n",
      "Model config MT5Config {\n",
      "  \"_name_or_path\": \"google/mt5-small\",\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 1024,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 8,\n",
      "  \"num_heads\": 6,\n",
      "  \"num_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/mt5-small/resolve/main/spiece.model from cache at /home/wgilliam/.cache/huggingface/transformers/37d0f67f084f8c5fc5589e0bba5ff3c6307af833bb0b7f4eb33fbfd8d4038a9d.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n",
      "loading file https://huggingface.co/google/mt5-small/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/mt5-small/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/mt5-small/resolve/main/special_tokens_map.json from cache at /home/wgilliam/.cache/huggingface/transformers/685ac0ca8568ec593a48b61b0a3c272beee9bc194a3c7241d15dcadb5f875e53.f76030f3ec1b96a8199b2593390c610e76ca8028ef3d24680000619ffb646276\n",
      "loading file https://huggingface.co/google/mt5-small/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/6a9e52d6dd21568e37b65fc180ada927968e8f7124f0acd6efcaf90cd2e0f4bb.4b81e5d952ad810ca1de2b3e362b9a26a5cc77b4b75daf20caf69fb838751c32\n",
      "loading configuration file https://huggingface.co/google/mt5-small/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n",
      "Model config MT5Config {\n",
      "  \"_name_or_path\": \"google/mt5-small\",\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 1024,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 8,\n",
      "  \"num_heads\": 6,\n",
      "  \"num_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/mt5-small/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n",
      "Model config MT5Config {\n",
      "  \"_name_or_path\": \"google/mt5-small\",\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 1024,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 8,\n",
      "  \"num_heads\": 6,\n",
      "  \"num_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/mt5-small/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/8e7b2a80ddcb5611b27d8c89e1e8e33a947e105415051402a22b9c8d7d1caeb0.e22331f3a065b885b30ae3dd1ff11ccaf7fbc444485f6eb07ef5e0138bca8b70\n",
      "All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of MT5ForConditionalGeneration were initialized from the model checkpoint at google/mt5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tmt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tMT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- Gabriel García Márquez, the influential, Nobel Prize-winning author of \"One Hundred Years of Solitude\" and \"Love in the Time of Cholera,\" has died, his family and officials said. He was 87. The literary giant was treated in April</td>\n",
       "      <td>NEW: Colombia's President declares three days of national mourning. The 87-year-old is widely credited with helping to popularize \"magical realism</td>\n",
       "      <td>[&lt;extra_id_0&gt;., &lt;extra_id_0&gt;.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sshleifer/distill-pegasus-cnn-16-4 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/sshleifer/distill-pegasus-cnn-16-4/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/92d1694f3fcb38270087c7ebb95db5c294e0176e0d80e80f70c255a5db4a3148.85b07a8a13b57e57308b9918c95cc24e7e9f4cb277d694da36cc222d2a4d687d\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distill-pegasus-cnn-16-4\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"save_step\": 15,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/sshleifer/distill-pegasus-cnn-16-4/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/92d1694f3fcb38270087c7ebb95db5c294e0176e0d80e80f70c255a5db4a3148.85b07a8a13b57e57308b9918c95cc24e7e9f4cb277d694da36cc222d2a4d687d\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distill-pegasus-cnn-16-4\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"save_step\": 15,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/sshleifer/distill-pegasus-cnn-16-4/resolve/main/spiece.model from cache at /home/wgilliam/.cache/huggingface/transformers/fcfb15bf27c850ac66617d55ff2c645f9228dfcd7acc28ef30877ba55b8458ce.1acf68c74589da6c7fa3548093824dfc450a54637f4356929bbfea7e294a68f8\n",
      "loading file https://huggingface.co/sshleifer/distill-pegasus-cnn-16-4/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/sshleifer/distill-pegasus-cnn-16-4/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/sshleifer/distill-pegasus-cnn-16-4/resolve/main/special_tokens_map.json from cache at /home/wgilliam/.cache/huggingface/transformers/10ee9225127390e58f7ec630cfc9ac842ecfdcd6e927cd97727c30cea725d5ca.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
      "loading file https://huggingface.co/sshleifer/distill-pegasus-cnn-16-4/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/87cbaa7128e299135a73cf6182e92aa6f49ebd205fe40e82fee01386e7245cd1.43f396f0ee3b974f9128267d49f69a26b11f3ed290851ac5788a549cc2979671\n",
      "loading configuration file https://huggingface.co/sshleifer/distill-pegasus-cnn-16-4/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/92d1694f3fcb38270087c7ebb95db5c294e0176e0d80e80f70c255a5db4a3148.85b07a8a13b57e57308b9918c95cc24e7e9f4cb277d694da36cc222d2a4d687d\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distill-pegasus-cnn-16-4\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"save_step\": 15,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/sshleifer/distill-pegasus-cnn-16-4/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/92d1694f3fcb38270087c7ebb95db5c294e0176e0d80e80f70c255a5db4a3148.85b07a8a13b57e57308b9918c95cc24e7e9f4cb277d694da36cc222d2a4d687d\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"sshleifer/distill-pegasus-cnn-16-4\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"save_step\": 15,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/sshleifer/distill-pegasus-cnn-16-4/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/764f29ca73d0c980e62ecfba6e571aab42dc7236c0aa3e9df0d11f0473d1f7fc.07f8e66c3573b88cd4137114c2649f158456fd02f3e9c37af35441b8e812dca7\n",
      "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
      "\n",
      "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at sshleifer/distill-pegasus-cnn-16-4.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tpegasus\n",
      "tokenizer:\tPegasusTokenizerFast\n",
      "model:\t\tPegasusForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- When Ji Yeqing awakened, she was already in the recovery room. Chinese authorities had dragged her out of her home and down four flights of stairs, she said, restraining and beating her husband as he tried to come to her aid. They whisked her into a clinic, held her down</td>\n",
       "      <td>China's one-child policy results in forced abortions and sterilizations, activists say. Women tell of emotional and physical consequences from the procedures. Activist Chen Guangcheng works to advocate for</td>\n",
       "      <td>[Ji Yeqing was dragged out of her home and down four flights of stairs . She said she was restraining and beating her husband as he tried to come to her aid ., Hamas security sources say at least 60 Israeli airstrikes across Gaza on Monday night into Tuesday . \"Operation Protective Edge is underway,\" Israel says .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/t5-small/resolve/main/spiece.model from cache at /home/wgilliam/.cache/huggingface/transformers/65fc04e21f45f61430aea0c4fedffac16a4d20d78b8e6601d8d996ebefefecd2.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\n",
      "loading file https://huggingface.co/t5-small/resolve/main/tokenizer.json from cache at /home/wgilliam/.cache/huggingface/transformers/06779097c78e12f47ef67ecb728810c2ae757ee0a9efe9390c6419783d99382d.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\n",
      "loading file https://huggingface.co/t5-small/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/t5-small/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/t5-small/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/t5-small/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/t5-small/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summarize: Los Angeles (CNN) -- A former Los Angeles cop with military training vowed war against other men in blue Thursday, leaving one officer dead days after he allegedly killed two other people to begin a wave of retribution for being fired, police said. The focus of the</td>\n",
       "      <td>NEW: With snow coming, authorities continue to hunt for the suspect near Big Bear Lake. Police believe former cop Christopher Jordan Dorner shot three officers, killing one. This was days after</td>\n",
       "      <td>[a former cop with military training vowed war against other men in blue . one officer died days after he allegedly killed two, Andy Warhol visited Beijing in 1982 and was told there wasn't a McDonald's . twenty-six years after his death]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# |hide\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "bsz = 2\n",
    "inp_seq_sz = 64\n",
    "trg_seq_sz = 40\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error = None\n",
    "\n",
    "    print(f\"=== {model_name} ===\\n\")\n",
    "\n",
    "    hf_tok_kwargs = {}\n",
    "    if model_name == \"sshleifer/tiny-mbart\":\n",
    "        hf_tok_kwargs[\"src_lang\"], hf_tok_kwargs[\"tgt_lang\"] = \"en_XX\", \"en_XX\"\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "        model_name, model_cls=model_cls, tokenizer_kwargs=hf_tok_kwargs\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n\"\n",
    "    )\n",
    "\n",
    "    # 1. build your DataBlock\n",
    "    text_gen_kwargs = {}\n",
    "    if hf_arch in [\"bart\", \"t5\"]:\n",
    "        text_gen_kwargs = {\n",
    "            **hf_config.task_specific_params[\"summarization\"],\n",
    "            **{\"max_length\": 30, \"min_length\": 10},\n",
    "        }\n",
    "\n",
    "    # not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "    generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "    for k in text_gen_kwargs.copy():\n",
    "        if k not in generate_func_args:\n",
    "            del text_gen_kwargs[k]\n",
    "\n",
    "    if hf_arch == \"mbart\":\n",
    "        text_gen_kwargs[\"decoder_start_token_id\"] = hf_tokenizer.get_vocab()[\"en_XX\"]\n",
    "\n",
    "    def add_t5_prefix(inp):\n",
    "        return f\"summarize: {inp}\" if (hf_arch == \"t5\") else inp\n",
    "\n",
    "    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "        hf_arch,\n",
    "        hf_config,\n",
    "        hf_tokenizer,\n",
    "        hf_model,\n",
    "        padding=\"max_length\",\n",
    "        max_length=inp_seq_sz,\n",
    "        max_target_length=trg_seq_sz,\n",
    "        text_gen_kwargs=text_gen_kwargs,\n",
    "    )\n",
    "\n",
    "    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "    dblock = DataBlock(\n",
    "        blocks=blocks,\n",
    "        get_x=Pipeline([ColReader(\"article\"), add_t5_prefix]),\n",
    "        get_y=ColReader(\"highlights\"),\n",
    "        splitter=RandomSplitter(),\n",
    "    )\n",
    "\n",
    "    dls = dblock.dataloaders(cnndm_df, bs=bsz)\n",
    "    b = dls.one_batch()\n",
    "\n",
    "    # 2. build your Learner\n",
    "    seq2seq_metrics = {\n",
    "        \"rouge\": {\n",
    "            \"compute_kwargs\": {\n",
    "                \"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "                \"use_stemmer\": True,\n",
    "            },\n",
    "            \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    model = BaseModelWrapper(hf_model)\n",
    "    learn_cbs = [BaseModelCallback]\n",
    "    fit_cbs = [\n",
    "        ShortEpochCallback(0.05, short_valid=True),\n",
    "        Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics),\n",
    "    ]\n",
    "\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        opt_func=ranger,\n",
    "        loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "        cbs=learn_cbs,\n",
    "        splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    "    ).to_fp16()\n",
    "\n",
    "    learn.create_opt()\n",
    "    learn.freeze()\n",
    "\n",
    "    # 3. Run your tests\n",
    "    try:\n",
    "        print(\"*** TESTING DataLoaders ***\\n\")\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0][\"input_ids\"]), bsz)\n",
    "        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, inp_seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        #         print('*** TESTING One pass through the model ***')\n",
    "        #         preds = learn.model(b[0])\n",
    "        #         test_eq(preds[1].shape[0], bsz)\n",
    "        #         test_eq(preds[1].shape[2], hf_config.vocab_size)\n",
    "\n",
    "        print(\"*** TESTING Training/Results ***\")\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n",
    "\n",
    "        test_results.append(\n",
    "            (\n",
    "                hf_arch,\n",
    "                type(hf_tokenizer).__name__,\n",
    "                type(hf_model).__name__,\n",
    "                \"PASSED\",\n",
    "                \"\",\n",
    "            )\n",
    "        )\n",
    "        learn.show_results(\n",
    "            learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250\n",
    "        )\n",
    "    except Exception as err:\n",
    "        test_results.append(\n",
    "            (\n",
    "                hf_arch,\n",
    "                type(hf_tokenizer).__name__,\n",
    "                type(hf_model).__name__,\n",
    "                \"FAILED\",\n",
    "                err,\n",
    "            )\n",
    "        )\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>led</td>\n",
       "      <td>LEDTokenizerFast</td>\n",
       "      <td>LEDForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mbart</td>\n",
       "      <td>MBartTokenizerFast</td>\n",
       "      <td>MBartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mt5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>MT5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pegasus</td>\n",
       "      <td>PegasusTokenizerFast</td>\n",
       "      <td>PegasusForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>T5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | echo: false\n",
    "test_results_df = pd.DataFrame(\n",
    "    test_results, columns=[\"arch\", \"tokenizer\", \"model_name\", \"result\", \"error\"]\n",
    ")\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_callbacks.ipynb.\n",
      "Converted 00_utils.ipynb.\n",
      "Converted 01_text-callbacks.ipynb.\n",
      "Converted 01_text-utils.ipynb.\n",
      "Converted 11_text-data-core.ipynb.\n",
      "Converted 11_text-modeling-core.ipynb.\n",
      "Converted 12_text-data-language-modeling.ipynb.\n",
      "Converted 12_text-modeling-language-modeling.ipynb.\n",
      "Converted 13_text-data-token-classification.ipynb.\n",
      "Converted 13_text-modeling-token-classification.ipynb.\n",
      "Converted 14_text-data-question-answering.ipynb.\n",
      "Converted 14_text-modeling-question-answering.ipynb.\n",
      "Converted 20_text-data-seq2seq-core.ipynb.\n",
      "Converted 20_text-modeling-seq2seq-core.ipynb.\n",
      "Converted 21_text-data-seq2seq-summarization.ipynb.\n",
      "Converted 21_text-modeling-seq2seq-summarization.ipynb.\n",
      "Converted 22_text-data-seq2seq-translation.ipynb.\n",
      "Converted 22_text-modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_text-examples-high-level-api.ipynb.\n",
      "Converted 99b_text-examples-glue.ipynb.\n",
      "Converted 99c_text-examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_text-examples-multilabel.ipynb.\n",
      "Converted 99e_text-examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
