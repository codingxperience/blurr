[
  {
    "objectID": "examples.text.glue_low_level_api.html",
    "href": "examples.text.glue_low_level_api.html",
    "title": "Using the Low-level fastai API",
    "section": "",
    "text": "Using GPU #1: GeForce GTX 1080 Ti"
  },
  {
    "objectID": "examples.text.glue_low_level_api.html#glue-tasks",
    "href": "examples.text.glue_low_level_api.html#glue-tasks",
    "title": "Using the Low-level fastai API",
    "section": "GLUE tasks",
    "text": "GLUE tasks\n\n\n\n\n\n  \n    \n      Abbr\n      Name\n      Task type\n      Description\n      Size\n      Metrics\n    \n  \n  \n    \n      CoLA\n      Corpus of Linguistic Acceptability\n      Single-Sentence Task\n      Predict whether a sequence is a grammatical English sentence\n      8.5k\n      Matthews corr.\n    \n    \n      SST-2\n      Stanford Sentiment Treebank\n      Single-Sentence Task\n      Predict the sentiment of a given sentence\n      67k\n      Accuracy\n    \n    \n      MRPC\n      Microsoft Research Paraphrase Corpus\n      Similarity and Paraphrase Tasks\n      Predict whether two sentences are semantically equivalent\n      3.7k\n      F1/Accuracy\n    \n    \n      SST-B\n      Semantic Textual Similarity Benchmark\n      Similarity and Paraphrase Tasks\n      Predict the similarity score for two sentences on a scale from 1 to 5\n      7k\n      Pearson/Spearman corr.\n    \n    \n      QQP\n      Quora question pair\n      Similarity and Paraphrase Tasks\n      Predict if two questions are a paraphrase of one another\n      364k\n      F1/Accuracy\n    \n    \n      MNLI\n      Mulit-Genre Natural Language Inference\n      Inference Tasks\n      Predict whether the premise entails, contradicts or is neutral to the hypothesis\n      393k\n      Accuracy\n    \n    \n      QNLI\n      Stanford Question Answering Dataset\n      Inference Tasks\n      Predict whether the context sentence contains the answer to the question\n      105k\n      Accuracy\n    \n    \n      RTE\n      Recognize Textual Entailment\n      Inference Tasks\n      Predict whether one sentece entails another\n      2.5k\n      Accuracy\n    \n    \n      WNLI\n      Winograd Schema Challenge\n      Inference Tasks\n      Predict if the sentence with the pronoun substituted is entailed by the original sentence\n      634\n      Accuracy"
  },
  {
    "objectID": "examples.text.glue_low_level_api.html#define-the-task-and-hyperparmeters",
    "href": "examples.text.glue_low_level_api.html#define-the-task-and-hyperparmeters",
    "title": "Using the Low-level fastai API",
    "section": "Define the task and hyperparmeters",
    "text": "Define the task and hyperparmeters\nWe’ll use the “distilroberta-base” checkpoint for this example, but if you want to try an architecture that returns token_type_ids for example, you can use something like bert-cased.\n\ntask = 'mrpc'\ntask_meta = glue_tasks[task]\ntrain_ds_name = task_meta['dataset_names'][\"train\"]\nvalid_ds_name = task_meta['dataset_names'][\"valid\"]\ntest_ds_name = task_meta['dataset_names'][\"test\"]\n\ntask_inputs =  task_meta['inputs']\ntask_target =  task_meta['target']\ntask_metrics = task_meta['metric_funcs']\n\npretrained_model_name = \"distilroberta-base\" # bert-base-cased | distilroberta-base\n\nbsz = 16\nval_bsz = bsz *2"
  },
  {
    "objectID": "examples.text.glue_low_level_api.html#raw-data",
    "href": "examples.text.glue_low_level_api.html#raw-data",
    "title": "Using the Low-level fastai API",
    "section": "Raw data",
    "text": "Raw data\nLet’s start by building our DataBlock. We’ll load the MRPC datset from huggingface’s datasets library which will be cached after downloading via the load_dataset method. For more information on the datasets API, see the documentation here.\n\nraw_datasets = load_dataset('glue', task) \nprint(f'{raw_datasets}\\n')\nprint(f'{raw_datasets[train_ds_name][0]}\\n')\nprint(f'{raw_datasets[train_ds_name].features}\\n')\n\nReusing dataset glue (/home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['idx', 'label', 'sentence1', 'sentence2'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['idx', 'label', 'sentence1', 'sentence2'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['idx', 'label', 'sentence1', 'sentence2'],\n        num_rows: 1725\n    })\n})\n\n{'idx': 0, 'label': 1, 'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'}\n\n{'idx': Value(dtype='int32', id=None), 'label': ClassLabel(num_classes=2, names=['not_equivalent', 'equivalent'], names_file=None, id=None), 'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None)}"
  },
  {
    "objectID": "examples.text.glue_low_level_api.html#prepare-the-hugging-face-objects",
    "href": "examples.text.glue_low_level_api.html#prepare-the-hugging-face-objects",
    "title": "Using the Low-level fastai API",
    "section": "Prepare the Hugging Face objects",
    "text": "Prepare the Hugging Face objects\nMy #1 answer as to the question, “Why aren’t my transformers training?”, is that you likely don’t have num_labels set correctly. The default for sequence classification tasks is 2, and even though that is what we have here, let’s show how to set this either way.\n\nn_lbls = raw_datasets[train_ds_name].features[task_target].num_classes\nn_lbls\n\n2\n\n\n\nmodel_cls = AutoModelForSequenceClassification\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, \n                                                                  model_cls=model_cls, \n                                                                  config_kwargs={'num_labels': n_lbls})\n\nprint(hf_arch)\nprint(type(hf_config))\nprint(type(hf_tokenizer))\nprint(type(hf_model))\n\nroberta\n<class 'transformers.models.roberta.configuration_roberta.RobertaConfig'>\n<class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>\n<class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>"
  },
  {
    "objectID": "examples.text.glue_low_level_api.html#build-the-tokenized-datasets",
    "href": "examples.text.glue_low_level_api.html#build-the-tokenized-datasets",
    "title": "Using the Low-level fastai API",
    "section": "Build the tokenized datasets",
    "text": "Build the tokenized datasets\nTokenize (and numericalize) the raw text using the datasets.map function, and then remove unnecessary and/or problematic attributes from the resulting tokenized dataset (e.g., things like strings that can’t be converted to a tensor)\n\ndef tokenize_function(example):\n    return hf_tokenizer(*[example[inp] for inp in task_inputs ], truncation=True)\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n\n\n\n\n\n\n\n\n\n\n\ntokenized_datasets = tokenized_datasets.remove_columns(task_inputs + ['idx'])\ntokenized_datasets = tokenized_datasets.rename_column('label', 'labels')\ntokenized_datasets[\"train\"].column_names\n\n['attention_mask', 'input_ids', 'labels']"
  },
  {
    "objectID": "examples.text.glue_low_level_api.html#using-pytorch-dataloaders",
    "href": "examples.text.glue_low_level_api.html#using-pytorch-dataloaders",
    "title": "Using the Low-level fastai API",
    "section": "1. Using PyTorch DataLoaders",
    "text": "1. Using PyTorch DataLoaders\n\nBuild the DataLoaders\nBlurrBatchCreator augments the default DataCollatorWithPadding method to return a tuple of inputs/targets. As huggingface returns a BatchEncoding object after the call to DataCollatorWithPadding, this class will convert it to a dict so that fastai can put the batches on the correct device for training\nBuild the plain ol’ PyTorch DataLoaders\n\ndata_collator = TextBatchCreator(hf_arch, hf_config, hf_tokenizer, hf_model)\n\ntrain_dataloader = torch.utils.data.DataLoader(tokenized_datasets[train_ds_name], shuffle=True, batch_size=bsz, \n                                               collate_fn=data_collator)\n\neval_dataloader = torch.utils.data.DataLoader(tokenized_datasets[valid_ds_name], batch_size=val_bsz, \n                                              collate_fn=data_collator)\n\n\ndls = DataLoaders(train_dataloader, eval_dataloader)\n\n\nfor b in dls.train: break\nb[0]['input_ids'].shape, b[1].shape, b[0]['input_ids'].device, b[1].device\n\n(torch.Size([16, 72]),\n torch.Size([16]),\n device(type='cpu'),\n device(type='cpu'))\n\n\n\n\nTrain\nWith our plain ol’ PyTorch DataLoaders built, we can now build our Learner and train.\nNote: Certain fastai methods like dls.one_batch, get_preds and dls.test_dl won’t work with standard PyTorch DataLoaders … but we’ll show how to remedy that in a moment :)\n\nmodel = BaseModelWrapper(hf_model)\n\nlearn = Learner(dls, \n                model,\n                opt_func=partial(Adam),\n                loss_func=PreCalculatedCrossEntropyLoss(),\n                metrics=task_metrics,\n                cbs=[BaseModelCallback],\n                splitter=blurr_splitter).to_fp16()\n\nlearn.freeze()\n\n\nlearn.summary()\n\n\nlearn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\nSuggestedLRs(minimum=0.00036307806149125097, steep=0.015848932787775993, valley=0.0006918309954926372, slide=0.001737800776027143)\n\n\n\n\n\n\nlearn.fit_one_cycle(1, lr_max=2e-3)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.532319\n      0.480080\n      0.843450\n      0.759804\n      00:10\n    \n  \n\n\n\n\nlearn.unfreeze()\nlearn.lr_find(start_lr=1e-12, end_lr=2e-3, suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\nSuggestedLRs(minimum=1.3779609397968073e-11, steep=8.513399187004556e-12, valley=4.234914013068192e-05, slide=2.2274794901022688e-05)\n\n\n\n\n\n\nlearn.fit_one_cycle(2, lr_max=slice(2e-5, 2e-4))\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.467265\n      0.358624\n      0.889643\n      0.840686\n      00:19\n    \n    \n      1\n      0.279453\n      0.335163\n      0.910321\n      0.870098\n      00:19\n    \n  \n\n\n\n\n\nEvaluate\nHow did we do?\n\nval_res = learn.validate()\n\n\n\n\n\nval_res_d = { 'loss': val_res[0]}\nfor idx, m in enumerate(learn.metrics): val_res_d[m.name] = val_res[idx+1]\n    \nval_res_d\n\n{'loss': 0.33516255021095276,\n 'f1_score': 0.9103214890016922,\n 'accuracy': 0.8700980544090271}\n\n\n\n# preds, targs = learn.get_preds()  # ... won't work :(\n\n\n\nInference\nLet’s do item inference on an example from our test dataset\n\nraw_test_df = raw_datasets[test_ds_name].to_pandas()\nraw_test_df.head()\n\n\n\n\n\n  \n    \n      \n      idx\n      label\n      sentence1\n      sentence2\n    \n  \n  \n    \n      0\n      0\n      1\n      PCCW 's chief operating officer , Mike Butcher , and Alex Arena , the chief financial officer , will report directly to Mr So .\n      Current Chief Operating Officer Mike Butcher and Group Chief Financial Officer Alex Arena will report to So .\n    \n    \n      1\n      1\n      1\n      The world 's two largest automakers said their U.S. sales declined more than predicted last month as a late summer sales frenzy caused more of an industry backlash than expected .\n      Domestic sales at both GM and No. 2 Ford Motor Co. declined more than predicted as a late summer sales frenzy prompted a larger-than-expected industry backlash .\n    \n    \n      2\n      2\n      1\n      According to the federal Centers for Disease Control and Prevention ( news - web sites ) , there were 19 reported cases of measles in the United States in 2002 .\n      The Centers for Disease Control and Prevention said there were 19 reported cases of measles in the United States in 2002 .\n    \n    \n      3\n      3\n      0\n      A tropical storm rapidly developed in the Gulf of Mexico Sunday and was expected to hit somewhere along the Texas or Louisiana coasts by Monday night .\n      A tropical storm rapidly developed in the Gulf of Mexico on Sunday and could have hurricane-force winds when it hits land somewhere along the Louisiana coast Monday night .\n    \n    \n      4\n      4\n      0\n      The company didn 't detail the costs of the replacement and repairs .\n      But company officials expect the costs of the replacement work to run into the millions of dollars .\n    \n  \n\n\n\n\n\ntest_ex_idx = 0\ntest_ex = raw_test_df.iloc[test_ex_idx][task_inputs].values.tolist()\n\n\ninputs = hf_tokenizer(*test_ex, return_tensors=\"pt\").to('cuda:1')\n\n\noutputs = hf_model(**inputs)\noutputs.logits\n\ntensor([[-1.6640,  1.0325]], device='cuda:1', grad_fn=<AddmmBackward0>)\n\n\n\ntorch.argmax(torch.softmax(outputs.logits, dim=-1))\n\ntensor(1, device='cuda:1')\n\n\nLet’s do batch inference on the entire test dataset\n\n# test_dl = dls.test_dl(tokenized_datasets[test_ds_name]) # ... won't work :(\n\ntest_dataloader = torch.utils.data.DataLoader(tokenized_datasets[test_ds_name], \n                                              shuffle=False, batch_size=val_bsz, \n                                              collate_fn=data_collator)\n\nhf_model.eval()\n\nprobs, preds = [], []\nfor xb,yb in test_dataloader: \n    xb = to_device(xb,'cuda')\n    with torch.no_grad(): \n        outputs = hf_model(**xb)\n        \n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    \n    probs.append(logits)\n    preds.append(predictions)\n\n\nall_probs = torch.cat(probs, dim=0)\nall_preds = torch.cat(preds, dim=0)\n\nprint(all_probs.shape, all_preds.shape)\n\ntorch.Size([1725, 2]) torch.Size([1725])"
  },
  {
    "objectID": "examples.text.glue_low_level_api.html#using-fastai-dataloaders",
    "href": "examples.text.glue_low_level_api.html#using-fastai-dataloaders",
    "title": "Using the Low-level fastai API",
    "section": "2. Using fastai DataLoaders",
    "text": "2. Using fastai DataLoaders\nLet’s start with a fresh set of huggingface objects\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, \n                                                                  model_cls=model_cls, \n                                                                  config_kwargs={'num_labels': n_lbls})\n\n… and the fix is this simple! Instead of using the PyTorch Dataloaders, let’s use the fastai flavor like this …\n\ntrain_dataloader = TextDataLoader(tokenized_datasets[train_ds_name], \n                                   hf_arch, hf_config, hf_tokenizer, hf_model,\n                                   preproccesing_func=preproc_hf_dataset, shuffle=True, batch_size=bsz)\n\neval_dataloader = TextDataLoader(tokenized_datasets[valid_ds_name],\n                                  hf_arch, hf_config, hf_tokenizer, hf_model,\n                                  preproccesing_func=preproc_hf_dataset, batch_size=val_bsz)\n\ndls = DataLoaders(train_dataloader, eval_dataloader)\n\nEverything else is the same … but now we get both our fast.ai AND Blurr features back!\n\ndls.show_batch(dataloaders=dls, trunc_at=500, max_n=2)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      The broader Standard & Poor's 500 Index <.SPX > edged down 9 points, or 0.98 percent, to 921. The Standard & Poor's 500 Index shed 5.20, or 0.6 percent, to 924.42 as of 9 : 33 a.m. in New York.\n      1\n    \n    \n      1\n      \" When I talked to him last time, did I think that was the end-all - one conversation with somebody? When I talked to him last time, did I think it was the end-all?\n      1\n    \n  \n\n\n\n\nb = dls.one_batch()\nb[0]['input_ids'].shape, b[1].shape, b[0]['input_ids'].device, b[1].device\n\n(torch.Size([16, 81]),\n torch.Size([16]),\n device(type='cpu'),\n device(type='cpu'))\n\n\n\nTrain\n\nmodel = BaseModelWrapper(hf_model)\n\nlearn = Learner(dls, \n                model,\n                opt_func=partial(Adam),\n                loss_func=PreCalculatedCrossEntropyLoss(),\n                metrics=task_metrics,\n                cbs=[BaseModelCallback],\n                splitter=blurr_splitter).to_fp16()\n\nlearn.freeze()\n\n\nlearn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\nSuggestedLRs(minimum=0.0007585775572806596, steep=0.0063095735386013985, valley=0.0004786300996784121, slide=0.0003981071640737355)\n\n\n\n\n\n\nlearn.fit_one_cycle(1, lr_max=2e-3)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.531747\n      0.474415\n      0.855738\n      0.784314\n      00:12\n    \n  \n\n\n\n\nlearn.unfreeze()\nlearn.lr_find(start_lr=1e-12, end_lr=2e-3, suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\nSuggestedLRs(minimum=1.6185790555067748e-12, steep=1.3065426344993636e-11, valley=7.238505190798605e-07, slide=1.451419939257903e-05)\n\n\n\n\n\n\nlearn.fit_one_cycle(2, lr_max=slice(2e-5, 2e-4))\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.461239\n      0.342700\n      0.887299\n      0.845588\n      00:20\n    \n    \n      1\n      0.274237\n      0.305770\n      0.897527\n      0.857843\n      00:20\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, trunc_at=500, max_n=2)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      The state's House delegation currently consists of 17 Democrats and 15 Republicans. Democrats hold a 17-15 edge in the state's U.S. House delegation.\n      1\n      0\n    \n    \n      1\n      The announcement was made during the recording of a Christmas concert attended by top Vatican cardinals, bishops, and many elite from Italian society, witnesses said. The broadside came during the recording on Saturday night of a Christmas concert attended by top Vatican cardinals, bishops and many elite of Italian society, witnesses said.\n      1\n      1\n    \n  \n\n\n\n\n\nEvaluate\nHow did we do?\n\nval_res = learn.validate()\n\n\n\n\n\nval_res_d = { 'loss': val_res[0]}\nfor idx, m in enumerate(learn.metrics): val_res_d[m.name] = val_res[idx+1]\n    \nval_res_d\n\n{'loss': 0.30576950311660767,\n 'f1_score': 0.8975265017667844,\n 'accuracy': 0.8578431606292725}\n\n\nNow we can use Learner.get_preds()\n\npreds, targs = learn.get_preds()\nprint(preds.shape, targs.shape)\nprint(accuracy(preds, targs))\n\n\n\n\ntorch.Size([408, 2]) torch.Size([408])\nTensorBase(0.8578)\n\n\n\n\nInference\nLet’s do item inference on an example from our test dataset\n\nraw_test_df = raw_datasets[test_ds_name].to_pandas()\nraw_test_df.head()\n\n\n\n\n\n  \n    \n      \n      idx\n      label\n      sentence1\n      sentence2\n    \n  \n  \n    \n      0\n      0\n      1\n      PCCW 's chief operating officer , Mike Butcher , and Alex Arena , the chief financial officer , will report directly to Mr So .\n      Current Chief Operating Officer Mike Butcher and Group Chief Financial Officer Alex Arena will report to So .\n    \n    \n      1\n      1\n      1\n      The world 's two largest automakers said their U.S. sales declined more than predicted last month as a late summer sales frenzy caused more of an industry backlash than expected .\n      Domestic sales at both GM and No. 2 Ford Motor Co. declined more than predicted as a late summer sales frenzy prompted a larger-than-expected industry backlash .\n    \n    \n      2\n      2\n      1\n      According to the federal Centers for Disease Control and Prevention ( news - web sites ) , there were 19 reported cases of measles in the United States in 2002 .\n      The Centers for Disease Control and Prevention said there were 19 reported cases of measles in the United States in 2002 .\n    \n    \n      3\n      3\n      0\n      A tropical storm rapidly developed in the Gulf of Mexico Sunday and was expected to hit somewhere along the Texas or Louisiana coasts by Monday night .\n      A tropical storm rapidly developed in the Gulf of Mexico on Sunday and could have hurricane-force winds when it hits land somewhere along the Louisiana coast Monday night .\n    \n    \n      4\n      4\n      0\n      The company didn 't detail the costs of the replacement and repairs .\n      But company officials expect the costs of the replacement work to run into the millions of dollars .\n    \n  \n\n\n\n\n\ntest_ex_idx = 0\ntest_ex = raw_test_df.iloc[test_ex_idx][task_inputs].values.tolist()\n\n\ninputs = hf_tokenizer(*test_ex, return_tensors=\"pt\").to('cuda:1')\n\n\noutputs = hf_model(**inputs)\noutputs.logits\n\ntensor([[-1.8848,  2.3550]], device='cuda:1', grad_fn=<AddmmBackward0>)\n\n\n\ntorch.argmax(torch.softmax(outputs.logits, dim=-1))\n\ntensor(1, device='cuda:1')\n\n\nLet’s do batch inference on the entire test dataset using dls.test_dl\n\ntest_dl = dls.test_dl(tokenized_datasets[test_ds_name])\npreds = learn.get_preds(dl=test_dl)\npreds\n\n\n\n\n(tensor([[0.0142, 0.9858],\n         [0.0965, 0.9035],\n         [0.0098, 0.9902],\n         ...,\n         [0.0504, 0.9496],\n         [0.0096, 0.9904],\n         [0.0355, 0.9645]]),\n tensor([1, 1, 1,  ..., 0, 1, 1]))"
  },
  {
    "objectID": "examples.text.glue_low_level_api.html#summary",
    "href": "examples.text.glue_low_level_api.html#summary",
    "title": "Using the Low-level fastai API",
    "section": "Summary",
    "text": "Summary\nSo you can see, with one simple swap of the DataLoader objects, you can get back a lot of that nice fastai functionality folks using the mid/high-level APIs have at their disposal. Nevertheless, if you’re hell bent on using the standard PyTorch DataLoaders, you’re still good to go with using the fastai Learner, it’s callbacks, etc…"
  },
  {
    "objectID": "examples.text.high_level_api.html",
    "href": "examples.text.high_level_api.html",
    "title": "Using the high-level Blurr API",
    "section": "",
    "text": "While most of the code and examples in the documentation show how to work with Blurr given a pandas Dataframe, these set of examples will show you how to use the high-level Blurr API with any Hugging Face dataset. The high-level API provides one liners to build your DataBlock, DataLoaders, and Learner (with sensible defaults) from a DataFrame, CSV file, or a list of dictionaries as we do so here."
  },
  {
    "objectID": "examples.text.high_level_api.html#sequence-classification",
    "href": "examples.text.high_level_api.html#sequence-classification",
    "title": "Using the high-level Blurr API",
    "section": "Sequence Classification",
    "text": "Sequence Classification\n\nMulticlassification (one input)\n\nraw_datasets = load_dataset(\"glue\", \"cola\")\nprint(f\"{raw_datasets}\\n\")\nprint(f'{raw_datasets[\"train\"][0]}\\n')\nprint(f'{raw_datasets[\"train\"].features}\\n')\n\nReusing dataset glue (/home/wgilliam/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['idx', 'label', 'sentence'],\n        num_rows: 8551\n    })\n    validation: Dataset({\n        features: ['idx', 'label', 'sentence'],\n        num_rows: 1043\n    })\n    test: Dataset({\n        features: ['idx', 'label', 'sentence'],\n        num_rows: 1063\n    })\n})\n\n{'idx': 0, 'label': 1, 'sentence': \"Our friends won't buy this analysis, let alone the next one we propose.\"}\n\n{'idx': Value(dtype='int32', id=None), 'label': ClassLabel(num_classes=2, names=['unacceptable', 'acceptable'], names_file=None, id=None), 'sentence': Value(dtype='string', id=None)}\n\n\n\nCapture the indexes for both train and validation sets, use the datasets concatenate_datasets to put them into a single dataset, and finally use the IndexSplitter method to define our train/validation splits as such:\n\ntrain_ds = raw_datasets[\"train\"]  # .select(range(10000))\nvalid_ds = raw_datasets[\"validation\"]  # .select(range(2000))\n\n\nn_train, n_valid = train_ds.num_rows, valid_ds.num_rows\ntrain_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\nraw_ds = concatenate_datasets([train_ds, valid_ds])\n\n\ndl_kwargs = {\"bs\": 4, \"val_bs\": 8}\nlearn_kwargs = {\"metrics\": [accuracy]}\n\nlearn = BlearnerForSequenceClassification.from_data(\n    raw_ds,\n    \"distilroberta-base\",\n    text_attr=\"sentence\",\n    label_attr=\"label\",\n    dblock_splitter=IndexSplitter(valid_idxs),\n    dl_kwargs=dl_kwargs,\n    learner_kwargs=learn_kwargs,\n)\nlearn = learn.to_fp16()\n\n\nlearn.dls.show_batch(dataloaders=learn.dls, trunc_at=500, max_n=5)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      Everybody who has ever, worked in any office which contained any typewriter which had ever been used to type any letters which had to be signed by any administrator who ever worked in any department like mine will know what I mean.\n      1\n    \n    \n      1\n      I watched the Indians who the man who had been my advisor in my freshman year had advised me to study when I got to Utah talk.\n      0\n    \n    \n      2\n      Which packages is it possible that Sam didn't pick up which are to be mailed tomorrow until it had stopped raining?\n      0\n    \n    \n      3\n      Willy is taller than Bill by as much as that Bill is taller than Dan is believed.\n      0\n    \n  \n\n\n\n\nlearn.fit_one_cycle(1, lr_max=2e-3)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.477010\n      0.519977\n      0.746884\n      00:53\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=5)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      Scientists at the South Hanoi Institute of Technology have succeeded in raising one dog with five legs, another with a cow's liver, and a third with no head.\n      1\n      1\n    \n    \n      1\n      The newspaper has reported that they are about to appoint someone, but I can't remember who the newspaper has reported that they are about to appoint.\n      1\n      1\n    \n    \n      2\n      Sandy is very anxious to see if the students will be able to solve the homework problem in a particular way, but she won't tell us in which way.\n      1\n      1\n    \n    \n      3\n      Sandy is very anxious to see if the students will be able to solve the homework problem in a particular way, but she won't tell us which.\n      1\n      1\n    \n    \n      4\n      Put a picture of Bill on your desk before tomorrow, this girl in the red coat will put a picture of Bill on your desk before tomorrow.\n      0\n      1\n    \n  \n\n\n\nLearner.blurr_predict works here too\n\nlearn.blurr_predict(\"Blurr aint no joke yo\")\n\n[{'label': '0',\n  'score': 0.6082450747489929,\n  'class_index': 0,\n  'class_labels': [0, 1],\n  'probs': [0.6082450747489929, 0.3917549252510071]}]\n\n\n\n\nMulticlassification (two inputs)\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")\nprint(f\"{raw_datasets}\\n\")\nprint(f'{raw_datasets[\"train\"][0]}\\n')\nprint(f'{raw_datasets[\"train\"].features}\\n')\n\nReusing dataset glue (/home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['idx', 'label', 'sentence1', 'sentence2'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['idx', 'label', 'sentence1', 'sentence2'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['idx', 'label', 'sentence1', 'sentence2'],\n        num_rows: 1725\n    })\n})\n\n{'idx': 0, 'label': 1, 'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'}\n\n{'idx': Value(dtype='int32', id=None), 'label': ClassLabel(num_classes=2, names=['not_equivalent', 'equivalent'], names_file=None, id=None), 'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None)}\n\n\n\n\ntrain_ds = raw_datasets[\"train\"]  # .select(range(10000))\nvalid_ds = raw_datasets[\"validation\"]  # .select(range(2000))\n\n\nn_train, n_valid = train_ds.num_rows, valid_ds.num_rows\ntrain_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\nraw_ds = concatenate_datasets([train_ds, valid_ds])\n\n\ndl_kwargs = {\"bs\": 4, \"val_bs\": 8}\nlearn_kwargs = {\"metrics\": [F1Score(), accuracy]}\n\nlearn = BlearnerForSequenceClassification.from_data(\n    raw_ds,\n    \"distilroberta-base\",\n    text_attr=[\"sentence1\", \"sentence2\"],\n    label_attr=\"label\",\n    dblock_splitter=IndexSplitter(valid_idxs),\n    dl_kwargs=dl_kwargs,\n    learner_kwargs=learn_kwargs,\n)\nlearn = learn.to_fp16()\n\n\nlearn.dls.show_batch(dataloaders=learn.dls, trunc_at=500, max_n=5)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      \" In Iraq, \" Sen. Pat Roberts, R-Kan., chairman of the intelligence committee, said on CNN's \" Late Edition \" Sunday, \" we're now fighting an anti-guerrilla... effort. \" \" In Iraq, \" Sen. Pat Roberts ( R-Kan. ), chairman of the intelligence committee, said on CNN's \" Late Edition \" yesterday, \" we're now fighting an anti-guerrilla... effort. \"\n      1\n    \n    \n      1\n      Media moguls jostled for position as the deadline for bids for Vivendi Universal's U.S. entertainment empire neared on Monday in an auction of some of Hollywood's best-known assets. Media giant Vivendi Universal has given itself two weeks to sift through offers for its U.S. entertainment empire in a multi-billion dollar auction of some of Hollywood's best-known assets.\n      1\n    \n    \n      2\n      Against the dollar, the euro rose as high as $ 1.1535 -- a fresh four-year high -- in morning trade before standing at $ 1.1518 / 23 at 0215 GMT. Against the dollar, the euro rose as high as $ 1.1537, a fresh four-year high and up a half cent from around $ 1.1480 in late U.S. trade.\n      0\n    \n    \n      3\n      Under the NBC proposal, Vivendi would merge its U.S. film and TV business with NBC's broadcast network, Spanish-language network and cable channels including CNBC and Bravo. Under a deal with General Electric's NBC, Vivendi's film and TV business would merge with NBC's broadcast network, Spanish- language network and cable channels including CNBC and Bravo.\n      1\n    \n  \n\n\n\n\nlearn.fit_one_cycle(1, lr_max=2e-3)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.489009\n      0.444209\n      0.861386\n      0.794118\n      00:22\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=5)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      He said the foodservice pie business doesn 't fit the company's long-term growth strategy. \" The foodservice pie business does not fit our long-term growth strategy.\n      1\n      1\n    \n    \n      1\n      \" Close co-operation between our law enforcement agencies, close co-operation between our intelligence services lie at the heart of the ongoing fight against terrorism. \" Close cooperation between regional law enforcement agencies and intelligence services was at the heart of the fight against terrorism, he said.\n      1\n      1\n    \n    \n      2\n      They were being held Sunday in the Camden County Jail on $ 100,000 bail. They remained in Camden County Jail on Sunday on $ 100,000 bail.\n      1\n      1\n    \n    \n      3\n      Sales for the quarter beat expectations, rising 37 percent year-on-year to 1.76 billion euros. Sales rose 37 per cent year-on-year to 1.76bn, beating expectations.\n      1\n      1\n    \n    \n      4\n      ONG KONG, July 9 Tens of thousands of demonstrators gathered tonight before the legislature building here to call for free elections and the resignation of Hong Kong's leader. Tens of thousands of demonstrators gathered yesterday evening to stand before this city's legislature building and call for free elections and the resignation of Hong Kong's leader.\n      1\n      1\n    \n  \n\n\n\n\n\nMultilabel classification\n\nraw_datasets = load_dataset(\"civil_comments\")\nprint(f\"{raw_datasets}\\n\")\nprint(f'{raw_datasets[\"train\"][0]}\\n')\nprint(f'{raw_datasets[\"train\"].features}\\n')\n\nUsing custom data configuration default\nReusing dataset civil_comments (/home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab)\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['identity_attack', 'insult', 'obscene', 'severe_toxicity', 'sexual_explicit', 'text', 'threat', 'toxicity'],\n        num_rows: 1804874\n    })\n    validation: Dataset({\n        features: ['identity_attack', 'insult', 'obscene', 'severe_toxicity', 'sexual_explicit', 'text', 'threat', 'toxicity'],\n        num_rows: 97320\n    })\n    test: Dataset({\n        features: ['identity_attack', 'insult', 'obscene', 'severe_toxicity', 'sexual_explicit', 'text', 'threat', 'toxicity'],\n        num_rows: 97320\n    })\n})\n\n{'identity_attack': 0.0, 'insult': 0.0, 'obscene': 0.0, 'severe_toxicity': 0.0, 'sexual_explicit': 0.0, 'text': \"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\", 'threat': 0.0, 'toxicity': 0.0}\n\n{'identity_attack': Value(dtype='float32', id=None), 'insult': Value(dtype='float32', id=None), 'obscene': Value(dtype='float32', id=None), 'severe_toxicity': Value(dtype='float32', id=None), 'sexual_explicit': Value(dtype='float32', id=None), 'text': Value(dtype='string', id=None), 'threat': Value(dtype='float32', id=None), 'toxicity': Value(dtype='float32', id=None)}\n\n\n\n\nlbl_cols = [\"identity_attack\", \"insult\", \"obscene\", \"toxicity\", \"severe_toxicity\", \"sexual_explicit\", \"threat\"]\n\n\ntrain_ds = raw_datasets[\"train\"].select(range(10000))\nvalid_ds = raw_datasets[\"validation\"].select(range(2000))\n\n\nn_train, n_valid = len(train_ds), len(valid_ds)\ntrain_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\nraw_ds = concatenate_datasets([train_ds, valid_ds])\n\nThe labels need to be OHE as ints (the raw data has them as floats). We could also do this kind of preprocessing by passing in a preprocess_func to our BlearnerForSequenceClassification factory method, especially useful if such preprocessing depends on one or more of the Hugging Face objects (e.g., config, tokenizer, model, architecture)\n\ndef make_ohe(item):\n    for k in item.keys():\n        if k in lbl_cols:\n            item[k] = int(np.round(item[k]))\n    return item\n\n\nraw_ds = raw_ds.map(make_ohe)\n\n\n\n\n\ndl_kwargs = {\"bs\": 4, \"val_bs\": 8}\nlearn_kwargs = {\"metrics\": [F1ScoreMulti(), accuracy_multi]}\n\n# using a List[dict] such as a Hugging Face dataset\nlearn = BlearnerForSequenceClassification.from_data(\n    raw_ds,\n    \"distilroberta-base\",\n    text_attr=\"text\",\n    label_attr=lbl_cols,\n    dblock_splitter=IndexSplitter(valid_idxs),\n    dl_kwargs=dl_kwargs,\n    learner_kwargs=learn_kwargs,\n)\nlearn = learn.to_fp16()\n\n\nlearn.dls.show_batch(dataloaders=learn.dls, trunc_at=500, max_n=5)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      I have had a question about Einstein's Special Theory of Relativity for some time which scientists all seem to run away from.  Until 1887 the equations used for Relativity were the Galilean transformation equations.\\n\\n                                                   x'=x-vt\\n                                                   y'=y\\n                                                   z'=z\\n                                                   t'=t\\n\\nAfter 1887, scientists threw away the Galilean transfo\n      []\n    \n    \n      1\n      To Maintain The Status Quo Of A 12% Road Repair Deficit Over The Next Five Years\\nFY 16/17 = $11,400,000 + $43,600,000 = $55,00,000\\nFY 17/18 = $11,400,000 + $43,600,000 = $55,00,000\\nFY 18/19 = $11,400,000 + $43,600,000 = $55,00,000\\nFY 19/20 = $11,400,000 + $43,600,000 = $55,00,000\\nFY 20/21 = $11,400,000 + $43,600,000 = $55,00,000\\nTotal over 5 years = $275,000,000\\n\\n1. The Portland city council shall adopt a five year road repair budget agreement that uses funds already available in the general fu\n      []\n    \n    \n      2\n      \"Voodoo Journalism: Dr. Krugman Strikes Again—Risking His Credibility\":\\n\\n\"The fact that Sanders’ ethical platform does, in fact, result in economic gains shouldn’t be surprising. Empirical evidence shows that the 3 times we’ve adopted a laisez-fair approach to regulating the economy, it has resulted in extreme income inequality leading inevitably to the 3 biggest economic disruptions in US history: the Depression in 1890’s, the Great Depression in 1930’s, and the Great Recession in 2008. This s\n      []\n    \n    \n      3\n      Again, interesting.  First, I don’t think anyone in this discussion has self-defined as “far left.”  I would, for myself, as I believe in universal health care, nationalizing all utilities—including oil companies and big banks, free education (PK-grad), and 1950s tax rates (91% marginal tax rate is about right).  NOBODY in Congress is proposing any of those, so there really is no “far left” representation in Congress.\\nRe the marriage equality issue.  What is RIGHT with it is that it guarantees\n      []\n    \n  \n\n\n\n\nlearn.fit_one_cycle(1, lr_max=2e-3)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.029894\n      0.047098\n      0.098025\n      0.986285\n      01:10\n    \n  \n\n\n\n/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n\n\n\nlearn.show_results(learner=learn, trun_at=500, max_n=5)\n\n\n\n\n/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      Everyone tries to hack everyone else.   I have no doubt Russia would try to hack even canada.   However, the US has been doing the same, if we recall Snowden.\\n\\nEven Merkel's phone conversations were being tapped by the CIA. \\n\\nThe real purpose of this issue is political.  Trump is upset because people are trying to imply that he didn't deserve his victory, that the Russians helped him.  It's an ego thing.  Good CEOs sometimes have giant egos.  I have no problem with that as long as they produce results, I gladly buy shares in their company.\\n\\nOtoh, Russia did invade Crimea recently, and their missile brought down a commercial airliner and killed lots of innocent people.  The world has a right to be annoyed at the Russians.\\n\\nIf you want to find evidence of Russians hacking, you will find them.  But if you want to find China or some guy in a basement somewhere, I have no doubt you can find the same as well.  Whether they succeeded or not, that's hard to prove, but there's lots of blackhats\n      []\n      []\n    \n    \n      1\n      \"We will stand by the Governor as he searches for answers to the crime wave.\" says Senator Kelly.\\n  Where the heck has Kelly been the last three years as the crime wave grew?.  And just what is your job Kelly?..if the Governor is doing the one doing the searching?  Oh I remember,..it`s to continue to be against broad-based taxes once again for Alaska, for any reasonable fix he comes up with, as your Senate caucus has said for four special sessions \"there will be no tax bill to raise revenue\" for whatever \"fixes\" you say we need, and that the Governor searches,,..without you apparently.  They say in the media your back-pedaling now, that your now willing to have the debate over the need for a tax to put this state on a balanced keel going forward.  We`ll see if your oily conflicted fellow senators agree.   Voters are watching, and want a plan to fix this crime/budget issue. If it takes more cops and new taxes to get it done then let's do it.  We had a tax before and nobody died from it.\n      []\n      []\n    \n    \n      2\n      Mr. Alali, I am sympathetic to your position and feelings. As a Canadian I hold no ill will towards you or your family relocating to Canada. You should be aware that you and your family have been used as political pawns following the glib and ill conceived election promise made by our Prime Minister to bring 25 thousand of your compatriots to Canada by the end of 2015. It sounds as if Mr McCallum and assistants scoured UN refugee lists in an effort to press gang hapless individuals and coerce them into settling and being shipped to Canada. The expedition of your arrival was made with no regard to the logistics of accommodating vulnerable and traumatized families in a respectful and decent manner following your staged and publicized arrivals. As for your future in Canada I fear you will be lucky to find some subsistence level employment. The chances are that your children, if you allow them to assimilate into the Canadian culture, will thrive and have a rewarding life in here. Good Luck\n      []\n      []\n    \n    \n      3\n      I abjure violence of any kind and this includes violence propagated through money by those who have the means to do so.  I believe in free speech except when used to incite violence or hatred.  I believe in the right of individual freedoms providing  harm to others is not caused..  This is my bias.\\n\\nOthers believe an economic and social order that favours a few is natural to human nature and that those who can gain advantage, without consideration of harm to others, should be allowed to do so.  That is their bias.\\n\\nEither view will result in bad behaviour by either side depending on who is ascendant.  Trump was not against suppressing free speech or condoning violence as one could see during his campaign rallies.\\n\\nThe world will never be perfect or fair but beginning with Roosevelt and ending with Reagan there was a time when average people could see a slow but steady increase in living standards and opportunity.  The rise of neo-liberal policies has removed this expectation for most.\n      []\n      []\n    \n    \n      4\n      Regarding \"Lonely Woman\" Yes, involve herself in organizations but perhaps not a church. I enjoy my church and it is important but... Many have gossips. When living in Denver my best friend Linda and I attended together for years and I was a maid of honer in her wedding. When they moved, I attended alone and some wives began speculating I was looking for a husband. Some of the single guys heard variations of that speculation. During service a guy slid across to me and began flirting. I whispered loud enough for all around me to hear, \"Who are you! Get lost!\" The minister heard. He took a second to force down a laugh and nodded at me. The guy slithered away. The gossips saw and were nice to me afterward but that was my last day. I still saw friends who assured me it was only a few bad apples. Point being to \"Lonely Woman\" Some churches have gossip mongrels who ruin it for young, decent women. Here's an oldie but goodie for you gossips. \"Do not bare false witness against your neighbor.\"\n      []\n      []"
  },
  {
    "objectID": "examples.text.high_level_api.html#token-classification",
    "href": "examples.text.high_level_api.html#token-classification",
    "title": "Using the high-level Blurr API",
    "section": "Token Classification",
    "text": "Token Classification\n\nraw_datasets = load_dataset(\"germeval_14\")\nprint(f\"{raw_datasets}\\n\")\nprint(f'{raw_datasets[\"train\"][0]}\\n')\nprint(f'{raw_datasets[\"train\"].features}\\n')\n\nReusing dataset germ_eval14 (/home/wgilliam/.cache/huggingface/datasets/germ_eval14/germeval_14/2.0.0/0f174b84866aa3b8ebae65c271610520be4422405d7e8467bd24cfd493d325f0)\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'ner_tags', 'nested_ner_tags', 'source', 'tokens'],\n        num_rows: 24000\n    })\n    validation: Dataset({\n        features: ['id', 'ner_tags', 'nested_ner_tags', 'source', 'tokens'],\n        num_rows: 2200\n    })\n    test: Dataset({\n        features: ['id', 'ner_tags', 'nested_ner_tags', 'source', 'tokens'],\n        num_rows: 5100\n    })\n})\n\n{'id': '0', 'ner_tags': [19, 0, 0, 0, 7, 0, 0, 0, 0, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'nested_ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'source': 'n-tv.de vom 26.02.2005 [2005-02-26] ', 'tokens': ['Schartau', 'sagte', 'dem', '\"', 'Tagesspiegel', '\"', 'vom', 'Freitag', ',', 'Fischer', 'sei', '\"', 'in', 'einer', 'Weise', 'aufgetreten', ',', 'die', 'alles', 'andere', 'als', 'überzeugend', 'war', '\"', '.']}\n\n{'id': Value(dtype='string', id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=25, names=['O', 'B-LOC', 'I-LOC', 'B-LOCderiv', 'I-LOCderiv', 'B-LOCpart', 'I-LOCpart', 'B-ORG', 'I-ORG', 'B-ORGderiv', 'I-ORGderiv', 'B-ORGpart', 'I-ORGpart', 'B-OTH', 'I-OTH', 'B-OTHderiv', 'I-OTHderiv', 'B-OTHpart', 'I-OTHpart', 'B-PER', 'I-PER', 'B-PERderiv', 'I-PERderiv', 'B-PERpart', 'I-PERpart'], names_file=None, id=None), length=-1, id=None), 'nested_ner_tags': Sequence(feature=ClassLabel(num_classes=25, names=['O', 'B-LOC', 'I-LOC', 'B-LOCderiv', 'I-LOCderiv', 'B-LOCpart', 'I-LOCpart', 'B-ORG', 'I-ORG', 'B-ORGderiv', 'I-ORGderiv', 'B-ORGpart', 'I-ORGpart', 'B-OTH', 'I-OTH', 'B-OTHderiv', 'I-OTHderiv', 'B-OTHpart', 'I-OTHpart', 'B-PER', 'I-PER', 'B-PERderiv', 'I-PERderiv', 'B-PERpart', 'I-PERpart'], names_file=None, id=None), length=-1, id=None), 'source': Value(dtype='string', id=None), 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}\n\n\n\n\ntrain_ds = raw_datasets[\"train\"].select(range(1000))\nvalid_ds = raw_datasets[\"validation\"].select(range(500))\n\n\nn_train, n_valid = train_ds.num_rows, valid_ds.num_rows\ntrain_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\nraw_ds = concatenate_datasets([train_ds, valid_ds])\n\nWe can grab the “labels” a token can be associated with as we do here or we can let the BlearnerForTokenClassification factory methods figure it out for us.\n\nlabels = train_ds.features[\"ner_tags\"].feature.names\nlen(labels)\n\n25\n\n\nAs we need pass the tag (not the index) for each example’s tokens in a list, we use the handy datasets.map function to create a new attribute, “token_labels”, with that data. This could also be done by passing in a preprocess_func to a BlearnerForTokenClassification factory method; especially useful if we need to use one or more of the Hugging Face objects (e.g., tokenzier, model, config, or architecture name)\n\ndef get_item_labels(example):\n    example[\"token_labels\"] = [labels[tag_idx] for tag_idx in example[\"ner_tags\"]]\n    return example\n\n\nraw_ds = raw_ds.map(get_item_labels)\n\n\n\n\n\nlearn = BlearnerForTokenClassification.from_data(\n    raw_ds,\n    \"distilroberta-base\",\n    tokens_attr=\"tokens\",\n    token_labels_attr=\"ner_tags\",\n    labels=labels,\n    dl_kwargs={\"bs\": 2},\n)\n\nlearn.unfreeze()\n\n\nlearn.dls.show_batch(dataloaders=learn.dls, max_n=2)\n\n\n\n  \n    \n      \n      word / target label\n    \n  \n  \n    \n      0\n      [('Helbig', 'B-OTH'), ('et', 'I-OTH'), ('al', 'I-OTH'), ('.', 'O'), ('(', 'O'), ('1994', 'O'), (')', 'O'), ('S.', 'O'), ('593.', 'O'), ('Wink', 'B-OTH'), ('&', 'I-OTH'), ('Seibold', 'I-OTH'), ('et', 'I-OTH'), ('al', 'I-OTH'), ('.', 'O'), ('(', 'O'), ('1998', 'O'), (')', 'O'), ('S.', 'O'), ('32', 'O'), ('Inwieweit', 'O'), ('noch', 'O'), ('andere', 'O'), ('Falken', 'O'), (',', 'O'), ('wie', 'O'), ('der', 'O'), ('Afrikanische', 'B-LOCderiv'), ('Baumfalke', 'O'), ('(', 'O'), ('Falco', 'O'), ('cuvieri', 'O'), (')', 'O'), ('oder', 'O'), ('der', 'O'), ('Malaienbaumfalke', 'O'), ('(', 'O'), ('Falco', 'O'), ('serverus', 'O'), (')', 'O'), ('dieser', 'O'), ('Gruppe', 'O'), ('zuzuzählen', 'O'), ('sind', 'O'), (',', 'O'), ('ist', 'O'), ('Gegenstand', 'O'), ('der', 'O'), ('Forschung', 'O'), ('.', 'O')]\n    \n    \n      1\n      [('Erstmals', 'O'), ('Urkundlich', 'O'), ('erwähnt', 'O'), ('ist', 'O'), ('Nimburg', 'B-LOC'), ('bereits', 'O'), ('im', 'O'), ('Jahre', 'O'), ('977', 'O'), ('.', 'O'), ('Im', 'O'), ('ausgehenden', 'O'), ('11.', 'O'), ('Jahrhundert', 'O'), ('werden', 'O'), ('die', 'O'), ('Grafen', 'O'), ('von', 'O'), ('Nimburg', 'B-LOC'), ('erwähnt', 'O'), (',', 'O'), ('die', 'O'), ('Gefolgsleute', 'O'), ('der', 'O'), ('in', 'O'), ('jener', 'O'), ('Zeit', 'O'), ('mächtigen', 'O'), ('Herzöge', 'O'), ('von', 'O'), ('Zähringen', 'O'), ('und', 'O'), ('unter', 'O'), ('anderem', 'O'), ('auch', 'O'), ('Teilnehmer', 'O'), ('der', 'O'), ('Kreuzzüge', 'O'), ('waren', 'O'), ('.', 'O')]\n    \n  \n\n\n\n\nlearn.fit_one_cycle(1, lr_max=3e-5, moms=(0.8, 0.7, 0.8), cbs=[BlearnerForTokenClassification.get_metrics_cb()])\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      precision\n      recall\n      f1\n      time\n    \n  \n  \n    \n      0\n      0.287480\n      0.260162\n      0.934187\n      0.422222\n      0.548077\n      0.476987\n      00:28\n    \n  \n\n\n\n/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=10)\n\n\n\n\n\n\n  \n    \n      \n      token / target label / predicted label\n    \n  \n  \n    \n      0\n      [('Wenn', 'O', 'O'), ('man', 'O', 'O'), ('gegen', 'O', 'O'), ('so', 'O', 'O'), ('eine', 'O', 'O'), ('Mannschaft', 'O', 'O'), ('trifft', 'O', 'O'), (',', 'O', 'O'), ('hat', 'O', 'O'), ('man', 'O', 'O')]\n    \n    \n      1\n      [('Die', 'O', 'O'), ('Flügel', 'O', 'O'), ('Die', 'O', 'O'), ('geöffneten', 'O', 'O'), ('Flügel', 'O', 'O'), ('zeigen', 'O', 'O'), ('in', 'O', 'O'), ('vier', 'O', 'O'), ('Szenen', 'O', 'O'), ('Höhepunkte', 'O', 'O')]\n    \n  \n\n\n\n\nprint(learn.token_classification_report)\n\n              precision    recall  f1-score   support\n\n         LOC       0.62      0.51      0.56       129\n    LOCderiv       0.49      0.72      0.58        25\n     LOCpart       0.00      0.00      0.00         0\n         ORG       0.22      0.27      0.24        60\n     ORGpart       0.00      0.00      0.00         0\n         OTH       0.04      0.67      0.08         3\n    OTHderiv       0.00      0.00      0.00         0\n     OTHpart       0.00      0.00      0.00         0\n         PER       0.69      0.73      0.71        95\n    PERderiv       0.00      0.00      0.00         0\n     PERpart       0.00      0.00      0.00         0\n\n   micro avg       0.42      0.55      0.48       312\n   macro avg       0.19      0.26      0.20       312\nweighted avg       0.55      0.55      0.54       312\n\n\n\nLearner.blurr_predict_tokens works here too\n\ntxt = \"I live in California, but I'd love to travel to Scotland and visit the Macallan distillery.\"\ntxt2 = \"Jane Doe loves working for ohmeow.com.\"\n\n\nresults = learn.predict([txt, txt2])\nfor res in results:\n    print(f\"{res}\\n\")\n\n[{'entity_group': 'LOC', 'score': 0.2773939371109009, 'word': 'in', 'start': 7, 'end': 9}, {'entity_group': 'LOC', 'score': 0.354379802942276, 'word': 'California', 'start': 10, 'end': 20}, {'entity_group': 'LOC', 'score': 0.2855808138847351, 'word': 'to', 'start': 45, 'end': 47}, {'entity_group': 'LOC', 'score': 0.41248050332069397, 'word': 'Scotland', 'start': 48, 'end': 56}, {'entity_group': 'LOC', 'score': 0.26863470673561096, 'word': 'Mac', 'start': 71, 'end': 74}, {'entity_group': 'LOC', 'score': 0.17475469410419464, 'word': 'all', 'start': 74, 'end': 77}, {'entity_group': 'LOC', 'score': 0.11444361507892609, 'word': 'an', 'start': 77, 'end': 79}]\n\n[{'entity_group': 'PER', 'score': 0.6308206021785736, 'word': 'Jane Doe', 'start': 0, 'end': 8}]"
  },
  {
    "objectID": "examples.text.high_level_api.html#question-answering",
    "href": "examples.text.high_level_api.html#question-answering",
    "title": "Using the high-level Blurr API",
    "section": "Question Answering",
    "text": "Question Answering\n\nraw_datasets = load_dataset(\"squad_v2\")\nprint(f\"{raw_datasets}\\n\")\nprint(f'{raw_datasets[\"train\"][0]}\\n')\nprint(f'{raw_datasets[\"train\"].features}\\n')\n\nReusing dataset squad_v2 (/home/wgilliam/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 130319\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 11873\n    })\n})\n\n{'id': '56be85543aeaaa14008c9063', 'title': 'Beyoncé', 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".', 'question': 'When did Beyonce start becoming popular?', 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}\n\n{'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}\n\n\n\n\ntrain_ds = raw_datasets[\"train\"].select(range(1000))\ntrain_df = train_ds.to_pandas()\n\nExtractive question/answering tasks require preprocessing, which we’ll apply prior to creating our BlearnerForQuestionAnswering.\n\ntrain_df[\"ans_start_char_idx\"] = train_df.answers.apply(lambda v: v[\"answer_start\"][0] if len(v[\"answer_start\"]) > 0 else \"0\")\ntrain_df[\"answer_text\"] = train_df.answers.apply(lambda v: v[\"text\"][0] if len(v[\"text\"]) > 0 else \"\")\ntrain_df[\"ans_end_char_idx\"] = train_df[\"ans_start_char_idx\"].astype(int) + train_df[\"answer_text\"].str.len()\n\n\nfrom blurr.text.data.question_answering import QAPreprocessor\n\n\npretrained_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\nhf_tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n\n# preprocess\ntok_kwargs = {\"return_overflowing_tokens\": True, \"max_length\": 128, \"stride\": 24}\npreprocessor = QAPreprocessor(hf_tokenizer, id_attr=\"id\", tok_kwargs=tok_kwargs)\nproc_df = preprocessor.process_df(train_df)\n\n# build our `Learner`\nlearn = BlearnerForQuestionAnswering.from_data(\n    proc_df, pretrained_model_name, max_seq_len=128, dblock_splitter=RandomSplitter(), dl_kwargs={\"bs\": 4}\n)\nlearn = learn.to_fp16()\n\n\nlearn.dls.show_batch(dataloaders=learn.dls, max_n=2, trunc_at=500)\n\n\n\n  \n    \n      \n      text\n      found\n      start/end\n      answer\n    \n  \n  \n    \n      0\n      which prominent star felt the 2009 female video of the year award should have went to beyonce instead of taylor swift? on april 4, 2008, beyonce married jay z. she publicly revealed their marriage in a video montage at the listening party for her third studio album, i am... sasha fierce, in manhattan's sony club on october 22, 2008. i am... sasha fierce was released on november 18, 2008 in the united states. the album formally introduces beyonce's alter ego sasha fierce, conceived during the mak\n      True\n      (74, 76)\n      . i\n    \n    \n      1\n      for which decade, did beyonce have more top ten songs than any other woman? on april 4, 2008, beyonce married jay z. she publicly revealed their marriage in a video montage at the listening party for her third studio album, i am... sasha fierce, in manhattan's sony club on october 22, 2008. i am... sasha fierce was released on november 18, 2008 in the united states. the album formally introduces beyonce's alter ego sasha fierce, conceived during the making of her 2003 single \" crazy in love \", s\n      False\n      (0, 0)\n      \n    \n  \n\n\n\n\nlearn.fit_one_cycle(1, lr_max=1e-3)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      2.262114\n      1.950846\n      01:09\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, skip_special_tokens=True, max_n=2, trunc_at=500)\n\n\n\n\n\n\n  \n    \n      \n      text\n      found\n      start/end\n      answer\n      pred start/end\n      pred answer\n    \n  \n  \n    \n      0\n      where was beyonce's first public performance after giving birth? on january 7, 2012, beyonce gave birth to her first child, a daughter, blue ivy carter, at lenox hill hospital in new york. five months later, she performed for four nights at revel atlantic city's ovation hall to celebrate the resort's opening, her first performances since giving birth to blue ivy.\n      True\n      (54, 63)\n      revel atlantic city's ovation hall\n      (54, 0)\n      \n    \n    \n      1\n      what was the name of beyonce's first dance instructor? beyonce attended st. mary's elementary school in fredericksburg, texas, where she enrolled in dance classes. her singing talent was discovered when dance instructor darlette johnson began humming a song and she finished it, able to hit the high - pitched notes. beyonce's interest in music and performing continued after winning a school talent show at age seven, singing john lennon's \" imagine \" to beat 15 / 16 - year - olds. in fall of 1990,\n      False\n      (0, 0)\n      \n      (44, 0)"
  },
  {
    "objectID": "examples.text.high_level_api.html#language-modeling",
    "href": "examples.text.high_level_api.html#language-modeling",
    "title": "Using the high-level Blurr API",
    "section": "Language modeling",
    "text": "Language modeling\n\nraw_datasets = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\nprint(f\"{raw_datasets}\\n\")\nprint(f'{raw_datasets[\"train\"][0]}\\n')\nprint(f'{raw_datasets[\"train\"].features}\\n')\n\n\n\n\n\n\n\nDownloading and preparing dataset wikitext/wikitext-2-raw-v1 (download: 4.50 MiB, generated: 12.90 MiB, post-processed: Unknown size, total: 17.40 MiB) to /home/wgilliam/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126...\n\n\n\n\n\n\n\n\n\n\n\nDataset wikitext downloaded and prepared to /home/wgilliam/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126. Subsequent calls will reuse this data.\n\n\n\n\n\nDatasetDict({\n    test: Dataset({\n        features: ['text'],\n        num_rows: 4358\n    })\n    train: Dataset({\n        features: ['text'],\n        num_rows: 36718\n    })\n    validation: Dataset({\n        features: ['text'],\n        num_rows: 3760\n    })\n})\n\n{'text': ''}\n\n{'text': Value(dtype='string', id=None)}\n\n\n\n\ntrain_ds = raw_datasets[\"train\"].select(range(1000))\nvalid_ds = raw_datasets[\"validation\"].select(range(1000))\n\n\nn_train, n_valid = train_ds.num_rows, valid_ds.num_rows\ntrain_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\nraw_ds = concatenate_datasets([train_ds, valid_ds])\n\n\ndef remove_empty_text(example):\n    if example[\"text\"].strip() == \"\":\n        example[\"text\"] = \"  \"\n    return example\n\n\nraw_ds = raw_ds.map(remove_empty_text)\n\n\n\n\nCausal language modeling\n\nlearn = BlearnerForLM.from_data(\n    raw_ds, \"gpt2\", text_attr=\"text\", lm_strategy_cls=CausalLMStrategy, dblock_splitter=IndexSplitter(valid_idxs), dl_kwargs={\"bs\": 2}\n).to_fp16()\n\nUsing pad_token, but it is not set yet.\n\n\n\nlearn.dls.show_batch(dataloaders=learn.dls, max_n=2, trunc_at=250)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      A lookout aboard Weehawken spotted Atlanta at 04 : 10 on the morning of 17 June. When the latter ship closed to within about 1 @.@ 5 miles ( 2 @.@ 4 km ) of the two Union ships, she fired one round from her bow gun that passed over Weehawken and lan\n      lookout aboard Weehawken spotted Atlanta at 04 : 10 on the morning of 17 June. When the latter ship closed to within about 1 @.@ 5 miles ( 2 @.@ 4 km ) of the two Union ships, she fired one round from her bow gun that passed over Weehawken and lande\n    \n    \n      1\n      The music was composed by Hitoshi Sakimoto, who had also worked on the previous Valkyria Chronicles games. When he originally heard about the project, he thought it would be a light tone similar to other Valkyria Chronicles games, but found the them\n      music was composed by Hitoshi Sakimoto, who had also worked on the previous Valkyria Chronicles games. When he originally heard about the project, he thought it would be a light tone similar to other Valkyria Chronicles games, but found the themes m\n    \n  \n\n\n\n\nlearn.fit_one_cycle(1, lr_max=3e-4, cbs=[BlearnerForLM.get_metrics_cb()])\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      perplexity\n      lm_accuracy\n      time\n    \n  \n  \n    \n      0\n      4.627799\n      4.504875\n      90.457054\n      0.268662\n      00:35\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=500)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      Meridian is rightly considered an architectural treasure trove being one the nations most intact cities from the turn of the last century. Architecture students from around the nation and Canada are known to visit Meridian in groups as part of their coursework due to numerous structures in the city having been designed by noted architects. The only home in the US south designed by noted Canadian born Architect Louis S. Curtiss, famous for inventing the glass curtain wall skyscraper, is extant o\n      is rightly considered an architectural treasure trove being one the nations most intact cities from the turn of the last century. Architecture students from around the nation and Canada are known to visit Meridian in groups as part of their coursework due to numerous structures in the city having been designed by noted architects. The only home in the US south designed by noted Canadian born Architect Louis S. Curtiss, famous for inventing the glass curtain wall skyscraper, is extant on Highlan\n      \\n a the.. of of and. the time of the century century.\\n is are the the world are the are for be the, the of well of the academic.. to the historical and the city. been built by and architect and\\n city of the world of of by renowned architects architect and.a.Siss. is for hising the first and,,raper, famous known in the Park, The onlyfort, by Mile,, located considered an of the most buildingsistico buildingsrapers in the world, is generally considered to the'ss Three Threeman. The only American ar\n    \n    \n      1\n      Meridian is served by the Meridian @-@ Lauderdale County Public Library, located at the corner of 7th Street and 26th Avenue. The city originally had two Carnegie libraries, both built in 1913 – one for blacks and one for whites. A group of women had formed the Fortnightly Book and Magazine Club in the 1880s and began raising money to build a library for the city. The books they collected and shared within the club were later the basis of the library collection for Meridian. With wide support f\n      is served by the Meridian @-@ Lauderdale County Public Library, located at the corner of 7th Street and 26th Avenue. The city originally had two Carnegie libraries, both built in 1913 – one for blacks and one for whites. A group of women had formed the Fortnightly Book and Magazine Club in the 1880s and began raising money to build a library for the city. The books they collected and shared within the club were later the basis of the library collection for Meridian. With wide support for the li\n      \\n a by the United Hotel The -,, Library. and at: intersection ofth and andth Avenue,\\n Meridian of opened a lakes Mellon, located of by the. the in the and one for whites. The new of people, been the \" Lauderdale @, Club Book,, citys. 1890 publishing money for a new. blacks city. The city were were were published with the city were the used book of the... the. The the from the city, the city was the,, a-, to the library libraryic, Carnegie, the the in The city was the and located in theth Street\n    \n  \n\n\n\nLearner.blurr_generate works here too\n\nlearn.blurr_generate(\"Blurr is fun to work with because\", max_length=50, do_sample=True, top_k=25)\n\n[{'generated_texts': ' Blurr is fun to work with because and\\n and the and the and the and of the and.\\n\\nThere will be some of those with those who are not with us and some of those who are.\\nand the'}]\n\n\nMasked language modeling\n\nlearn = BlearnerForLM.from_data(\n    raw_ds,\n    \"bert-base-uncased\",\n    text_attr=\"text\",\n    lm_strategy_cls=BertMLMStrategy,\n    dblock_splitter=IndexSplitter(valid_idxs),\n    dl_kwargs={\"bs\": 2},\n).to_fp16()\n\n\nlearn.fit_one_cycle(1, lr_max=3e-4, cbs=[BlearnerForLM.get_metrics_cb()])\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      perplexity\n      lm_accuracy\n      time\n    \n  \n  \n    \n      0\n      1.062873\n      0.823877\n      2.279321\n      0.676234\n      00:32\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=500)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      meridian is right ##ly considered an architectural treasure tr ##ove being one the nations most intact cities from [meta] turn of the last century [MASK] architecture students from around [MASK] nation [baptiste] canada are known to [MASK] meridian in [MASK] as part of their course ##work due to numerous structures in the city having been designed by noted architects . the only home in the us south [MASK] by noted [MASK] born architect [MASK] s . curtiss , famous for [MASK] ##venting the glass curtain wall skyscraper [MASK] [MASK] extant on highland park . the frank fort designed [MASK] [MASK] building is generally considered one of the best [MASK] deco skyscraper [MASK] [MASK] the us and is [MASK] compared to [detroit] ' s famed fisher building [##top] noted california [MASK] wallace ne ##ff designed a number of homes [MASK] [MASK] as well [MASK] in [MASK] alabama black [MASK] [which] [MASK] ##jo ##ins the city across the [MASK] [MASK] state line [.] he had relatives in meridian and selma who were [MASK] in the then thriving railroad industry and would take commissions [MASK] the area when [MASK] [discipline] california were lean . [MASK] work is mostly [concentrated] in the lower numbered blocks of pop ##lar springs drive where his 251 ##6 pop ##lar [MASK] [wheeler] is [often] compared to the similarly designed falcon lair [MASK] the beverly hills [MASK] in benedict canyon of rudolph valentin ##o . [MASK] ne ##ff work was lost to an expansion of anderson hospital in [MASK] and another in marion park [MASK] in the 1950s . the meridian post office with [MASK] interior done entirely [of] bronze and verde marble is also [MASK] as a very fine example of [MASK] type of post office structures built in thriving and [MASK] to do cities [MASK] the 1920s and [MASK] had lal [MASK] lighting [MASK] was removed sadly during a 1960s re ##mo ##del ##ing and which are now in private residences on pop ##lar springs drive and in north hills [MASK]\n      meridian is right ##ly considered an architectural treasure tr ##ove being one the nations most intact cities from [the] turn of the last century [.] architecture students from around [the] nation [and] canada are known to [visit] meridian in [groups] as part of their course ##work due to numerous structures in the city having been designed by noted architects . the only home in the us south [designed] by noted [canadian] born architect [louis] s . curtiss , famous for [in] ##venting the glass curtain wall skyscraper [,] [is] extant on highland park . the frank fort designed [three] [##foot] building is generally considered one of the best [art] deco skyscraper [##s] [in] the us and is [often] compared to [detroit] ' s famed fisher building [.] noted california [architect] wallace ne ##ff designed a number of homes [in] [meridian] as well [as] in [the] alabama black [belt] [which] [ad] ##jo ##ins the city across the [nearby] [alabama] state line [.] he had relatives in meridian and selma who were [executives] in the then thriving railroad industry and would take commissions [in] the area when [commissions] [in] california were lean . [his] work is mostly [concentrated] in the lower numbered blocks of pop ##lar springs drive where his 251 ##6 pop ##lar [springs] [drive] is [often] compared to the similarly designed falcon lair [,] the beverly hills [home] in benedict canyon of rudolph valentin ##o . [one] ne ##ff work was lost to an expansion of anderson hospital in [1990] and another in marion park [burned] in the 1950s . the meridian post office with [its] interior done entirely [of] bronze and verde marble is also [noteworthy] as a very fine example of [the] type of post office structures built in thriving and [well] to do cities [in] the 1920s and [originally] had lal [##ique] lighting [which] was removed sadly during a 1960s re ##mo ##del ##ing and which are now in private residences on pop ##lar springs drive and in north hills [.]\n      meridian is right ##ly considered an architectural treasure tr ##ove being one the nations most intact cities from [the] turn of the last century [.] architecture students from around [the] nation [and] canada are known to [visit] meridian in [particular] as part of their course ##work due to numerous structures in the city having been designed by noted architects . the only home in the us south [is] by noted [american] born architect [william] s . curtiss , famous for [in] ##venting the glass curtain wall skyscraper [that] [still] extant on highland park . the frank fort designed [the] [tower] building is generally considered one of the best [art] deco skyscraper [##s] [in] the us and is [often] compared to [detroit] ' s famed fisher building [.] noted california [architect] wallace ne ##ff designed a number of homes [in] [meridian] as well [as] in [the] alabama black [hills] [which] [ad] ##jo ##ins the city across the [alabama] [tennessee] state line [.] he had relatives in meridian and selma who were [involved] in the then thriving railroad industry and would take commissions [in] the area when [the] [in] california were lean . [his] work is mostly [concentrated] in the lower numbered blocks of pop ##lar springs drive where his 251 ##6 pop ##lar [springs] [wheeler] is [often] compared to the similarly designed falcon lair [and] the beverly hills [and] in benedict canyon of rudolph valentin ##o . [the] ne ##ff work was lost to an expansion of anderson hospital in [1950] and another in marion park [beginning] in the 1950s . the meridian post office with [its] interior done entirely [of] bronze and verde marble is also [regarded] as a very fine example of [the] type of post office structures built in thriving and [well] to do cities [in] the 1920s and [1930s] had lal [##l] lighting [which] was removed sadly during a 1960s re ##mo ##del ##ing and which are now in private residences on pop ##lar springs drive and in north hills [.]\n    \n    \n      1\n      [MASK] cap is [light] [MASK] @ - @ brown , with a diameter typically ranging from 1 [MASK] 4 @ [##我] @ 5 cm ( 0 @ . @ 4 [MASK] 1 @ . @ 8 in ) . initially con ##ic to bell @ - @ shaped to convex , it flat ##tens during [MASK] [MASK] [MASK] [visible] surface grooves corresponding to the gills underneath the cap . the margin of the cap has minute but distinct [MASK] [MASK] ##ops . the surface is moist and smooth , and h ##y ##gr ##op ##han ##ous [MASK] the cap frequently develops splits [MASK] [fraternity] margin , or cracks in the [MASK] [MASK] the central part of the cap ) . the flesh of the cap is thick [MASK] [MASK] [repertory] but [MASK] elsewhere , gray ##ish to whitish , fragile , and with a slightly meal ##y odor [MASK] taste . the gills have a dec ##urrent attachment to the stem ( [##pta] [MASK] , running down the length of [MASK] [MASK] [MASK] and are a pale brownish color with ting ##es of red . they are broad ( between 3 and 6 mm ) , and have a close to sub ##dis ##tan [MASK] spa ##cing , with about 26 – 35 gills reaching the stem . the fragile stem is 3 to [MASK] [MASK] [MASK] [MASK] @ . @ 2 to 3 @ . @ 5 in ) long by [MASK] [MASK] . @ [MASK] to 0 @ . @ 4 cm [MASK] 0 @ [MASK] @ 06 to 0 @ . [cm] 16 in ) thick and yellow [MASK] yellow @ [-] @ brown , becoming reddish @ - @ brown to orange @ - @ brown [MASK] [MASK] bottom half [in] maturity [MASK] [MASK] lower portion [MASK] young stems is covered with white fl ##eck ##s . roughly equal in [MASK] at [MASK] [MASK] and bottom , the base of the [MASK] is covered by [MASK] yellowish my ##cel ##ium [that] can be [up] to a third of the length of the stem . the ed ##ibility of the mushroom [MASK] \" doubtful [MASK] and consumption \" best avoided \" .\n      [the] cap is [light] [reddish] @ - @ brown , with a diameter typically ranging from 1 [to] 4 @ [.] @ 5 cm ( 0 @ . @ 4 [to] 1 @ . @ 8 in ) . initially con ##ic to bell @ - @ shaped to convex , it flat ##tens during [maturity] [,] [developing] [visible] surface grooves corresponding to the gills underneath the cap . the margin of the cap has minute but distinct [sc] [##all] ##ops . the surface is moist and smooth , and h ##y ##gr ##op ##han ##ous [.] the cap frequently develops splits [in] [the] margin , or cracks in the [disc] [(] the central part of the cap ) . the flesh of the cap is thick [in] [the] [center] but [thin] elsewhere , gray ##ish to whitish , fragile , and with a slightly meal ##y odor [and] taste . the gills have a dec ##urrent attachment to the stem ( [that] [is] , running down the length of [the] [stem] [)] and are a pale brownish color with ting ##es of red . they are broad ( between 3 and 6 mm ) , and have a close to sub ##dis ##tan [##t] spa ##cing , with about 26 – 35 gills reaching the stem . the fragile stem is 3 to [9] [cm] [(] [1] @ . @ 2 to 3 @ . @ 5 in ) long by [0] [@] . @ [15] to 0 @ . @ 4 cm [(] 0 @ [.] @ 06 to 0 @ . [@] 16 in ) thick and yellow [to] yellow @ [-] @ brown , becoming reddish @ - @ brown to orange @ - @ brown [in] [the] bottom half [in] maturity [.] [the] lower portion [of] young stems is covered with white fl ##eck ##s . roughly equal in [thickness] at [the] [top] and bottom , the base of the [stem] is covered by [a] yellowish my ##cel ##ium [that] can be [up] to a third of the length of the stem . the ed ##ibility of the mushroom [is] \" doubtful [\"] and consumption \" best avoided \" .\n      [the] cap is [light] [brown] @ - @ brown , with a diameter typically ranging from 1 [.] 4 @ [.] @ 5 cm ( 0 @ . @ 4 [@] 1 @ . @ 8 in ) . initially con ##ic to bell @ - @ shaped to convex , it flat ##tens during [growth] [,] [with] [visible] surface grooves corresponding to the gills underneath the cap . the margin of the cap has minute but distinct [white] [wall] ##ops . the surface is moist and smooth , and h ##y ##gr ##op ##han ##ous [(] the cap frequently develops splits [,] [the] margin , or cracks in the [cap] [of] the central part of the cap ) . the flesh of the cap is thick [in] [in] [,] but [,] elsewhere , gray ##ish to whitish , fragile , and with a slightly meal ##y odor [and] taste . the gills have a dec ##urrent attachment to the stem ( [gills] [)] , running down the length of [the] [cap] [,] and are a pale brownish color with ting ##es of red . they are broad ( between 3 and 6 mm ) , and have a close to sub ##dis ##tan [##t] spa ##cing , with about 26 – 35 gills reaching the stem . the fragile stem is 3 to [4] [4] [.] [@] @ . @ 2 to 3 @ . @ 5 in ) long by [4] [@] . @ [1] to 0 @ . @ 4 cm [(] 0 @ [.] @ 06 to 0 @ . [@] 16 in ) thick and yellow [to] yellow @ [-] @ brown , becoming reddish @ - @ brown to orange @ - @ brown [in] [in] bottom half [in] maturity [.] [the] lower portion [of] young stems is covered with white fl ##eck ##s . roughly equal in [size] at [top] [top] and bottom , the base of the [stem] is covered by [a] yellowish my ##cel ##ium [that] can be [up] to a third of the length of the stem . the ed ##ibility of the mushroom [is] \" doubtful [\"] and consumption \" best avoided \" .\n    \n  \n\n\n\n\ntfm = first_blurr_tfm(learn.dls)\n\nLearner.blurr_fill_mask works here too\n\nlearn.blurr_fill_mask(f\"Blurr is a {tfm.hf_tokenizer.mask_token}.\", n_preds=5)\n\n['Blurr is a word.',\n 'Blurr is a game.',\n 'Blurr is a term.',\n 'Blurr is a concept.',\n 'Blurr is a name.']"
  },
  {
    "objectID": "examples.text.high_level_api.html#summarization",
    "href": "examples.text.high_level_api.html#summarization",
    "title": "Using the high-level Blurr API",
    "section": "Summarization",
    "text": "Summarization\n\nraw_datasets = load_dataset(\"cnn_dailymail\", \"3.0.0\")\nprint(f\"{raw_datasets}\\n\")\nprint(f'{raw_datasets[\"train\"][0]}\\n')\nprint(f'{raw_datasets[\"train\"].features}\\n')\n\nReusing dataset cnn_dailymail (/home/wgilliam/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 287113\n    })\n    validation: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 13368\n    })\n    test: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 11490\n    })\n})\n\n{'article': 'It\\'s official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It\\'s a step that is set to turn an international crisis into a fierce domestic political battle. There are key questions looming over the debate: What did U.N. weapons inspectors find in Syria? What happens if Congress votes no? And how will the Syrian government react? In a televised address from the White House Rose Garden earlier Saturday, the president said he would take his case to Congress, not because he has to -- but because he wants to. \"While I believe I have the authority to carry out this military action without specific congressional authorization, I know that the country will be stronger if we take this course, and our actions will be even more effective,\" he said. \"We should have this debate, because the issues are too big for business as usual.\" Obama said top congressional leaders had agreed to schedule a debate when the body returns to Washington on September 9. The Senate Foreign Relations Committee will hold a hearing over the matter on Tuesday, Sen. Robert Menendez said. Transcript: Read Obama\\'s full remarks . Syrian crisis: Latest developments . U.N. inspectors leave Syria . Obama\\'s remarks came shortly after U.N. inspectors left Syria, carrying evidence that will determine whether chemical weapons were used in an attack early last week in a Damascus suburb. \"The aim of the game here, the mandate, is very clear -- and that is to ascertain whether chemical weapons were used -- and not by whom,\" U.N. spokesman Martin Nesirky told reporters on Saturday. But who used the weapons in the reported toxic gas attack in a Damascus suburb on August 21 has been a key point of global debate over the Syrian crisis. Top U.S. officials have said there\\'s no doubt that the Syrian government was behind it, while Syrian officials have denied responsibility and blamed jihadists fighting with the rebels. British and U.S. intelligence reports say the attack involved chemical weapons, but U.N. officials have stressed the importance of waiting for an official report from inspectors. The inspectors will share their findings with U.N. Secretary-General Ban Ki-moon Ban, who has said he wants to wait until the U.N. team\\'s final report is completed before presenting it to the U.N. Security Council. The Organization for the Prohibition of Chemical Weapons, which nine of the inspectors belong to, said Saturday that it could take up to three weeks to analyze the evidence they collected. \"It needs time to be able to analyze the information and the samples,\" Nesirky said. He noted that Ban has repeatedly said there is no alternative to a political solution to the crisis in Syria, and that \"a military solution is not an option.\" Bergen:  Syria is a problem from hell for the U.S. Obama: \\'This menace must be confronted\\' Obama\\'s senior advisers have debated the next steps to take, and the president\\'s comments Saturday came amid mounting political pressure over the situation in Syria. Some U.S. lawmakers have called for immediate action while others warn of stepping into what could become a quagmire. Some global leaders have expressed support, but the British Parliament\\'s vote against military action earlier this week was a blow to Obama\\'s hopes of getting strong backing from key NATO allies. On Saturday, Obama proposed what he said would be a limited military action against Syrian President Bashar al-Assad. Any military attack would not be open-ended or include U.S. ground forces, he said. Syria\\'s alleged use of chemical weapons earlier this month \"is an assault on human dignity,\" the president said. A failure to respond with force, Obama argued,  \"could lead to escalating use of chemical weapons or their proliferation to terrorist groups who would do our people harm. In a world with many dangers, this menace must be confronted.\" Syria missile strike: What would happen next? Map: U.S. and allied assets around Syria . Obama decision came Friday night . On Friday night, the president made a last-minute decision to consult lawmakers. What will happen if they vote no? It\\'s unclear. A senior administration official told CNN that Obama has the authority to act without Congress -- even if Congress rejects his request for authorization to use force. Obama on Saturday continued to shore up support for a strike on the al-Assad government. He spoke by phone with French President Francois Hollande before his Rose Garden speech. \"The two leaders agreed that the international community must deliver a resolute message to the Assad regime -- and others who would consider using chemical weapons -- that these crimes are unacceptable and those who violate this international norm will be held accountable by the world,\" the White House said. Meanwhile, as uncertainty loomed over how Congress would weigh in, U.S. military officials said they remained at the ready. 5 key assertions: U.S. intelligence report on Syria . Syria: Who wants what after chemical weapons horror . Reactions mixed to Obama\\'s speech . A spokesman for the Syrian National Coalition said that the opposition group was disappointed by Obama\\'s announcement. \"Our fear now is that the lack of action could embolden the regime and they repeat his attacks in a more serious way,\" said spokesman Louay Safi. \"So we are quite concerned.\" Some members of Congress applauded Obama\\'s decision. House Speaker John Boehner, Majority Leader Eric Cantor, Majority Whip Kevin McCarthy and Conference Chair Cathy McMorris Rodgers issued a statement Saturday praising the president. \"Under the Constitution, the responsibility to declare war lies with Congress,\" the Republican lawmakers said. \"We are glad the president is seeking authorization for any military action in Syria in response to serious, substantive questions being raised.\" More than 160 legislators, including 63 of Obama\\'s fellow Democrats, had signed letters calling for either a vote or at least a \"full debate\" before any U.S. action. British Prime Minister David Cameron, whose own attempt to get lawmakers in his country to support military action in Syria failed earlier this week, responded to Obama\\'s speech in a Twitter post Saturday. \"I understand and support Barack Obama\\'s position on Syria,\" Cameron said. An influential lawmaker in Russia -- which has stood by Syria and criticized the United States -- had his own theory. \"The main reason Obama is turning to the Congress:  the military operation did not get enough support either in the world, among allies of the US or in the United States itself,\" Alexei Pushkov, chairman of the international-affairs committee of the Russian State Duma, said in a Twitter post. In the United States, scattered groups of anti-war protesters around the country took to the streets Saturday. \"Like many other Americans...we\\'re just tired of the United States getting involved and invading and bombing other countries,\" said Robin Rosecrans, who was among hundreds at a Los Angeles demonstration. What do Syria\\'s neighbors think? Why Russia, China, Iran stand by Assad . Syria\\'s government unfazed . After Obama\\'s speech, a military and political analyst on Syrian state TV said Obama is \"embarrassed\" that Russia opposes military action against Syria, is \"crying for help\" for someone to come to his rescue and is facing two defeats -- on the political and military levels. Syria\\'s prime minister appeared unfazed by the saber-rattling. \"The Syrian Army\\'s status is on maximum readiness and fingers are on the trigger to confront all challenges,\" Wael Nader al-Halqi said during a meeting with a delegation of Syrian expatriates from Italy, according to a banner on Syria State TV that was broadcast prior to Obama\\'s address. An anchor on Syrian state television said Obama \"appeared to be preparing for an aggression on Syria based on repeated lies.\" A top Syrian diplomat told the state television network that Obama was facing pressure to take military action from Israel, Turkey, some Arabs and right-wing extremists in the United States. \"I think he has done well by doing what Cameron did in terms of taking the issue to Parliament,\" said Bashar Jaafari, Syria\\'s ambassador to the United Nations. Both Obama and Cameron, he said, \"climbed to the top of the tree and don\\'t know how to get down.\" The Syrian government has denied that it used chemical weapons in the August 21 attack, saying that jihadists fighting with the rebels used them in an effort to turn global sentiments against it. British intelligence had put the number of people killed in the attack at more than 350. On Saturday, Obama said \"all told, well over 1,000 people were murdered.\" U.S. Secretary of State John Kerry on Friday cited a death toll of 1,429, more than 400 of them children. No explanation was offered for the discrepancy. Iran: U.S. military action in Syria would spark \\'disaster\\' Opinion: Why strikes in Syria are a bad idea .', 'highlights': 'Syrian official: Obama climbed to the top of the tree, \"doesn\\'t know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .', 'id': '0001d1afc246a7964130f43ae940af6bc6c57f01'}\n\n{'article': Value(dtype='string', id=None), 'highlights': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None)}\n\n\n\n\ntrain_ds = raw_datasets[\"train\"].select(range(1000))\nvalid_ds = raw_datasets[\"validation\"].select(range(500))\n\n\nn_train, n_valid = train_ds.num_rows, valid_ds.num_rows\ntrain_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\nraw_ds = concatenate_datasets([train_ds, valid_ds])\n\n\nlearn = BlearnerForSummarization.from_data(\n    raw_ds,\n    \"facebook/bart-large-cnn\",\n    text_attr=\"article\",\n    summary_attr=\"highlights\",\n    max_length=256,\n    max_target_length=130,\n    dblock_splitter=IndexSplitter(valid_idxs),\n    dl_kwargs={\"bs\": 2},\n).to_fp16()\n\n\nlearn.dls.show_batch(dataloaders=learn.dls, max_n=2, input_trunc_at=500, target_trunc_at=250)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      <s> (CNN) -- When Ji Yeqing awakened, she was already in the recovery room. Chinese authorities had dragged her out of her home and down four flights of stairs, she said, restraining and beating her husband as he tried to come to her aid. They whisked her into a clinic, held her down on a bed and forced her to undergo an abortion. Her offense? Becoming pregnant with a second child, in violation of China's one-child policy. \"After the abortion, I felt empty, as if something was scooped out of me,\n      China's one-child policy results in forced abortions and sterilizations, activists say.\\nWomen tell of emotional and physical consequences from the procedures.\\nActivist Chen Guangcheng works to advocate for victims of such practices.\n    \n    \n      1\n      <s> (CNN Student News) -- January 13, 2011. Download PDF maps related to today's show:. • Arizona • Australia. Transcript. THIS IS A RUSH TRANSCRIPT. THIS COPY MAY NOT BE IN ITS FINAL FORM AND MAY BE UPDATED. CARL AZUZ, CNN STUDENT NEWS ANCHOR: A problem that won't be solved, even if the solution is clear. The story and the reasons, leading off today's broadcast of CNN Student News! My name is Carl Azuz! First Up: Winter Storm Woes. AZUZ: Florida is the only state in the union without snow on th\n      A winter storm slams the northeastern United States.\\nThe U.S. House of Representatives condemns the Arizona shooting.\\nMassive floods leave vast areas of Australia underwater.\\nUse the Daily Discussion to help students understand today's featured news\n    \n  \n\n\n\n\nmetrics_cb = BlearnerForSummarization.get_metrics_cb()\nlearn.fit_one_cycle(1, lr_max=4e-5, cbs=[metrics_cb])\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      rouge1\n      rouge2\n      rougeL\n      rougeLsum\n      bertscore_precision\n      bertscore_recall\n      bertscore_f1\n      time\n    \n  \n  \n    \n      0\n      1.805652\n      1.987627\n      0.348567\n      0.148174\n      0.243829\n      0.319418\n      0.871049\n      0.893810\n      0.882177\n      10:06\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      (CNN)Reading the headlines out of Madison, Wisconsin, it's hard not to think about Ferguson, Missouri. But law enforcement's response to the shooting of 19-year-old Tony Robinson will not unfold in the same chaotic, violent and distrusting way as the shooting of 18-year-old Michael Brown, Madison's top police leaders vowed. \"I think it's very clear that Madison, Wisconsin, is not Ferguson, Missouri,\" said Jim Palmer, the executive director of the Wisconsin Professional Police Association. The h\n      Police officials in Madison say their responses to shooting by officer reflect their role in community.\\nOne example: Madison chief talked to teen's family soon after shooting.\\nA month went by before Ferguson chief apologized to Brown's family.\n      [ Law enforcement in Madison, Wisconsin, says it has a strong relationship with the people it serves .\\nPolice chief says he understands people are angry and want answers .\\nChief says he went to the shooting victim's mother's home within hours of the shooting .\\nThe chief says the department is working to \"bring community back into the fold\" of the community .,  ISIS claimed responsibility for Yemen's deadliest terror attack on Friday .\\nThe group's momentum may have stalled in Syria and Iraq, but its supporters appear to be heeding its call to \"erupt volcanoes of jihad\"\\nISIS was only thought to have a fledgling presence in Yemen and had only claimed one previous attack .]\n    \n  \n\n\n\nLearner.blurr_generate works here too\n\ntest_article = \"\"\"\nAbout 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \ninto France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \nBasel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \nbut could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \nof armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \ncashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \noccurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \nher, and took off for the French border. The other gunmen followed into France, which is only about 100 \nmeters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \nThere were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \nrobbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \nGill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \ncontributed to this report.\n\"\"\"\n\n\noutputs = learn.blurr_generate(test_article, num_return_sequences=3)\n\nfor idx, o in enumerate(outputs):\n    print(f\"=== Prediction {idx+1} ===\\n{o}\\n\")\n\n=== Prediction 1 ===\n{'generated_texts': [\" Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nOne group tried to break into the casino's vault on the lower level, but could not get in .\\nA woman driving by unknowingly blocked the robbers' vehicles and a gunman beat her to death .\\nThere were no serious injuries, although one guest on the Casino floor was kicked in the head .\", \" Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nOne group tried to break into the casino's vault on the lower level, but could not get in .\\nA woman driving by unknowingly blocked the robbers' vehicles and a gunman beat her to death .\\nThere were about 600 people in the casino at the time of the robbery .\", \" Robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nOne group tried to break into the casino's vault on the lower level, but could not get in .\\nA woman driving by unknowingly blocked the robbers' vehicles and a gunman beat her to death .\"]}"
  },
  {
    "objectID": "examples.text.high_level_api.html#translation",
    "href": "examples.text.high_level_api.html#translation",
    "title": "Using the high-level Blurr API",
    "section": "Translation",
    "text": "Translation\n\nraw_datasets = load_dataset(\"wmt16\", \"de-en\")\nprint(f\"{raw_datasets}\\n\")\nprint(f'{raw_datasets[\"train\"][0]}\\n')\nprint(f'{raw_datasets[\"train\"].features}\\n')\n\nReusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 4548885\n    })\n    validation: Dataset({\n        features: ['translation'],\n        num_rows: 2169\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 2999\n    })\n})\n\n{'translation': {'de': 'Wiederaufnahme der Sitzungsperiode', 'en': 'Resumption of the session'}}\n\n{'translation': Translation(languages=['de', 'en'], id=None)}\n\n\n\n\ntrain_ds = raw_datasets[\"train\"].select(range(1000))\nvalid_ds = raw_datasets[\"validation\"].select(range(500))\n\n\nn_train, n_valid = train_ds.num_rows, valid_ds.num_rows\ntrain_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\nraw_ds = concatenate_datasets([train_ds, valid_ds])\n\n\ndef make_dict(item):\n    return item[\"translation\"]\n\n\nraw_ds = raw_ds.map(make_dict)\n\nLoading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f/cache-33c5db1dfc9c3c37.arrow\n\n\n\ntrain_df = pd.DataFrame(raw_ds[\"translation\"], columns=[\"de\", \"en\"])\n\n\nlearn = BlearnerForTranslation.from_data(\n    train_df,\n    \"Helsinki-NLP/opus-mt-de-en\",\n    src_lang_name=\"German\",\n    src_lang_attr=\"de\",\n    trg_lang_name=\"English\",\n    trg_lang_attr=\"en\",\n    dblock_splitter=RandomSplitter(),\n    dl_kwargs={\"bs\": 2},\n).to_fp16()\n\n\nlearn.dls.show_batch(dataloaders=learn.dls, max_n=2, input_trunc_at=500, target_trunc_at=250)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      ▁Angesichts▁dieser Situation▁muß▁aus dem▁Bericht, den das▁Parlament annimmt,▁klar▁hervorgehen,▁daß▁Maßnahmen▁notwendig▁sind, die▁eindeutig auf die▁Bekämpfung der relativen▁Armut und der Arbeitslosigkeit▁gerichtet▁sind.▁Maßnahmen▁wie die für diese▁Zwecke▁angemessene▁Verwendung der▁Strukturfonds, die▁häufig▁unsachgemäß▁eingesetzt▁werden, und▁zwar mit▁zentralen▁staatlichen▁Politiken, die▁Modernisierung der▁Bereiche Telekommunikation und▁Kommunikation,▁indem man vor▁allem die am▁wenigsten▁entwickelt\n      Given this situation, the report approved by Parliament must highlight the need for measures that aim unequivocally to fight relative poverty and unemployment: measures such as the appropriate use of structural funds for these purposes, which are oft\n    \n    \n      1\n      In▁unseren Änderungsanträgen▁haben wir▁festgeschrieben,▁welche▁Bedeutung wir der Herausbildung der▁notwendigen▁Synergien▁zwischen den▁Strukturfonds, dem▁Kohäsionsfonds und den▁Gemeinschaftsinitiativen▁beimessen, so▁daß▁ihre▁Anwendung auf▁optimale und rentabelste▁Weise im▁zunehmenden▁Abbau der▁regionalen▁Ungleichheiten und in der▁Schaffung von▁Arbeitsplätzen▁ihren▁Niederschlag▁findet, die▁letztendlich die▁beiden▁Hauptziele der hier zur▁Debatte▁stehenden▁Fonds▁sind.<pad><pad><pad><pad><pad><pad><p\n      In our amendments, we have stated the importance of the necessary synergies being produced between the Structural Funds, the Cohesion Fund and Community initiatives, so that their application should be reflected, in the best and most profitable way,\n    \n  \n\n\n\n\nmetrics_cb = BlearnerForTranslation.get_metrics_cb()\nlearn.fit_one_cycle(1, lr_max=4e-5, cbs=[metrics_cb])\n\n[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      bleu\n      meteor\n      sacrebleu\n      time\n    \n  \n  \n    \n      0\n      1.360521\n      1.345847\n      0.334178\n      0.613131\n      31.482812\n      01:14\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      ▁Angesichts▁dessen▁müssen wir in▁diesem▁Parlament auf▁jeden Fall▁verlangen,▁daß die▁gemeinschaftlichen▁Förderkonzepte für den▁fraglichen▁Zeitraum in▁diesem▁Parlament vor▁ihrer▁Annahme▁geprüft und▁erörtert▁werden, und▁zwar▁anhand der▁Leitlinien, die wir▁heute▁vorlegen,▁denn wir▁halten▁sie für▁ganz▁besonders▁geeignet,▁Arbeitsplätze in den▁ärmsten oder am▁wenigsten▁entwickelten▁Regionen zu▁schaffen, und so▁tragen wir▁dazu▁bei, den▁negativen, zur▁Ungleichheit▁führenden▁Tendenzen in der▁europäischen\n      Bearing this in mind, this House should, in any event, demand that, before the Community support frameworks for the period in question are approved, they be studied and submitted for debate in this Parliament, specifically in light of the guidelines\n      [In view of this, we in this Parliament must in any case demand that the Community support frameworks for the period in question be examined and discussed in this Parliament before they are adopted, on the basis of the guidelines that we are presenting today, because we consider them to be particularly suitable for creating jobs in the poorest or least developed regions, and thus we are helping to counter the negative trends leading to inequality in European society, so that we can achieve a fairer Europe., The guidelines, moreover, are based on two horizontal principles: rural development - and the issue of a sustainable transport structure, Madam rapporteur, which has been at my heart for a long time, especially since my time as my country' s Minister for the Environment - and the second principle is equal opportunities, especially between women and men, as well as the European employment strategy and economic and monetary union.]\n    \n  \n\n\n\nLearner.blurr_generate works here too\n\ntest_de = \"Ich trinke gerne Bier\"\n\n\nlearn.blurr_generate(test_de)\n\n[{'generated_texts': 'I like to drink beer'}]"
  },
  {
    "objectID": "examples.text.high_level_api.html#summary",
    "href": "examples.text.high_level_api.html#summary",
    "title": "Using the high-level Blurr API",
    "section": "Summary",
    "text": "Summary\nIn summary, whether you want to work with Blurr’s low, mid, or high-level API … we got you covered :)"
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "utils",
    "section": "",
    "text": "source\n\n\n\n Singleton (cls)\n\nInitialize self. See help(type(self)) for accurate signature.\nSingleton functions as python decorator. Use this above any class to turn that class into a singleton (see here for more info on the singleton pattern).\n\n@Singleton\nclass TestSingleton:\n    pass\n\n\na = TestSingleton()\nb = TestSingleton()\ntest_eq(a, b)"
  },
  {
    "objectID": "utils.html#utility-methods",
    "href": "utils.html#utility-methods",
    "title": "utils",
    "section": "Utility methods",
    "text": "Utility methods\n\nsource\n\nstr_to_type\n\n str_to_type (typename:str)\n\nConverts a type represented as a string to the actual class\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ntypename\nstr\n\n\n\nReturns\ntype\nThe name of a type as a string # Returns the actual type\n\n\n\nHow to use:\n\nprint(str_to_type(\"test_eq\"))\nprint(str_to_type(\"TestSingleton\"))\n\n<function test_eq>\n<__main__.Singleton object>\n\n\n\nsource\n\n\nprint_versions\n\n print_versions (packages:str|list[str])\n\nPrints the name and version of one or more packages in your environment\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\npackages\nstr | list[str]\nA string of space delimited package names or a list of package names\n\n\n\nHow to use:\n\nprint_versions(\"torch transformers fastai\")\nprint(\"---\")\nprint_versions([\"torch\", \"transformers\", \"fastai\"])\n\ntorch: 1.9.0+cu102\ntransformers: 4.21.2\nfastai: 2.7.9\n---\ntorch: 1.9.0+cu102\ntransformers: 4.21.2\nfastai: 2.7.9\n\n\n\nsource\n\n\nset_seed\n\n set_seed (seed_value:int=42)\n\nThis needs to be ran before creating your DataLoaders, before creating your Learner, and before each call to your fit function to help ensure reproducibility.\n\nsource\n\n\nreset_memory\n\n reset_memory (learn:fastai.learner.Learner=None)\n\nA function which clears gpu memory.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlearn\nLearner\nNone\nThe fastai learner to delete"
  },
  {
    "objectID": "utils.html#loss-functions",
    "href": "utils.html#loss-functions",
    "title": "utils",
    "section": "Loss functions",
    "text": "Loss functions\n\nsource\n\nPreCalculatedMSELoss\n\n PreCalculatedMSELoss (*args, axis=-1, floatify=True, **kwargs)\n\nIf you want to let your Hugging Face model calculate the loss for you, make sure you include the labels argument in your inputs and use PreCalculatedLoss as your loss function. Even though we don’t really need a loss function per se, we have to provide a custom loss class/function for fastai to function properly (e.g. one with a decodes and activation methods). Why? Because these methods will get called in methods like show_results to get the actual predictions.\nNote: The Hugging Face models will always calculate the loss for you if you pass a labels dictionary along with your other inputs (so only include it if that is what you intend to happen)\n\nsource\n\n\nPreCalculatedBCELoss\n\n PreCalculatedBCELoss (*args, axis:int=-1, floatify:bool=True,\n                       thresh:float=0.5, weight=None, reduction='mean',\n                       pos_weight=None, flatten:bool=True,\n                       is_2d:bool=True)\n\nIf you want to let your Hugging Face model calculate the loss for you, make sure you include the labels argument in your inputs and use PreCalculatedLoss as your loss function. Even though we don’t really need a loss function per se, we have to provide a custom loss class/function for fastai to function properly (e.g. one with a decodes and activation methods). Why? Because these methods will get called in methods like show_results to get the actual predictions.\nNote: The Hugging Face models will always calculate the loss for you if you pass a labels dictionary along with your other inputs (so only include it if that is what you intend to happen)\n\nsource\n\n\nPreCalculatedCrossEntropyLoss\n\n PreCalculatedCrossEntropyLoss (*args, axis:int=-1, weight=None,\n                                ignore_index=-100, reduction='mean',\n                                flatten:bool=True, floatify:bool=False,\n                                is_2d:bool=True)\n\nIf you want to let your Hugging Face model calculate the loss for you, make sure you include the labels argument in your inputs and use PreCalculatedLoss as your loss function. Even though we don’t really need a loss function per se, we have to provide a custom loss class/function for fastai to function properly (e.g. one with a decodes and activation methods). Why? Because these methods will get called in methods like show_results to get the actual predictions.\nNote: The Hugging Face models will always calculate the loss for you if you pass a labels dictionary along with your other inputs (so only include it if that is what you intend to happen)\n\nsource\n\n\nPreCalculatedLoss\n\n PreCalculatedLoss (loss_cls, *args, axis:int=-1, flatten:bool=True,\n                    floatify:bool=False, is_2d:bool=True, **kwargs)\n\nIf you want to let your Hugging Face model calculate the loss for you, make sure you include the labels argument in your inputs and use PreCalculatedLoss as your loss function. Even though we don’t really need a loss function per se, we have to provide a custom loss class/function for fastai to function properly (e.g. one with a decodes and activation methods). Why? Because these methods will get called in methods like show_results to get the actual predictions.\nNote: The Hugging Face models will always calculate the loss for you if you pass a labels dictionary along with your other inputs (so only include it if that is what you intend to happen)\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nloss_cls\n\n\nUninitialized PyTorch-compatible loss\n\n\nargs\n\n\n\n\n\naxis\nint\n-1\n\n\n\nflatten\nbool\nTrue\n\n\n\nfloatify\nbool\nFalse\n\n\n\nis_2d\nbool\nTrue\n\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nMultiTargetLoss\n\n MultiTargetLoss (loss_classes:list[Callable]=[<class\n                  'fastai.losses.CrossEntropyLossFlat'>, <class\n                  'fastai.losses.CrossEntropyLossFlat'>],\n                  loss_classes_kwargs:list[dict]=[{}, {}],\n                  weights:list[float]|list[int]=[1, 1],\n                  reduction:str='mean')\n\nProvides the ability to apply different loss functions to multi-modal targets/predictions.\nThis new loss function can be used in many other multi-modal architectures, with any mix of loss functions. For example, this can be ammended to include the is_impossible task, as well as the start/end token tasks in the SQUAD v2 dataset (or in any extractive question/answering task)\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nloss_classes\nlist[Callable]\n[<class ‘fastai.losses.CrossEntropyLossFlat’>, <class ‘fastai.losses.CrossEntropyLossFlat’>]\nThe loss function for each target\n\n\nloss_classes_kwargs\nlist[dict]\n[{}, {}]\nAny kwargs you want to pass to the loss functions above\n\n\nweights\nlist[float] | list[int]\n[1, 1]\nThe weights you want to apply to each loss (default: [1,1])\n\n\nreduction\nstr\nmean\nThe reduction parameter of the lass function (default: ‘mean’)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Getting Started",
    "section": "",
    "text": "Named after the fastest transformer (well, at least of the Autobots), BLURR provides both a comprehensive and extensible framework for training and deploying 🤗 huggingface transformer models with fastai >= 2.0.\nUtilizing features like fastai’s new @typedispatch and @patch decorators, along with a simple class hiearchy, BLURR provides fastai developers with the ability to train and deploy transformers on a variety of tasks. It includes a high, mid, and low-level API that will allow developers to use much of it out-of-the-box or customize it as needed.\nSupported Text/NLP Tasks: - Sequence Classification\n- Token Classification\n- Question Answering\n- Summarization\n- Tranlsation\n- Language Modeling (Causal and Masked)\nSupported Vision Tasks: - In progress\nSupported Audio Tasks: - In progress"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Getting Started",
    "section": "Install",
    "text": "Install\nYou can now pip install blurr via pip install ohmeow-blurr\nOr, even better as this library is under very active development, create an editable install like this:\ngit clone https://github.com/ohmeow/blurr.git\ncd blurr\npip install -e \".[dev]\""
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "Getting Started",
    "section": "How to use",
    "text": "How to use\nPlease check the documentation for more thorough examples of how to use this package.\nThe following two packages need to be installed for blurr to work:\n1. fastai\n2. Hugging Face transformers\n\nImports\n\nimport os, warnings\n\nimport torch\nfrom transformers import *\nfrom transformers.utils import logging as hf_logging\nfrom fastai.text.all import *\n\nfrom blurr.text.data.all import *\nfrom blurr.text.modeling.all import *\n\n\nwarnings.simplefilter(\"ignore\")\nhf_logging.set_verbosity_error()\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n\n\nGet your data\n\npath = untar_data(URLs.IMDB_SAMPLE)\n\nmodel_path = Path(\"models\")\nimdb_df = pd.read_csv(path / \"texts.csv\")\n\n\n\nGet n_labels from data for config later\n\nn_labels = len(imdb_df[\"label\"].unique())\n\n\n\nGet your 🤗 objects\n\nmodel_cls = AutoModelForSequenceClassification\n\npretrained_model_name = \"bert-base-uncased\"\n\nconfig = AutoConfig.from_pretrained(pretrained_model_name)\nconfig.num_labels = n_labels\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n    pretrained_model_name,\n    model_cls=model_cls, \n    config=config\n)\n\n\n\nBuild your Data 🧱 and your DataLoaders\n\n# single input\nblocks = (\n    TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), \n    CategoryBlock\n)\ndblock = DataBlock(\n    blocks=blocks, \n    get_x=ColReader(\"text\"), \n    get_y=ColReader(\"label\"), \n    splitter=ColSplitter()\n)\n\ndls = dblock.dataloaders(imdb_df, bs=4)\n\n\ndls.show_batch(dataloaders=dls, max_n=2, trunc_at=250)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      raising victor vargas : a review < br / > < br / > you know, raising victor vargas is like sticking your hands into a big, steaming bowl of oatmeal. it's warm and gooey, but you're not sure if it feels right. try as i might, no matter how warm and go\n      negative\n    \n    \n      1\n      the shop around the corner is one of the sweetest and most feel - good romantic comedies ever made. there's just no getting around that, and it's hard to actually put one's feeling for this film into words. it's not one of those films that tries too\n      positive\n    \n  \n\n\n\n\n\n… and 🚂\n\nmodel = BaseModelWrapper(hf_model)\n\nlearn = Learner(\n    dls,\n    hf_model,\n    opt_func=partial(Adam, decouple_wd=True),\n    loss_func=CrossEntropyLossFlat(),\n    metrics=[accuracy],\n    cbs=[BaseModelCallback],\n    splitter=blurr_splitter,\n)\n\nlearn.freeze()\n\nlearn.fit_one_cycle(3, lr_max=1e-3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.628744\n      0.453862\n      0.780000\n      00:21\n    \n    \n      1\n      0.367063\n      0.294906\n      0.895000\n      00:22\n    \n    \n      2\n      0.238181\n      0.279067\n      0.900000\n      00:22\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=250)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      the trouble with the book, \" memoirs of a geisha \" is that it had japanese surfaces but underneath the surfaces it was all an american man's way of thinking. reading the book is like watching a magnificent ballet with great music, sets, and costumes\n      negative\n      negative\n    \n    \n      1\n      < br / > < br / > i'm sure things didn't exactly go the same way in the real life of homer hickam as they did in the film adaptation of his book, rocket boys, but the movie \" october sky \" ( an anagram of the book's title ) is good enough to stand al\n      positive\n      positive\n    \n  \n\n\n\n\n\nUsing the high-level Blurr API\nUsing the high-level API we can reduce DataBlock, DataLoaders, and Learner creation into a single line of code.\nIncluded in the high-level API is a general BLearner class (pronouned “Blurrner”) that you can use with hand crafted DataLoaders, as well as, task specific BLearners like BLearnerForSequenceClassification that will handle everything given your raw data sourced from a pandas DataFrame, CSV file, or list of dictionaries (for example a huggingface datasets dataset)\n\nlearn = BlearnerForSequenceClassification.from_data(\n    imdb_df, \n    pretrained_model_name, \n    dl_kwargs={\"bs\": 4}\n)\n\n\nlearn.fit_one_cycle(1, lr_max=1e-3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.530218\n      0.484683\n      0.789189\n      0.805000\n      00:22\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=250)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      the trouble with the book, \" memoirs of a geisha \" is that it had japanese surfaces but underneath the surfaces it was all an american man's way of thinking. reading the book is like watching a magnificent ballet with great music, sets, and costumes\n      negative\n      negative\n    \n    \n      1\n      < br / > < br / > i'm sure things didn't exactly go the same way in the real life of homer hickam as they did in the film adaptation of his book, rocket boys, but the movie \" october sky \" ( an anagram of the book's title ) is good enough to stand al\n      positive\n      positive"
  },
  {
    "objectID": "index.html#props",
    "href": "index.html#props",
    "title": "Getting Started",
    "section": "⭐ Props",
    "text": "⭐ Props\nA word of gratitude to the following individuals, repos, and articles upon which much of this work is inspired from:\n\nThe wonderful community that is the fastai forum and especially the tireless work of both Jeremy and Sylvain in building this amazing framework and place to learn deep learning.\nAll the great tokenizers, transformers, docs, examples, and people over at huggingface\nFastHugs\nFastai with 🤗Transformers (BERT, RoBERTa, XLNet, XLM, DistilBERT)\nFastai integration with BERT: Multi-label text classification identifying toxicity in texts\nfastinference"
  },
  {
    "objectID": "examples.text.causal_lm_gpt2.html",
    "href": "examples.text.causal_lm_gpt2.html",
    "title": "Causal Language Modeling with GPT-2",
    "section": "",
    "text": "raw_data_path = Path('./data/task-language-modeling/pt-2/')\nraw_data_path.ls()\n\n(#3) [Path('data/task-language-modeling/pt-2/valid'),Path('data/task-language-modeling/pt-2/train'),Path('data/task-language-modeling/pt-2/test')]\n\n\n\n(raw_data_path/'train').ls()\n\n(#730) [Path('data/task-language-modeling/pt-2/train/Bandeira_de_Angola.txt'),Path('data/task-language-modeling/pt-2/train/Pâncreas.txt'),Path('data/task-language-modeling/pt-2/train/Governo_Federal_do_Brasil.txt'),Path('data/task-language-modeling/pt-2/train/Monte_da_Pedra.txt'),Path('data/task-language-modeling/pt-2/train/Pouso_Alegre.txt'),Path('data/task-language-modeling/pt-2/train/Ararinha-azul.txt'),Path('data/task-language-modeling/pt-2/train/Deus.txt'),Path('data/task-language-modeling/pt-2/train/Ernest_Hemingway.txt'),Path('data/task-language-modeling/pt-2/train/Brasileiros.txt'),Path('data/task-language-modeling/pt-2/train/Distrito_de_Beja.txt')...]\n\n\n\nlen((raw_data_path/'train').ls()), len((raw_data_path/'valid').ls())\n\n(730, 56)"
  },
  {
    "objectID": "examples.text.causal_lm_gpt2.html#get-your-hf-objects",
    "href": "examples.text.causal_lm_gpt2.html#get-your-hf-objects",
    "title": "Causal Language Modeling with GPT-2",
    "section": "Get your HF objects",
    "text": "Get your HF objects\n\nmodel_cls = AutoModelForCausalLM\n\npretrained_model_name = \"gpt2\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\nif (hf_tokenizer.pad_token is None): \n    hf_tokenizer.add_special_tokens({'pad_token': '<pad>'})  \n    hf_config.pad_token_id = hf_tokenizer.get_vocab()['<pad>']\n    hf_model.resize_token_embeddings(len(hf_tokenizer))\n\nUsing pad_token, but it is not set yet."
  },
  {
    "objectID": "examples.text.causal_lm_gpt2.html#build-your-datablock",
    "href": "examples.text.causal_lm_gpt2.html#build-your-datablock",
    "title": "Causal Language Modeling with GPT-2",
    "section": "Build your DataBlock",
    "text": "Build your DataBlock\n\nDefine how to get the raw data\n\n# the folders we want to grab the files from\nget_wiki_files = partial(get_text_files, folders=['train', 'valid'])\n\n\nfnames = get_wiki_files(raw_data_path)\n\n\nfnames[0]\n\nPath('data/task-language-modeling/pt-2/valid/Hipótese_de_Riemann.txt')\n\n\n\n\nDefine how we want to split our validation and training datasets\n\n# custom splitter to split on parent folder name\nsplitter = FuncSplitter(lambda fpath: Path(fpath).parent.name == 'valid')\n\n\nsplitter(fnames)\n\n((#730) [56,57,58,59,60,61,62,63,64,65...], (#56) [0,1,2,3,4,5,6,7,8,9...])\n\n\n\n\nDefine our DataBlock using the appropriate Blurr transforms\n\n# our before_batch_tfm and TextBlock updated for causal modeling task\nbbtfm =  LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=CausalLMStrategy)\nblocks = (TextBlock(before_batch_tfm=bbtfm, input_return_type=CausalLMTextInput), noop)\n\n# our DataBlock\ndblock = DataBlock(\n    blocks=blocks, \n    get_x=lambda x: x.read_text(),   # read each text file\n    get_items=get_wiki_files,        # grab the text files\n    splitter=splitter                # split on parent folder name (validation = 'valid')\n)\n\nValueError: You must supply an hf_arch, hf_config, hf_tokenizer, hf_model -or- a BatchTokenizeTransform\n\n\n\n# dblock.summary(raw_data_path)\n\n\ndls = dblock.dataloaders(raw_data_path, bs=2, val_bs=4)\n\n\nb = dls.one_batch()\n\n\nb[0]['input_ids'].shape, b[1].shape\n\n(torch.Size([2, 1024]), torch.Size([2, 1024]))\n\n\n\ndls.show_batch(dataloaders=dls, trunc_at=500, max_n=2)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      Aquecimento global é o processo de aumento da temperatura média dos oceanos e da atmosfera da Terra causado por massivas emissões de gases que intensificam o efeito estufa, originados de uma série de atividades humanas, especialmente a queima de combustíveis fósseis e mudanças no uso da terra, como o desmatamento, bem como de várias outras fontes secundárias. Essas causas são um produto direto da explosão populacional, do crescimento econômico, do uso de tecnologias e fontes de energia poluidor\n      ecimento global é o processo de aumento da temperatura média dos oceanos e da atmosfera da Terra causado por massivas emissões de gases que intensificam o efeito estufa, originados de uma série de atividades humanas, especialmente a queima de combustíveis fósseis e mudanças no uso da terra, como o desmatamento, bem como de várias outras fontes secundárias. Essas causas são um produto direto da explosão populacional, do crescimento econômico, do uso de tecnologias e fontes de energia poluidoras e\n    \n    \n      1\n      Os astecas eram uma cultura mesoamericana que floresceu no centro do México no período pós-clássico, de 1300 a 1521. Os povos astecas incluíam diferentes grupos étnicos do México central, particularmente aqueles grupos que falavam a língua náuatle e dominaram grandes partes da Mesoamérica entre os séculos XIV ao XVI. A cultura asteca era organizada em cidades-Estados ( &quot; altepetl &quot; ), algumas das quais se juntaram para formar alianças, confederações políticas ou impérios. O Império As\n      astecas eram uma cultura mesoamericana que floresceu no centro do México no período pós-clássico, de 1300 a 1521. Os povos astecas incluíam diferentes grupos étnicos do México central, particularmente aqueles grupos que falavam a língua náuatle e dominaram grandes partes da Mesoamérica entre os séculos XIV ao XVI. A cultura asteca era organizada em cidades-Estados ( &quot; altepetl &quot; ), algumas das quais se juntaram para formar alianças, confederações políticas ou impérios. O Império Astec"
  },
  {
    "objectID": "examples.text.causal_lm_gpt2.html#train",
    "href": "examples.text.causal_lm_gpt2.html#train",
    "title": "Causal Language Modeling with GPT-2",
    "section": "Train",
    "text": "Train\n\nmodel = BaseModelWrapper(hf_model)\nfit_cbs = [LMMetricsCallback()]\n\nlearn = Learner(dls, \n                model,\n                opt_func=partial(Adam),\n                loss_func=PreCalculatedLoss(),\n                cbs=[BaseModelCallback],\n                metrics=[perplexity],\n                splitter=blurr_splitter).to_fp16()\n\n# learn.freeze()\n\n\nlearn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\n/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/fastai/callback/schedule.py:269: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"ro\" (-> color='r'). The keyword argument will take precedence.\n  ax.plot(val, idx, 'ro', label=nm, c=color)\n\n\nSuggestedLRs(minimum=0.02089296132326126, steep=0.17378008365631104, valley=0.00019054606673307717, slide=0.2089296132326126)\n\n\n\n\n\n\nlearn.fit_one_cycle(1, lr_max=3e-3, cbs=fit_cbs)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      perplexity\n      lm_accuracy\n      time\n    \n  \n  \n    \n      0\n      3.192033\n      3.088641\n      21.947229\n      0.427133\n      02:30\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=500)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      A Idade Média ( adj. medieval ) é um período da história da Europa entre os séculos V e XV. Inicia-se com a Queda do Império Romano do Ocidente e termina durante a transição para a Idade Moderna. A Idade Média é o período intermédio da divisão clássica da História ocidental em três períodos : a Antiguidade, Idade Média e Idade Moderna, sendo frequentemente dividido em Alta e Baixa Idade Média.\\nDurante a Alta Idade Média verifica-se a continuidade dos processos de despovoamento, regressão urbana\n      Idade Média ( adj. medieval ) é um período da história da Europa entre os séculos V e XV. Inicia-se com a Queda do Império Romano do Ocidente e termina durante a transição para a Idade Moderna. A Idade Média é o período intermédio da divisão clássica da História ocidental em três períodos : a Antiguidade, Idade Média e Idade Moderna, sendo frequentemente dividido em Alta e Baixa Idade Média.\\nDurante a Alta Idade Média verifica-se a continuidade dos processos de despovoamento, regressão urbana,\n      aade dedia é o. & & é u �íodo de �ória da Id,re os �éculos X. V,\\nicialisse ao �úa, Estério daano, Sulcidente, aou aante o sumissção de a Europaade Méa.\\n Idade Média fo a período daaédio de Europaisão daássica, Europaória,uidental. queês estíodos. a Idiguidade, aade Média, Idade Méa. ao aemente aido em �enteç aixa,ade,dia,\\nAante o Idta,ade Média,dou-se aoarade de �os de estó eo e aando ebana, a aasão�es deritsicnicas,iciaadas.ante a Idiguidade Méambin,\\n �cados doárbaras deam avos,os de comenado\n    \n    \n      1\n      Itália ( ), oficialmente República Italiana, é uma república parlamentar unitária localizada no centro-sul da Europa. Ao norte, faz fronteira com França, Suíça, Áustria e Eslovênia ao longo dos Alpes. A parte sul consiste na totalidade da península Itálica, Sicília, Sardenha, as duas maiores ilhas no mar Mediterrâneo, e muitas outras ilhas menores ficam no entorno do território italiano. Os Estados independentes de San Marino e do Vaticano são enclaves no interior da Itália, enquanto Campione d\n      ália ( ), oficialmente República Italiana, é uma república parlamentar unitária localizada no centro-sul da Europa. Ao norte, faz fronteira com França, Suíça, Áustria e Eslovênia ao longo dos Alpes. A parte sul consiste na totalidade da península Itálica, Sicília, Sardenha, as duas maiores ilhas no mar Mediterrâneo, e muitas outras ilhas menores ficam no entorno do território italiano. Os Estados independentes de San Marino e do Vaticano são enclaves no interior da Itália, enquanto Campione d &a\n      ario é ) é éicialmente,ública (a, é umma freública dealentoá deário doizada pel Brasro daameró, Uni.\\n Repe da comaz partonteira com oa, queíça e E�rearia, �spanâinania,o longo do paente.\\n suir do doe em � deade de Europaínsula,áliaa, queâlia, Itãoia, S fras principaiores dohas, �,iterrâno, e oaiso mras ilhas door.azç- santo do paório.aliano.\\n principados Unes do Portugal Marino e S Brasilaano,ão aadas em territ do Europaálic, queanto ao,asquos; Repá & a paéminist doaliano. Europaíça.\\n paório It\n    \n  \n\n\n\n\nlearn.blurr_generate('Itália ( ), oficialmente República Italiana', max_length=100, do_sample=True, top_k=25)\n\n[' Itália ( ), oficialmente República Italiana , que o estudante do Brasil , é um município da Beira e suporte com o Brasileiro de Portugal em 1824 . No Brasil , ao município da Beira é o distrito de Beira . A sua capital da Beira é o seu capital , do nome da América do Sul e do nordeste']"
  },
  {
    "objectID": "examples.text.causal_lm_gpt2.html#summary",
    "href": "examples.text.causal_lm_gpt2.html#summary",
    "title": "Causal Language Modeling with GPT-2",
    "section": "Summary",
    "text": "Summary\nThis example demonstrates how to train a causal language model where the raw data examples are in individual files (similar to how the standard wikitext-103 is defined). We also defined a custom splitter function so as to put all the files under /valid as part of the validation set and all the files under /train in the training set."
  },
  {
    "objectID": "text.modeling.seq2seq.core.html",
    "href": "text.modeling.seq2seq.core.html",
    "title": "Modeling",
    "section": "",
    "text": "We add a custom param splitter to give us a bit more depth in applying discriminative learning rates for Seq2Seq tasks.\n\nsource\n\n\n\n blurr_seq2seq_splitter (m:transformers.modeling_utils.PreTrainedModel,\n                         arch:str)\n\nCustom param splitter for summarization models\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nm\nPreTrainedModel\nA Hugging Face model\n\n\narch\nstr\nThe name of the architecture you are working with (e.g., bart, fsmt, pegasus, etc…)\n\n\n\n\nsource\n\n\n\n\n Seq2SeqMetricsCallback (custom_metrics:dict=None, calc_every:str='epoch',\n                         ignore_token_id=-100, text_gen_kwargs:dict={},\n                         **kwargs)\n\nA callback that adds seq2seq metrics\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncustom_metrics\ndict\nNone\nA dictionary of seq2seq metrics we want to use. See below and the various task specific seq2seq docs\n\n\nfor examples of how to configure this per task\n\n\n\n\n\ncalc_every\nstr\nepoch\nCalculation of these metrics requires text generation, which is expensive. You can choose to calculate\n\n\nthese metrics on every ‘epoch’, ‘other_epoch’, or ‘last_epoch’ instead (default: ‘epoch’)\n\n\n\n\n\nignore_token_id\nint\n-100\nThe token ID that should be ignored when calculating the loss\n\n\ntext_gen_kwargs\ndict\n{}\nAny keyword arguments to pass to the hf_model.generate method\n\n\nkwargs\n\n\n\n\n\n\nBLURR provides a special callback for seq2seq models for calculating a variety of useful metrics that require decoding both given and predicted input_ids to be calculated. The are:\n\nrouge (e.g., “rouge1”, “rouge2”, “rougeL”, “rougeLsum”)\nbert_score (e.g., “precision”, “recall”, “f1”)\nbleu\nbleurt\nmeteor\nsacrebleu\n\n\n\n\n\ndataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:1000]\")\ncnndm_df = pd.DataFrame(dataset)\ncnndm_df.head(2)\n\nReusing dataset cnn_dailymail (/home/wgilliam/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n\n\n\n\n\n\n  \n    \n      \n      article\n      highlights\n      id\n    \n  \n  \n    \n      0\n      It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...\n      Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .\n      0001d1afc246a7964130f43ae940af6bc6c57f01\n    \n    \n      1\n      (CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...\n      Usain Bolt wins third gold of world championship .\\nAnchors Jamaica to 4x100m relay victory .\\nEighth gold at the championships for Bolt .\\nJamaica double up in women's 4x100m relay .\n      0002095e55fcbd3a2f366d9bf92a95433dc305ef\n    \n  \n\n\n\n\n\npretrained_model_name = \"facebook/bart-large-cnn\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=BartForConditionalGeneration)\nhf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)\n\n('bart',\n transformers.models.bart.configuration_bart.BartConfig,\n transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,\n transformers.models.bart.modeling_bart.BartForConditionalGeneration)\n\n\n\nbatch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=256, max_target_length=130)\nblocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"article\"), get_y=ColReader(\"highlights\"), splitter=RandomSplitter())\n\n\ndls = dblock.dataloaders(cnndm_df, bs=2)\n\n\nb = dls.one_batch()\n\n\nlen(b), b[0][\"input_ids\"].shape, b[1].shape\n\n(2, torch.Size([2, 256]), torch.Size([2, 54]))\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      <s> (CNN) -- When Ji Yeqing awakened, she was already in the recovery room. Chinese authorities had dragged her out of her home and down four flights of stairs, she said, restraining and beating her husband as he tried to come to her aid. They whisked her into a clinic, held her down on a bed and forced her to undergo an abortion. Her offense? Becoming pregnant with a second child, in violation of China's one-child policy. \"After the abortion, I felt empty, as if something was scooped out of me,\" Ji told a congressional panel in September. \"My husband and I had been so excited for our new baby. Now suddenly all that hope and joy and excitement disappeared.... I was very depressed and despondent. For a long time, whenever I thought about my lost child, I would cry.\" As she lay unconscious, she said, an IUD to prevent future pregnancies was inserted. The issue of forced abortions -- and in some cases, forced sterilizations -- in China has seized the spotlight in recent days with news of escaped activist Chen Guangcheng. Chen, a blind, self-taught lawyer, rose to fame in the late 1990s because of his advocacy for what he calls victims</s>\n      China's one-child policy results in forced abortions and sterilizations, activists say.\\nWomen tell of emotional and physical consequences from the procedures.\\nActivist Chen Guangcheng works to advocate for victims of such practices.\n    \n    \n      1\n      <s> Few question that there was a major chemical attack in Syria last week, and the United States has made clear that it blames the government of President Bashar al-Assad. Now, the question is how President Barack Obama will respond. For almost two years, Obama has avoided direct military involvement in Syria's civil war, only escalating aid to rebel fighters in June after suspected smaller-scale chemical weapons attacks by Syrian government forces. However, last week's attack on a Damascus suburb that reportedly killed and wounded more than 3,000 people obliterated the \"red line\" Obama set just over a year ago against the use of Syria's chemical weapons stocks. At the White House, spokesman Jay Carney told reporters Monday that Obama was evaluating \"a response to the clear use on a mass scale with repugnant results of chemical weapons,\" adding that \"there is very little doubt that the Syrian regime... used those weapons.\" Meanwhile, U.S. Secretary of State John Kerry called the attack \"inexcusable\" and \"undeniable,\" and said there was \"a clear reason that the world has banned entirely chemical weapons.\" He said that evidence \"strongly indicates\" chemical weapons were used in Syria and that \"we know the Syrian regime maintains custody\" of such weapons and has</s>\n      U.S. evidence includes satellite imagery, official says.\\nObama is considering how to respond to Syrian chemical attack.\\nOfficial: Obama could be presented with options within days.\\nA U.S. strike \"can't just be one and done,\" a Middle East analyst says.\n    \n  \n\n\n\n\n\n\nseq2seq_metrics = {\n    \"rouge\": {\n        \"compute_kwargs\": {\"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], \"use_stemmer\": True},\n        \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n    },\n    \"bertscore\": {\"compute_kwargs\": {\"lang\": \"en\"}, \"returns\": [\"precision\", \"recall\", \"f1\"]},\n    \"bleu\": {\"returns\": \"bleu\"},\n    \"meteor\": {\"returns\": \"meteor\"},\n    \"sacrebleu\": {\"returns\": \"score\"},\n}\n\nmodel = BaseModelWrapper(hf_model)\nlearn_cbs = [BaseModelCallback]\nfit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics, calc_every=\"other_epoch\")]\n\nlearn = Learner(\n    dls,\n    model,\n    opt_func=partial(Adam),\n    loss_func=PreCalculatedCrossEntropyLoss(),  # CrossEntropyLossFlat()\n    cbs=learn_cbs,\n    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n)\n\n# learn = learn.to_native_fp16() #.to_fp16()\nlearn.unfreeze()\n\n[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n\n\n\nb = dls.one_batch()\npreds = learn.model(b[0])\n\nlen(preds), preds[\"loss\"].shape, preds[\"logits\"].shape\n\n(4, torch.Size([]), torch.Size([2, 58, 50264]))\n\n\n\nb = dls.one_batch()\npreds = learn.model(b[0])\n\nlen(preds), preds[\"loss\"].shape, preds[\"logits\"].shape\n\n(4, torch.Size([]), torch.Size([2, 69, 50264]))\n\n\n\nprint(len(learn.opt.param_groups))\n\n3\n\n\n\nlearn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\nSuggestedLRs(minimum=2.7542287716642023e-05, steep=1.0964781722577754e-06, valley=1.737800812406931e-05, slide=9.999999747378752e-06)\n\n\n\n\n\n\nlearn.fit_one_cycle(1, lr_max=slice(9e-7, 9e-5), cbs=fit_cbs)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      rouge1\n      rouge2\n      rougeL\n      rougeLsum\n      bertscore_precision\n      bertscore_recall\n      bertscore_f1\n      bleu\n      meteor\n      sacrebleu\n      time\n    \n  \n  \n    \n      0\n      1.926532\n      1.814343\n      0.376596\n      0.157966\n      0.260184\n      0.351594\n      0.877255\n      0.890926\n      0.883944\n      0.148116\n      0.350684\n      11.629698\n      03:56\n    \n  \n\n\n\n\n\n\nBelow we’ll add in additional functionality to take advantage of Hugging Face’s PreTrainedModel.generate model, which can be used to easily implement beam search, top-k/nucleous sampling, etc… so that we get more human sounding results.\nTo make things even easier, for text generation tasks you can simply call the Learn.blurr_generate method, optionally passing in whatever text generation kwargs you wish, to accomplish the same as above.\n\ntest_article = \"\"\"\nAbout 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \ninto France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \nBasel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \nbut could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \nof armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \ncashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \noccurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \nher, and took off for the French border. The other gunmen followed into France, which is only about 100 \nmeters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \nThere were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \nrobbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \nGill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \ncontributed to this report.\n\"\"\"\n\n\nb = dls.valid.one_batch()\n\ntfm = first_blurr_tfm(dls)\n\nb_hf_tokenizer = tfm.hf_tokenizer\nb_ignore_token_id = tfm.ignore_token_id\n\ntest_input_ids = b[0][\"input_ids\"][0].unsqueeze(0).to(learn.model.hf_model.device)\ntest_trg_ids = b[1][0].unsqueeze(0).to(learn.model.hf_model.device)\ntest_trg_ids = [trg[trg != b_ignore_token_id] for trg in test_trg_ids]\n\ngen_text = learn.model.hf_model.generate(test_input_ids, num_beams=4, max_length=130, min_length=30)\n\nprint(\"=== Target ===\")\nprint(f\"{b_hf_tokenizer.decode(test_trg_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)}\\n\")\n\nprint(\"=== Prediction ===\")\nprint(b_hf_tokenizer.decode(gen_text[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n\n=== Target ===\n A winter storm slams the northeastern United States.\nThe U.S. House of Representatives condemns the Arizona shooting.\nMassive floods leave vast areas of Australia underwater.\nUse the Daily Discussion to help students understand today's featured news stories.\n\n=== Prediction ===\n This is a RUSH transcript of today's CNN Student News show.\nUse the Transcript to help students with reading comprehension and vocabulary.\nThe Story of a problem that won't be solved, even if the solution is clear.\nA look at the storm system that iced out the southeast.\nLearn about the problem that will never be solved in Australia.\nExplore the story and the reasons why a problem won't solve itself.\n\n\n\noutputs = learn.blurr_generate(test_article, num_return_sequences=3)\noutputs\n\n[{'generated_texts': [\" The robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nAs the thieves were leaving the casino, a woman driving by unknowingly blocked the armed robbers' vehicles .\\nA gunman pulled the woman from her vehicle, beat her up, and took off for the French border .\\nThere were about 600 people in the casino at the time of the robbery .\",\n   \" The robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nAs the thieves were leaving the casino, a woman driving by unknowingly blocked the armed robbers' vehicles .\\nA gunman pulled the woman from her vehicle, beat her up, and took off for the French border .\\nThere were about 600 people in the casino at the time of the raid .\",\n   \" The robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nAs the thieves were leaving the casino, a woman driving by unknowingly blocked the armed robbers' vehicles .\\nA gunman pulled the woman from her vehicle, beat her up, and took off for the French border .\\nFrench authorities are working closely with Swiss authorities .\"]}]\n\n\n\n\n\nMuch nicer!!! Now, we can update our @typedispatched show_results to use this new method.\n\nlearn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      (CNN Student News) -- January 13, 2011. Download PDF maps related to today's show:. • Arizona • Australia. Transcript. THIS IS A RUSH TRANSCRIPT. THIS COPY MAY NOT BE IN ITS FINAL FORM AND MAY BE UPDATED. CARL AZUZ, CNN STUDENT NEWS ANCHOR: A problem that won't be solved, even if the solution is clear. The story and the reasons, leading off today's broadcast of CNN Student News! My name is Carl Azuz! First Up: Winter Storm Woes. AZUZ: Florida is the only state in the union without snow on the g\n      A winter storm slams the northeastern United States.\\nThe U.S. House of Representatives condemns the Arizona shooting.\\nMassive floods leave vast areas of Australia underwater.\\nUse the Daily Discussion to help students understand today's featured news\n      [ This is a RUSH transcript of today's CNN Student News show .\\nUse the Transcript to help students with reading comprehension and vocabulary .\\nThe Story of a problem that won't be solved, even if the solution is clear .\\nA look at the storm system that iced out the southeast .\\nLearn about the problem that will never be solved in Australia .\\nExplore the story and the reasons why a problem won't solve itself .,  The Cotswolds are a slice of picture-postcard England .\\nThe wool trade boomed in these rolling hills in medieval times and today the region is littered with achingly pretty villages .\\nLeading members of the arts and crafts movement were among the first to visit Chipping Campden with its long curving high street .]\n    \n  \n\n\n\n\n\n\n\n\nexport_fname = \"summarize_export\"\n\n\nlearn.metrics = None\nlearn.export(fname=f\"{export_fname}.pkl\")\n\n\ninf_learn = load_learner(fname=f\"{export_fname}.pkl\")\ninf_learn.blurr_generate(test_article)\n\n[{'generated_texts': \" The robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nAs the thieves were leaving the casino, a woman driving by unknowingly blocked the armed robbers' vehicles .\\nA gunman pulled the woman from her vehicle, beat her up, and took off for the French border .\\nThere were about 600 people in the casino at the time of the robbery .\"}]"
  },
  {
    "objectID": "text.data.seq2seq.translation.html",
    "href": "text.data.seq2seq.translation.html",
    "title": "Data",
    "section": "",
    "text": "We’ll use a subset of wmt16 to demonstrate how to configure your BLURR for translation tasks\n\nraw_dataset = load_dataset(\"wmt16\", \"de-en\", split=\"train[:1%]\")\nraw_dataset\n\nReusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)\n\n\nDataset({\n    features: ['translation'],\n    num_rows: 45489\n})\n\n\n\nprint(raw_dataset[0].keys())\nprint(raw_dataset[0])\n\ndict_keys(['translation'])\n{'translation': {'de': 'Wiederaufnahme der Sitzungsperiode', 'en': 'Resumption of the session'}}\n\n\n\nwmt_df = pd.DataFrame(raw_dataset[\"translation\"], columns=[\"de\", \"en\"])\n\nprint(len(wmt_df))\nwmt_df.head(2)\n\n45489\n\n\n\n\n\n\n  \n    \n      \n      de\n      en\n    \n  \n  \n    \n      0\n      Wiederaufnahme der Sitzungsperiode\n      Resumption of the session\n    \n    \n      1\n      Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\n      I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n    \n  \n\n\n\n\n\npretrained_model_name = \"facebook/bart-large-cnn\"\nmodel_cls = AutoModelForSeq2SeqLM\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\nhf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)\n\n('bart',\n transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,\n transformers.models.bart.configuration_bart.BartConfig,\n transformers.models.bart.modeling_bart.BartForConditionalGeneration)"
  },
  {
    "objectID": "text.data.seq2seq.translation.html#preprocessing",
    "href": "text.data.seq2seq.translation.html#preprocessing",
    "title": "Data",
    "section": "Preprocessing",
    "text": "Preprocessing\nStarting with version 2.0, BLURR provides a preprocessing base class that can be used to build task specific pre-processed datasets from pandas DataFrames or Hugging Face Datasets\n\nsource\n\nTranslationPreprocessor\n\n TranslationPreprocessor (hf_tokenizer:transformers.tokenization_utils_bas\n                          e.PreTrainedTokenizerBase, batch_size:int=1000,\n                          id_attr:Optional[str]=None,\n                          text_attr:str='original_text',\n                          max_input_tok_length:Optional[int]=None,\n                          target_text_attr:str='translated_text',\n                          max_target_tok_length:Optional[int]=None,\n                          is_valid_attr:Optional[str]='is_valid',\n                          tok_kwargs:dict={})\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nbatch_size\nint\n1000\nThe number of examples to process at a time\n\n\nid_attr\nOptional\nNone\nThe unique identifier in the dataset\n\n\ntext_attr\nstr\noriginal_text\nThe attribute holding the text to translate\n\n\nmax_input_tok_length\nOptional\nNone\nThe maximum length (# of tokens) allowed for inputs. Will default to the max length allowed\n\n\nby the model if not provided\n\n\n\n\n\ntarget_text_attr\nstr\ntranslated_text\nThe attribute holding the summary\n\n\nmax_target_tok_length\nOptional\nNone\nThe maximum length (# of tokens) allowed for targets\n\n\nis_valid_attr\nOptional\nis_valid\nThe attribute that should be created if your are processing individual training and validation\n\n\ndatasets into a single dataset, and will indicate to which each example is associated\n\n\n\n\n\ntok_kwargs\ndict\n{}\nTokenization kwargs that will be applied with calling the tokenizer\n\n\n\nThis class can be used for preprocessing translation tasks, and includes a proc_{your_text_attr} and proc_{target_text_attr} attributes containing your modified input and target texts as a result of tokenization (e.g., if you specify a max_length the proc_{your_text_attr} may contain truncated text).\n\nUsing a DataFrame\n\npreprocessor = TranslationPreprocessor(\n    hf_tokenizer, text_attr=\"de\", target_text_attr=\"en\", max_input_tok_length=128, max_target_tok_length=128\n)\nproc_df = preprocessor.process_df(wmt_df)\nproc_df.columns, len(proc_df)\nproc_df.head(2)\n\n\n\n\n\n  \n    \n      \n      proc_en\n      proc_de\n      de\n      en\n      de_start_char_idx\n      de_end_char_idx\n      en_start_char_idx\n      en_end_char_idx\n    \n  \n  \n    \n      0\n      Resumption of the session\n      Wiederaufnahme der Sitzungsperiode\n      Wiederaufnahme der Sitzungsperiode\n      Resumption of the session\n      0\n      34\n      0\n      25\n    \n    \n      1\n      I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n      Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\n      Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\n      I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n      0\n      218\n      0\n      207"
  },
  {
    "objectID": "text.data.seq2seq.translation.html#examples",
    "href": "text.data.seq2seq.translation.html#examples",
    "title": "Data",
    "section": "Examples",
    "text": "Examples\n\nUsing the mid-level API\n\nBatch-Time Tokenization\n\nStep 1: Get your Hugging Face objects.\n\npretrained_model_name = \"facebook/bart-large-cnn\"\nmodel_cls = AutoModelForSeq2SeqLM\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\n\n\nStep 2: Create your DataBlock\nTwo lines! Notice we pass in noop for our targets (e.g. our summaries) because the batch transform will take care of both out inputs and targets.\n\nblocks = (Seq2SeqTextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"de\"), get_y=ColReader(\"en\"), splitter=RandomSplitter())\n\n\n# dblock.summary(wmt_df)\n\n\n\nStep 3: Build your DataLoaders\n\ndls = dblock.dataloaders(wmt_df, bs=4)\n\n\nb = dls.one_batch()\n\n\nlen(b), b[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape\n\n(2, torch.Size([4, 483]), torch.Size([4, 86]), torch.Size([4, 86]))\n\n\n\nb[0][\"labels\"][0], b[1][0]\n\n(tensor([    0,  2223,    13,  1402,  4723,    89,   189,    28, 16855,   111,\n            38,   524,  2053,  4010,     9,     5,  2788,  4755,  1293,     6,\n           147,     5,  1492,     9,  9813,   696,  4685,   372,  2212,   111,\n             5,  3038,    40,    28, 10142,    13,   258,     5,   796,  1332,\n             8,  1625,     4,   286,     5,   796,  1332,     6,   142,     5,\n          7147,     9,    10,   481,   721,   443,    40,  3155,    24,     7,\n          9648,     5,  2621, 10153,   532,    56,    11,  4938,  1048,   137,\n             5, 13783,  1288,   376,    88,  1370,     6,  3329,    92,  2919,\n          1616,    13,   796,   451,     4,     2], device='cuda:1'),\n tensor([    0,  2223,    13,  1402,  4723,    89,   189,    28, 16855,   111,\n            38,   524,  2053,  4010,     9,     5,  2788,  4755,  1293,     6,\n           147,     5,  1492,     9,  9813,   696,  4685,   372,  2212,   111,\n             5,  3038,    40,    28, 10142,    13,   258,     5,   796,  1332,\n             8,  1625,     4,   286,     5,   796,  1332,     6,   142,     5,\n          7147,     9,    10,   481,   721,   443,    40,  3155,    24,     7,\n          9648,     5,  2621, 10153,   532,    56,    11,  4938,  1048,   137,\n             5, 13783,  1288,   376,    88,  1370,     6,  3329,    92,  2919,\n          1616,    13,   796,   451,     4,     2], device='cuda:1'))\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=250, target_trunc_at=250)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      <s> Was nun die Ergebnisse der Verhandlungen über die Anwendung der Artikel 3, 4, 5, 6 und 12 des Interimsabkommens bezüglich Warenhandel, öffentlicher Aufträge, Wettbewerb, Konsultationsmechanismen bei Fragen des geistigen Eigentums und Beilegung vo\n      Although for certain sectors there may be flaws - I am thinking specifically of the textiles sector, where the rules of origin issue causes great concern - the effects will be beneficial for both the European Union and Mexico. For the European Union\n    \n    \n      1\n      <s> Die allgemeine Ausrichtung der umgesetzten Wirtschaftspolitik, der Stabilitätspakt sowie die strengen Konvergenzprogramme, die der Beschäftigung empfindlich schaden und Beschäftigungsfähigkeit sowie Flexibilität der Arbeitsverhältnisse und Arbeit\n      The general lines of the implemented economic policy, the Stability Pact and the strict convergence programmes, which are a constant menace to employment and which promote employability and the flexibilisation of labour relations, and the organisati\n    \n  \n\n\n\n\n\n\nUsing a preprocessed dataset\n\nStep 1a: Get your Hugging Face objects.\n\npretrained_model_name = \"facebook/bart-large-cnn\"\nmodel_cls = AutoModelForSeq2SeqLM\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\n\n\nStep 1b. Preprocess dataset\n\npreprocessor = TranslationPreprocessor(\n    hf_tokenizer, text_attr=\"de\", target_text_attr=\"en\", max_input_tok_length=128, max_target_tok_length=128\n)\nproc_df = preprocessor.process_df(wmt_df)\n\n\n\nStep 2: Create your DataBlock\n\nblocks = (Seq2SeqTextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"proc_de\"), get_y=ColReader(\"proc_en\"), splitter=RandomSplitter())\n\n\n\nStep 3: Build your DataLoaders\n\ndls = dblock.dataloaders(proc_df, bs=4)\n\n\nb = dls.one_batch()\n\n\nlen(b), b[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape\n\n(2, torch.Size([4, 129]), torch.Size([4, 83]), torch.Size([4, 83]))\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=250, target_trunc_at=250)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      <s> Hierbei denke ich an systematische Dokumentation und Informationsbeschaffung, professionelle Formen der Beobachtung, die Entwicklung von Aufklärungsaktionen, die Verwendung von Geldern zur Unterstützung der demokratischen Kräfte in dem betreffend\n      The following spring to mind in this respect: the systematic collation of documentation and information, professional forms of observation, the development of information campaigns, the use of cash to support democratic forces in the country concern\n    \n    \n      1\n      <s> Eine letzte Bemerkung: Die durch die Struktur des Internet bedingte permanente Verfügbarkeit von Sexuellem im ausschließlich anonymisierten privaten Bereich und die Tatsache, daß der sexuelle Mißbrauch der öffentlichen und damit der sozialen Kont\n      One final comment: the permanent availability of sexual material in the exclusively anonymous private sphere, which is conditioned by the structure of the Internet, and the attendant fact that sexual abuse is removed from public and, hence, social c"
  },
  {
    "objectID": "text.data.seq2seq.translation.html#tests",
    "href": "text.data.seq2seq.translation.html#tests",
    "title": "Data",
    "section": "Tests",
    "text": "Tests\nThe purpose of the following tests is to ensure as much as possible, that the core DataBlock code above works for the pretrained translation models below. These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\nNote: Feel free to modify the code below to test whatever pretrained translation models you are working with … and if any of your pretrained summarization models fail, please submit a github issue (or a PR if you’d like to fix it yourself)\n\n[model_type for model_type in NLP.get_models(task=\"ConditionalGeneration\") if (not model_type.startswith(\"TF\"))]\n\n['BartForConditionalGeneration',\n 'BigBirdPegasusForConditionalGeneration',\n 'BlenderbotForConditionalGeneration',\n 'BlenderbotSmallForConditionalGeneration',\n 'FSMTForConditionalGeneration',\n 'LEDForConditionalGeneration',\n 'M2M100ForConditionalGeneration',\n 'MBartForConditionalGeneration',\n 'MT5ForConditionalGeneration',\n 'PegasusForConditionalGeneration',\n 'ProphetNetForConditionalGeneration',\n 'Speech2TextForConditionalGeneration',\n 'T5ForConditionalGeneration',\n 'XLMProphetNetForConditionalGeneration']\n\n\n\npretrained_model_names = [\n    \"facebook/bart-base\",\n    \"facebook/wmt19-de-en\",  # FSMT\n    \"Helsinki-NLP/opus-mt-de-en\",  # MarianMT\n    \"sshleifer/tiny-mbart\",\n    \"google/mt5-small\",\n    \"t5-small\",\n]\n\n\npath = Path(\"./\")\nwmt_df = pd.DataFrame(raw_dataset[\"translation\"], columns=[\"de\", \"en\"])\n\n\nmodel_cls = AutoModelForSeq2SeqLM\nbsz = 2\nseq_sz = 128\ntrg_seq_sz = 128\n\ntest_results = []\nfor model_name in pretrained_model_names:\n    error = None\n\n    print(f\"=== {model_name} ===\\n\")\n\n    hf_tok_kwargs = {}\n    if model_name == \"sshleifer/tiny-mbart\":\n        hf_tok_kwargs[\"src_lang\"], hf_tok_kwargs[\"tgt_lang\"] = \"de_DE\", \"en_XX\"\n\n    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(model_name, model_cls=model_cls, tokenizer_kwargs=hf_tok_kwargs)\n\n    print(f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\n\")\n\n    # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n    if hf_tokenizer.pad_token is None:\n        hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n        hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n        hf_model.resize_token_embeddings(len(hf_tokenizer))\n\n    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n        hf_arch, hf_config, hf_tokenizer, hf_model, padding=\"max_length\", max_length=seq_sz, max_target_length=trg_seq_sz\n    )\n\n    def add_t5_prefix(inp):\n        return f\"translate German to English: {inp}\" if (hf_arch == \"t5\") else inp\n\n    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n    dblock = DataBlock(blocks=blocks, get_x=Pipeline([ColReader(\"de\"), add_t5_prefix]), get_y=ColReader(\"en\"), splitter=RandomSplitter())\n\n    dls = dblock.dataloaders(wmt_df, bs=bsz)\n    b = dls.one_batch()\n\n    try:\n        print(\"*** TESTING DataLoaders ***\\n\")\n        test_eq(len(b), 2)\n        test_eq(len(b[0][\"input_ids\"]), bsz)\n        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, seq_sz]))\n        test_eq(len(b[1]), bsz)\n        test_eq(b[1].shape, torch.Size([bsz, trg_seq_sz]))\n\n        if hasattr(hf_tokenizer, \"add_prefix_space\"):\n            test_eq(hf_tokenizer.add_prefix_space, True)\n\n        test_results.append((hf_arch, type(hf_tokenizer).__name__, model_name, \"PASSED\", \"\"))\n        dls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=1000)\n\n    except Exception as err:\n        test_results.append((hf_arch, type(hf_tokenizer).__name__, model_name, \"FAILED\", err))\n\n\n\n\n\n  \n    \n      \n      arch\n      tokenizer\n      model_name\n      result\n      error\n    \n  \n  \n    \n      0\n      bart\n      BartTokenizerFast\n      facebook/bart-base\n      PASSED\n      \n    \n    \n      1\n      fsmt\n      FSMTTokenizer\n      facebook/wmt19-de-en\n      PASSED\n      \n    \n    \n      2\n      marian\n      MarianTokenizer\n      Helsinki-NLP/opus-mt-de-en\n      PASSED\n      \n    \n    \n      3\n      mbart\n      MBartTokenizerFast\n      sshleifer/tiny-mbart\n      PASSED\n      \n    \n    \n      4\n      mt5\n      T5TokenizerFast\n      google/mt5-small\n      PASSED\n      \n    \n    \n      5\n      t5\n      T5TokenizerFast\n      t5-small\n      PASSED"
  },
  {
    "objectID": "text.modeling.language_modeling.html",
    "href": "text.modeling.language_modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "For this example, we’ll use the WIKITEXT_TINY dataset available from fastai to demonstrate how to configure BLURR code for language modeling\n\nwiki_path = untar_data(URLs.WIKITEXT_TINY)\n\ntrain_df = pd.read_csv(wiki_path / \"train.csv\", header=None)\nvalid_df = pd.read_csv(wiki_path / \"test.csv\", header=None)\n\ntrain_df[\"is_valid\"] = False\nvalid_df[\"is_valid\"] = True\n\ndf = pd.concat([train_df, valid_df])\n\nprint(len(df))\ndf.head()\n\n662\n\n\n\n\n\n\n  \n    \n      \n      0\n      is_valid\n    \n  \n  \n    \n      0\n      \\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...\n      False\n    \n    \n      1\n      \\n = Big Boy ( song ) = \\n \\n \" Big Boy \" <unk> \" I 'm A Big Boy Now \" was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including \" Big Boy \" . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \\n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re...\n      False\n    \n    \n      2\n      \\n = The Remix ( Lady Gaga album ) = \\n \\n The Remix is a remix album by American recording artist Lady Gaga . Released in Japan on March 3 , 2010 , it contains remixes of the songs from her first studio album , The Fame ( 2008 ) , and her third extended play , The Fame Monster ( 2009 ) . A revised version of the track list was prepared for release in additional markets , beginning with Mexico on May 3 , 2010 . A number of recording artists have produced the songs , including Pet Shop Boys , Passion Pit and The Sound of Arrows . The remixed versions feature both uptempo and <unk> composit...\n      False\n    \n    \n      3\n      \\n = New Year 's Eve ( Up All Night ) = \\n \\n \" New Year 's Eve \" is the twelfth episode of the first season of the American comedy television series Up All Night . The episode originally aired on NBC in the United States on January 12 , 2012 . It was written by Erica <unk> and was directed by Beth McCarthy @-@ Miller . The episode also featured a guest appearance from Jason Lee as Chris and Reagan 's neighbor and Ava 's boyfriend , Kevin . \\n During Reagan ( Christina Applegate ) and Chris 's ( Will <unk> ) first New Year 's Eve game night , Reagan 's competitiveness comes out causing Ch...\n      False\n    \n    \n      4\n      \\n = Geopyxis carbonaria = \\n \\n Geopyxis carbonaria is a species of fungus in the genus Geopyxis , family <unk> . First described to science in 1805 , and given its current name in 1889 , the species is commonly known as the charcoal loving elf @-@ cup , dwarf <unk> cup , <unk> <unk> cup , or pixie cup . The small , <unk> @-@ shaped fruitbodies of the fungus are reddish @-@ brown with a whitish fringe and measure up to 2 cm ( 0 @.@ 8 in ) across . They have a short , tapered stalk . Fruitbodies are commonly found on soil where brush has recently been burned , sometimes in great numbers ....\n      False"
  },
  {
    "objectID": "text.modeling.language_modeling.html#mid-level-api",
    "href": "text.modeling.language_modeling.html#mid-level-api",
    "title": "Modeling",
    "section": "Mid-level API",
    "text": "Mid-level API\n\nsource\n\nLMMetricsCallback\n\n LMMetricsCallback (**kwargs)\n\nA fastai friendly metric implemented as a callback so that we can handle use cases where we don’t want to count tokens marked to be ignored or else not count batches where there are no targs\nIn this section, we’ll add helpful metrics for calculating accuracy and perplexity for both causal and masked language modeling tasks.\n\n\nExamples\n\nCausal Language Modeling\nIn causal language modeling, we are attempting to predict the next token given those before it.\n\nmodel_cls = AutoModelForCausalLM\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"gpt2\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\nif hf_tokenizer.pad_token is None:\n    hf_tokenizer.pad_token = \"[PAD]\"\n\nUsing pad_token, but it is not set yet.\n\n\n\npreprocessor = LMPreprocessor(hf_tokenizer, chunk_size=128, text_attr=0)\nproc_df = preprocessor.process_df(train_df, valid_df)\n\n\nbbtfm = LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=CausalLMStrategy)\nblocks = (TextBlock(batch_tokenize_tfm=bbtfm, input_return_type=CausalLMTextInput), noop)\n\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"proc_0\"), splitter=ColSplitter(col=\"is_valid\"))\n\n\ndls = dblock.dataloaders(proc_df, bs=2)\n\n\nb = dls.one_batch()\nb[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape\n\n(torch.Size([2, 129]), torch.Size([2, 129]), torch.Size([2, 129]))\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      ₹ 40 million ( US $ 590 @,@ 000 ) was spent solely on VFX for Magadheera. \\n \\n = = = <unk> = = = \\n \\n During the film's shoot at Ramoji Film City in late November 2008, a 500 square feet ( 46 m2 ) film can, containing two or three scenes, was discovered missing from Rainbow lab. The filmmakers filed a case at <unk> police station. Security personnel and film unit members searched, but failed to recover the reels. Rajamouli's unit said it was not important if the scenes from\n      �� 40 million ( US $ 590 @,@ 000 ) was spent solely on VFX for Magadheera. \\n \\n = = = <unk> = = = \\n \\n During the film's shoot at Ramoji Film City in late November 2008, a 500 square feet ( 46 m2 ) film can, containing two or three scenes, was discovered missing from Rainbow lab. The filmmakers filed a case at <unk> police station. Security personnel and film unit members searched, but failed to recover the reels. Rajamouli's unit said it was not important if the scenes from\n    \n    \n      1\n      ology of Ritual and Magic was reviewed by John Hutchings for the Folklore journal, the published arm of The Folklore Society. He highlighted how the work would be of benefit to folklorists, by putting various charms then in museum exhibits – such as dead cats, buried shoes and witch bottles – into the wider context of ritual activity. He opined that it was \" a little disappointing \" that the examples were almost all from London and the Home Counties, but described the book as \" <unk> written, c\n      logy of Ritual and Magic was reviewed by John Hutchings for the Folklore journal, the published arm of The Folklore Society. He highlighted how the work would be of benefit to folklorists, by putting various charms then in museum exhibits – such as dead cats, buried shoes and witch bottles – into the wider context of ritual activity. He opined that it was \" a little disappointing \" that the examples were almost all from London and the Home Counties, but described the book as \" <unk> written, car\n    \n  \n\n\n\n\nTraining\n\nmodel = BaseModelWrapper(hf_model)\nfit_cbs = [LMMetricsCallback()]\n\nlearn = Learner(\n    dls,\n    model,\n    opt_func=partial(Adam),\n    loss_func=PreCalculatedCrossEntropyLoss(),\n    cbs=[BaseModelCallback],\n    metrics=[perplexity],\n    splitter=blurr_splitter,\n).to_fp16()\n\nlearn.freeze()\n\n\nlearn.summary()\n\n\n# b = dls.one_batch()\n# preds = learn.model(b[0])\n# len(preds),preds[0], preds[1].shape\n\n\nprint(len(learn.opt.param_groups))\n\n5\n\n\n\nlearn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\n\n\n\n\nSuggestedLRs(minimum=0.0013182567432522773, steep=3.311311274956097e-06, valley=0.0012022644514217973, slide=0.0030199517495930195)\n\n\n\n\n\n\nlearn.fit_one_cycle(1, lr_max=3e-3, cbs=fit_cbs)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      perplexity\n      lm_accuracy\n      time\n    \n  \n  \n    \n      0\n      3.461066\n      3.167435\n      23.746506\n      0.417437\n      24:57\n    \n  \n\n\n\n\n\nShowing results\nBelow we’ll add in additional functionality to more intuitively show the results of our model.\n\nlearn.show_results(learner=learn, trunc_at=250)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      . \\n The German government has said that it does not consider Scientology a religion, but a \" commercial enterprise with a history of taking advantage of vulnerable individuals and an extreme dislike of any criticism \" whose \" totalitarian structure a\n      \\n The German government has said that it does not consider Scientology a religion, but a \" commercial enterprise with a history of taking advantage of vulnerable individuals and an extreme dislike of any criticism \" whose \" totalitarian structure an\n      <\\n  < army was been that the is not want the to threat, but that \" cult organization \" a commercial of religious advantage of the individuals \" the interest religious of the form of. \" < ideology \" political \" be a threat to the \"s national system \"\n    \n    \n      1\n      the Japanese launched a heavy counter @-@ attack, which was turned back with heavy casualties. After this, the situation on <unk> became largely static, as the Japanese focused primarily on subsistence, and the US forces chose to adopt a mainly defe\n      Japanese launched a heavy counter @-@ attack, which was turned back with heavy casualties. After this, the situation on <unk> became largely static, as the Japanese focused primarily on subsistence, and the US forces chose to adopt a mainly defensiv\n      < < a series attackattack-@ attack on but was launched back by a fire.  the, the Japanese was theunk> was more peaceful. with the Japanese were on on the farming and the Japanese and were to concentrate a more defensive strategy. on the the defensiv\n    \n  \n\n\n\n\n\nPrediction\n\nlearn.blurr_generate(\"Blurr is fun to work with because\", max_length=50, do_sample=True, top_k=25)\n\n[{'generated_texts': ' Blurr is fun to work with because the way he moves and talks to the audience is reminiscent of the way he talks to an audience and the way he behaves . He has a tendency to laugh at himself and others , especially when his humor seems'}]\n\n\n\n\n\nMasked Language Modeling\nIn masked language modeling (MLM), we are attempting to predict the masked tokens. In Blurr, these are encapsulated by classes implementing the BaseLMStrategy base class.\nFor a list of some of the more common strategies, see table 3 of the Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer paper. When fine-tuning a MLM model. you’ll want to make sure you use the same approach as the model authors should you be looking to reproduce their results … but our approach here makes it easy to play with different strategies regardless.\nIn the example below, we’ll tell Blurr we want to use the BERT-style masking strategy.\n\nmodel_cls = AutoModelForMaskedLM\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"distilroberta-base\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\nif hf_tokenizer.pad_token is None:\n    hf_tokenizer.pad_token = \"[PAD]\"\n\n\npreprocessor = LMPreprocessor(hf_tokenizer, chunk_size=128, text_attr=0)\nproc_df = preprocessor.process_df(train_df, valid_df)\n\n\nbbtfm = LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=BertMLMStrategy)\nblocks = (TextBlock(batch_tokenize_tfm=bbtfm, input_return_type=MLMTextInput), noop)\n\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"proc_0\"), splitter=ColSplitter(col=\"is_valid\"))\n\n\ndls = dblock.dataloaders(proc_df, bs=2)\n\n\nb = dls.one_batch()\nb[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape\n\n(torch.Size([2, 130]), torch.Size([2, 130]), torch.Size([2, 130]))\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2, trunc_at=250)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      � � � [u]  —  wanted  to  forcibly  retire  officers  with  more  than  25  years  of  service ,  as  they  thought <mask>  to  be    and <mask> , <mask>  most  importantly ,  rivals  for  power .  Most  of  the  older  officers  had [ more]  experience [ under]  the  Vietnamese  National <mask>  during  the  French  colonial  era ,  and  some  of [host]  younger  men  saw  them  as <mask>  detached <mask> <mask>  modern  situation .  The  Young  Turks  had  quite  a  lot <mask>  influence  over  Kh án h ,  as  Th i  and  K � � � <mask>  intervened  milit <mask>  to <mask>  him  from  a  coup  attempt  in  September <mask> <mask> als <mask>  V � � <mask>    and  D � � � � ng  V � �\n      � � � [u]  —  wanted  to  forcibly  retire  officers  with  more  than  25  years  of  service ,  as  they  thought [ them]  to  be    and [ ineffective] , [ but]  most  importantly ,  rivals  for  power .  Most  of  the  older  officers  had [ more]  experience [ under]  the  Vietnamese  National [ Army]  during  the  French  colonial  era ,  and  some  of [ the]  younger  men  saw  them  as [ too]  detached [ from] [ the]  modern  situation .  The  Young  Turks  had  quite  a  lot [ of]  influence  over  Kh án h ,  as  Th i  and  K � � � [ had]  intervened  milit [arily]  to [ save]  him  from  a  coup  attempt  in  September [ by] [ Gener] als [ ]  V � � [n]    and  D � � � � ng  V � �\n    \n    \n      1\n      � �  t  wait <mask>  a  fresh  start .  \"  Later  in  the <mask> , <mask>  the  Phillies  won  game  five [,]  a    Brett  Myers    asked  Ham els  :  \"  What  are [ you]  doing <mask> ?  I  thought  you  quit .  \"  The  Phillies <mask>  the  World  Series <mask>  the  New  York <mask>  in  six  games .   \\n  Rob   <mask> <mask>  and  columnist  for  ESPN . com , [ contradicted]  anyone  who <mask> [ burgers] els  ' <mask>  had  deteriorated , <mask>  commenting <mask>   \\n  \"  Last  October ,  everybody  was  ready  to    Ham els  some  sort  of  superhero .  This  was  largely <mask>  he  went <mask>  –  0  during  the  Phillies  '  championship  run ,  but\n      � �  t  wait [ for]  a  fresh  start .  \"  Later  in  the [ series] , [ after]  the  Phillies  won  game  five [,]  a    Brett  Myers    asked  Ham els  :  \"  What  are [ you]  doing [ here] ?  I  thought  you  quit .  \"  The  Phillies [ lost]  the  World  Series [ to]  the  New  York [ Yankees]  in  six  games .   \\n  Rob   [ a] [ ]  and  columnist  for  ESPN . com , [ contradicted]  anyone  who [ asserted] [ Ham] els  ' [ skills]  had  deteriorated , [ instead]  commenting [,]   \\n  \"  Last  October ,  everybody  was  ready  to    Ham els  some  sort  of  superhero .  This  was  largely [ because]  he  went [ 4]  –  0  during  the  Phillies  '  championship  run ,  but\n    \n  \n\n\n\n\nTraining\n\nmodel = BaseModelWrapper(hf_model)\nfit_cbs = [LMMetricsCallback()]\n\nlearn = Learner(\n    dls,\n    model,\n    opt_func=partial(Adam, decouple_wd=True),\n    loss_func=PreCalculatedCrossEntropyLoss(),\n    cbs=[BaseModelCallback],\n    metrics=[perplexity],\n    splitter=blurr_splitter,\n).to_fp16()\n\nlearn.freeze()\n\n\nlearn.summary()\n\n\nprint(len(learn.opt.param_groups))\n\n3\n\n\n\nlearn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\n\n\n\n\nSuggestedLRs(minimum=7.585775847473997e-08, steep=0.0003311311302240938, valley=0.0014454397605732083, slide=0.04786301031708717)\n\n\n\n\n\n\nlearn.fit_one_cycle(1, lr_max=1e-4, cbs=fit_cbs)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      perplexity\n      lm_accuracy\n      time\n    \n  \n  \n    \n      0\n      1.901993\n      1.800679\n      6.053758\n      0.638759\n      34:37\n    \n  \n\n\n\n\n\nShowing results\nBelow we’ll add in additional functionality to more intuitively show the results of our model.\n\nlearn.show_results(learner=learn, trunc_at=250)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      hostile  when  the <mask> ler  ' <mask>  presence <mask>  to  competition  over  resources ,  and  to <mask>  occupation [ of]  the  indigenous  inhabitants  '  lands .  European  diseases  dec imated  Aboriginal  populations <mask>  and  the <mask>  or  destruction  of [eper]  and  food <mask> [ sometimes]  led  to  starvation .  By <mask>  large  neither  the <mask>  nor  the    approached  the  conflict  in  an  organised  sense  and  conflict  occurred  between  groups  of  settlers  and  individual  tribes  rather  than  systematic  warfare .  At  times , <mask> ,  the <mask>  wars  did  see  the  involvement  of  British  soldiers <mask>  later  mounted [ police]  units .  Not  all  Aboriginal  groups <mask>  white  encro achment <mask>  their  lands <mask>  while  many    served  in  mounted  police  units  and  were  involved  in\n      hostile  when  the [ sett] ler  ' [s]  presence [ led]  to  competition  over  resources ,  and  to [ the]  occupation [ of]  the  indigenous  inhabitants  '  lands .  European  diseases  dec imated  Aboriginal  populations [,]  and  the [ occupation]  or  destruction  of [ lands]  and  food [ resources] [ sometimes]  led  to  starvation .  By [ and]  large  neither  the [ British]  nor  the    approached  the  conflict  in  an  organised  sense  and  conflict  occurred  between  groups  of  settlers  and  individual  tribes  rather  than  systematic  warfare .  At  times , [ however] ,  the [ frontier]  wars  did  see  the  involvement  of  British  soldiers [ and]  later  mounted [ police]  units .  Not  all  Aboriginal  groups [ resisted]  white  encro achment [ on]  their  lands [,]  while  many    served  in  mounted  police  units  and  were  involved  in\n      hostile  when  the [ sett] ler  ' [s]  presence [ led]  to  competition  over  resources ,  and  to [ the]  occupation [ of]  the  indigenous  inhabitants  '  lands .  European  diseases  dec imated  Aboriginal  populations [,]  and  the [ theft]  or  destruction  of [ crops]  and  food [ supplies] [ sometimes]  led  to  starvation .  By [ the]  large  neither  the [ British]  nor  the    approached  the  conflict  in  an  organised  sense  and  conflict  occurred  between  groups  of  settlers  and  individual  tribes  rather  than  systematic  warfare .  At  times , [ however] ,  the [ Indian]  wars  did  see  the  involvement  of  British  soldiers [ and]  later  mounted [ police]  units .  Not  all  Aboriginal  groups [ saw]  white  encro achment [ on]  their  lands [,]  while  many    served  in  mounted  police  units  and  were  involved  in\n    \n    \n      1\n      ,  the  two <mask> , [ along]  with  the  Meridian  Downtown  Association ,  spearheaded  the  downtown    effort .  The  Alliance  serves  as  an  umbrella  organization ,  allowing  the  other  two  organizations  to <mask>  the  its  support [ staff] <mask>  housing ,  and  in  turn <mask>  Alliance  serves <mask>  a  liaison  between  the  organizations .  Plans  were <mask>  to  renov ate  the    Building , <mask> <mask> <mask>  Mayor    Barry  killed  the  plans  in  early  2010 <mask>  Today <mask>  the  Alliance  helps  to  promote [ qual]  development  and  restoration  downtown <mask>  its  goal  is  to  assist  businesses  such  as  specialty  shops ,  restaurants ,  and  bars [ because]  these  help  downtown <mask> <mask>  active <mask>  the  day  and  at  night .  The  Meridian  Downtown  Association\n      ,  the  two [ organizations] , [ along]  with  the  Meridian  Downtown  Association ,  spearheaded  the  downtown    effort .  The  Alliance  serves  as  an  umbrella  organization ,  allowing  the  other  two  organizations  to [ use]  the  its  support [ staff] [ and]  housing ,  and  in  turn [ the]  Alliance  serves [ as]  a  liaison  between  the  organizations .  Plans  were [ underway]  to  renov ate  the    Building , [ but] [ newly] [ elected]  Mayor    Barry  killed  the  plans  in  early  2010 [.]  Today [,]  the  Alliance  helps  to  promote [ further]  development  and  restoration  downtown [ ;]  its  goal  is  to  assist  businesses  such  as  specialty  shops ,  restaurants ,  and  bars [ because]  these  help  downtown [ become] [ more]  active [ during]  the  day  and  at  night .  The  Meridian  Downtown  Association\n      ,  the  two [ organizations] , [ along]  with  the  Meridian  Downtown  Association ,  spearheaded  the  downtown    effort .  The  Alliance  serves  as  an  umbrella  organization ,  allowing  the  other  two  organizations  to [ provide]  the  its  support [ staff] [ and]  housing ,  and  in  turn [ the]  Alliance  serves [ as]  a  liaison  between  the  organizations .  Plans  were [ made]  to  renov ate  the    Building , [ but] [ ] [,]  Mayor    Barry  killed  the  plans  in  early  2010 [.]  Today [,]  the  Alliance  helps  to  promote [ economic]  development  and  restoration  downtown [ ;]  its  goal  is  to  assist  businesses  such  as  specialty  shops ,  restaurants ,  and  bars [ because]  these  help  downtown [ businesses] [ stay]  active [ during]  the  day  and  at  night .  The  Meridian  Downtown  Association\n    \n  \n\n\n\n\n\nPrediction\nWhile Learner.blurr_generate will work well for causal LMs designed for text generation, it won’t for MLM models designed to predict masked tokens. To accomodate the later, we add Learner.blurr_fill_mask …\n\nsource\n\n\n\n\nLearner.blurr_fill_mask\n\n Learner.blurr_fill_mask (inp:Union[List[int],str], n_preds:int=1,\n                          **kwargs)\n\nFor MLM models\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninp\nUnion\n\nYour input_ids or raw text string with a hf_tokenizer.mask_token\n\n\nn_preds\nint\n1\nThe number of predictions you want to return for the [MASK]ed token\n\n\nkwargs\n\n\n\n\n\n\n\nlearn.blurr_fill_mask(f\"The best place on earth is {hf_tokenizer.mask_token}.\", n_preds=5)\n\n['The best place on earth is here.',\n 'The best place on earth is there.',\n 'The best place on earth is America.',\n 'The best place on earth is hell.',\n 'The best place on earth is ours.']"
  },
  {
    "objectID": "text.modeling.language_modeling.html#high-level-api",
    "href": "text.modeling.language_modeling.html#high-level-api",
    "title": "Modeling",
    "section": "High-level API",
    "text": "High-level API\n\nsource\n\nBlearnerForLM\n\n BlearnerForLM (dls:fastai.data.core.DataLoaders,\n                hf_model:transformers.modeling_utils.PreTrainedModel, base\n                _model_cb:blurr.text.modeling.core.BaseModelCallback=<clas\n                s 'blurr.text.modeling.core.BaseModelCallback'>,\n                loss_func:callable|None=None, opt_func=<function Adam>,\n                lr=0.001, splitter:callable=<function trainable_params>,\n                cbs=None, metrics=None, path=None, model_dir='models',\n                wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95,\n                0.85, 0.95), default_cbs:bool=True)\n\nGroup together a model, some dls and a loss_func to handle training\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndls\n\nDataLoaders containing data for each dataset needed for model\n\n\nhf_model\nPreTrainedModel\n\n\n\n\nWe can use the BlearnerForLM for either Causal or Masked language models. With one line of code, we get our DataBlock, DataLoaders, and Blearner with sensible defaults and ready for training\n\n\nExample\n\nCausal language modeling\n\nlearn = BlearnerForLM.from_data(df, \"gpt2\", text_attr=0, dl_kwargs={\"bs\": 2}).to_fp16()\n\nUsing pad_token, but it is not set yet.\n\n\n\nlearn.dls.show_batch(dataloaders=learn.dls, max_n=2, trunc_at=500)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      \\n = Bob Dylan = \\n \\n Bob Dylan ( / <unk> / ; born Robert Allen Zimmerman, May 24, 1941 ) is an American singer @-@ songwriter, artist and writer. He has been influential in popular music and culture for more than five decades. Much of his most celebrated work dates from the 1960s when his songs chronicled social unrest, although Dylan repudiated suggestions from journalists that he was a spokesman for his generation. Nevertheless, early songs such as \" Blowin'in the Wind \" and \" The Times They A\n      \\n = Bob Dylan = \\n \\n Bob Dylan ( / <unk> / ; born Robert Allen Zimmerman, May 24, 1941 ) is an American singer @-@ songwriter, artist and writer. He has been influential in popular music and culture for more than five decades. Much of his most celebrated work dates from the 1960s when his songs chronicled social unrest, although Dylan repudiated suggestions from journalists that he was a spokesman for his generation. Nevertheless, early songs such as \" Blowin'in the Wind \" and \" The Times They Ar\n    \n    \n      1\n      \\n = George Calvert, 1st Baron Baltimore = \\n \\n George Calvert, 1st Baron Baltimore ( <unk> – 15 April 1632 ) was an English politician and <unk>. He achieved domestic political success as a Member of Parliament and later Secretary of State under King James I. He lost much of his political power after his support for a failed marriage alliance between Prince Charles and the Spanish House of Habsburg royal family. Rather than continue in politics, he resigned all of his political offices in 1625 e\n      \\n = George Calvert, 1st Baron Baltimore = \\n \\n George Calvert, 1st Baron Baltimore ( <unk> – 15 April 1632 ) was an English politician and <unk>. He achieved domestic political success as a Member of Parliament and later Secretary of State under King James I. He lost much of his political power after his support for a failed marriage alliance between Prince Charles and the Spanish House of Habsburg royal family. Rather than continue in politics, he resigned all of his political offices in 1625 ex\n    \n  \n\n\n\n\nlearn.fit_one_cycle(1, lr_max=3e-3, cbs=[BlearnerForLM.get_metrics_cb()])\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      perplexity\n      lm_accuracy\n      time\n    \n  \n  \n    \n      0\n      3.530678\n      3.135360\n      22.996923\n      0.427218\n      02:35\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, trunc_at=250)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      \\n = Military history of Australia = \\n \\n The military history of Australia spans the nation's 220 @-@ year modern history, from the early Australian frontier wars between <unk> and Europeans to the ongoing conflicts in Iraq and Afghanistan in the ear\n      \\n = Military history of Australia = \\n \\n The military history of Australia spans the nation's 220 @-@ year modern history, from the early Australian frontier wars between <unk> and Europeans to the ongoing conflicts in Iraq and Afghanistan in the earl\n      \\n\\n =\\n = the\\n\\n\\n =\\n = Australian history of Australia is the period froms history- 1@ years period era. including the early days colonial to to the 18> Australia < < the early conflict between the and Afghanistan. the late 1980st century. The the histo\n    \n    \n      1\n      \\n = Air Rhodesia Flight <unk> = \\n \\n Air Rhodesia Flight <unk> was a scheduled passenger flight that was shot down by the Zimbabwe People's Revolutionary Army ( <unk> ) on 3 September 1978, during the Rhodesian Bush War. The aircraft involved, a Vick\n      \\n = Air Rhodesia Flight <unk> = \\n \\n Air Rhodesia Flight <unk> was a scheduled passenger flight that was shot down by the Zimbabwe People's Revolutionary Army ( <unk> ) on 3 September 1978, during the Rhodesian Bush War. The aircraft involved, a Vicke\n      \\n\\n = Force\\n\\n\\n\\n> = Air\\n =\\n = Rhodesia Flight <unk> = a flight flight flight from was scheduled down by a Sovietan'ss Liberation Army (Zunk> ) in September August 1944. killing a liberationian civil War. The plane was in was civilian- aircraftickersoun\n    \n  \n\n\n\n\nlearn.blurr_generate(\"Blurr is fun to work with because\", max_length=50, do_sample=True, top_k=25)\n\n[{'generated_texts': \" Blurr is fun to work with because it it is it is the '\\n\\n- A bit of work in addition to playing is done at http:// @ www. @ https:// https:// @\"}]\n\n\n\n\nMasked language modeling\n\nlearn = BlearnerForLM.from_data(df, \"bert-base-cased\", lm_strategy_cls=BertMLMStrategy, text_attr=0, dl_kwargs={\"bs\": 2}).to_fp16()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlearn.dls.show_batch(dataloaders=learn.dls, max_n=2, trunc_at=250)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      = Bob [MASK] = Bob Dylan ( / [<] un ##k > / ; born Robert Allen [MASK] ##immer [MASK] , May 24 , 1941 [MASK] is an American singer @ [MASK] @ songwriter , artist [MASK] writer . He [MASK] been influential in popular music [MASK] culture for more than five decades . [MASK] of his most celebrated work dates from the 1960s when his [MASK] [MASK] ##d social unrest , although Dylan re ##pu ##dia ##ted suggestions from journalists that he was a spokesman for his generation . Nevertheless , early songs such as \" B ##low ##in ' in [the] Wind \" [MASK] \" The Times They Are a @ - @ < un ##k > ' \" became anthem ##s [MASK] the American civil rights and anti @ [-] @ war movements . After he left his initial base in the American folk music revival , his [missions] @ - @ minute single \" Like a [Rolling] Stone [MASK] altered the range of popular music [MASK] 1965 . His [MASK] @ - @ [MASK] recordings , backed by rock musicians , reached the top end of the United States music charts while also [perpendicular] < un ##k > and [MASK] from others in [MASK] folk movement . Dylan ' s lyrics have incorporated various political [glued] social [MASK] philosophical , and [MASK] influences . They def ##ied existing pop music conventions and [MASK] to the b ##urge ##oning counter ##culture . Initially inspired by the performances\n      = Bob [Dylan] = Bob Dylan ( / [<] un ##k > / ; born Robert Allen [Z] ##immer [##man] , May 24 , 1941 [)] is an American singer @ [-] @ songwriter , artist [and] writer . He [has] been influential in popular music [and] culture for more than five decades . [Much] of his most celebrated work dates from the 1960s when his [songs] [chronicle] ##d social unrest , although Dylan re ##pu ##dia ##ted suggestions from journalists that he was a spokesman for his generation . Nevertheless , early songs such as \" B ##low ##in ' in [the] Wind \" [and] \" The Times They Are a @ - @ < un ##k > ' \" became anthem ##s [for] the American civil rights and anti @ [-] @ war movements . After he left his initial base in the American folk music revival , his [six] @ - @ minute single \" Like a [Rolling] Stone [\"] altered the range of popular music [in] 1965 . His [mid] @ - @ [1960s] recordings , backed by rock musicians , reached the top end of the United States music charts while also [attracting] < un ##k > and [criticism] from others in [the] folk movement . Dylan ' s lyrics have incorporated various political [,] social [,] philosophical , and [literary] influences . They def ##ied existing pop music conventions and [appealed] to the b ##urge ##oning counter ##culture . Initially inspired by the performances\n    \n    \n      1\n      = George [MASK] , 1st Baron Baltimore = George Calvert , 1st Baron Baltimore [MASK] < un ##k > – 15 April 163 ##2 ) was an [English] politician and < [##ortex] [MASK] > . He achieved domestic political success [MASK] [MASK] [MASK] of Parliament and later Secretary [##年] State under King James I [MASK] He lost much of his [political] power [MASK] his support for a [MASK] marriage alliance between Prince Charles and the Spanish House of Habsburg royal family . Rather than continue in [MASK] , he resigned all [MASK] his [MASK] offices [MASK] 162 ##5 except for his position on the Privy Council and declared his Catholicism publicly . He was created Baron Baltimore in [MASK] Irish peer ##age upon his resignation . Baltimore [MASK] was located in County Long ##ford , Ireland . Calvert took an interest in [MASK] British colonization of the Americas , [MASK] first for commercial reasons [MASK] later to create a refuge for English [MASK] [MASK] He became [MASK] proprietor of Avalon , the first sustained English settlement on the southeastern [MASK] on [MASK] island of [MASK] ( off the eastern coast of modern Canada ) . < un ##k > by its cold [MASK] sometimes in ##hos [MASK] ##able climate and the < un ##k [MASK] of [MASK] settlers , Sir George [MASK] for a more suitable spot further south [MASK] sought [MASK] new royal charter [MASK] settle the region , [MASK] would become the [MASK] of Maryland . Calvert died\n      = George [Calvert] , 1st Baron Baltimore = George Calvert , 1st Baron Baltimore [(] < un ##k > – 15 April 163 ##2 ) was an [English] politician and < [un] [##k] > . He achieved domestic political success [as] [a] [Member] of Parliament and later Secretary [of] State under King James I [.] He lost much of his [political] power [after] his support for a [failed] marriage alliance between Prince Charles and the Spanish House of Habsburg royal family . Rather than continue in [politics] , he resigned all [of] his [political] offices [in] 162 ##5 except for his position on the Privy Council and declared his Catholicism publicly . He was created Baron Baltimore in [the] Irish peer ##age upon his resignation . Baltimore [Manor] was located in County Long ##ford , Ireland . Calvert took an interest in [the] British colonization of the Americas , [at] first for commercial reasons [and] later to create a refuge for English [Catholics] [.] He became [the] proprietor of Avalon , the first sustained English settlement on the southeastern [peninsula] on [the] island of [Newfoundland] ( off the eastern coast of modern Canada ) . < un ##k > by its cold [and] sometimes in ##hos [##pit] ##able climate and the < un ##k [>] of [the] settlers , Sir George [looked] for a more suitable spot further south [and] sought [a] new royal charter [to] settle the region , [which] would become the [state] of Maryland . Calvert died\n    \n  \n\n\n\n\nlearn.fit_one_cycle(1, lr_max=6e-4, cbs=[BlearnerForLM.get_metrics_cb()])\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      perplexity\n      lm_accuracy\n      time\n    \n  \n  \n    \n      0\n      2.676882\n      2.456665\n      11.665836\n      0.581747\n      01:03\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, trunc_at=250)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      = Military [MASK] of Australia = [MASK] military history of Australia [MASK] the nation ' [Shawn] 220 [MASK] - @ year modern history , from the early Australian frontier [MASK] between < un ##k [MASK] and Europeans to the [MASK] conflicts in Iraq and Afghanistan in [MASK] early 21st century . Although this history is short when compared [MASK] that of many other nations , Australia has been involved [‑] numerous conflicts and wars [MASK] and war and military service [MASK] been [MASK] influences on Australian [MASK] and national identity , [tablets] the An ##zac spirit [.] The relationship between war and Australian society has also been [MASK] by the enduring themes of Australian strategic culture [MASK] its unique security [MASK] ##lemma . As [##aman] [MASK] un [##k] > , the Australian colonies participated in [MASK] ' s small wars of the 19th century [MASK] while later as a < un [MASK] > do ##mini ##on , and then an independent nation , [MASK] fought [MASK] the First World War and Second World [MASK] , as well as in the wars in Korea , Malaya , Borneo and Vietnam during the Cold War . In the [MASK] [MASK] - @ [MASK] [era] Australian forces [MASK] been involved in [##↑] international peace ##keeping missions , through the United Nations and [MASK] agencies , including in the Sinai , [MASK] Gulf , < [MASK] ##k > , Somalia , East Timor and the Solomon Islands , while more recently they have also\n      = Military [history] of Australia = [The] military history of Australia [spans] the nation ' [s] 220 [@] - @ year modern history , from the early Australian frontier [wars] between < un ##k [>] and Europeans to the [ongoing] conflicts in Iraq and Afghanistan in [the] early 21st century . Although this history is short when compared [to] that of many other nations , Australia has been involved [in] numerous conflicts and wars [,] and war and military service [have] been [significant] influences on Australian [society] and national identity , [including] the An ##zac spirit [.] The relationship between war and Australian society has also been [shaped] by the enduring themes of Australian strategic culture [and] its unique security [di] ##lemma . As [British] [<] un [##k] > , the Australian colonies participated in [Britain] ' s small wars of the 19th century [,] while later as a < un [##k] > do ##mini ##on , and then an independent nation , [Australia] fought [in] the First World War and Second World [War] , as well as in the wars in Korea , Malaya , Borneo and Vietnam during the Cold War . In the [Post] [@] - @ [Vietnam] [era] Australian forces [have] been involved in [numerous] international peace ##keeping missions , through the United Nations and [other] agencies , including in the Sinai , [Persian] Gulf , < [un] ##k > , Somalia , East Timor and the Solomon Islands , while more recently they have also\n      = Military [history] of Australia = [The] military history of Australia [and] the nation ' [s] 220 [@] - @ year modern history , from the early Australian frontier [wars] between < un ##k [>] and Europeans to the [military] conflicts in Iraq and Afghanistan in [the] early 21st century . Although this history is short when compared [to] that of many other nations , Australia has been involved [in] numerous conflicts and wars [,] and war and military service [have] been [important] influences on Australian [culture] and national identity , [particularly] the An ##zac spirit [.] The relationship between war and Australian society has also been [shaped] by the enduring themes of Australian strategic culture [and] its unique security [di] ##lemma . As [<] [<] un [##k] > , the Australian colonies participated in [Australia] ' s small wars of the 19th century [,] while later as a < un [##k] > do ##mini ##on , and then an independent nation , [Australia] fought [in] the First World War and Second World [War] , as well as in the wars in Korea , Malaya , Borneo and Vietnam during the Cold War . In the [post] [@] - @ [-] [era] Australian forces [have] been involved in [numerous] international peace ##keeping missions , through the United Nations and [other] agencies , including in the Sinai , [Persian] Gulf , < [un] ##k > , Somalia , East Timor and the Solomon Islands , while more recently they have also\n    \n    \n      1\n      = Air Rhodesia Flight < un ##k > = [MASK] Rhodesia Flight < un ##k > was a scheduled passenger flight that was shot down [MASK] [MASK] Zimbabwe [MASK] ' s Revolutionary Army ( < un [MASK] > ) on 3 September 1978 , during the Rhodesia [MASK] Bush [MASK] . The aircraft involved , a Vickers Viscount named the < un ##k > , was [MASK] the last leg [of] Air Rhodesia ' [MASK] regular scheduled service from Victoria [MASK] to the capital Salisbury , via the [Friends] town of < un ##k > . Soon after Flight < un ##k > took off , a [MASK] of < un ##k > guerrilla [MASK] scored a direct [Université] on its star ##board wing with a [MASK] @ - @ made < un [MASK] > 2 surface @ - [MASK] to @ - @ air infrared < un ##k [>] missile , [MASK] damaging the aircraft and forcing an emergency [landing] . An attempted belly [MASK] in a cotton field just west of < un ##k > [MASK] < [MASK] ##k > by an unseen ditch , which caused the plane to [MASK] ##wheel and break up . Of [MASK] 52 passengers and [MASK] crew , 38 died in this crash ; [MASK] [MASK] then approached [merchant] wreckage , rounded [MASK] the 10 survivors they could see and massacre ##d them with automatic gunfire [.] [MASK] passengers survived [MASK] hiding in the [MASK] [MASK] , while a further five lived\n      = Air Rhodesia Flight < un ##k > = [Air] Rhodesia Flight < un ##k > was a scheduled passenger flight that was shot down [by] [the] Zimbabwe [People] ' s Revolutionary Army ( < un [##k] > ) on 3 September 1978 , during the Rhodesia [##n] Bush [War] . The aircraft involved , a Vickers Viscount named the < un ##k > , was [flying] the last leg [of] Air Rhodesia ' [s] regular scheduled service from Victoria [Falls] to the capital Salisbury , via the [resort] town of < un ##k > . Soon after Flight < un ##k > took off , a [group] of < un ##k > guerrilla [##s] scored a direct [hit] on its star ##board wing with a [Soviet] @ - @ made < un [##k] > 2 surface @ - [@] to @ - @ air infrared < un ##k [>] missile , [critically] damaging the aircraft and forcing an emergency [landing] . An attempted belly [landing] in a cotton field just west of < un ##k > [was] < [un] ##k > by an unseen ditch , which caused the plane to [cart] ##wheel and break up . Of [the] 52 passengers and [four] crew , 38 died in this crash ; [the] [insurgents] then approached [the] wreckage , rounded [up] the 10 survivors they could see and massacre ##d them with automatic gunfire [.] [Three] passengers survived [by] hiding in the [surrounding] [bush] , while a further five lived\n      = Air Rhodesia Flight < un ##k > = [Air] Rhodesia Flight < un ##k > was a scheduled passenger flight that was shot down [by] [the] Zimbabwe [People] ' s Revolutionary Army ( < un [##k] > ) on 3 September 1978 , during the Rhodesia [##n] Bush [War] . The aircraft involved , a Vickers Viscount named the < un ##k > , was [on] the last leg [of] Air Rhodesia ' [s] regular scheduled service from Victoria [Falls] to the capital Salisbury , via the [small] town of < un ##k > . Soon after Flight < un ##k > took off , a [group] of < un ##k > guerrilla [##s] scored a direct [hit] on its star ##board wing with a [surface] @ - @ made < un [##k] > 2 surface @ - [@] to @ - @ air infrared < un ##k [>] missile , [severely] damaging the aircraft and forcing an emergency [landing] . An attempted belly [landing] in a cotton field just west of < un ##k > [caused] < [un] ##k > by an unseen ditch , which caused the plane to [pin] ##wheel and break up . Of [the] 52 passengers and [2] crew , 38 died in this crash ; [the] [survivors] then approached [the] wreckage , rounded [up] the 10 survivors they could see and massacre ##d them with automatic gunfire [.] [Two] passengers survived [by] hiding in the [open] [area] , while a further five lived\n    \n  \n\n\n\n\nbatch_tfm = first_blurr_tfm(learn.dls)\n\n\nlearn.blurr_fill_mask(f\"The best place on earth is {batch_tfm.hf_tokenizer.mask_token}.\", n_preds=5)\n\n['The best place on earth is heaven.',\n 'The best place on earth is here.',\n 'The best place on earth is Egypt.',\n 'The best place on earth is there.',\n 'The best place on earth is Heaven.']"
  },
  {
    "objectID": "text.modeling.seq2seq.summarization.html",
    "href": "text.modeling.seq2seq.summarization.html",
    "title": "Modeling",
    "section": "",
    "text": "The objective of summarization is to generate a concise and accurate representation of a much larger body of text. For example, we may want to summarize an article in a single sentence.\n\ndataset = load_dataset(\"ccdv/cnn_dailymail\", \"3.0.0\", split=\"train[:1000]\")\ncnndm_df = pd.DataFrame(dataset)\ncnndm_df.head(2)\n\nReusing dataset cnn_dailymail (/home/wgilliam/.cache/huggingface/datasets/ccdv___cnn_dailymail/3.0.0/3.0.0/0107f7388b5c6fae455a5661bcd134fc22da53ea75852027040d8d1e997f101f)\n\n\n\n\n\n\n  \n    \n      \n      article\n      highlights\n      id\n    \n  \n  \n    \n      0\n      It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...\n      Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .\n      0001d1afc246a7964130f43ae940af6bc6c57f01\n    \n    \n      1\n      (CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...\n      Usain Bolt wins third gold of world championship .\\nAnchors Jamaica to 4x100m relay victory .\\nEighth gold at the championships for Bolt .\\nJamaica double up in women's 4x100m relay .\n      0002095e55fcbd3a2f366d9bf92a95433dc305ef\n    \n  \n\n\n\n\n\npretrained_model_name = \"sshleifer/distilbart-cnn-6-6\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=BartForConditionalGeneration)\n\nhf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)\n\nloading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\nModel config BartConfig {\n  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartForConditionalGeneration\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 16,\n  \"encoder_ffn_dim\": 4096,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 2,\n  \"extra_pos_embeddings\": 2,\n  \"force_bos_token_to_be_generated\": true,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"length_penalty\": 2.0,\n  \"max_length\": 142,\n  \"max_position_embeddings\": 1024,\n  \"min_length\": 56,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"prefix\": \" \",\n  \"replacing_rate\": 0,\n  \"scale_embedding\": false,\n  \"static_position_embeddings\": false,\n  \"student_decoder_layers\": null,\n  \"student_encoder_layers\": null,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 142,\n      \"min_length\": 56,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4\n    }\n  },\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\nloading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\nModel config BartConfig {\n  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartForConditionalGeneration\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 16,\n  \"encoder_ffn_dim\": 4096,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 2,\n  \"extra_pos_embeddings\": 2,\n  \"force_bos_token_to_be_generated\": true,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"length_penalty\": 2.0,\n  \"max_length\": 142,\n  \"max_position_embeddings\": 1024,\n  \"min_length\": 56,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"prefix\": \" \",\n  \"replacing_rate\": 0,\n  \"scale_embedding\": false,\n  \"static_position_embeddings\": false,\n  \"student_decoder_layers\": null,\n  \"student_encoder_layers\": null,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 142,\n      \"min_length\": 56,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4\n    }\n  },\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\nloading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/c457182dd3c47e71636dfe957c948acf12fd6b1d17d3e16a69f9bd731f340157.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\nloading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/1917cd1903f32920951797d984eff6fb9707c20aa7c0eba679d033d5d5dbc7d3.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\nloading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/tokenizer.json from cache at None\nloading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/special_tokens_map.json from cache at None\nloading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/41a44e7ad55ba42aa9abd4697be8ff844b95c3f33ad59ceb5059b263caf581fe.67d01b18f2079bd75eac0b2f2e7235768c7f26bd728e7a855a1c5acae01a91a8\nloading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\nModel config BartConfig {\n  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartForConditionalGeneration\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 16,\n  \"encoder_ffn_dim\": 4096,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 2,\n  \"extra_pos_embeddings\": 2,\n  \"force_bos_token_to_be_generated\": true,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"length_penalty\": 2.0,\n  \"max_length\": 142,\n  \"max_position_embeddings\": 1024,\n  \"min_length\": 56,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"prefix\": \" \",\n  \"replacing_rate\": 0,\n  \"scale_embedding\": false,\n  \"static_position_embeddings\": false,\n  \"student_decoder_layers\": null,\n  \"student_encoder_layers\": null,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 142,\n      \"min_length\": 56,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4\n    }\n  },\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\nloading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\nModel config BartConfig {\n  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartForConditionalGeneration\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 16,\n  \"encoder_ffn_dim\": 4096,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 2,\n  \"extra_pos_embeddings\": 2,\n  \"force_bos_token_to_be_generated\": true,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"length_penalty\": 2.0,\n  \"max_length\": 142,\n  \"max_position_embeddings\": 1024,\n  \"min_length\": 56,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"prefix\": \" \",\n  \"replacing_rate\": 0,\n  \"scale_embedding\": false,\n  \"static_position_embeddings\": false,\n  \"student_decoder_layers\": null,\n  \"student_encoder_layers\": null,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 142,\n      \"min_length\": 56,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4\n    }\n  },\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\nloading weights file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/b3a80b0a1380627404ab7beeafae5a22d57a6caee6d637757be7b02319a26d37.a3aeae96c9bbfd0fad6832e6f41a23b7f17b292daca2c554b8064433b145e921\nAll model checkpoint weights were used when initializing BartForConditionalGeneration.\n\nAll the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-6-6.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n\n\n('bart',\n transformers.models.bart.configuration_bart.BartConfig,\n transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,\n transformers.models.bart.modeling_bart.BartForConditionalGeneration)\n\n\n\ntext_gen_kwargs = {}\nif hf_arch in [\"bart\", \"t5\"]:\n    text_gen_kwargs = {**hf_config.task_specific_params[\"summarization\"], **{\"max_length\": 30, \"min_length\": 10}}\n\n# not all \"summarization\" parameters are for the model.generate method ... remove them here\ngenerate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\nfor k in text_gen_kwargs.copy():\n    if k not in generate_func_args:\n        del text_gen_kwargs[k]\n\nif hf_arch == \"mbart\":\n    text_gen_kwargs[\"decoder_start_token_id\"] = hf_tokenizer.get_vocab()[\"en_XX\"]\n\n\ntok_kwargs = {}\nif hf_arch == \"mbart\":\n    tok_kwargs[\"src_lang\"], tok_kwargs[\"tgt_lang\"] = \"en_XX\", \"en_XX\"\n\n\nbatch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n    hf_arch,\n    hf_config,\n    hf_tokenizer,\n    hf_model,\n    max_length=256,\n    max_target_length=130,\n    tok_kwargs=tok_kwargs,\n    text_gen_kwargs=text_gen_kwargs,\n)\n\nblocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"article\"), get_y=ColReader(\"highlights\"), splitter=RandomSplitter())\n\n\ndls = dblock.dataloaders(cnndm_df, bs=2)\n\n\nb = dls.one_batch()\n\n\nlen(b), b[0][\"input_ids\"].shape, b[1].shape\n\n(2, torch.Size([2, 256]), torch.Size([2, 75]))\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      <s> (CNN) -- When Ji Yeqing awakened, she was already in the recovery room. Chinese authorities had dragged her out of her home and down four flights of stairs, she said, restraining and beating her husband as he tried to come to her aid. They whisked her into a clinic, held her down on a bed and forced her to undergo an abortion. Her offense? Becoming pregnant with a second child, in violation of China's one-child policy. \"After the abortion, I felt empty, as if something was scooped out of me,\" Ji told a congressional panel in September. \"My husband and I had been so excited for our new baby. Now suddenly all that hope and joy and excitement disappeared.... I was very depressed and despondent. For a long time, whenever I thought about my lost child, I would cry.\" As she lay unconscious, she said, an IUD to prevent future pregnancies was inserted. The issue of forced abortions -- and in some cases, forced sterilizations -- in China has seized the spotlight in recent days with news of escaped activist Chen Guangcheng. Chen, a blind, self-taught lawyer, rose to fame in the late 1990s because of his advocacy for what he calls victims</s>\n      China's one-child policy results in forced abortions and sterilizations, activists say.\\nWomen tell of emotional and physical consequences from the procedures.\\nActivist Chen Guangcheng works to advocate for victims of such practices.\n    \n    \n      1\n      <s> (CNN) -- The generation of gays and lesbians that literally created the modern LGBT movement -- from the heroes of the 1969 Stonewall riots to their slightly younger friends -- is at, or nearing, retirement age. That used to mean the beginning of an extremely difficult time in an LGBT person's life. But as gay baby boomers find more acceptance in mainstream society and continue to do what they've always done -- push to make a better world for the LGBT community -- their retirement options are slowly improving. That is, if they decide to retire at all. \"The notion of retirement has never been a part of my vocabulary,\" said Bob Witeck, CEO and co-founder of Witeck Communications. Nearly 61, Witeck has put some thought into what he should do with his strategic public relations and marketing firm as he gets older. Like many friends his age who are also entrepreneurs, he plans to keep working. \"Because I run a business, as I get older I can change the intensity of my engagement in the kinds of work I take on,\" Witeck said. \"I know I'm lucky that way, and I'm lucky in my personal life as well. My husband is 50, so I have a younger man to help me</s>\n      LGBT baby boomers changed the visibility of the gay community.\\nAs they approach retirement, they face different obstacles than their straight counterparts.\\nWithout marriage equality, same-sex couples may face financial hardships.\\nAdvocates say the situation is slowly improving.\n    \n  \n\n\n\n\n\n\nseq2seq_metrics = {\n    \"rouge\": {\n        \"compute_kwargs\": {\"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], \"use_stemmer\": True},\n        \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n    },\n    \"bertscore\": {\"compute_kwargs\": {\"lang\": \"en\"}, \"returns\": [\"precision\", \"recall\", \"f1\"]},\n}\n\n\nmodel = BaseModelWrapper(hf_model)\nlearn_cbs = [BaseModelCallback]\nfit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n\nlearn = Learner(\n    dls,\n    model,\n    opt_func=partial(Adam),\n    loss_func=CrossEntropyLossFlat(),\n    cbs=learn_cbs,\n    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n)\n\n# learn = learn.to_native_fp16() #.to_fp16()\nlearn.freeze()\n\n\nlearn.summary()\n\n\nb = dls.one_batch()\npreds = learn.model(b[0])\n\nlen(preds), preds[\"loss\"].shape, preds[\"logits\"].shape\n\n(3, torch.Size([]), torch.Size([2, 59, 50264]))\n\n\n\nlen(b), len(b[0]), b[0][\"input_ids\"].shape, len(b[1]), b[1].shape\n\n(2, 3, torch.Size([2, 256]), 2, torch.Size([2, 59]))\n\n\n\nprint(len(learn.opt.param_groups))\n\n3\n\n\n\nlearn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\nSuggestedLRs(minimum=4.786300996784121e-05, steep=6.309573450380412e-07, valley=6.30957365501672e-05, slide=1.4454397387453355e-05)\n\n\n\n\n\n\nlearn.fit_one_cycle(1, lr_max=4e-5, cbs=fit_cbs)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      rouge1\n      rouge2\n      rougeL\n      rougeLsum\n      bertscore_precision\n      bertscore_recall\n      bertscore_f1\n      time\n    \n  \n  \n    \n      0\n      2.306568\n      2.146496\n      0.296782\n      0.124385\n      0.222347\n      0.275367\n      0.892347\n      0.865695\n      0.878717\n      01:12\n    \n  \n\n\n\nCould not locate the tokenizer configuration file, will try to use the model config instead.\nloading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\nModel config RobertaConfig {\n  \"_name_or_path\": \"roberta-large\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.18.0\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\nloading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\nloading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\nloading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None\nloading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None\nloading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\nModel config RobertaConfig {\n  \"_name_or_path\": \"roberta-large\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.18.0\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\nloading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\nModel config RobertaConfig {\n  \"_name_or_path\": \"roberta-large\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.18.0\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\nloading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\nAll the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.\n\n\n\n\n\nAnd here we create a @typedispatched implementation of Learner.show_results.\n\nlearn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      (CNN Student News) -- January 13, 2011. Download PDF maps related to today's show:. • Arizona • Australia. Transcript. THIS IS A RUSH TRANSCRIPT. THIS COPY MAY NOT BE IN ITS FINAL FORM AND MAY BE UPDATED. CARL AZUZ, CNN STUDENT NEWS ANCHOR: A problem that won't be solved, even if the solution is clear. The story and the reasons, leading off today's broadcast of CNN Student News! My name is Carl Azuz! First Up: Winter Storm Woes. AZUZ: Florida is the only state in the union without snow on the g\n      A winter storm slams the northeastern United States.\\nThe U.S. House of Representatives condemns the Arizona shooting.\\nMassive floods leave vast areas of Australia underwater.\\nUse the Daily Discussion to help students understand today's featured news\n      [ Find out how a storm system iced out the southeast . Use the Daily Discussion to help students understand today's featured news stories,  Jeb Bush and Mitt Romney are putting pressure on New Jersey Gov. Chris Christie .\\nBush has been a well-liked figure]\n    \n  \n\n\n\n\n\n\nWe add here Learner.blurr_summarize method to bring the results inline with the format returned via Hugging Face’s pipeline method\n\ntest_article = \"\"\"\nAbout 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \ninto France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \nBasel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \nbut could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \nof armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \ncashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \noccurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \nher, and took off for the French border. The other gunmen followed into France, which is only about 100 \nmeters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \nThere were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \nrobbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \nGill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \ncontributed to this report.\n\"\"\"\n\n\noutputs = learn.blurr_generate(test_article, key=\"summary_texts\", num_return_sequences=3)\noutputs\n\n[{'summary_texts': [\" 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the armed robbers' vehicles .\",\n   \" 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the robbers' vehicles .\",\n   \" 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\"]}]\n\n\n\nsource\n\n\n\n\n\n Learner.blurr_summarize (inp, **kwargs)\n\n\nlearn.blurr_summarize(test_article, num_return_sequences=3)\n\n[{'summary_texts': [\" 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the armed robbers' vehicles .\",\n   \" 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the robbers' vehicles .\",\n   \" 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\"]}]\n\n\n\n\nUsing fast.ai Learner.export and load_learner\n\nexport_fname = \"summarize_export\"\n\n\nlearn.metrics = None\nlearn.export(fname=f\"{export_fname}.pkl\")\n\n\ninf_learn = load_learner(fname=f\"{export_fname}.pkl\")\ninf_learn.blurr_summarize(test_article)\n\n[{'summary_texts': ' 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski'}]"
  },
  {
    "objectID": "text.modeling.seq2seq.summarization.html#high-level-api",
    "href": "text.modeling.seq2seq.summarization.html#high-level-api",
    "title": "Modeling",
    "section": "High-level API",
    "text": "High-level API\n\nsource\n\nBlearnerForSummarization\n\n BlearnerForSummarization (dls:fastai.data.core.DataLoaders,\n                           hf_model:transformers.modeling_utils.PreTrained\n                           Model, base_model_cb:blurr.text.modeling.core.B\n                           aseModelCallback=<class\n                           'blurr.text.modeling.core.BaseModelCallback'>,\n                           loss_func:callable|None=None,\n                           opt_func=<function Adam>, lr=0.001,\n                           splitter:callable=<function trainable_params>,\n                           cbs=None, metrics=None, path=None,\n                           model_dir='models', wd=None, wd_bn_bias=False,\n                           train_bn=True, moms=(0.95, 0.85, 0.95),\n                           default_cbs:bool=True)\n\nGroup together a model, some dls and a loss_func to handle training\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndls\n\nDataLoaders containing data for each dataset needed for model\n\n\nhf_model\nPreTrainedModel\n\n\n\n\n\nExample\n\nlearn = BlearnerForSummarization.from_data(\n    cnndm_df,\n    \"sshleifer/distilbart-cnn-6-6\",\n    text_attr=\"article\",\n    summary_attr=\"highlights\",\n    max_length=256,\n    max_target_length=130,\n    dblock_splitter=RandomSplitter(),\n    dl_kwargs={\"bs\": 2},\n).to_fp16()\n\nloading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\nModel config BartConfig {\n  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartForConditionalGeneration\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 16,\n  \"encoder_ffn_dim\": 4096,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 2,\n  \"extra_pos_embeddings\": 2,\n  \"force_bos_token_to_be_generated\": true,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"length_penalty\": 2.0,\n  \"max_length\": 142,\n  \"max_position_embeddings\": 1024,\n  \"min_length\": 56,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"prefix\": \" \",\n  \"replacing_rate\": 0,\n  \"scale_embedding\": false,\n  \"static_position_embeddings\": false,\n  \"student_decoder_layers\": null,\n  \"student_encoder_layers\": null,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 142,\n      \"min_length\": 56,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4\n    }\n  },\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\nloading weights file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/b3a80b0a1380627404ab7beeafae5a22d57a6caee6d637757be7b02319a26d37.a3aeae96c9bbfd0fad6832e6f41a23b7f17b292daca2c554b8064433b145e921\nAll model checkpoint weights were used when initializing BartForConditionalGeneration.\n\nAll the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-6-6.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\nloading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\nModel config BartConfig {\n  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartForConditionalGeneration\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 16,\n  \"encoder_ffn_dim\": 4096,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 2,\n  \"extra_pos_embeddings\": 2,\n  \"force_bos_token_to_be_generated\": true,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"length_penalty\": 2.0,\n  \"max_length\": 142,\n  \"max_position_embeddings\": 1024,\n  \"min_length\": 56,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"prefix\": \" \",\n  \"replacing_rate\": 0,\n  \"scale_embedding\": false,\n  \"static_position_embeddings\": false,\n  \"student_decoder_layers\": null,\n  \"student_encoder_layers\": null,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 142,\n      \"min_length\": 56,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4\n    }\n  },\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\nloading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\nModel config BartConfig {\n  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartForConditionalGeneration\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 16,\n  \"encoder_ffn_dim\": 4096,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 2,\n  \"extra_pos_embeddings\": 2,\n  \"force_bos_token_to_be_generated\": true,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"length_penalty\": 2.0,\n  \"max_length\": 142,\n  \"max_position_embeddings\": 1024,\n  \"min_length\": 56,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"prefix\": \" \",\n  \"replacing_rate\": 0,\n  \"scale_embedding\": false,\n  \"static_position_embeddings\": false,\n  \"student_decoder_layers\": null,\n  \"student_encoder_layers\": null,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 142,\n      \"min_length\": 56,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4\n    }\n  },\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\nloading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/c457182dd3c47e71636dfe957c948acf12fd6b1d17d3e16a69f9bd731f340157.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\nloading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/1917cd1903f32920951797d984eff6fb9707c20aa7c0eba679d033d5d5dbc7d3.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\nloading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/tokenizer.json from cache at None\nloading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/special_tokens_map.json from cache at None\nloading file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/41a44e7ad55ba42aa9abd4697be8ff844b95c3f33ad59ceb5059b263caf581fe.67d01b18f2079bd75eac0b2f2e7235768c7f26bd728e7a855a1c5acae01a91a8\nloading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\nModel config BartConfig {\n  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartForConditionalGeneration\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 16,\n  \"encoder_ffn_dim\": 4096,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 2,\n  \"extra_pos_embeddings\": 2,\n  \"force_bos_token_to_be_generated\": true,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"length_penalty\": 2.0,\n  \"max_length\": 142,\n  \"max_position_embeddings\": 1024,\n  \"min_length\": 56,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"prefix\": \" \",\n  \"replacing_rate\": 0,\n  \"scale_embedding\": false,\n  \"static_position_embeddings\": false,\n  \"student_decoder_layers\": null,\n  \"student_encoder_layers\": null,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 142,\n      \"min_length\": 56,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4\n    }\n  },\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\nloading configuration file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/98e51ece807bb08f235356791c26c1d775cc56c394304f0ddf1809c6bc45b391.a394a5757192281a4f3940a7ccf20051a750f630dd86fffbaa84d8cff7a0d496\nModel config BartConfig {\n  \"_name_or_path\": \"sshleifer/distilbart-cnn-6-6\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"gelu\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"BartForConditionalGeneration\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 1024,\n  \"decoder_attention_heads\": 16,\n  \"decoder_ffn_dim\": 4096,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 2,\n  \"dropout\": 0.1,\n  \"early_stopping\": true,\n  \"encoder_attention_heads\": 16,\n  \"encoder_ffn_dim\": 4096,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 2,\n  \"extra_pos_embeddings\": 2,\n  \"force_bos_token_to_be_generated\": true,\n  \"forced_bos_token_id\": 0,\n  \"forced_eos_token_id\": 2,\n  \"gradient_checkpointing\": false,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"length_penalty\": 2.0,\n  \"max_length\": 142,\n  \"max_position_embeddings\": 1024,\n  \"min_length\": 56,\n  \"model_type\": \"bart\",\n  \"no_repeat_ngram_size\": 3,\n  \"normalize_before\": false,\n  \"normalize_embedding\": true,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"output_past\": true,\n  \"pad_token_id\": 1,\n  \"prefix\": \" \",\n  \"replacing_rate\": 0,\n  \"scale_embedding\": false,\n  \"static_position_embeddings\": false,\n  \"student_decoder_layers\": null,\n  \"student_encoder_layers\": null,\n  \"task_specific_params\": {\n    \"summarization\": {\n      \"early_stopping\": true,\n      \"length_penalty\": 2.0,\n      \"max_length\": 142,\n      \"min_length\": 56,\n      \"no_repeat_ngram_size\": 3,\n      \"num_beams\": 4\n    }\n  },\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 50264\n}\n\nloading weights file https://huggingface.co/sshleifer/distilbart-cnn-6-6/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/b3a80b0a1380627404ab7beeafae5a22d57a6caee6d637757be7b02319a26d37.a3aeae96c9bbfd0fad6832e6f41a23b7f17b292daca2c554b8064433b145e921\nAll model checkpoint weights were used when initializing BartForConditionalGeneration.\n\nAll the weights of BartForConditionalGeneration were initialized from the model checkpoint at sshleifer/distilbart-cnn-6-6.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n\n\n\nlearn.fit_one_cycle(1, lr_max=4e-5, cbs=[BlearnerForSummarization.get_metrics_cb()])\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      rouge1\n      rouge2\n      rougeL\n      rougeLsum\n      bertscore_precision\n      bertscore_recall\n      bertscore_f1\n      time\n    \n  \n  \n    \n      0\n      2.217999\n      2.165818\n      0.363228\n      0.142654\n      0.249067\n      0.338458\n      0.879375\n      0.888943\n      0.884054\n      02:44\n    \n  \n\n\n\nCould not locate the tokenizer configuration file, will try to use the model config instead.\nloading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\nModel config RobertaConfig {\n  \"_name_or_path\": \"roberta-large\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.18.0\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\nloading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\nloading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /home/wgilliam/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\nloading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None\nloading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None\nloading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\nModel config RobertaConfig {\n  \"_name_or_path\": \"roberta-large\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.18.0\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\nloading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\nModel config RobertaConfig {\n  \"_name_or_path\": \"roberta-large\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.18.0\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\nloading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352\nAll the weights of RobertaModel were initialized from the model checkpoint at roberta-large.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.\n\n\n\nlearn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      (CNN) -- When Ji Yeqing awakened, she was already in the recovery room. Chinese authorities had dragged her out of her home and down four flights of stairs, she said, restraining and beating her husband as he tried to come to her aid. They whisked her into a clinic, held her down on a bed and forced her to undergo an abortion. Her offense? Becoming pregnant with a second child, in violation of China's one-child policy. \"After the abortion, I felt empty, as if something was scooped out of me,\" J\n      China's one-child policy results in forced abortions and sterilizations, activists say.\\nWomen tell of emotional and physical consequences from the procedures.\\nActivist Chen Guangcheng works to advocate for victims of such practices.\n      [ Ji Yeqing says she was forced to have an abortion in violation of China's one-child policy .\\nShe says she felt \"empty\" after the abortion .\\nThe issue of forced abortions in China has seized the spotlight in recent days .\\nIn some cases, forced sterilizations are used to prevent future pregnancies .,  Malala Yousufzai was shot in the neck by Taliban militants on Tuesday .\\nMalala is recovering after surgeons worked for three hours to remove a bullet lodged in her neck .\\nAn angry chorus of voices in social media, on the street, and over the airwaves decries the attack .\\nThe 14-year-old is a defiant blogger .]\n    \n  \n\n\n\n\ntest_article = \"\"\"\nAbout 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \ninto France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \nBasel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \nbut could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \nof armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \ncashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \noccurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \nher, and took off for the French border. The other gunmen followed into France, which is only about 100 \nmeters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \nThere were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \nrobbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \nGill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \ncontributed to this report.\n\"\"\"\n\n\nlearn.predict(test_article, num_return_sequences=3)\n\n[{'summary_texts': [\" 10 men raid Swiss casino in early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the armed robbers' vehicles .\",\n   \" 10 men raid Swiss casino in early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the robbers' vehicles .\",\n   \" 10 men raid Swiss casino in early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the robbers' vehicles .\\n\"]}]\n\n\n\nexport_fname = \"summarize_export\"\n\nlearn.metrics = None\nlearn = learn.to_fp32()\nlearn.export(fname=f\"{export_fname}.pkl\")\n\ninf_learn = load_learner(fname=f\"{export_fname}.pkl\")\ninf_learn.blurr_summarize(test_article)\n\n[{'summary_texts': \" 10 men raid Swiss casino in early hours of Sunday morning, police say .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the vault on the lower level but could not get in .\\nA woman driving by and unaware of what was happening unknowingly blocked the armed robbers' vehicles .\"}]"
  },
  {
    "objectID": "text.modeling.seq2seq.summarization.html#tests",
    "href": "text.modeling.seq2seq.summarization.html#tests",
    "title": "Modeling",
    "section": "Tests",
    "text": "Tests\nThe purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained summarization models below. These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\nNote: Feel free to modify the code below to test whatever pretrained summarization models you are working with … and if any of your pretrained summarization models fail, please submit a github issue (or a PR if you’d like to fix it yourself)\n\n\n\n\n  \n    \n      \n      arch\n      tokenizer\n      model_name\n      result\n      error\n    \n  \n  \n    \n      0\n      bart\n      BartTokenizerFast\n      BartForConditionalGeneration\n      PASSED\n      \n    \n    \n      1\n      led\n      LEDTokenizerFast\n      LEDForConditionalGeneration\n      PASSED\n      \n    \n    \n      2\n      mbart\n      MBartTokenizerFast\n      MBartForConditionalGeneration\n      PASSED\n      \n    \n    \n      3\n      mt5\n      T5TokenizerFast\n      MT5ForConditionalGeneration\n      PASSED\n      \n    \n    \n      4\n      pegasus\n      PegasusTokenizerFast\n      PegasusForConditionalGeneration\n      PASSED\n      \n    \n    \n      5\n      t5\n      T5TokenizerFast\n      T5ForConditionalGeneration\n      PASSED"
  },
  {
    "objectID": "text.modeling.question_answering.html",
    "href": "text.modeling.question_answering.html",
    "title": "Modeling",
    "section": "",
    "text": "What we're running with at the time this documentation was generated:\ntorch: 1.9.0+cu102\nfastai: 2.7.9\ntransformers: 4.21.2"
  },
  {
    "objectID": "text.modeling.question_answering.html#setup",
    "href": "text.modeling.question_answering.html#setup",
    "title": "Modeling",
    "section": "Setup",
    "text": "Setup\nWe’ll use a subset of squad_v2 to demonstrate how to configure your blurr code for training extractive question answering models. See the data.question_answering module if any of this setting up of the squad_df below looks unfamiliar to you.\n\nraw_datasets = load_dataset(\"squad\", split=[\"train[:1000]\", \"validation[:200]\"])\n\nraw_train_df = pd.DataFrame(raw_datasets[0])\nraw_valid_df = pd.DataFrame(raw_datasets[1])\n\nraw_train_df[\"is_valid\"] = False\nraw_valid_df[\"is_valid\"] = True\n\nsquad_df = pd.concat([raw_train_df, raw_valid_df])\n\nsquad_df[\"ans_start_char_idx\"] = squad_df.answers.apply(lambda v: v[\"answer_start\"][0] if len(v[\"answer_start\"]) > 0 else \"0\")\nsquad_df[\"answer_text\"] = squad_df.answers.apply(lambda v: v[\"text\"][0] if len(v[\"text\"]) > 0 else \"\")\nsquad_df[\"ans_end_char_idx\"] = squad_df[\"ans_start_char_idx\"].astype(int) + squad_df[\"answer_text\"].str.len()\n\nprint(len(squad_df))\n\nReusing dataset squad (/home/wgilliam/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n\n\n\n\n\n1200\n\n\n\nmodel_cls = AutoModelForQuestionAnswering\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\nmax_seq_len = 128\nvocab = dict(enumerate(range(max_seq_len)))\n\n\npreprocessor = QAPreprocessor(\n    hf_tokenizer, id_attr=\"id\", tok_kwargs={\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 64}\n)\n\nproc_df = preprocessor.process_df(squad_df)\nproc_df.head(1)\n\n\n\n\n\n  \n    \n      \n      id\n      title\n      context\n      question\n      answers\n      is_valid\n      ans_start_char_idx\n      answer_text\n      ans_end_char_idx\n      proc_question\n      proc_context\n      ans_start_token_idx\n      ans_end_token_idx\n      is_answerable\n    \n  \n  \n    \n      0\n      5733be284776f41900661182\n      University_of_Notre_Dame\n      Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...\n      To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n      {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}\n      False\n      515\n      Saint Bernadette Soubirous\n      541\n      To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n      Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed\n      0\n      0\n      False\n    \n  \n\n\n\n\n\nbefore_batch_tfm = QABatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_seq_len)\n\nblocks = (\n    TextBlock(batch_tokenize_tfm=before_batch_tfm, input_return_type=QATextInput),\n    CategoryBlock(vocab=vocab),\n    CategoryBlock(vocab=vocab),\n)\n\n# since its preprocessed, we include an \"text\" key with the values of our question and context\ndef get_x(item):\n    return {\"text\": (item.proc_question, item.proc_context), \"id\": item.id}\n\n\ndblock = DataBlock(\n    blocks=blocks,\n    get_x=get_x,\n    get_y=[ItemGetter(\"ans_start_token_idx\"), ItemGetter(\"ans_end_token_idx\")],\n    splitter=ColSplitter(),\n    n_inp=1,\n)\n\n\ndls = dblock.dataloaders(proc_df, bs=4)\n\n\nlen(dls.vocab), dls.vocab[0], dls.vocab[1]\n\n(2,\n [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127],\n [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])\n\n\n\ndls.valid.show_batch(dataloaders=dls, max_n=2)\n\n\n\n  \n    \n      \n      text\n      found\n      start/end\n      answer\n    \n  \n  \n    \n      0\n      which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 – 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the league emphasized the \" golden anniversary \" with various gold - themed initiatives, as well as temporarily suspending the\n      True\n      (46, 48)\n      denver broncos\n    \n    \n      1\n      which nfl team represented the afc at super bowl 50? earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the league emphasized the \" golden anniversary \" with various gold - themed initiatives, as well as temporarily suspending the tradition of naming each super bowl game with roman numerals ( under which the game would have been known as \" super bowl l \" ), so that the logo could prominently feature the arabic numerals 50.\n      False\n      (0, 0)"
  },
  {
    "objectID": "text.modeling.question_answering.html#mid-level-api",
    "href": "text.modeling.question_answering.html#mid-level-api",
    "title": "Modeling",
    "section": "Mid-level API",
    "text": "Mid-level API\n\nsource\n\nQAModelCallback\n\n QAModelCallback (base_model_wrapper_kwargs:dict={})\n\nThe prediction is a combination start/end logits\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbase_model_wrapper_kwargs\ndict\n{}\nAdditional keyword arguments passed to BaseModelWrapper\n\n\n\nHere we create a question/answer specific subclass of BaseModelCallback in order to get all the start and end prediction.\n\nsource\n\n\nQAMetricsCallback\n\n QAMetricsCallback (compute_metrics_func, validation_ds,\n                    qa_metrics=['exact_match', 'f1'], **kwargs)\n\nBasic class handling tweaks of the training loop by changing a Learner in various events\n\nsource\n\n\ncompute_qa_metrics\n\n compute_qa_metrics (results, dataset, hf_tokenizer, tok_kwargs,\n                     id_attr='id', n_best=20)\n\n\nsource\n\n\nPreCalculatedQALoss\n\n PreCalculatedQALoss (*args, axis=-1, **kwargs)\n\nIf you want to let your Hugging Face model calculate the loss for you, make sure you include the labels argument in your inputs and use PreCalculatedLoss as your loss function. Even though we don’t really need a loss function per se, we have to provide a custom loss class/function for fastai to function properly (e.g. one with a decodes and activation methods). Why? Because these methods will get called in methods like show_results to get the actual predictions.\nNote: The Hugging Face models will always calculate the loss for you if you pass a labels dictionary along with your other inputs (so only include it if that is what you intend to happen)\nHugging Face question answering models will calculate the loss for you when you include both the start_positions and end_positions in the inputs dictionary. This is done by the QABatchTokenizeTransform when include_labels = True (which is the default). This also requires fastai developers to set their Learner’s loss function to the PreCalculatedQALoss for training to work properly.\n\n\nExample\nNotice below how I had to define the loss function after creating the Learner object. I’m not sure why, but the MultiTargetLoss above prohibits the learner from being exported if I do.\n\nTraining\n\nmodel = BaseModelWrapper(hf_model)\nlearn_cbs = [QAModelCallback]\n\nvalidation_ds = proc_df[proc_df.is_valid == True].to_dict(orient=\"records\")\nfit_cbs = [QAMetricsCallback(compute_metrics_func=compute_qa_metrics, validation_ds=validation_ds)]\n\nlearn = Learner(dls, model, opt_func=partial(Adam), cbs=learn_cbs, splitter=blurr_splitter)\n\nlearn.loss_func = PreCalculatedQALoss()  # MultiTargetLoss()\nlearn.create_opt()  # -> will create your layer groups based on your \"splitter\" function\nlearn.freeze()\n\n\n# learn.summary() # no glory here :(\n\n\nprint(len(learn.opt.param_groups))\n\n3\n\n\n\nlearn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\n\n\n\n\nSuggestedLRs(minimum=0.003981071710586548, steep=6.918309736647643e-06, valley=0.0014454397605732083, slide=0.0006918309954926372)\n\n\n\n\n\n\nlearn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      exact_match\n      f1\n      time\n    \n  \n  \n    \n      0\n      1.132470\n      1.128738\n      79.672131\n      85.973167\n      01:29\n    \n  \n\n\n\n\n\nShowing results\nAnd here we create a @typedispatched implementation of Learner.show_results for a more intuitive QA task\n\nlearn.show_results(learner=learn, skip_special_tokens=True, max_n=4, trunc_at=500)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      found\n      start/end\n      answer\n      pred start/end\n      pred answer\n    \n  \n  \n    \n      0\n      which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 – 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was\n      True\n      (46, 48)\n      denver broncos\n      (46, 48)\n      denver broncos\n    \n    \n      1\n      when did the san francisco bay area last host the super bowl? recent one being super bowl xliv in 2010. the san francisco bay area last hosted in 1985 ( super bowl xix ), held at stanford stadium in stanford, california, won by the home team 49ers. the miami bid depended on whether the stadium underwent renovations. however, on may 3, 2013, the florida legislature refused to approve the funding plan to pay for the renovations, dealing a significant blow to miami's chances.\n      True\n      (33, 34)\n      1985\n      (33, 34)\n      1985\n    \n    \n      2\n      where did the spring meetings of the nfl owners take place? on may 21, 2013, nfl owners at their spring meetings in boston voted and awarded the game to levi's stadium. the $ 1. 2 billion stadium opened in 2014. it is the first super bowl held in the san francisco bay area since super bowl xix in 1985, and the first in california since super bowl xxxvii took place in san diego in 2003.\n      True\n      (27, 28)\n      boston\n      (27, 28)\n      boston\n    \n    \n      3\n      who was the commissioner of the nfl in 2012? in early 2012, nfl commissioner roger goodell stated that the league planned to make the 50th super bowl \" spectacular \" and that it would be \" an important game for us as a league \".\n      True\n      (18, 21)\n      roger goodell\n      (18, 21)\n      roger goodell\n    \n  \n\n\n\n\nlearn.unfreeze()\n\n\nlearn.fit_one_cycle(1, lr_max=slice(1e-9, 1e-7), cbs=fit_cbs)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      exact_match\n      f1\n      time\n    \n  \n  \n    \n      0\n      0.947245\n      1.128543\n      79.672131\n      85.973167\n      03:13\n    \n  \n\n\n\n\nlearn.recorder.plot_loss()\n\n\n\n\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=100)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      found\n      start/end\n      answer\n      pred start/end\n      pred answer\n    \n  \n  \n    \n      0\n      which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to\n      True\n      (46, 48)\n      denver broncos\n      (46, 48)\n      denver broncos\n    \n    \n      1\n      what day was the super bowl played on? third super bowl title. the game was played on february 7, 20\n      True\n      (21, 25)\n      february 7, 2016\n      (21, 23)\n      february 7\n    \n  \n\n\n\n\n\nPrediction\nNote that there is a bug currently in fastai v2 (or with how I’m assembling everything) that currently prevents us from seeing the decoded predictions and probabilities for the “end” token.\n\nsource\n\n\n\nLearner.blurr_predict_answers\n\n Learner.blurr_predict_answers (question_contexts:Union[dict,List[dict]],\n                                slow_word_ids_func:Optional[Callable]=None\n                                )\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nquestion_contexts\nUnion\n\nThe str (or list of strings) you want to get token classification predictions for\n\n\nslow_word_ids_func\nOptional\nNone\nIf using a slow tokenizer, users will need to prove a slow_word_ids_func that accepts a\n\n\n\ntokenizzer, example index, and a batch encoding as arguments and in turn returnes the equavlient of fast tokenizer’s `word_ids`` |\n\ncontext = \"George Lucas created Star Wars in 1977. He directed and produced it.\"\n\nlearn.blurr_predict_answers({\"question\": \"What did George Lucas make?\", \"context\": context})\n\n[{'answer': 'Star Wars', 'start': 21, 'end': 30, 'score': 0.9519550800323486}]\n\n\n\ncontext = \"George Lucas created Star Wars in 1977. He directed and produced it.\"\n\nlearn.blurr_predict_answers(\n    [\n        {\"question\": \"What did George Lucas make?\", \"context\": context},\n        {\"question\": \"What year did Star Wars come out?\", \"context\": context},\n        {\"question\": \"What did George Lucas do?\", \"context\": context},\n        {\"question\": \"Who plays Spock in the movie?\", \"context\": context},\n    ]\n)\n\n[{'answer': 'Star Wars', 'start': 21, 'end': 30, 'score': 0.9519550800323486},\n {'answer': '1977', 'start': 34, 'end': 38, 'score': 0.8868365287780762},\n {'answer': 'created Star Wars in 1977. He directed and produced it',\n  'start': 13,\n  'end': 67,\n  'score': 0.17095458507537842},\n {'answer': 'George Lucas',\n  'start': 0,\n  'end': 12,\n  'score': 0.3317754566669464}]\n\n\n\nInference\nNote that I had to replace the loss function because of the above-mentioned issue to exporting the model with the MultiTargetLoss loss function. After getting our inference learner, we put it back and we’re good to go!\n\nexport_name = \"q_and_a_learn_export\"\n\n\nlearn.loss_func = CrossEntropyLossFlat()\nlearn.export(fname=f\"{export_name}.pkl\")\n\n\ninf_learn = load_learner(fname=f\"{export_name}.pkl\")\ninf_learn.loss_func = MultiTargetLoss()\n\ncontext = \"George Lucas created Star Wars in 1977. He directed and produced it.\"\n\ninf_learn.blurr_predict_answers(\n    [\n        {\"question\": \"What did George Lucas make?\", \"context\": context},\n        {\"question\": \"What year did Star Wars come out?\", \"context\": context},\n        {\"question\": \"What did George Lucas do?\", \"context\": context},\n        {\"question\": \"Who plays Spock in the movie?\", \"context\": context},\n    ]\n)\n\n[{'answer': 'Star Wars', 'start': 21, 'end': 30, 'score': 0.9519549608230591},\n {'answer': '1977', 'start': 34, 'end': 38, 'score': 0.8868366479873657},\n {'answer': 'created Star Wars in 1977. He directed and produced it',\n  'start': 13,\n  'end': 67,\n  'score': 0.17095446586608887},\n {'answer': 'George Lucas',\n  'start': 0,\n  'end': 12,\n  'score': 0.33177539706230164}]"
  },
  {
    "objectID": "text.modeling.question_answering.html#high-level-api",
    "href": "text.modeling.question_answering.html#high-level-api",
    "title": "Modeling",
    "section": "High-level API",
    "text": "High-level API\n\nsource\n\nBlearnerForQuestionAnswering\n\n BlearnerForQuestionAnswering (dls:fastai.data.core.DataLoaders,\n                               hf_model:transformers.modeling_utils.PreTra\n                               inedModel, base_model_cb:blurr.text.modelin\n                               g.core.BaseModelCallback=<class 'blurr.text\n                               .modeling.core.BaseModelCallback'>,\n                               loss_func:callable|None=None,\n                               opt_func=<function Adam>, lr=0.001,\n                               splitter:callable=<function\n                               trainable_params>, cbs=None, metrics=None,\n                               path=None, model_dir='models', wd=None,\n                               wd_bn_bias=False, train_bn=True,\n                               moms=(0.95, 0.85, 0.95),\n                               default_cbs:bool=True)\n\nGroup together a model, some dls and a loss_func to handle training\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndls\n\nDataLoaders containing data for each dataset needed for model\n\n\nhf_model\nPreTrainedModel\n\n\n\n\n\n\nExample\nBLearnerForQuestionAnswering requires a question, context (within which to find the answer to the question), and the start/end indices of where the answer lies in the tokenized context. Because those indices vary by tokenizer, we can pass a preprocess_func that will take our raw data, perform any preprocessing we want, and return it in a way that will work for extractive QA.\n\nPreprocess data\n\n# build our training and validation DataFrames\nraw_datasets = load_dataset(\"squad\", split=[\"train[:1000]\", \"validation[:200]\"])\n\nraw_train_df = pd.DataFrame(raw_datasets[0])\nraw_valid_df = pd.DataFrame(raw_datasets[1])\n\nraw_train_df[\"is_valid\"] = False\nraw_valid_df[\"is_valid\"] = True\n\n# concatenate into a single DataFrame\nsquad_df = pd.concat([raw_train_df, raw_valid_df])\n\n# include the required start/end character indicies and full text of the answer\nsquad_df[\"ans_start_char_idx\"] = squad_df.answers.apply(lambda v: v[\"answer_start\"][0] if len(v[\"answer_start\"]) > 0 else \"0\")\nsquad_df[\"answer_text\"] = squad_df.answers.apply(lambda v: v[\"text\"][0] if len(v[\"text\"]) > 0 else \"\")\nsquad_df[\"ans_end_char_idx\"] = squad_df[\"ans_start_char_idx\"].astype(int) + squad_df[\"answer_text\"].str.len()\n\n# run our modified DataFrame thru the QAPreprocessor to get the start/end \"token\" indices we want to predict\npreprocessor = QAPreprocessor(\n    hf_tokenizer, id_attr=\"id\", tok_kwargs={\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 64}\n)\n\nproc_df = preprocessor.process_df(squad_df)\nproc_df.head(1)\n\nReusing dataset squad (/home/wgilliam/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      id\n      title\n      context\n      question\n      answers\n      is_valid\n      ans_start_char_idx\n      answer_text\n      ans_end_char_idx\n      proc_question\n      proc_context\n      ans_start_token_idx\n      ans_end_token_idx\n      is_answerable\n    \n  \n  \n    \n      0\n      5733be284776f41900661182\n      University_of_Notre_Dame\n      Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...\n      To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n      {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}\n      False\n      515\n      Saint Bernadette Soubirous\n      541\n      To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n      Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed\n      0\n      0\n      False\n    \n  \n\n\n\n\n\n\nDefine your Blearner\n\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n\nlearn = BlearnerForQuestionAnswering.from_data(\n    proc_df,\n    pretrained_model_name,\n    id_attr=\"id\",\n    question_attr=\"proc_question\",\n    context_attr=\"proc_context\",\n    max_seq_len=128,\n    dl_kwargs={\"bs\": 4},\n).to_fp16()\n\nvalidation_ds = proc_df[proc_df.is_valid == True].to_dict(orient=\"records\")\nfit_cbs = [QAMetricsCallback(compute_metrics_func=compute_qa_metrics, validation_ds=validation_ds)]\n\n\nlearn.dls.show_batch(dataloaders=learn.dls, max_n=4, trunc_at=500)\n\n\n\n  \n    \n      \n      text\n      found\n      start/end\n      answer\n    \n  \n  \n    \n      0\n      with what institute did notre dame agree to an exchange program in the 1960s? ism. \" thomas blantz, c. s. c., notre dame's vice president of student affairs, added that coeducation \" opened up a whole other pool of very bright students. \" two of the male residence halls were converted for the newly admitted female students that first year, while two others were converted for the next school year. in 1971 mary ann proctor became the first female undergraduate ; she transferred from st. mary's col\n      False\n      (0, 0)\n      \n    \n    \n      1\n      what types of garments are sold by beyonce's clothing line? eon, a respected seamstress. according to tina, the overall style of the line best reflects her and beyonce's taste and style. beyonce and her mother founded their family's company beyond productions, which provides the licensing and brand management for house of dereon, and its junior collection, dereon. house of dereon pieces were exhibited in destiny's child's shows and tours, during their destiny fulfilled era. the collection featur\n      True\n      (106, 125)\n      sportswear, denim offerings with fur, outerwear and accessories that include handbags and footwear\n    \n    \n      2\n      what notable football player played at notre dame from 1916 to 1920? george gipp was the school's legendary football player during 1916 – 20. he played semiprofessional baseball and smoked, drank, and gambled when not playing sports. he was also humble, generous to the needy, and a man of integrity. it was in 1928 that famed coach knute rockne used his final conversation with the dying gipp to inspire the notre dame team to beat the army team and \" win one for the gipper. \" the 1940 film, knute\n      True\n      (15, 18)\n      george gipp\n    \n    \n      3\n      beyonce's first modelling event was at where? in september 2010, beyonce made her runway modelling debut at tom ford's spring / summer 2011 fashion show. she was named \" world's most beautiful woman \" by people and the \" hottest female singer of all time \" by complex in 2012. in january 2013, gq placed her on its cover, featuring her atop its \" 100 sexiest women of the 21st century \" list. vh1 listed her at number 1 on its 100 sexiest artists list. several wax figures of beyonce are found at mad\n      True\n      (23, 33)\n      tom ford's spring / summer 2011 fashion show\n    \n  \n\n\n\n\n\nTrain\n\nvalidation_ds = proc_df[proc_df.is_valid == True].to_dict(orient=\"records\")\nfit_cbs = [QAMetricsCallback(compute_metrics_func=compute_qa_metrics, validation_ds=validation_ds)]\n\nlearn.fit_one_cycle(3, lr_max=1e-3, cbs=fit_cbs)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      exact_match\n      f1\n      time\n    \n  \n  \n    \n      0\n      0.864185\n      1.243750\n      71.803279\n      77.245525\n      01:56\n    \n    \n      1\n      0.558980\n      1.031230\n      77.377049\n      83.185627\n      01:58\n    \n    \n      2\n      0.361602\n      0.989997\n      78.688525\n      85.122314\n      02:04\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, skip_special_tokens=True, max_n=2, trunc_at=500)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      found\n      start/end\n      answer\n      pred start/end\n      pred answer\n    \n  \n  \n    \n      0\n      which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 – 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was\n      True\n      (46, 48)\n      denver broncos\n      (46, 48)\n      denver broncos\n    \n    \n      1\n      who was the head coach of the broncos in super bowl xlviii? for the third straight season, the number one seeds from both conferences met in the super bowl. the carolina panthers became one of only ten teams to have completed a regular season with only one loss, and one of only six teams to have acquired a 15 – 1 record, while the denver broncos became one of four teams to have made eight appearances in the super bowl. the broncos made their second super bowl appearance in three years, having re\n      False\n      (0, 0)\n      \n      (0, 0)\n      \n    \n  \n\n\n\n\n\nInference\n\nlearn = learn.to_fp32()\nlearn.loss_func = CrossEntropyLossFlat()\nlearn.export(fname=f\"{export_name}.pkl\")\n\n\ninf_learn = load_learner(fname=f\"{export_name}.pkl\")\ninf_learn.loss_func = MultiTargetLoss()\n\ncontext = \"George Lucas created Star Wars in 1977. He directed and produced it.\"\n\ninf_learn.blurr_predict_answers(\n    [\n        {\"question\": \"What did George Lucas make?\", \"context\": context},\n        {\"question\": \"What year did Star Wars come out?\", \"context\": context},\n        {\"question\": \"What did George Lucas do?\", \"context\": context},\n        {\"question\": \"Who plays Spock in the movie?\", \"context\": context},\n    ]\n)\n\n[{'answer': 'Star Wars', 'start': 21, 'end': 30, 'score': 0.9926180243492126},\n {'answer': '1977', 'start': 34, 'end': 38, 'score': 0.6034910082817078},\n {'answer': 'directed and produced',\n  'start': 43,\n  'end': 64,\n  'score': 0.19618140161037445},\n {'answer': None, 'start': 0, 'end': 0, 'score': 0.8134177327156067}]"
  },
  {
    "objectID": "examples.text.multilabel_classification.html",
    "href": "examples.text.multilabel_classification.html",
    "title": "Multi-label classification",
    "section": "",
    "text": "Let’s start by building our DataBlock"
  },
  {
    "objectID": "examples.text.multilabel_classification.html#mid-level-api",
    "href": "examples.text.multilabel_classification.html#mid-level-api",
    "title": "Multi-label classification",
    "section": "Mid-level API",
    "text": "Mid-level API\n\nStep 1: Build our Hugging Face objects\nFor our huggingface model, let’s used the distilled version of RoBERTa. This should allow us to train the model on bigger mini-batches without much performance loss. Even on my 1080Ti, I should be able to train all the parameters (which isn’t possible with the roberta-base model)\n\nmodel_cls = AutoModelForSequenceClassification\n\npretrained_model_name = \"distilroberta-base\"\nconfig = AutoConfig.from_pretrained(pretrained_model_name)\nconfig.num_labels = len(lbl_cols)\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls, config=config)\nhf_model.config.problem_type = \"multi_label_classification\"\n\nprint(hf_arch)\nprint(type(hf_config))\nprint(type(hf_tokenizer))\nprint(type(hf_model))\n\nroberta\n<class 'transformers.models.roberta.configuration_roberta.RobertaConfig'>\n<class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>\n<class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>\n\n\nNote how we have to configure the num_labels to the number of labels we are predicting. Given that our labels are already encoded, we use a MultiCategoryBlock with encoded=True and vocab equal to the columns with our 1’s and 0’s.\n\n\nStep 2: Build our DataLoaders\n\nblocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), MultiCategoryBlock(encoded=True, vocab=lbl_cols))\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(lbl_cols), splitter=ColSplitter())\n\n\ndls = dblock.dataloaders(toxic_df, bs=4, val_bs=8)\n\n\nb = dls.one_batch()\nlen(b), b[0][\"input_ids\"].shape, b[1].shape\n\n(2, torch.Size([4, 512]), torch.Size([4, 7]))\n\n\n\n\nStep 3: Build our Learner\nWith our DataLoaders built, we can now build our Learner and train. We’ll use mixed precision so we can train with bigger batches\n\nmodel = BaseModelWrapper(hf_model)\n\nlearn = Learner(\n    dls,\n    model,\n    opt_func=partial(Adam),\n    loss_func=BCEWithLogitsLossFlat(),  # PreCalculatedBCELoss()\n    metrics=[partial(accuracy_multi, thresh=0.2)],\n    cbs=[BaseModelCallback],\n    splitter=blurr_splitter,\n).to_fp16()\n\nlearn.loss_func.thresh = 0.15\nlearn.freeze()\n\n\nlearn.summary()\n\n\npreds = model(b[0])\npreds.logits.shape, preds\n\n(torch.Size([4, 7]),\n SequenceClassifierOutput(loss=TensorMultiCategory(0.6522, device='cuda:1', grad_fn=<AliasBackward0>), logits=tensor([[-0.3090,  0.0359, -0.1667, -0.0387, -0.3063, -0.0053,  0.0813],\n         [-0.2999,  0.0705, -0.1847, -0.0136, -0.3005,  0.0097,  0.0636],\n         [-0.2754,  0.0481, -0.1672, -0.0302, -0.2681,  0.0213,  0.0820],\n         [-0.2759,  0.0567, -0.1639, -0.0284, -0.2742,  0.0129,  0.1228]],\n        device='cuda:1', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None))\n\n\n\n\nStep 4: Train\n\nlearn.lr_find()\n\n\n\n\nSuggestedLRs(valley=0.0003981071640737355)\n\n\n\n\n\n\nlearn.fit_one_cycle(1, lr_max=1e-2)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.089716\n      0.064052\n      0.984928\n      01:10\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      Richard Ellmyer - I think most sane, patriotic Americans hear and agree with your total exasperation at this lawless, ridiculous situation.  However, while I agree I am very disturbed at the approach by the FBI SACs in Nevada and Portland, I think you are missing who is responsible here.  On January 4, the White House made a public announcement that this terrorist takeover of U.S. Federal Government land and buildings was \"ultimately a local law enforcement matter.\"  Then after that, \"Obama administration leaders\" told Reuters that the Obama administration had \"ordered\" federal law enforcement not to have a \"conflict\" with these Sovereign Citizen terrorists in Oregon. So while there is plenty of blame to go around, I think the focus needs to be on the person who is actually making the REAL decisions here, and it is not ultimately FBI Portland SAC.  I urge Oregonians to contact the White House and also presidential candidates and DEMAND a restoral of the rule of law to this anarchic situation.  More children, more citizens are put at risk, and history has shown the failure to act in Nevada in 2014 ultimately cost the lives of other Americans in Las Vegas down the road from such terrorist supporters.  It is time our leadership spends time doing THEIR JOB, not playing political games with media.\n      []\n      []\n    \n    \n      1\n      @Rick Tubania:  You know Rick, technically there's not much of a difference between an Independent Contractor and an Employee and the only things really are the lack of health insurance and benefits.  They both do work for the companies they serve.  You're just trying to justify his actions because he's your buddy and we seem to be picking on him.  LOL!  It's still disingenuous and an abuse of vacation time to regularly take vacation at around the same time of the month or quarter from his job as Mayor that Caldwell himself declares that he's doing 24/7 on numerous occasions because he loves the job.  IF he loves the job as Mayor so much, why does he need to do other work as an Independent Contractor during time that he would normally spend being the Mayor?  Bottom line is Caldwell needs to be replaced as Mayor because the public can't trust what he says.  I remember he told the legislature that if they extended the GET 5 years, he would have enough funds to finish rail.  Wrong!  LOL!!\n      []\n      []\n    \n  \n\n\n\n\nlearn.unfreeze()\n\n\nlearn.fit_one_cycle(1, lr_max=slice(1e-8, 1e-4))\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.064716\n      0.063631\n      0.984928\n      02:18\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      Richard Ellmyer - I think most sane, patriotic Americans hear and agree with your total exasperation at this lawless, ridiculous situation.  However, while I agree I am very disturbed at the approach by the FBI SACs in Nevada and Portland, I think you are missing who is responsible here.  On January 4, the White House made a public announcement that this terrorist takeover of U.S. Federal Government land and buildings was \"ultimately a local law enforcement matter.\"  Then after that, \"Obama administration leaders\" told Reuters that the Obama administration had \"ordered\" federal law enforcement not to have a \"conflict\" with these Sovereign Citizen terrorists in Oregon. So while there is plenty of blame to go around, I think the focus needs to be on the person who is actually making the REAL decisions here, and it is not ultimately FBI Portland SAC.  I urge Oregonians to contact the White House and also presidential candidates and DEMAND a restoral of the rule of law to this anarchic situation.  More children, more citizens are put at risk, and history has shown the failure to act in Nevada in 2014 ultimately cost the lives of other Americans in Las Vegas down the road from such terrorist supporters.  It is time our leadership spends time doing THEIR JOB, not playing political games with media.\n      []\n      []\n    \n    \n      1\n      \"But local economist Paul Brewbaker said the monetary savings of abandoning the project doesn’t take into account how such a move would derail Honolulu’s efforts to achieve higher urban density and improved urban mobility, and would further discourage companies from investing in Hawaii\"\\n\\nAgain, rail was first touted for traffic decongestion, then for affordable housing, but it's  really for TOD - Transit Oriented Development - for corporations to develop in Hawaii. It may sound okay from a business standpoint but Oahu is a small island. \\n\\nWhat about the small private mom-and-pop property owners along the Honolulu Rail Corridor? Will the city/state abuse its powers of eminent domain to pave the way for bigger private corporate development? When will the public know about this little secret of Honolulu Rail?\\n\\nThe  Rail powers-that-be acted intransigently to railroad this project.  They grossly UNDER-estimated the projected costs, KNOWING they could blackmail Oahu into this present stage.\n      []\n      []\n    \n  \n\n\n\n\nlearn.loss_func.thresh = 0.02\n\n\ncomment = \"\"\"\nThose damned affluent white people should only eat their own food, like cod cakes and boiled potatoes. \nNo enchiladas for them!\n\"\"\"\nlearn.blurr_predict(comment)\n\n[{'labels': ['insult', 'toxicity'],\n  'scores': [0.04288223758339882, 0.056340090930461884],\n  'class_indices': [0, 1, 0, 1, 0, 0, 0],\n  'class_labels': ['identity_attack', 'insult', 'obscene', 'toxicity', 'severe_toxicity', 'sexual_explicit', 'threat'],\n  'probs': [0.004133968148380518,\n   0.04288223758339882,\n   0.004117917735129595,\n   0.056340090930461884,\n   2.225281377832289e-06,\n   0.0007947254925966263,\n   0.0011740821646526456]}]\n\n\n\npreds, targs, losses = learn.get_preds(with_loss=True)\npreds.shape, targs.shape, losses.shape\n\n\n\n\n(torch.Size([2000, 7]), torch.Size([2000, 7]), torch.Size([2000]))"
  },
  {
    "objectID": "examples.text.multilabel_classification.html#high-level-api",
    "href": "examples.text.multilabel_classification.html#high-level-api",
    "title": "Multi-label classification",
    "section": "High-level API",
    "text": "High-level API\nWith the high-level API, we can create our DataBlock, DataLoaders, and Blearner in one line of code\n\nStep 1: Build our Hugging Face objects\n\nmodel_cls = AutoModelForSequenceClassification\n\npretrained_model_name = \"distilroberta-base\"\nconfig = AutoConfig.from_pretrained(pretrained_model_name)\nconfig.num_labels = len(lbl_cols)\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls, config=config)\nhf_model.config.problem_type = \"multi_label_classification\"\n\nprint(hf_arch)\nprint(type(hf_config))\nprint(type(hf_tokenizer))\nprint(type(hf_model))\n\nroberta\n<class 'transformers.models.roberta.configuration_roberta.RobertaConfig'>\n<class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>\n<class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>\n\n\n\n\nStep 2: Configure our BlearnerForSequenceClassification\n\nlearn = BlearnerForSequenceClassification.from_data(\n    toxic_df, pretrained_model_name, text_attr=\"text\", label_attr=lbl_cols, dl_kwargs={\"bs\": 4}\n)\n\nlearn.loss_func.thresh = 0.1\n\n\n\nStep 3: Train\n\nlearn.fit_one_cycle(1, lr_max=1e-2)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.079307\n      0.063679\n      0.000000\n      0.984928\n      01:03\n    \n  \n\n\n\n/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n\n\n\nlearn.show_results(learner=learn, max_n=2)\n\n\n\n\n/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      Richard Ellmyer - I think most sane, patriotic Americans hear and agree with your total exasperation at this lawless, ridiculous situation.  However, while I agree I am very disturbed at the approach by the FBI SACs in Nevada and Portland, I think you are missing who is responsible here.  On January 4, the White House made a public announcement that this terrorist takeover of U.S. Federal Government land and buildings was \"ultimately a local law enforcement matter.\"  Then after that, \"Obama administration leaders\" told Reuters that the Obama administration had \"ordered\" federal law enforcement not to have a \"conflict\" with these Sovereign Citizen terrorists in Oregon. So while there is plenty of blame to go around, I think the focus needs to be on the person who is actually making the REAL decisions here, and it is not ultimately FBI Portland SAC.  I urge Oregonians to contact the White House and also presidential candidates and DEMAND a restoral of the rule of law to this anarchic situation.  More children, more citizens are put at risk, and history has shown the failure to act in Nevada in 2014 ultimately cost the lives of other Americans in Las Vegas down the road from such terrorist supporters.  It is time our leadership spends time doing THEIR JOB, not playing political games with media.\n      []\n      []\n    \n    \n      1\n      Your comment is ridiculous.  Should I protest at a hospital because I want less military spending?  Disrespecting a symbol of why you are free to protest/have dumb thoughts on a subject/are safe does not make sense.  The Flag and Anthem are not symbols you disrespect just as I would never burn a cross, Star of David or Koran.  Those are symbols and things held dear to people.  If its fine to dis the flag, what if they decided to burn a cross?\\nThe whole BLM movement is a racist farce in America.  Stats show there IS NOT any genocide of black men or anyone by cops in America.  There are very, very few black men shot by cops in questionable circumstances in America.  Ferguson is one example.  The cop was almost killed and Mike Brown deserved what he got.  The false narrative was that he was knelt down and shot in the back of the head by a racist cop.  Sorry, didn't happen.What does happen is thousands and thousands of young black men murder one another and BLM ignores that horrifying stat\n      [insult, toxicity]\n      []\n    \n  \n\n\n\n\nlearn.loss_func.thresh = 0.01\n\ncomment = \"\"\"\nThose damned affluent white people should only eat their own food, like cod cakes and boiled potatoes. \nNo enchiladas for them!\n\"\"\"\nlearn.predict(comment)\n\n[{'labels': ['insult', 'toxicity'],\n  'scores': [0.045652199536561966, 0.060720182955265045],\n  'class_indices': [0, 1, 0, 1, 0, 0, 0],\n  'class_labels': ['identity_attack', 'insult', 'obscene', 'toxicity', 'severe_toxicity', 'sexual_explicit', 'threat'],\n  'probs': [0.003910946659743786,\n   0.045652199536561966,\n   0.003097661305218935,\n   0.060720182955265045,\n   1.0245050816592993e-06,\n   0.00038578492240048945,\n   0.0010632844641804695]}]\n\n\n\n# if using the precalculated loss, you need to set `with_loss=False`\npreds, targs = learn.get_preds(with_loss=False)\npreds.shape, targs.shape\n\n\n\n\n/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n\n\n(torch.Size([2000, 7]), torch.Size([2000, 7]))"
  },
  {
    "objectID": "examples.text.multilabel_classification.html#low-level-api",
    "href": "examples.text.multilabel_classification.html#low-level-api",
    "title": "Multi-label classification",
    "section": "Low-level API",
    "text": "Low-level API\n\nStep 1: Build our Hugging Face objects\n\nmodel_cls = AutoModelForSequenceClassification\n\npretrained_model_name = \"distilroberta-base\"\nconfig = AutoConfig.from_pretrained(pretrained_model_name)\nconfig.num_labels = len(lbl_cols)\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls, config=config)\nhf_model.config.problem_type = \"multi_label_classification\"\n\nprint(hf_arch)\nprint(type(hf_config))\nprint(type(hf_tokenizer))\nprint(type(hf_model))\n\nroberta\n<class 'transformers.models.roberta.configuration_roberta.RobertaConfig'>\n<class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>\n<class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>\n\n\n\n\nStep 2: Prepare your dataset\nWe’ll create a labels column that includes the OHE labels for each example. The raw values come in the form of probabilities ranging from 0. to 1., so we simply round those >= .51 to 1.0, else set it to 0. for our purposes here\n\nraw_datasets = datasets.load_dataset(\"civil_comments\", split=[\"train[:1000]\", \"validation[:500]\"])\nraw_datasets\n\nUsing custom data configuration default\nReusing dataset civil_comments (/home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab)\n\n\n\n\n\n[Dataset({\n     features: ['identity_attack', 'insult', 'obscene', 'severe_toxicity', 'sexual_explicit', 'text', 'threat', 'toxicity'],\n     num_rows: 1000\n }),\n Dataset({\n     features: ['identity_attack', 'insult', 'obscene', 'severe_toxicity', 'sexual_explicit', 'text', 'threat', 'toxicity'],\n     num_rows: 500\n })]\n\n\n\ndef tokenize_function(example):\n    inputs = hf_tokenizer(example[\"text\"], truncation=True)\n    targets = [\n        float(round(example[lbl]))\n        for lbl in [\"identity_attack\", \"insult\", \"obscene\", \"severe_toxicity\", \"sexual_explicit\", \"threat\", \"toxicity\"]\n    ]\n    return {**inputs, **{\"labels\": targets}}\n\n\ntokenized_datasets = [ds.map(tokenize_function, batched=False) for ds in raw_datasets]\n\n\n\n\n\n\n\n\n\nStep 3: Build our DataLoaders\nBy assigning the aforementioned labels to the label_names argument of our BlurrDataLoaders, we get the friendly label printed when we run show_batch or show_results intead of the label’s index.\n\nlabel_names = [\"identity_attack\", \"insult\", \"obscene\", \"severe_toxicity\", \"sexual_explicit\", \"threat\", \"toxicity\"]\n\ntrn_dl = TextDataLoader(\n    tokenized_datasets[0],\n    hf_arch=hf_arch,\n    hf_config=hf_config,\n    hf_tokenizer=hf_tokenizer,\n    hf_model=hf_model,\n    preproccesing_func=preproc_hf_dataset,\n    batch_decode_kwargs={\"labels\": label_names},\n    shuffle=True,\n    batch_size=8,\n)\n\nval_dl = TextDataLoader(\n    tokenized_datasets[1],\n    hf_arch=hf_arch,\n    hf_config=hf_config,\n    hf_tokenizer=hf_tokenizer,\n    hf_model=hf_model,\n    preproccesing_func=preproc_hf_dataset,\n    batch_decode_kwargs={\"labels\": label_names},\n    batch_size=16,\n)\n\ndls = DataLoaders(trn_dl, val_dl)\n\n\nb = dls.one_batch()\nb[0][\"input_ids\"].shape, b[1].shape\n\n(torch.Size([8, 208]), torch.Size([8, 7]))\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      I was at that event... It was a private event and the alcohol that was consumed there was complimentary... I understand the OLCC's desire to set firm boundaries early on in this Wild Wild West of legalization; but this looks more like they have a personal grudge against the owner (since they have investigated her in the past and could prove no wrongdoing).\n      []\n    \n    \n      1\n      If you haven't had a chance to see Hateful Eight on 70mm, DO IT. DO IT NOW.\n      []\n    \n  \n\n\n\n\n\nStep 4: Train\n\nmodel = BaseModelWrapper(hf_model)\n\nlearn = Learner(\n    dls,\n    model,\n    opt_func=partial(Adam),\n    loss_func=PreCalculatedBCELoss(),\n    metrics=[partial(accuracy_multi, thresh=0.2)],\n    cbs=[BaseModelCallback],\n    splitter=blurr_splitter,\n).to_fp16()\n\nlearn.loss_func.thresh = 0.1\nlearn.freeze()\n\n\nlearn.fit(1, 1e-2)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.113307\n      0.087454\n      0.983714\n      00:10\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      Delivery by drone??  I wonder what they are smoking.\n      []\n      []\n    \n    \n      1\n      All the things going on around here and This is considered news? What a waste of time and talent that could have been applied on things that matter...\n      []\n      []"
  },
  {
    "objectID": "examples.text.multilabel_classification.html#summary",
    "href": "examples.text.multilabel_classification.html#summary",
    "title": "Multi-label classification",
    "section": "Summary",
    "text": "Summary\nIf your sequence classification model isn’t training, make sure you have set the num_labels correctly (95% of the time this is the culprit). And with this example, you can see that Blurr can make both your multiclassification and multilabel classification tasks a breeze."
  },
  {
    "objectID": "examples.text.glue.html",
    "href": "examples.text.glue.html",
    "title": "GLUE classification tasks",
    "section": "",
    "text": "Using GPU #1: GeForce GTX 1080 Ti"
  },
  {
    "objectID": "examples.text.glue.html#glue-tasks",
    "href": "examples.text.glue.html#glue-tasks",
    "title": "GLUE classification tasks",
    "section": "GLUE tasks",
    "text": "GLUE tasks\n\n\n\n\n\n  \n    \n      Abbr\n      Name\n      Task type\n      Description\n      Size\n      Metrics\n    \n  \n  \n    \n      CoLA\n      Corpus of Linguistic Acceptability\n      Single-Sentence Task\n      Predict whether a sequence is a grammatical English sentence\n      8.5k\n      Matthews corr.\n    \n    \n      SST-2\n      Stanford Sentiment Treebank\n      Single-Sentence Task\n      Predict the sentiment of a given sentence\n      67k\n      Accuracy\n    \n    \n      MRPC\n      Microsoft Research Paraphrase Corpus\n      Similarity and Paraphrase Tasks\n      Predict whether two sentences are semantically equivalent\n      3.7k\n      F1/Accuracy\n    \n    \n      SST-B\n      Semantic Textual Similarity Benchmark\n      Similarity and Paraphrase Tasks\n      Predict the similarity score for two sentences on a scale from 1 to 5\n      7k\n      Pearson/Spearman corr.\n    \n    \n      QQP\n      Quora question pair\n      Similarity and Paraphrase Tasks\n      Predict if two questions are a paraphrase of one another\n      364k\n      F1/Accuracy\n    \n    \n      MNLI\n      Mulit-Genre Natural Language Inference\n      Inference Tasks\n      Predict whether the premise entails, contradicts or is neutral to the hypothesis\n      393k\n      Accuracy\n    \n    \n      QNLI\n      Stanford Question Answering Dataset\n      Inference Tasks\n      Predict whether the context sentence contains the answer to the question\n      105k\n      Accuracy\n    \n    \n      RTE\n      Recognize Textual Entailment\n      Inference Tasks\n      Predict whether one sentece entails another\n      2.5k\n      Accuracy\n    \n    \n      WNLI\n      Winograd Schema Challenge\n      Inference Tasks\n      Predict if the sentence with the pronoun substituted is entailed by the original sentence\n      634\n      Accuracy"
  },
  {
    "objectID": "examples.text.glue.html#define-the-task-and-hyperparmeters",
    "href": "examples.text.glue.html#define-the-task-and-hyperparmeters",
    "title": "GLUE classification tasks",
    "section": "Define the task and hyperparmeters",
    "text": "Define the task and hyperparmeters\nWe’ll use the “distilroberta-base” checkpoint for this example, but if you want to try an architecture that returns token_type_ids for example, you can use something like bert-cased.\n\ntask = \"mrpc\"\ntask_meta = glue_tasks[task]\ntrain_ds_name = task_meta[\"dataset_names\"][\"train\"]\nvalid_ds_name = task_meta[\"dataset_names\"][\"valid\"]\ntest_ds_name = task_meta[\"dataset_names\"][\"test\"]\n\ntask_inputs = task_meta[\"inputs\"]\ntask_target = task_meta[\"target\"]\ntask_metrics = task_meta[\"metric_funcs\"]\n\npretrained_model_name = \"distilroberta-base\"  # bert-base-cased | distilroberta-base\n\nbsz = 16\nval_bsz = bsz * 2"
  },
  {
    "objectID": "examples.text.glue.html#prepare-the-datasets",
    "href": "examples.text.glue.html#prepare-the-datasets",
    "title": "GLUE classification tasks",
    "section": "Prepare the datasets",
    "text": "Prepare the datasets\nLet’s start by building our DataBlock. We’ll load the MRPC datset from huggingface’s datasets library which will be cached after downloading via the load_dataset method. For more information on the datasets API, see the documentation here.\n\nraw_datasets = load_dataset(\"glue\", task)\nprint(f\"{raw_datasets}\\n\")\nprint(f\"{raw_datasets[train_ds_name][0]}\\n\")\nprint(f\"{raw_datasets[train_ds_name].features}\\n\")\n\nReusing dataset glue (/home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['idx', 'label', 'sentence1', 'sentence2'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['idx', 'label', 'sentence1', 'sentence2'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['idx', 'label', 'sentence1', 'sentence2'],\n        num_rows: 1725\n    })\n})\n\n{'idx': 0, 'label': 1, 'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'}\n\n{'idx': Value(dtype='int32', id=None), 'label': ClassLabel(num_classes=2, names=['not_equivalent', 'equivalent'], names_file=None, id=None), 'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None)}\n\n\n\nThere are a variety of ways we can preprocess the dataset for DataBlock consumption. For example, we could push the data into a DataFrame, add a boolean is_valid column, and use the ColSplitter method to define our train/validation splits like this:\n\nraw_train_df = pd.DataFrame(raw_datasets[train_ds_name], columns=list(raw_datasets[train_ds_name].features.keys()))\nraw_train_df[\"is_valid\"] = False\n\nraw_valid_df = pd.DataFrame(raw_datasets[valid_ds_name], columns=list(raw_datasets[train_ds_name].features.keys()))\nraw_valid_df[\"is_valid\"] = True\n\nraw_df = pd.concat([raw_train_df, raw_valid_df])\nprint(len(raw_df))\nraw_df.head()\n\n4076\n\n\n\n\n\n\n  \n    \n      \n      idx\n      label\n      sentence1\n      sentence2\n      is_valid\n    \n  \n  \n    \n      0\n      0\n      1\n      Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .\n      Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .\n      False\n    \n    \n      1\n      1\n      0\n      Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\n      Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 .\n      False\n    \n    \n      2\n      2\n      1\n      They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .\n      On June 10 , the ship 's owners had published an advertisement on the Internet , offering the explosives for sale .\n      False\n    \n    \n      3\n      3\n      0\n      Around 0335 GMT , Tab shares were up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .\n      Tab shares jumped 20 cents , or 4.6 % , to set a record closing high at A $ 4.57 .\n      False\n    \n    \n      4\n      4\n      1\n      The stock rose $ 2.11 , or about 11 percent , to close Friday at $ 21.51 on the New York Stock Exchange .\n      PG & E Corp. shares jumped $ 1.63 or 8 percent to $ 21.03 on the New York Stock Exchange on Friday .\n      False\n    \n  \n\n\n\n\nAnother option is to capture the indexes for both train and validation sets, use the datasets concatenate_datasets to put them into a single dataset, and finally use the IndexSplitter method to define our train/validation splits as such:\n\nn_train, n_valid = raw_datasets[train_ds_name].num_rows, raw_datasets[valid_ds_name].num_rows\ntrain_idxs, valid_idxs = L(range(n_train)), L(range(n_train, n_train + n_valid))\nraw_ds = concatenate_datasets([raw_datasets[train_ds_name], raw_datasets[valid_ds_name]])"
  },
  {
    "objectID": "examples.text.glue.html#mid-level-api",
    "href": "examples.text.glue.html#mid-level-api",
    "title": "GLUE classification tasks",
    "section": "Mid-level API",
    "text": "Mid-level API\n\nPrepare the huggingface objects\nHow many classes are we working with? Depending on your approach above, you can do one of the two approaches below.\n\nn_lbls = raw_df[task_target].nunique()\nn_lbls\n\n2\n\n\n\nn_lbls = len(set([item[task_target] for item in raw_ds]))\nn_lbls\n\n2\n\n\n\nmodel_cls = AutoModelForSequenceClassification\n\nconfig = AutoConfig.from_pretrained(pretrained_model_name)\nconfig.num_labels = n_lbls\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls, config=config)\n\nprint(hf_arch)\nprint(type(hf_config))\nprint(type(hf_tokenizer))\nprint(type(hf_model))\n\nroberta\n<class 'transformers.models.roberta.configuration_roberta.RobertaConfig'>\n<class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>\n<class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>\n\n\n\n\nBuild the DataBlock\n\nblocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), CategoryBlock())\n\n\ndef get_x(r, attr):\n    return r[attr] if (isinstance(attr, str)) else tuple(r[inp] for inp in attr)\n\n\ndblock = DataBlock(blocks=blocks, get_x=partial(get_x, attr=task_inputs), get_y=ItemGetter(task_target), splitter=IndexSplitter(valid_idxs))\n\n\ndls = dblock.dataloaders(raw_ds, bs=bsz, val_bs=val_bsz)\n\n\nb = dls.one_batch()\nlen(b), b[0][\"input_ids\"].shape, b[1].shape\n\n(2, torch.Size([16, 103]), torch.Size([16]))\n\n\n\nif \"token_type_ids\" in b[0]:\n    print(\n        [\n            (hf_tokenizer.convert_ids_to_tokens(inp_id.item()), inp_id.item(), tt_id.item())\n            for inp_id, tt_id in zip(b[0][\"input_ids\"][0], b[0][\"token_type_ids\"][0])\n            if inp_id != hf_tokenizer.pad_token_id\n        ]\n    )\n\n\ndls.show_batch(dataloaders=dls, max_n=5)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      \" In Iraq, \" Sen. Pat Roberts, R-Kan., chairman of the intelligence committee, said on CNN's \" Late Edition \" Sunday, \" we're now fighting an anti-guerrilla... effort. \" \" In Iraq, \" Sen. Pat Roberts ( R-Kan. ), chairman of the intelligence committee, said on CNN's \" Late Edition \" yesterday, \" we're now fighting an anti-guerrilla... effort. \"\n      1\n    \n    \n      1\n      Media giant Vivendi Universal EAUG.PA V.N set to work sifting through bids for its U.S. entertainment empire on Monday in a multibillion-dollar auction of some of Hollywood's best-known assets. Media moguls jostled for position as the deadline for bids for Vivendi Universal's U.S. entertainment empire neared on Monday in an auction of some of Hollywood's best-known assets.\n      1\n    \n    \n      2\n      The compilers are available in two flavors : the Intel C + + Compiler for Microsoft eMbedded Visual C + + retails for USD $ 399 and is intended for application development use. The compilers are available in two forms : The Intel C + + Compiler for Microsoft eMbedded Visual C + + is available from Intel for $ 399, and is intended for applications development.\n      1\n    \n    \n      3\n      The technology-laced Nasdaq Composite Index.IXIC rose 39.39 points, or 2.2 percent, to 1,826.33, after losing more than 2 percent on Tuesday. The blue-chip Dow Jones industrial average.DJI jumped 194.14 points, or 2.09 percent, to 9,469.20 after sinking more than 1 percent a day earlier.\n      0\n    \n    \n      4\n      Ryland Group ( nyse : RYL - news - people ), a homebuilder and mortgage-finance company, sank $ 9.65, or 11.6 percent, to $ 73.40. Swedish telecom equipment maker Ericsson ( nasdaq : QCOM - news - people ) jumped $ 2.88, or 15.7 percent, to $ 21.28.\n      0\n    \n  \n\n\n\n\n\nTrain\nWith our DataLoaders built, we can now build our Learner and train. We’ll use mixed precision so we can train with bigger batches\n\nmodel = BaseModelWrapper(hf_model)\n\nlearn = Learner(\n    dls,\n    model,\n    opt_func=partial(Adam),\n    loss_func=CrossEntropyLossFlat(),\n    metrics=task_metrics,\n    cbs=[BaseModelCallback],\n    splitter=blurr_splitter,\n).to_fp16()\n\nlearn.freeze()\n\n\nlearn.summary()\n\n\npreds = model(b[0])\npreds.logits.shape, preds\n\n(torch.Size([16, 2]),\n SequenceClassifierOutput(loss=TensorCategory(0.7086, device='cuda:1', grad_fn=<AliasBackward0>), logits=tensor([[ 0.0667, -0.0891],\n         [ 0.0869, -0.1019],\n         [ 0.0746, -0.0834],\n         [ 0.0695, -0.0800],\n         [ 0.0657, -0.0969],\n         [ 0.0618, -0.0819],\n         [ 0.0782, -0.1044],\n         [ 0.0634, -0.0794],\n         [ 0.0600, -0.0805],\n         [ 0.0681, -0.1136],\n         [ 0.0677, -0.0923],\n         [ 0.0729, -0.1105],\n         [ 0.0629, -0.1071],\n         [ 0.0617, -0.0813],\n         [ 0.0639, -0.0912],\n         [ 0.0577, -0.1013]], device='cuda:1', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None))\n\n\n\nlearn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\nSuggestedLRs(minimum=0.0007585775572806596, steep=0.0063095735386013985, valley=0.0006918309954926372, slide=0.002511886414140463)\n\n\n\n\n\n\nlearn.fit_one_cycle(1, lr_max=2e-3)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.513179\n      0.441491\n      0.853377\n      0.781863\n      00:10\n    \n  \n\n\n\n\nlearn.unfreeze()\nlearn.lr_find(start_lr=1e-12, end_lr=2e-3, suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\nSuggestedLRs(minimum=9.98718086009376e-10, steep=1.3065426344993636e-11, valley=1.173113162167283e-09, slide=1.451419939257903e-05)\n\n\n\n\n\n\nlearn.fit_one_cycle(2, lr_max=slice(2e-5, 2e-4))\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.469480\n      0.379988\n      0.866779\n      0.806373\n      00:18\n    \n    \n      1\n      0.272824\n      0.324750\n      0.896194\n      0.852941\n      00:18\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=5)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      He said the foodservice pie business doesn 't fit the company's long-term growth strategy. \" The foodservice pie business does not fit our long-term growth strategy.\n      1\n      1\n    \n    \n      1\n      According to the Merchant Marine Ministry, the 37-year-old ship is registered to Alpha Shipping Inc. based in the Pacific Ocean nation of Marshall Islands. The Baltic Sky is a 37-year-old ship registered to Alpha Shipping Inc. based in the Pacific Ocean nation of Marshall Islands.\n      1\n      1\n    \n    \n      2\n      He said they lied on a sworn affidavit that requires them to list prior marriages. Morgenthau said the women, all U.S. citizens, lied on a sworn affidavit that requires them to list prior marriages.\n      1\n      1\n    \n    \n      3\n      Committee approval, expected today, would set the stage for debate on the Senate floor beginning Monday. That would clear the way for debate in the full Senate beginning on Monday.\n      1\n      1\n    \n    \n      4\n      Sources who knew of the bidding said last week that cable TV company Comcast Corp. was also looking at VUE. Late last week, sources told Reuters cable TV company Comcast Corp. CMCSA.O also was looking at buying VUE assets.\n      1\n      1\n    \n  \n\n\n\n\n\nEvaluate\nHow did we do?\n\nval_res = learn.validate()\n\n\n\n\n\nval_res_d = {\"loss\": val_res[0]}\nfor idx, m in enumerate(learn.metrics):\n    val_res_d[m.name] = val_res[idx + 1]\n\nval_res_d\n\n{'loss': 0.32474958896636963,\n 'f1_score': 0.8961937716262977,\n 'accuracy': 0.8529411554336548}\n\n\n\npreds, targs, losses = learn.get_preds(with_loss=True)\nprint(preds.shape, targs.shape, losses.shape)\nprint(losses.mean(), accuracy(preds, targs))\n\n\n\n\ntorch.Size([408, 2]) torch.Size([408]) torch.Size([408])\nTensorBase(0.3247) TensorBase(0.8529)\n\n\n\n\nInference\nLet’s do item inference on an example from our test dataset\n\nraw_test_df = pd.DataFrame(raw_datasets[test_ds_name], columns=list(raw_datasets[test_ds_name].features.keys()))\nraw_test_df.head(10)\n\n\n\n\n\n  \n    \n      \n      idx\n      label\n      sentence1\n      sentence2\n    \n  \n  \n    \n      0\n      0\n      1\n      PCCW 's chief operating officer , Mike Butcher , and Alex Arena , the chief financial officer , will report directly to Mr So .\n      Current Chief Operating Officer Mike Butcher and Group Chief Financial Officer Alex Arena will report to So .\n    \n    \n      1\n      1\n      1\n      The world 's two largest automakers said their U.S. sales declined more than predicted last month as a late summer sales frenzy caused more of an industry backlash than expected .\n      Domestic sales at both GM and No. 2 Ford Motor Co. declined more than predicted as a late summer sales frenzy prompted a larger-than-expected industry backlash .\n    \n    \n      2\n      2\n      1\n      According to the federal Centers for Disease Control and Prevention ( news - web sites ) , there were 19 reported cases of measles in the United States in 2002 .\n      The Centers for Disease Control and Prevention said there were 19 reported cases of measles in the United States in 2002 .\n    \n    \n      3\n      3\n      0\n      A tropical storm rapidly developed in the Gulf of Mexico Sunday and was expected to hit somewhere along the Texas or Louisiana coasts by Monday night .\n      A tropical storm rapidly developed in the Gulf of Mexico on Sunday and could have hurricane-force winds when it hits land somewhere along the Louisiana coast Monday night .\n    \n    \n      4\n      4\n      0\n      The company didn 't detail the costs of the replacement and repairs .\n      But company officials expect the costs of the replacement work to run into the millions of dollars .\n    \n    \n      5\n      5\n      1\n      The settling companies would also assign their possible claims against the underwriters to the investor plaintiffs , he added .\n      Under the agreement , the settling companies will also assign their potential claims against the underwriters to the investors , he added .\n    \n    \n      6\n      6\n      0\n      Air Commodore Quaife said the Hornets remained on three-minute alert throughout the operation .\n      Air Commodore John Quaife said the security operation was unprecedented .\n    \n    \n      7\n      7\n      1\n      A Washington County man may have the countys first human case of West Nile virus , the health department said Friday .\n      The countys first and only human case of West Nile this year was confirmed by health officials on Sept . 8 .\n    \n    \n      8\n      8\n      1\n      Moseley and a senior aide delivered their summary assessments to about 300 American and allied military officers on Thursday .\n      General Moseley and a senior aide presented their assessments at an internal briefing for American and allied military officers at Nellis Air Force Base in Nevada on Thursday .\n    \n    \n      9\n      9\n      0\n      The broader Standard & Poor 's 500 Index < .SPX > was 0.46 points lower , or 0.05 percent , at 997.02 .\n      The technology-laced Nasdaq Composite Index .IXIC was up 7.42 points , or 0.45 percent , at 1,653.44 .\n    \n  \n\n\n\n\n\nlearn.blurr_predict(raw_test_df.iloc[9].to_dict())\n\n[{'label': '0',\n  'score': 0.933854341506958,\n  'class_index': 0,\n  'class_labels': [0, 1],\n  'probs': [0.933854341506958, 0.06614568084478378]}]\n\n\nLet’s do batch inference on the entire test dataset\n\ntest_dl = dls.test_dl(raw_datasets[test_ds_name])\npreds = learn.get_preds(dl=test_dl)\npreds\n\n\n\n\n(tensor([[0.0061, 0.9939],\n         [0.0288, 0.9712],\n         [0.0032, 0.9968],\n         ...,\n         [0.0980, 0.9020],\n         [0.0041, 0.9959],\n         [0.0112, 0.9888]]),\n None)"
  },
  {
    "objectID": "examples.text.glue.html#high-level-api",
    "href": "examples.text.glue.html#high-level-api",
    "title": "GLUE classification tasks",
    "section": "High-level API",
    "text": "High-level API\nWith the high-level API, we can create our DataBlock, DataLoaders, and Blearner in one line of code\n\ndl_kwargs = {\"bs\": bsz, \"val_bs\": val_bsz}\nlearn_kwargs = {\"metrics\": task_metrics}\n\nlearn = BlearnerForSequenceClassification.from_data(\n    raw_df, pretrained_model_name, text_attr=task_inputs, label_attr=task_target, dl_kwargs=dl_kwargs, learner_kwargs=learn_kwargs\n)\n\n\nlearn.fit_one_cycle(1, lr_max=2e-3)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.516355\n      0.481201\n      0.857605\n      0.784314\n      00:09\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=5)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      He said the foodservice pie business doesn 't fit the company's long-term growth strategy. \" The foodservice pie business does not fit our long-term growth strategy.\n      1\n      1\n    \n    \n      1\n      On Saturday, a 149mph serve against Agassi equalled Rusedski's world record. On Saturday, Roddick equalled the world record with a 149 m.p.h. serve in beating Andre Agassi.\n      0\n      0\n    \n    \n      2\n      \" He may not have been there, \" the defence official said on Thursday. \" He may not have been there, \" said a defence official speaking on condition of anonymity.\n      1\n      1\n    \n    \n      3\n      Today in the US, the book - kept under wraps by its publishers, G. P. Putnam's Sons, since its inception - will appear in bookstores. Tomorrow the book, kept under wraps by G. P. Putnam's Sons since its inception, will appear in bookstores.\n      1\n      1\n    \n    \n      4\n      Gregory Parseghian, a former investment banker, was appointed chief executive. Greg Parseghian was appointed the new chief executive.\n      1\n      1"
  },
  {
    "objectID": "examples.text.glue.html#summary",
    "href": "examples.text.glue.html#summary",
    "title": "GLUE classification tasks",
    "section": "Summary",
    "text": "Summary\nThe general flow of this notebook was inspired by Zach Mueller’s “Text Classification with Transformers” example that can be found in the wonderful Walk With Fastai docs. Take a look there for another approach to working with fast.ai and Hugging Face on GLUE tasks."
  },
  {
    "objectID": "text.data.language_modeling.html",
    "href": "text.data.language_modeling.html",
    "title": "Data",
    "section": "",
    "text": "For this example, we’ll use the WIKITEXT_TINY dataset available from fastai. In addition to using the Datasets library from Hugging Face, fastai provides a lot of smaller datasets that are really useful when experimenting and/or in the early development of your training/validation/inference coding.\n\nwiki_path = untar_data(URLs.WIKITEXT_TINY)\nwiki_path.ls()\n\n(#2) [Path('/home/wgilliam/.fastai/data/wikitext-2/train.csv'),Path('/home/wgilliam/.fastai/data/wikitext-2/test.csv')]\n\n\n\ntrain_df = pd.read_csv(wiki_path / \"train.csv\", header=None)\nvalid_df = pd.read_csv(wiki_path / \"test.csv\", header=None)\n\nprint(len(train_df), len(valid_df))\ntrain_df.head()\n\n615 47\n\n\n\n\n\n\n  \n    \n      \n      0\n    \n  \n  \n    \n      0\n      \\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...\n    \n    \n      1\n      \\n = Big Boy ( song ) = \\n \\n \" Big Boy \" <unk> \" I 'm A Big Boy Now \" was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including \" Big Boy \" . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \\n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re...\n    \n    \n      2\n      \\n = The Remix ( Lady Gaga album ) = \\n \\n The Remix is a remix album by American recording artist Lady Gaga . Released in Japan on March 3 , 2010 , it contains remixes of the songs from her first studio album , The Fame ( 2008 ) , and her third extended play , The Fame Monster ( 2009 ) . A revised version of the track list was prepared for release in additional markets , beginning with Mexico on May 3 , 2010 . A number of recording artists have produced the songs , including Pet Shop Boys , Passion Pit and The Sound of Arrows . The remixed versions feature both uptempo and <unk> composit...\n    \n    \n      3\n      \\n = New Year 's Eve ( Up All Night ) = \\n \\n \" New Year 's Eve \" is the twelfth episode of the first season of the American comedy television series Up All Night . The episode originally aired on NBC in the United States on January 12 , 2012 . It was written by Erica <unk> and was directed by Beth McCarthy @-@ Miller . The episode also featured a guest appearance from Jason Lee as Chris and Reagan 's neighbor and Ava 's boyfriend , Kevin . \\n During Reagan ( Christina Applegate ) and Chris 's ( Will <unk> ) first New Year 's Eve game night , Reagan 's competitiveness comes out causing Ch...\n    \n    \n      4\n      \\n = Geopyxis carbonaria = \\n \\n Geopyxis carbonaria is a species of fungus in the genus Geopyxis , family <unk> . First described to science in 1805 , and given its current name in 1889 , the species is commonly known as the charcoal loving elf @-@ cup , dwarf <unk> cup , <unk> <unk> cup , or pixie cup . The small , <unk> @-@ shaped fruitbodies of the fungus are reddish @-@ brown with a whitish fringe and measure up to 2 cm ( 0 @.@ 8 in ) across . They have a short , tapered stalk . Fruitbodies are commonly found on soil where brush has recently been burned , sometimes in great numbers ....\n    \n  \n\n\n\n\n\ntrain_df[\"is_valid\"] = False\nvalid_df[\"is_valid\"] = True\n\ndf = pd.concat([train_df, valid_df])\ndf.head()\n\n\n\n\n\n  \n    \n      \n      0\n      is_valid\n    \n  \n  \n    \n      0\n      \\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...\n      False\n    \n    \n      1\n      \\n = Big Boy ( song ) = \\n \\n \" Big Boy \" <unk> \" I 'm A Big Boy Now \" was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including \" Big Boy \" . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \\n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re...\n      False\n    \n    \n      2\n      \\n = The Remix ( Lady Gaga album ) = \\n \\n The Remix is a remix album by American recording artist Lady Gaga . Released in Japan on March 3 , 2010 , it contains remixes of the songs from her first studio album , The Fame ( 2008 ) , and her third extended play , The Fame Monster ( 2009 ) . A revised version of the track list was prepared for release in additional markets , beginning with Mexico on May 3 , 2010 . A number of recording artists have produced the songs , including Pet Shop Boys , Passion Pit and The Sound of Arrows . The remixed versions feature both uptempo and <unk> composit...\n      False\n    \n    \n      3\n      \\n = New Year 's Eve ( Up All Night ) = \\n \\n \" New Year 's Eve \" is the twelfth episode of the first season of the American comedy television series Up All Night . The episode originally aired on NBC in the United States on January 12 , 2012 . It was written by Erica <unk> and was directed by Beth McCarthy @-@ Miller . The episode also featured a guest appearance from Jason Lee as Chris and Reagan 's neighbor and Ava 's boyfriend , Kevin . \\n During Reagan ( Christina Applegate ) and Chris 's ( Will <unk> ) first New Year 's Eve game night , Reagan 's competitiveness comes out causing Ch...\n      False\n    \n    \n      4\n      \\n = Geopyxis carbonaria = \\n \\n Geopyxis carbonaria is a species of fungus in the genus Geopyxis , family <unk> . First described to science in 1805 , and given its current name in 1889 , the species is commonly known as the charcoal loving elf @-@ cup , dwarf <unk> cup , <unk> <unk> cup , or pixie cup . The small , <unk> @-@ shaped fruitbodies of the fungus are reddish @-@ brown with a whitish fringe and measure up to 2 cm ( 0 @.@ 8 in ) across . They have a short , tapered stalk . Fruitbodies are commonly found on soil where brush has recently been burned , sometimes in great numbers ....\n      False\n    \n  \n\n\n\n\n\nmodel_cls = AutoModelForCausalLM\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"gpt2\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\n# some tokenizers like gpt and gpt2 do not have a pad token, so we add it here mainly for the purpose\n# of setting the \"labels\" key appropriately (see below)\nif hf_tokenizer.pad_token is None:\n    hf_tokenizer.pad_token = \"[PAD]\"\n\nhf_tokenizer.pad_token, hf_tokenizer.pad_token_id\n\nUsing pad_token, but it is not set yet.\n\n\n('[PAD]', 50256)\n\n\n\n# special_tokens_dict = {'additional_special_tokens': ['[C1]']}\n# num_added_toks = hf_tokenizer.add_special_tokens(special_tokens_dict)\n# hf_model.resize_token_embeddings(len(hf_tokenizer))"
  },
  {
    "objectID": "text.data.language_modeling.html#preprocessing",
    "href": "text.data.language_modeling.html#preprocessing",
    "title": "Data",
    "section": "Preprocessing",
    "text": "Preprocessing\nStarting with version 2.0, BLURR provides a language preprocessing class that can be used to preprocess DataFrames or Hugging Face Datasets for both causal and masked language modeling tasks.\n\nsource\n\nLMPreprocessor\n\n LMPreprocessor (hf_tokenizer:transformers.tokenization_utils_base.PreTrai\n                 nedTokenizerBase, batch_size:int=1000,\n                 chunk_size:Optional[int]=None,\n                 sep_token:Optional[str]=None, text_attr:str='text',\n                 is_valid_attr:Optional[str]='is_valid',\n                 tok_kwargs:dict={})\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nbatch_size\nint\n1000\nThe number of examples to process at a time\n\n\nchunk_size\nOptional\nNone\nHow big each chunk of text should be (default: hf_tokenizer.model_max_length)\n\n\nsep_token\nOptional\nNone\nHow to indicate the beginning on a new text example (default is hf_tokenizer.eos_token|sep_token\n\n\ntext_attr\nstr\ntext\nThe attribute holding the text\n\n\nis_valid_attr\nOptional\nis_valid\nThe attribute that should be created if your are processing individual training and validation\n\n\ndatasets into a single dataset, and will indicate to which each example is associated\n\n\n\n\n\ntok_kwargs\ndict\n{}\nTokenization kwargs that will be applied with calling the tokenizer\n\n\n\n\nUsing a DataFrame\n\npreprocessor = LMPreprocessor(hf_tokenizer, chunk_size=128, text_attr=0)\nproc_df = preprocessor.process_df(train_df, valid_df)\n\nprint(len(proc_df))\nproc_df.head(2)\n\n21330\n\n\n\n\n\n\n  \n    \n      \n      proc_0\n      is_valid\n    \n  \n  \n    \n      0\n      \\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only\n      False\n    \n    \n      1\n      above the relegation zone on goal difference , before a 17 @-@ match unbeaten run saw the team finish in seventh @-@ place in the 24 @-@ team 2013 – 14 Football League Two . This meant York qualified for the play @-@ offs , and they were eliminated in the semi @-@ final by Fleetwood Town . York were knocked out of the 2013 – 14 FA Cup , Football League Cup and Football League Trophy in their opening round matches . \\n 35 players made at least one appearance in nationally organised first @-@ team competition , and there were 12 different <unk> . Defender Ben Davies missed\n      False\n    \n  \n\n\n\n\n\n\nUsing a Hugging Face Dataset\n\n# TODO"
  },
  {
    "objectID": "text.data.language_modeling.html#lm-strategies",
    "href": "text.data.language_modeling.html#lm-strategies",
    "title": "Data",
    "section": "LM Strategies",
    "text": "LM Strategies\n\nsource\n\nLMType\n\n LMType (value, names=None, module=None, qualname=None, type=None,\n         start=1)\n\nUse this enum to indicate what kind of language model you are training\n\nsource\n\n\nBaseLMStrategy\n\n BaseLMStrategy (hf_tokenizer, ignore_token_id=-100)\n\nABC for various language modeling strategies (e.g., causal, BertMLM, WholeWordMLM, etc…)\nHere we include a BaseLMStrategy abstract class and several different strategies for building your inputs and targets for causal and masked language modeling tasks. With CLMs, the objective is to simply predict the next token, but with MLMs, a variety of masking strategies may be used (e.g., mask random tokens, mask random words, mask spans, etc…). A BertMLMStrategy is introduced below that follows the “mask random tokens” strategy used in the BERT paper, but users can create their own BaseLMStrategy subclass to support any masking strategy they desire.\n\nsource\n\n\nCausalLMStrategy\n\n CausalLMStrategy (hf_tokenizer, ignore_token_id=-100)\n\nFor next token prediction language modeling tasks, we want to use the CausalLMStrategy which makes the necessary changes in your inputs/targets for causal LMs\n\nsource\n\n\nBertMLMStrategy\n\n BertMLMStrategy (hf_tokenizer, ignore_token_id=-100)\n\nA masked language modeling strategy using the default BERT masking definition.\nFollows the masking strategy used in the BERT paper for random token masking"
  },
  {
    "objectID": "text.data.language_modeling.html#mid-level-api",
    "href": "text.data.language_modeling.html#mid-level-api",
    "title": "Data",
    "section": "Mid-level API",
    "text": "Mid-level API\n\nsource\n\nMLMTextInput\n\n MLMTextInput (x, **kwargs)\n\nThe base represenation of your inputs; used by the various fastai show methods\n\nsource\n\n\nCausalLMTextInput\n\n CausalLMTextInput (x, **kwargs)\n\nThe base represenation of your inputs; used by the various fastai show methods\nAgain, we define a custom classes for the @typedispatched methods to use so that we can override how both causal and masked language modeling inputs/targets are assembled, as well as, how the data is shown via methods like show_batch and show_results.\n\nsource\n\n\nLMBatchTokenizeTransform\n\n LMBatchTokenizeTransform (hf_arch:str,\n                           hf_config:transformers.configuration_utils.Pret\n                           rainedConfig, hf_tokenizer:transformers.tokeniz\n                           ation_utils_base.PreTrainedTokenizerBase, hf_mo\n                           del:transformers.modeling_utils.PreTrainedModel\n                           , include_labels:bool=True,\n                           ignore_token_id:int=-100,\n                           lm_strategy_cls:__main__.BaseLMStrategy=<class\n                           '__main__.CausalLMStrategy'>,\n                           max_length:int=None,\n                           padding:Union[bool,str]=True,\n                           truncation:Union[bool,str]=True,\n                           is_split_into_words:bool=False, tok_kwargs={},\n                           text_gen_kwargs={}, **kwargs)\n\nHandles everything you need to assemble a mini-batch of inputs and targets, as well as decode the dictionary produced as a byproduct of the tokenization process in the encodes method.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_arch\nstr\n\nThe abbreviation/name of your Hugging Face transformer architecture (e.b., bert, bart, etc..)\n\n\nhf_config\nPretrainedConfig\n\nA specific configuration instance you want to use\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nhf_model\nPreTrainedModel\n\nA Hugging Face model\n\n\ninclude_labels\nbool\nTrue\nTo control whether the “labels” are included in your inputs. If they are, the loss will be calculated in\n\n\nthe model’s forward function and you can simply use PreCalculatedLoss as your Learner’s loss function to use it\n\n\n\n\n\nignore_token_id\nint\n-100\nThe token ID that should be ignored when calculating the loss\n\n\nlm_strategy_cls\nBaseLMStrategy\nCausalLMStrategy\nThe language modeling strategy (or objective)\n\n\nmax_length\nint\nNone\nTo control the length of the padding/truncation. It can be an integer or None,\n\n\n\nin which case it will default to the maximum length the model can accept. If the model has no specific maximum input length, truncation/padding to max_length is deactivated. See Everything you always wanted to know about padding and truncation | | padding | Union | True | To control the padding applied to your hf_tokenizer during tokenization. If None, will default to False or 'do_not_pad'. See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation) | | truncation | Union | True | To controltruncationapplied to yourhf_tokenizerduring tokenization. If None, will default toFalseordo_not_truncate. See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation) | | is_split_into_words | bool | False | Theis_split_into_wordsargument applied to yourhf_tokenizerduring tokenization. Set this toTrueif your inputs are pre-tokenized (not numericalized) | | tok_kwargs | dict | {} | Any other keyword arguments you want included when using yourhf_tokenizer` to tokenize your inputs | | text_gen_kwargs | dict | {} | Any keyword arguments you want included when generated text See How to generate text | | kwargs | | | |\nOur LMBatchTokenizeTransform allows us to update the input’s labels and our targets appropriately given any language modeling task.\nThe labels argument allows you to forgo calculating the loss yourself by letting Hugging Face return it for you should you choose to do that. Padding tokens are set to -100 by default (e.g., CrossEntropyLossFlat().ignore_index) and prevent cross entropy loss from considering token prediction for tokens it should … i.e., the padding tokens. For more information on the meaning of this argument, see the Hugging Face glossary entry for “Labels”"
  },
  {
    "objectID": "text.data.language_modeling.html#examples",
    "href": "text.data.language_modeling.html#examples",
    "title": "Data",
    "section": "Examples",
    "text": "Examples\n\nUsing the mid-level API\n\nCausal LM\n\nStep 1: Get your Hugging Face objects.\n\nmodel_cls = AutoModelForCausalLM\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"gpt2\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\n# some tokenizers like gpt and gpt2 do not have a pad token, so we add it here mainly for the purpose\n# of setting the \"labels\" key appropriately (see below)\nif hf_tokenizer.pad_token is None:\n    hf_tokenizer.pad_token = \"[PAD]\"\n\nUsing pad_token, but it is not set yet.\n\n\n\n\nStep 2: Preprocess data\n\npreprocessor = LMPreprocessor(hf_tokenizer, chunk_size=128, text_attr=0)\nproc_df = preprocessor.process_df(train_df, valid_df)\n\nprint(len(proc_df))\nproc_df.head(2)\n\n21330\n\n\n\n\n\n\n  \n    \n      \n      proc_0\n      is_valid\n    \n  \n  \n    \n      0\n      \\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only\n      False\n    \n    \n      1\n      above the relegation zone on goal difference , before a 17 @-@ match unbeaten run saw the team finish in seventh @-@ place in the 24 @-@ team 2013 – 14 Football League Two . This meant York qualified for the play @-@ offs , and they were eliminated in the semi @-@ final by Fleetwood Town . York were knocked out of the 2013 – 14 FA Cup , Football League Cup and Football League Trophy in their opening round matches . \\n 35 players made at least one appearance in nationally organised first @-@ team competition , and there were 12 different <unk> . Defender Ben Davies missed\n      False\n    \n  \n\n\n\n\n\n\nStep 3: Create your DataBlock\n\nbatch_tok_tfm = LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=CausalLMStrategy)\n\nblocks = (TextBlock(batch_tokenize_tfm=batch_tok_tfm, input_return_type=CausalLMTextInput), noop)\n\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"proc_0\"), splitter=ColSplitter(col=\"is_valid\"))\n\n\n\nStep 4: Build your DataLoaders\n\ndls = dblock.dataloaders(proc_df, bs=4)\n\n\nb = dls.one_batch()\n\n\nb[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape\n\n(torch.Size([4, 129]), torch.Size([4, 129]), torch.Size([4, 129]))\n\n\n\nexplode_types(b)\n\n{tuple: [dict, torch.Tensor]}\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      ₹ 40 million ( US $ 590 @,@ 000 ) was spent solely on VFX for Magadheera. \\n \\n = = = <unk> = = = \\n \\n During the film's shoot at Ramoji Film City in late November 2008, a 500 square feet ( 46 m2 ) film can, containing two or three scenes, was discovered missing from Rainbow lab. The filmmakers filed a case at <unk> police station. Security personnel and film unit members searched, but failed to recover the reels. Rajamouli's unit said it was not important if the scenes from\n      �� 40 million ( US $ 590 @,@ 000 ) was spent solely on VFX for Magadheera. \\n \\n = = = <unk> = = = \\n \\n During the film's shoot at Ramoji Film City in late November 2008, a 500 square feet ( 46 m2 ) film can, containing two or three scenes, was discovered missing from Rainbow lab. The filmmakers filed a case at <unk> police station. Security personnel and film unit members searched, but failed to recover the reels. Rajamouli's unit said it was not important if the scenes from\n    \n    \n      1\n      ederation. Described as \" the most organized of the Northern Arabian tribes \", at the peak of its power in the 6th century BCE it controlled a large region between the Persian Gulf and the Sinai Peninsula. \\n Biblical tradition holds that the Qedarites are named for Qedar, the second son of Ishmael, mentioned in the Bible's books of Genesis ( 25 : 13 ) and 1 Chronicles ( 1 : 29 ), where there are also frequent references to Qedar as a tribe. The earliest <unk> inscriptions discovered by archaeol\n      eration. Described as \" the most organized of the Northern Arabian tribes \", at the peak of its power in the 6th century BCE it controlled a large region between the Persian Gulf and the Sinai Peninsula. \\n Biblical tradition holds that the Qedarites are named for Qedar, the second son of Ishmael, mentioned in the Bible's books of Genesis ( 25 : 13 ) and 1 Chronicles ( 1 : 29 ), where there are also frequent references to Qedar as a tribe. The earliest <unk> inscriptions discovered by archaeologi\n    \n  \n\n\n\n\n\n\nMasked LM\n\nStep 1: Get your Hugging Face objects.\n\nmodel_cls = AutoModelForMaskedLM\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"bert-base-uncased\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\n# some tokenizers like gpt and gpt2 do not have a pad token, so we add it here mainly for the purpose\n# of setting the \"labels\" key appropriately (see below)\nif hf_tokenizer.pad_token is None:\n    hf_tokenizer.pad_token = \"[PAD]\"\n\n\n\nStep 2: Preprocess data\n\npreprocessor = LMPreprocessor(hf_tokenizer, chunk_size=128, text_attr=0)\nproc_df = preprocessor.process_df(train_df, valid_df)\n\nprint(len(proc_df))\nproc_df.head(2)\n\nUsing eos_token, but it is not set yet.\n\n\n21227\n\n\n\n\n\n\n  \n    \n      \n      proc_0\n      is_valid\n    \n  \n  \n    \n      0\n      \\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...\n      False\n    \n    \n      1\n      goal difference , before a 17 @-@ match unbeaten run saw the team finish in seventh @-@ place in the 24 @-@ team 2013 – 14 Football League Two . This meant York qualified for the play @-@ offs , and they were eliminated in the semi @-@ final by Fleetwood Town . York were knocked out of the 2013 – 14 FA Cup , Football League Cup and Football League Trophy in their opening round matches . \\n 35 players made at least one appearance in nationally organised first @-@ team competition , and there were 12 different <unk> . Defender Ben Davies missed only five of the fifty @\n      False\n    \n  \n\n\n\n\n\n\nStep 3: Create your DataBlock\n\nbatch_tok_tfm = LMBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, lm_strategy_cls=BertMLMStrategy)\n\nblocks = (TextBlock(batch_tokenize_tfm=batch_tok_tfm, input_return_type=MLMTextInput), noop)\n\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"proc_0\"), splitter=ColSplitter(col=\"is_valid\"))\n\n\n\nStep 4: Build your DataLoaders\n\ndls = dblock.dataloaders(proc_df, bs=4)\n\n\nb = dls.one_batch()\nb[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape\n\n(torch.Size([4, 128]), torch.Size([4, 128]), torch.Size([4, 128]))\n\n\n\nb[0][\"input_ids\"][0][:20], b[0][\"labels\"][0][:20], b[1][0][:20]\n\n(tensor([ 101, 2003, 2098, 2340,  103, 2101,  103, 1026, 4895,  103, 1028, 1026,\n          103, 2243, 1028, 1998, 1996, 2674, 2736, 1037], device='cuda:1'),\n tensor([-100, -100, -100, -100, 2781, -100, 2083, -100, -100, 2243, -100, -100,\n         4895, -100, 1028, -100, -100, -100, -100, -100], device='cuda:1'),\n tensor([-100, -100, -100, -100, 2781, -100, 2083, -100, -100, 2243, -100, -100,\n         4895, -100, 1028, -100, -100, -100, -100, -100], device='cuda:1'))\n\n\n\nexplode_types(b)\n\n{tuple: [dict, torch.Tensor]}\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2, trunc_at=250)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      [##las] ##ed 11 minutes [MASK] through < [un] ##k > [MASK] un ##k > and the match finished a 1 [MASK] 1 [MASK] . york [were] knocked out of the fa cup after losing 3 – 2 at home to bristol rovers in a first round [MASK] ; the [MASK] were 3 [–] 0 up by 50 @ - @ minutes before fletcher pulled two back [MASK] york with a penalty [MASK] a long @ - @ range strike . defender keith [MASK] , of cheltenham , and [MASK] nick pope [MASK] of charlton athletic , were signed on loan until january 2014 . they [MASK] played in york ' s first league [MASK] [MASK] four weeks , 2 – 1 [MASK] , to southend united\n      [is] ##ed 11 minutes [later] through < [un] ##k > [<] un ##k > and the match finished a 1 [–] 1 [draw] . york [were] knocked out of the fa cup after losing 3 – 2 at home to bristol rovers in a first round [replay] ; the [visitors] were 3 [–] 0 up by 50 @ - @ minutes before fletcher pulled two back [for] york with a penalty [and] a long @ - @ range strike . defender keith [lowe] , of cheltenham , and [goalkeeper] nick pope [,] of charlton athletic , were signed on loan until january 2014 . they [both] played in york ' s first league [defeat] [in] four weeks , 2 – 1 [away] , to southend united\n    \n    \n      1\n      [MASK] ##on . [MASK] 134 ##5 [MASK] iii was planning a [MASK] assault on france . a three [MASK] [MASK] [MASK] < un ##k > attack would have the earl of northampton attacking from brittany [,] the [MASK] himself from flanders , while gr [bubble] ##mont was dispatched [MASK] < un ##k > to prepare a campaign in the south [MASK] moving rapidly through the country , he confronted the [comte] d ’ [MASK] at < un ##k > [on] [MASK] october and there achieved a victory described as \" [MASK] greatest single achievement of lancaster ' s entire military career \" . the ransom from the prisoners has been [MASK] at £ 50 @ , @ 000 . [MASK] next year , while edward was\n      [ign] ##on . [in] 134 ##5 [edward] iii was planning a [major] assault on france . a three [@] [-] [@] < un ##k > attack would have the earl of northampton attacking from brittany [,] the [king] himself from flanders , while gr [##os] ##mont was dispatched [to] < un ##k > to prepare a campaign in the south [.] moving rapidly through the country , he confronted the [comte] d ’ [isle] at < un ##k > [on] [21] october and there achieved a victory described as \" [the] greatest single achievement of lancaster ' s entire military career \" . the ransom from the prisoners has been [estimated] at £ 50 @ , @ 000 . [the] next year , while edward was"
  },
  {
    "objectID": "callbacks.html",
    "href": "callbacks.html",
    "title": "callbacks",
    "section": "",
    "text": "Downloading builder script:   0%|          | 0.00/1.72k [00:00<?, ?B/s]Downloading builder script: 4.50kB [00:00, 4.65MB/s]                   \nDownloading extra modules:   0%|          | 0.00/1.12k [00:00<?, ?B/s]Downloading extra modules: 3.31kB [00:00, 3.27MB/s]"
  },
  {
    "objectID": "callbacks.html#gradient-checkpointing",
    "href": "callbacks.html#gradient-checkpointing",
    "title": "callbacks",
    "section": "Gradient Checkpointing",
    "text": "Gradient Checkpointing\n\nsource\n\nCheckpointingNotSupported\n\n CheckpointingNotSupported (msg='Model does not support gradient\n                            checkpointing.')\n\nCommon base class for all non-exit exceptions.\n\nsource\n\n\nGradientCheckpointing\n\n GradientCheckpointing (after_create=None, before_fit=None,\n                        before_epoch=None, before_train=None,\n                        before_batch=None, after_pred=None,\n                        after_loss=None, before_backward=None,\n                        after_cancel_backward=None, after_backward=None,\n                        before_step=None, after_cancel_step=None,\n                        after_step=None, after_cancel_batch=None,\n                        after_batch=None, after_cancel_train=None,\n                        after_train=None, before_validate=None,\n                        after_cancel_validate=None, after_validate=None,\n                        after_cancel_epoch=None, after_epoch=None,\n                        after_cancel_fit=None, after_fit=None)\n\nA fastai callback to enable gradient checkpointing for compatible HuggingFace models.\nWe’ll use a minified version of the IMDB dataset for testing\n\npath = untar_data(URLs.IMDB_SAMPLE)\nmodel_path = Path(\"models\")\nimdb_df = pd.read_csv(path / \"texts.csv\")\n\nLet’s look at memory consumption without GradientCheckpointing\n\nnvidia_smi_idx = 2\n\n\ndef gpu_memory(device_idx=nvidia_smi_idx):\n    return GPU.getGPUs()[device_idx].memoryUsed\n\n\nlearn = BlearnerForSequenceClassification.from_data(imdb_df, \"roberta-large\", dl_kwargs={\"bs\": 4})\n\nlearn.fit_one_cycle(1, lr_max=1e-3)\n\nbase_mem = gpu_memory()\nprint(f\"{base_mem} MBs used.\")\n\nreset_memory(learn)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.341047\n      0.237419\n      0.918033\n      0.925000\n      00:57\n    \n  \n\n\n\n9499.0 MBs used.\n\n\nLet’s look at memory consumption with GradientCheckpointing\n\nlearn = BlearnerForSequenceClassification.from_data(imdb_df, \"roberta-large\", dl_kwargs={\"bs\": 4})\n\nlearn.fit_one_cycle(1, lr_max=1e-3, cbs=[GradientCheckpointing()])\n\ncheck_mem = gpu_memory()\nprint(f\"{check_mem} MBs used.\")\n\ntest_eq(base_mem > check_mem, True)\nreset_memory(learn)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.299704\n      0.222900\n      0.920455\n      0.930000\n      01:22\n    \n  \n\n\n\n4297.0 MBs used."
  },
  {
    "objectID": "text.utils.html",
    "href": "text.utils.html",
    "title": "utils",
    "section": "",
    "text": "What we're running with at the time this documentation was generated:\ntorch: 1.9.0+cu102\nfastai: 2.7.9\ntransformers: 4.21.2\nsource"
  },
  {
    "objectID": "text.utils.html#get_hf_objects",
    "href": "text.utils.html#get_hf_objects",
    "title": "utils",
    "section": "get_hf_objects",
    "text": "get_hf_objects\n\n get_hf_objects (pretrained_model_name_or_path:str|os.PathLike,\n                 model_cls:transformers.modeling_utils.PreTrainedModel, co\n                 nfig:transformers.configuration_utils.PretrainedConfig|st\n                 r|os.PathLike=None, tokenizer_cls:transformers.tokenizati\n                 on_utils_base.PreTrainedTokenizerBase=None,\n                 config_kwargs:dict={}, tokenizer_kwargs:dict={},\n                 model_kwargs:dict={}, cache_dir:str|os.PathLike=None)\n\nGiven at minimum a pretrained_model_name_or_path and model_cls (such asAutoModelForSequenceClassification”), this method returns all the Hugging Face objects you need to train a model using Blurr"
  },
  {
    "objectID": "text.utils.html#singleton-object-at-0x7f1898457e50",
    "href": "text.utils.html#singleton-object-at-0x7f1898457e50",
    "title": "utils",
    "section": "Singleton object at 0x7f1898457e50>",
    "text": "Singleton object at 0x7f1898457e50>\n\n Singleton object at 0x7f1898457e50> (*args, **kwargs)\n\nBlurrText is a Singleton (there exists only one instance, and the same instance is returned upon subsequent instantiation requests). You can get at via the NLP constant below.\n\nNLP = BlurrText()\nNLP2 = BlurrText()\ntest_eq(NLP, NLP2)\n\n… the task\n\n# show_doc(BlurrText(BlurrText).get_tasks)\n\n\nprint(NLP.get_tasks())\nprint(\"\")\nprint(NLP.get_tasks(\"bart\"))\n\n['AudioFrameClassification', 'CTC', 'CausalImageModeling', 'CausalLM', 'Classification', 'ConditionalGeneration', 'DepthEstimation', 'EntityClassification', 'EntityPairClassification', 'EntitySpanClassification', 'Generation', 'ImageAndTextRetrieval', 'ImageClassification', 'ImageClassificationConvProcessing', 'ImageClassificationFourier', 'ImageClassificationLearned', 'ImagesAndTextClassification', 'InstanceSegmentation', 'LMHead', 'LMHeadModel', 'MaskedImageModeling', 'MaskedLM', 'MultimodalAutoencoding', 'MultipleChoice', 'NextSentencePrediction', 'ObjectDetection', 'OpenQA', 'OpticalFlow', 'PreTraining', 'QuestionAnswering', 'QuestionAnsweringSimple', 'RegionToPhraseAlignment', 'SemanticSegmentation', 'SequenceClassification', 'Teacher', 'TokenClassification', 'VisualReasoning', 'XVector', 'merLayer', 'merModel', 'merPreTrainedModel']\n\n['CausalLM', 'ConditionalGeneration', 'QuestionAnswering', 'SequenceClassification']\n\n\n… the architecture\n\n# show_doc(BlurrText(BlurrText).get_architectures)\n\n\nprint(NLP.get_architectures())\n\n['albert', 'bart', 'barthez', 'bartpho', 'beit', 'bert', 'bert_generation', 'bert_japanese', 'bertweet', 'big_bird', 'bigbird_pegasus', 'blenderbot', 'blenderbot_small', 'bloom', 'byt5', 'camembert', 'canine', 'clip', 'codegen', 'convbert', 'convnext', 'cpm', 'ctrl', 'cvt', 'data2vec_audio', 'data2vec_text', 'data2vec_vision', 'deberta', 'deberta_v2', 'decision_transformer', 'deit', 'detr', 'distilbert', 'dpr', 'dpt', 'electra', 'encoder_decoder', 'flaubert', 'flava', 'fnet', 'fsmt', 'funnel', 'glpn', 'gpt2', 'gpt_neo', 'gpt_neox', 'gptj', 'groupvit', 'herbert', 'hubert', 'ibert', 'imagegpt', 'layoutlm', 'layoutlmv2', 'layoutlmv3', 'layoutxlm', 'led', 'levit', 'longformer', 'longt5', 'luke', 'lxmert', 'm2m_100', 'marian', 'maskformer', 'mbart', 'mbart50', 'mctct', 'megatron_bert', 'mluke', 'mmbt', 'mobilebert', 'mobilevit', 'mpnet', 'mt5', 'mvp', 'nezha', 'nllb', 'nystromformer', 'openai', 'opt', 'owlvit', 'pegasus', 'perceiver', 'phobert', 'plbart', 'poolformer', 'prophetnet', 'qdqbert', 'rag', 'realm', 'reformer', 'regnet', 'rembert', 'resnet', 'retribert', 'roberta', 'roformer', 'segformer', 'sew', 'sew_d', 'speech_encoder_decoder', 'speech_to_text', 'speech_to_text_2', 'splinter', 'squeezebert', 'swin', 't5', 'tapas', 'tapex', 'trajectory_transformer', 'transfo_xl', 'trocr', 'unispeech', 'unispeech_sat', 'van', 'vilt', 'vision_encoder_decoder', 'vision_text_dual_encoder', 'visual_bert', 'vit', 'vit_mae', 'wav2vec2', 'wav2vec2_conformer', 'wav2vec2_phoneme', 'wavlm', 'xglm', 'xlm', 'xlm_prophetnet', 'xlm_roberta', 'xlm_roberta_xl', 'xlnet', 'yolos', 'yoso']\n\n\n\n# show_doc(BlurrText(BlurrText).get_model_architecture)\n\n\nprint(NLP.get_model_architecture(\"RobertaForSequenceClassification\"))\n\nroberta\n\n\n… and lastly the models (optionally for a given task and/or architecture)\n\n# show_doc(BlurrText(BlurrText).get_models)\n\n\nprint(L(NLP.get_models())[:5])\n\n['AdaptiveEmbedding', 'AlbertForMaskedLM', 'AlbertForMultipleChoice', 'AlbertForPreTraining', 'AlbertForQuestionAnswering']\n\n\n\nprint(NLP.get_models(arch=\"bert\")[:5])\n\n['BertForMaskedLM', 'BertForMultipleChoice', 'BertForNextSentencePrediction', 'BertForPreTraining', 'BertForQuestionAnswering']\n\n\n\nprint(NLP.get_models(task=\"TokenClassification\")[:5])\n\n['AlbertForTokenClassification', 'BertForTokenClassification', 'BigBirdForTokenClassification', 'BloomForTokenClassification', 'CamembertForTokenClassification']\n\n\n\nprint(NLP.get_models(arch=\"bert\", task=\"TokenClassification\"))\n\n['BertForTokenClassification']"
  },
  {
    "objectID": "text.utils.html#to-get-all-your-hugging-face-objects-arch-config-tokenizer-and-model",
    "href": "text.utils.html#to-get-all-your-hugging-face-objects-arch-config-tokenizer-and-model",
    "title": "utils",
    "section": "To get all your Hugging Face objects (arch, config, tokenizer, and model)",
    "text": "To get all your Hugging Face objects (arch, config, tokenizer, and model)\nHow to use:\n\nfrom transformers import AutoModelForMaskedLM\n\nhf_logging.set_verbosity_error()\n\narch, config, tokenizer, model = get_hf_objects(\"bert-base-cased-finetuned-mrpc\", model_cls=AutoModelForMaskedLM)\n\nprint(arch)\nprint(type(config))\nprint(type(tokenizer))\nprint(type(model))\n\nbert\n<class 'transformers.models.bert.configuration_bert.BertConfig'>\n<class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>\n<class 'transformers.models.bert.modeling_bert.BertForMaskedLM'>\n\n\nDownloading config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]Downloading config.json: 100%|##########| 433/433 [00:00<00:00, 362kB/s]\nDownloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]Downloading tokenizer_config.json: 100%|##########| 29.0/29.0 [00:00<00:00, 30.9kB/s]\nDownloading vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]Downloading vocab.txt:  36%|###5      | 75.0k/208k [00:00<00:00, 644kB/s]Downloading vocab.txt: 100%|##########| 208k/208k [00:00<00:00, 1.32MB/s]\nDownloading tokenizer.json:   0%|          | 0.00/426k [00:00<?, ?B/s]Downloading tokenizer.json:  20%|#9        | 84.0k/426k [00:00<00:00, 734kB/s]Downloading tokenizer.json: 100%|##########| 426k/426k [00:00<00:00, 2.19MB/s]\nDownloading pytorch_model.bin:   0%|          | 0.00/413M [00:00<?, ?B/s]Downloading pytorch_model.bin:   0%|          | 1.57M/413M [00:00<00:26, 16.2MB/s]Downloading pytorch_model.bin:   1%|1         | 5.05M/413M [00:00<00:15, 28.0MB/s]Downloading pytorch_model.bin:   3%|2         | 10.4M/413M [00:00<00:10, 41.0MB/s]Downloading pytorch_model.bin:   5%|4         | 19.1M/413M [00:00<00:06, 60.5MB/s]Downloading pytorch_model.bin:   7%|6         | 28.9M/413M [00:00<00:05, 75.7MB/s]Downloading pytorch_model.bin:   9%|8         | 36.1M/413M [00:00<00:05, 70.7MB/s]Downloading pytorch_model.bin:  10%|#         | 42.9M/413M [00:00<00:05, 68.8MB/s]Downloading pytorch_model.bin:  12%|#1        | 49.5M/413M [00:00<00:06, 57.6MB/s]Downloading pytorch_model.bin:  14%|#3        | 56.0M/413M [00:01<00:06, 58.4MB/s]Downloading pytorch_model.bin:  15%|#5        | 64.0M/413M [00:01<00:06, 60.7MB/s]Downloading pytorch_model.bin:  17%|#7        | 72.0M/413M [00:01<00:06, 55.4MB/s]Downloading pytorch_model.bin:  19%|#8        | 78.3M/413M [00:01<00:06, 55.9MB/s]Downloading pytorch_model.bin:  20%|##        | 83.8M/413M [00:01<00:06, 49.6MB/s]Downloading pytorch_model.bin:  21%|##1       | 88.7M/413M [00:01<00:07, 42.6MB/s]Downloading pytorch_model.bin:  23%|##3       | 96.0M/413M [00:01<00:07, 43.8MB/s]Downloading pytorch_model.bin:  25%|##4       | 103M/413M [00:02<00:08, 38.5MB/s] Downloading pytorch_model.bin:  26%|##5       | 107M/413M [00:02<00:08, 37.0MB/s]Downloading pytorch_model.bin:  27%|##7       | 112M/413M [00:02<00:08, 38.7MB/s]Downloading pytorch_model.bin:  29%|##9       | 120M/413M [00:02<00:06, 44.6MB/s]Downloading pytorch_model.bin:  31%|###       | 128M/413M [00:02<00:06, 49.4MB/s]Downloading pytorch_model.bin:  33%|###2      | 136M/413M [00:02<00:05, 54.9MB/s]Downloading pytorch_model.bin:  35%|###4      | 144M/413M [00:02<00:04, 58.9MB/s]Downloading pytorch_model.bin:  37%|###6      | 152M/413M [00:03<00:04, 59.1MB/s]Downloading pytorch_model.bin:  39%|###8      | 160M/413M [00:03<00:04, 59.0MB/s]Downloading pytorch_model.bin:  41%|####      | 168M/413M [00:03<00:04, 56.8MB/s]Downloading pytorch_model.bin:  42%|####2     | 175M/413M [00:03<00:04, 61.3MB/s]Downloading pytorch_model.bin:  44%|####3     | 181M/413M [00:03<00:04, 54.3MB/s]Downloading pytorch_model.bin:  45%|####5     | 187M/413M [00:03<00:05, 40.8MB/s]Downloading pytorch_model.bin:  46%|####6     | 192M/413M [00:04<00:05, 40.3MB/s]Downloading pytorch_model.bin:  48%|####8     | 200M/413M [00:04<00:05, 44.0MB/s]Downloading pytorch_model.bin:  50%|#####     | 208M/413M [00:04<00:04, 52.4MB/s]Downloading pytorch_model.bin:  52%|#####1    | 214M/413M [00:04<00:04, 51.0MB/s]Downloading pytorch_model.bin:  53%|#####3    | 220M/413M [00:04<00:05, 39.9MB/s]Downloading pytorch_model.bin:  54%|#####4    | 224M/413M [00:04<00:05, 36.7MB/s]Downloading pytorch_model.bin:  55%|#####5    | 228M/413M [00:04<00:05, 36.4MB/s]Downloading pytorch_model.bin:  56%|#####6    | 232M/413M [00:05<00:05, 35.9MB/s]Downloading pytorch_model.bin:  58%|#####7    | 238M/413M [00:05<00:04, 40.8MB/s]Downloading pytorch_model.bin:  59%|#####8    | 242M/413M [00:05<00:04, 37.6MB/s]Downloading pytorch_model.bin:  60%|######    | 248M/413M [00:05<00:04, 35.1MB/s]Downloading pytorch_model.bin:  62%|######1   | 256M/413M [00:05<00:04, 38.6MB/s]Downloading pytorch_model.bin:  64%|######3   | 264M/413M [00:05<00:03, 44.7MB/s]Downloading pytorch_model.bin:  66%|######5   | 272M/413M [00:05<00:02, 51.7MB/s]Downloading pytorch_model.bin:  68%|######7   | 280M/413M [00:06<00:02, 56.2MB/s]Downloading pytorch_model.bin:  70%|######9   | 288M/413M [00:06<00:02, 50.4MB/s]Downloading pytorch_model.bin:  72%|#######1  | 296M/413M [00:06<00:02, 51.5MB/s]Downloading pytorch_model.bin:  73%|#######3  | 302M/413M [00:06<00:02, 52.0MB/s]Downloading pytorch_model.bin:  74%|#######4  | 307M/413M [00:06<00:02, 49.0MB/s]Downloading pytorch_model.bin:  76%|#######5  | 314M/413M [00:06<00:01, 53.8MB/s]Downloading pytorch_model.bin:  77%|#######7  | 319M/413M [00:06<00:01, 49.4MB/s]Downloading pytorch_model.bin:  78%|#######8  | 324M/413M [00:07<00:02, 39.0MB/s]Downloading pytorch_model.bin:  79%|#######9  | 328M/413M [00:07<00:02, 37.0MB/s]Downloading pytorch_model.bin:  81%|########1 | 336M/413M [00:07<00:02, 39.8MB/s]Downloading pytorch_model.bin:  83%|########2 | 342M/413M [00:07<00:01, 45.4MB/s]Downloading pytorch_model.bin:  84%|########3 | 347M/413M [00:07<00:01, 43.4MB/s]Downloading pytorch_model.bin:  85%|########5 | 352M/413M [00:07<00:01, 46.1MB/s]Downloading pytorch_model.bin:  87%|########6 | 359M/413M [00:07<00:01, 53.0MB/s]Downloading pytorch_model.bin:  88%|########8 | 364M/413M [00:07<00:01, 49.3MB/s]Downloading pytorch_model.bin:  90%|########9 | 370M/413M [00:08<00:00, 51.4MB/s]Downloading pytorch_model.bin:  91%|######### | 376M/413M [00:08<00:00, 48.3MB/s]Downloading pytorch_model.bin:  93%|#########2| 384M/413M [00:08<00:00, 43.6MB/s]Downloading pytorch_model.bin:  94%|#########3| 388M/413M [00:08<00:00, 43.5MB/s]Downloading pytorch_model.bin:  95%|#########5| 393M/413M [00:08<00:00, 40.4MB/s]Downloading pytorch_model.bin:  96%|#########6| 399M/413M [00:08<00:00, 40.7MB/s]Downloading pytorch_model.bin:  97%|#########7| 403M/413M [00:08<00:00, 38.1MB/s]Downloading pytorch_model.bin:  99%|#########9| 411M/413M [00:09<00:00, 49.6MB/s]Downloading pytorch_model.bin: 100%|##########| 413M/413M [00:09<00:00, 47.5MB/s]\n\n\n\nfrom transformers import AutoModelForQuestionAnswering\n\nhf_logging.set_verbosity_error()\n\narch, config, tokenizer, model = get_hf_objects(\"fmikaelian/flaubert-base-uncased-squad\", model_cls=AutoModelForQuestionAnswering)\n\nprint(arch)\nprint(type(config))\nprint(type(tokenizer))\nprint(type(model))\n\nflaubert\n<class 'transformers.models.flaubert.configuration_flaubert.FlaubertConfig'>\n<class 'transformers.models.flaubert.tokenization_flaubert.FlaubertTokenizer'>\n<class 'transformers.models.flaubert.modeling_flaubert.FlaubertForQuestionAnsweringSimple'>\n\n\nDownloading config.json:   0%|          | 0.00/1.49k [00:00<?, ?B/s]Downloading config.json: 100%|##########| 1.49k/1.49k [00:00<00:00, 1.58MB/s]\nDownloading tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]Downloading tokenizer_config.json: 100%|##########| 366/366 [00:00<00:00, 321kB/s]\nDownloading vocab.json:   0%|          | 0.00/1.26M [00:00<?, ?B/s]Downloading vocab.json:   7%|6         | 84.0k/1.26M [00:00<00:01, 732kB/s]Downloading vocab.json:  46%|####5     | 588k/1.26M [00:00<00:00, 2.87MB/s]Downloading vocab.json: 100%|##########| 1.26M/1.26M [00:00<00:00, 4.74MB/s]\nDownloading merges.txt:   0%|          | 0.00/584k [00:00<?, ?B/s]Downloading merges.txt:  14%|#4        | 84.0k/584k [00:00<00:00, 738kB/s]Downloading merges.txt:  94%|#########3| 548k/584k [00:00<00:00, 2.68MB/s]Downloading merges.txt: 100%|##########| 584k/584k [00:00<00:00, 2.53MB/s]\nDownloading special_tokens_map.json:   0%|          | 0.00/305 [00:00<?, ?B/s]Downloading special_tokens_map.json: 100%|##########| 305/305 [00:00<00:00, 259kB/s]\nDownloading pytorch_model.bin:   0%|          | 0.00/533M [00:00<?, ?B/s]Downloading pytorch_model.bin:   1%|          | 2.83M/533M [00:00<00:18, 29.7MB/s]Downloading pytorch_model.bin:   2%|2         | 11.4M/533M [00:00<00:08, 64.9MB/s]Downloading pytorch_model.bin:   4%|3         | 20.2M/533M [00:00<00:06, 77.3MB/s]Downloading pytorch_model.bin:   5%|5         | 29.0M/533M [00:00<00:06, 83.6MB/s]Downloading pytorch_model.bin:   7%|7         | 38.0M/533M [00:00<00:05, 87.2MB/s]Downloading pytorch_model.bin:   9%|8         | 46.8M/533M [00:00<00:05, 89.0MB/s]Downloading pytorch_model.bin:  10%|#         | 55.7M/533M [00:00<00:05, 90.4MB/s]Downloading pytorch_model.bin:  12%|#2        | 64.5M/533M [00:00<00:05, 91.0MB/s]Downloading pytorch_model.bin:  14%|#3        | 73.4M/533M [00:00<00:05, 91.8MB/s]Downloading pytorch_model.bin:  15%|#5        | 82.2M/533M [00:01<00:05, 91.9MB/s]Downloading pytorch_model.bin:  17%|#7        | 91.0M/533M [00:01<00:05, 92.1MB/s]Downloading pytorch_model.bin:  19%|#8        | 99.8M/533M [00:01<00:04, 92.2MB/s]Downloading pytorch_model.bin:  20%|##        | 109M/533M [00:01<00:04, 92.1MB/s] Downloading pytorch_model.bin:  22%|##2       | 117M/533M [00:01<00:04, 92.1MB/s]Downloading pytorch_model.bin:  24%|##3       | 126M/533M [00:01<00:04, 92.2MB/s]Downloading pytorch_model.bin:  25%|##5       | 135M/533M [00:01<00:04, 92.5MB/s]Downloading pytorch_model.bin:  27%|##7       | 144M/533M [00:01<00:04, 92.8MB/s]Downloading pytorch_model.bin:  29%|##8       | 153M/533M [00:01<00:04, 92.9MB/s]Downloading pytorch_model.bin:  30%|###       | 162M/533M [00:01<00:04, 92.9MB/s]Downloading pytorch_model.bin:  32%|###2      | 171M/533M [00:02<00:04, 93.0MB/s]Downloading pytorch_model.bin:  34%|###3      | 180M/533M [00:02<00:03, 93.3MB/s]Downloading pytorch_model.bin:  35%|###5      | 189M/533M [00:02<00:03, 93.3MB/s]Downloading pytorch_model.bin:  37%|###7      | 197M/533M [00:02<00:03, 93.2MB/s]Downloading pytorch_model.bin:  39%|###8      | 206M/533M [00:02<00:03, 92.9MB/s]Downloading pytorch_model.bin:  40%|####      | 215M/533M [00:02<00:03, 92.5MB/s]Downloading pytorch_model.bin:  42%|####2     | 224M/533M [00:02<00:03, 92.6MB/s]Downloading pytorch_model.bin:  44%|####3     | 233M/533M [00:02<00:03, 92.4MB/s]Downloading pytorch_model.bin:  45%|####5     | 242M/533M [00:02<00:03, 92.9MB/s]Downloading pytorch_model.bin:  47%|####7     | 251M/533M [00:02<00:03, 93.1MB/s]Downloading pytorch_model.bin:  49%|####8     | 260M/533M [00:03<00:03, 92.9MB/s]Downloading pytorch_model.bin:  50%|#####     | 269M/533M [00:03<00:02, 92.6MB/s]Downloading pytorch_model.bin:  52%|#####2    | 277M/533M [00:03<00:02, 92.8MB/s]Downloading pytorch_model.bin:  54%|#####3    | 286M/533M [00:03<00:02, 93.2MB/s]Downloading pytorch_model.bin:  55%|#####5    | 295M/533M [00:03<00:02, 93.4MB/s]Downloading pytorch_model.bin:  57%|#####7    | 304M/533M [00:03<00:02, 93.4MB/s]Downloading pytorch_model.bin:  59%|#####8    | 313M/533M [00:03<00:02, 93.4MB/s]Downloading pytorch_model.bin:  60%|######    | 322M/533M [00:03<00:02, 93.0MB/s]Downloading pytorch_model.bin:  62%|######2   | 331M/533M [00:03<00:02, 93.1MB/s]Downloading pytorch_model.bin:  64%|######3   | 340M/533M [00:03<00:02, 92.7MB/s]Downloading pytorch_model.bin:  65%|######5   | 349M/533M [00:04<00:02, 93.5MB/s]Downloading pytorch_model.bin:  67%|######7   | 358M/533M [00:04<00:01, 92.3MB/s]Downloading pytorch_model.bin:  69%|######8   | 367M/533M [00:04<00:01, 91.8MB/s]Downloading pytorch_model.bin:  70%|#######   | 376M/533M [00:04<00:01, 92.0MB/s]Downloading pytorch_model.bin:  72%|#######2  | 384M/533M [00:04<00:01, 92.1MB/s]Downloading pytorch_model.bin:  74%|#######3  | 393M/533M [00:04<00:01, 92.0MB/s]Downloading pytorch_model.bin:  75%|#######5  | 402M/533M [00:04<00:01, 92.3MB/s]Downloading pytorch_model.bin:  77%|#######7  | 411M/533M [00:04<00:02, 57.8MB/s]Downloading pytorch_model.bin:  79%|#######8  | 420M/533M [00:05<00:01, 65.0MB/s]Downloading pytorch_model.bin:  80%|########  | 428M/533M [00:05<00:01, 71.0MB/s]Downloading pytorch_model.bin:  82%|########1 | 437M/533M [00:05<00:01, 76.0MB/s]Downloading pytorch_model.bin:  84%|########3 | 446M/533M [00:05<00:01, 80.3MB/s]Downloading pytorch_model.bin:  85%|########5 | 455M/533M [00:05<00:00, 83.9MB/s]Downloading pytorch_model.bin:  87%|########6 | 464M/533M [00:05<00:00, 86.6MB/s]Downloading pytorch_model.bin:  89%|########8 | 472M/533M [00:05<00:00, 88.2MB/s]Downloading pytorch_model.bin:  90%|######### | 481M/533M [00:05<00:00, 89.6MB/s]Downloading pytorch_model.bin:  92%|#########1| 490M/533M [00:05<00:00, 90.4MB/s]Downloading pytorch_model.bin:  94%|#########3| 499M/533M [00:05<00:00, 91.3MB/s]Downloading pytorch_model.bin:  95%|#########5| 508M/533M [00:06<00:00, 91.9MB/s]Downloading pytorch_model.bin:  97%|#########6| 517M/533M [00:06<00:00, 92.1MB/s]Downloading pytorch_model.bin:  99%|#########8| 526M/533M [00:06<00:00, 92.2MB/s]Downloading pytorch_model.bin: 100%|##########| 533M/533M [00:06<00:00, 88.7MB/s]\n\n\n\nfrom transformers import BertTokenizer, BertForNextSentencePrediction\n\nhf_logging.set_verbosity_error()\n\narch, config, tokenizer, model = get_hf_objects(\n    \"bert-base-cased-finetuned-mrpc\", config=None, tokenizer_cls=BertTokenizer, model_cls=BertForNextSentencePrediction\n)\nprint(arch)\nprint(type(config))\nprint(type(tokenizer))\nprint(type(model))\n\nbert\n<class 'transformers.models.bert.configuration_bert.BertConfig'>\n<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>\n<class 'transformers.models.bert.modeling_bert.BertForNextSentencePrediction'>"
  },
  {
    "objectID": "text.modeling.core.html",
    "href": "text.modeling.core.html",
    "title": "Modeling",
    "section": "",
    "text": "Base splitter, model wrapper, and model callback\n\nsource\n\n\n\n blurr_splitter (m:fastai.torch_core.Module)\n\nSplits the Hugging Face model based on various model architecture conventions\n\nsource\n\n\n\n\n BaseModelWrapper (hf_model:transformers.modeling_utils.PreTrainedModel,\n                   output_hidden_states:bool=False,\n                   output_attentions:bool=False, hf_model_kwargs={})\n\nSame as nn.Module, but no need for subclasses to call super().__init__\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_model\nPreTrainedModel\n\nYour Hugging Face model\n\n\noutput_hidden_states\nbool\nFalse\nIf True, hidden_states will be returned and accessed from Learner\n\n\noutput_attentions\nbool\nFalse\nIf True, attentions will be returned and accessed from Learner\n\n\nhf_model_kwargs\ndict\n{}\nAny additional keyword arguments you want passed into your models forward method\n\n\n\nNote that BaseModelWrapper includes some nifty code for just passing in the things your model needs, as not all transformer architectures require/use the same information.\n\nsource\n\n\n\n\n BaseModelCallback (base_model_wrapper_kwargs:dict={})\n\nBasic class handling tweaks of the training loop by changing a Learner in various events\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbase_model_wrapper_kwargs\ndict\n{}\nAdditional keyword arguments passed to BaseModelWrapper\n\n\n\nWe use a Callback for handling the ModelOutput returned by Hugging Face transformers. It allows us to associate anything we want from that object to our Learner.\nNote that your Learner’s loss will be set for you only if the Hugging Face model returns one and you are using the PreCalculatedLoss loss function.\nAlso note that anything else you asked the model to return (for example, last hidden state, etc..) will be available for you via the blurr_model_outputs property attached to your Learner. For example, assuming you are using BERT for a classification task … if you have told your BaseModelWrapper instance to return attentions, you’d be able to access them via learn.blurr_model_outputs['attentions'].\n\n\n\nBelow demonstrates how to setup your pipeline for a sequence classification task (e.g., a model that requires a single text input) using the mid, high, and low-level API\n\nraw_datasets = load_dataset(\"imdb\", split=[\"train\", \"test\"])\nraw_datasets[0] = raw_datasets[0].add_column(\"is_valid\", [False] * len(raw_datasets[0]))\nraw_datasets[1] = raw_datasets[1].add_column(\"is_valid\", [True] * len(raw_datasets[1]))\n\nfinal_ds = concatenate_datasets([raw_datasets[0].shuffle().select(range(1000)), raw_datasets[1].shuffle().select(range(200))])\nimdb_df = pd.DataFrame(final_ds)\nimdb_df.head()\n\nReusing dataset imdb (/home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      label\n      is_valid\n    \n  \n  \n    \n      0\n      I wanted to see this movie ever since it was first advertised on TV. I went to Tinsel Town to see it Last Night at 7:40. I regret the day that wasted my ticket on this trash when I could of saw something better. The beginning was all a bunch sex trash and cliches. They exaggerated the way love works in reality. All of the girls were stereo types. The boyfriend was too stupid for his own age. The passing gases that the pregnant girl kept having barely got any laughs. The bank robbery was completely boring with gags that have been used in other movies. Their getaway car was an old beat up Ch...\n      0\n      False\n    \n    \n      1\n      As a huge baseball fan, my scrutiny of this film is how realistic it appears. Dennis Quaid had all of the right moves and stances of a major league pitcher. It is a fantastic true story told with just a little too much \"Disney\" for my taste.\n      1\n      False\n    \n    \n      2\n      This ranks as one of the worst movies I've seen in years. Besides Cuba and Angie, the acting is actually embarrassing. Wasn't Archer once a decent actress? What happened to her? The action is decent but completely implausible. The make up is so bad it's worth mentioning. I mean, who ever even thinks about the makeup in a contemporary feature film. Someone should tell the make up artist, and the DOP that you're not supposed to actually see it. The ending is a massive disappointment - along the lines of \"and then they realized it was all a dream\"<br /><br />Don't waste your time or your mone...\n      0\n      False\n    \n    \n      3\n      For those of us Baby Boomers who arrived too late on the scene to appreciate James Dean et. al., Martin Sheen showed us The Way in this great feature.<br /><br />The premise is easy enough: cool hood meets small town sheriff and All-Hell ensues, but the nuts and bolts of this movie enthrall the car nut in all of us. <br /><br />No, this isn't Casablanca, nor is it great Literature, but it IS a serious movie about cars, rebellion, and the genius that is Martin Sheen.<br /><br />Enjoy this and appreciate it for what it is, and for what Martin will become. I loved this movie growing up as a t...\n      1\n      False\n    \n    \n      4\n      Similar to \"On the Town,\" this musical about sailors on shore leave falls short of the later classic in terms of pacing and the quality of the songs, but it has its own charms. Kelly has three fabulous dance routines: one with Jerry the cartoon mouse of \"Tom and Jerry\" fame, one with a little girl, and a fantasy sequence where he is a Spanish lover determined to reach his lady on a high balcony. Sinatra, playing Kelly's shy, inexperienced buddy, and Grayson, the woman who serves as the love interest for both men, do most of the singing. Iturbi provides some fine piano playing. At nearly tw...\n      1\n      False\n    \n  \n\n\n\n\n\nlabels = raw_datasets[0].features[\"label\"].names\nlabels\n\n['neg', 'pos']\n\n\n\nmodel_cls = AutoModelForSequenceClassification\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\n\n# single input\nset_seed()\nblocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, batch_tokenize_kwargs={\"labels\": labels}), CategoryBlock)\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(\"label\"), splitter=RandomSplitter(seed=42))\n\n\ndls = dblock.dataloaders(imdb_df, bs=4)\n\n\ndls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      My Comments for VIVAH :- Its a charming, idealistic love story starring Shahid Kapoor and Amrita Rao. The film takes us back to small pleasures like the bride and bridegroom's families sleeping on the floor, playing games together, their friendly banter and mutual respect. Vivah is about the sanctity of marriage and the importance of commitment between two individuals. Yes, the central romance is naively visualized. But the sneaked-in romantic moments between the to-be-married couple and their\n      pos\n    \n    \n      1\n      WWE Armageddon, December 17, 2006 -- Live from Richmond Coliseum, Richmond, VA <br /><br />Kane vs. MVP in an Inferno match: So this is the fourth ever inferno match in the WWE and it is Kane vs. MVP (wonder why was it the first match on the card). I only viewed the ending parts where Kane sets MVP's ass on fire as they're on the apron and then MVP is running around the arena while yelling  eventually the refs put out the fire with a fire extinguisher as MVP sprawls around the entrance ramp. F\n      pos\n    \n  \n\n\n\n\n\n.to_fp16() requires a GPU so had to remove for tests to run on github. Let’s check that we can get predictions.\n\nset_seed()\n\nmodel = BaseModelWrapper(hf_model)\n\nlearn = Learner(\n    dls,\n    model,\n    opt_func=partial(OptimWrapper, opt=torch.optim.Adam),\n    loss_func=PreCalculatedCrossEntropyLoss(),  # CrossEntropyLossFlat(),\n    metrics=[accuracy],\n    cbs=[BaseModelCallback],\n    splitter=blurr_splitter,\n)\n\nlearn.freeze()\n\n\nlearn.summary()\n\n\nprint(len(learn.opt.param_groups))\n\n3\n\n\n\nlearn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\n\n\n\n\nSuggestedLRs(minimum=0.00012022644514217973, steep=0.0063095735386013985, valley=0.0003311311302240938, slide=0.0020892962347716093)\n\n\n\n\n\n\nset_seed()\nlearn.fit_one_cycle(1, lr_max=1e-3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.283207\n      0.279155\n      0.883333\n      00:13\n    \n  \n\n\n\n\n\n\nAnd here we create a @typedispatched implementation of Learner.show_results.\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=500)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      Haha, what a great little movie! Wayne Crawford strikes again, or rather this was his first big strike, a deliriously entertaining little ball of manic kitsch energy masquerading as a psycho killer movie. It's actually a **brilliant** satire on post-hippie American culture in flyover country, though the movie was actually filmed independently in Miami. It defies any kind of studio oriented convention or plot device that I can think of: SOMETIMES AUNT MARTHA DOES DREADFUL THINGS may not be a ver\n      pos\n      pos\n    \n    \n      1\n      Most would agree that the character of Wolverine is one of the most intriguing characters in comic book history. I'm no Marvel expert, but I did grow up with the adventures of the X-Men and definitely approved of Hugh Jackman's now widely known portrayal of the scruffy Logan. I enjoyed the first X-Men, found the sequel too heavy and messy and liked the third one as comic book entertainment. All through the three movies, I probably enjoyed Jackman more than anything else. I figured the idea of m\n      neg\n      neg\n    \n  \n\n\n\n\nlearn.unfreeze()\n\n\nset_seed()\nlearn.fit_one_cycle(2, lr_max=slice(1e-7, 1e-4))\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.226185\n      0.279885\n      0.879167\n      00:21\n    \n    \n      1\n      0.201225\n      0.233090\n      0.900000\n      00:21\n    \n  \n\n\n\n\nlearn.recorder.plot_loss()\n\n\n\n\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=500)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      Haha, what a great little movie! Wayne Crawford strikes again, or rather this was his first big strike, a deliriously entertaining little ball of manic kitsch energy masquerading as a psycho killer movie. It's actually a **brilliant** satire on post-hippie American culture in flyover country, though the movie was actually filmed independently in Miami. It defies any kind of studio oriented convention or plot device that I can think of: SOMETIMES AUNT MARTHA DOES DREADFUL THINGS may not be a ver\n      pos\n      pos\n    \n    \n      1\n      Most would agree that the character of Wolverine is one of the most intriguing characters in comic book history. I'm no Marvel expert, but I did grow up with the adventures of the X-Men and definitely approved of Hugh Jackman's now widely known portrayal of the scruffy Logan. I enjoyed the first X-Men, found the sequel too heavy and messy and liked the third one as comic book entertainment. All through the three movies, I probably enjoyed Jackman more than anything else. I figured the idea of m\n      neg\n      neg\n    \n  \n\n\n\n\n\n\nWe need to replace fastai’s Learner.predict method with the one above which is able to work with inputs that are represented by multiple tensors included in a dictionary.\n\nsource\n\n\n\n\n\n Learner.blurr_predict (items, rm_type_tfms=None)\n\n\nsource\n\n\n\n\n Learner.blurr_predict (items, rm_type_tfms=None)\n\n\nlearn.blurr_predict(\"I really liked the movie\")\n\n[{'label': 'pos',\n  'score': 0.9718672633171082,\n  'class_index': 1,\n  'class_labels': ['neg', 'pos'],\n  'probs': [0.028132732957601547, 0.9718672633171082]}]\n\n\n\nlearn.blurr_predict(\"Acting was so bad it was almost funny.\")\n\n[{'label': 'neg',\n  'score': 0.665842592716217,\n  'class_index': 0,\n  'class_labels': ['neg', 'pos'],\n  'probs': [0.665842592716217, 0.33415740728378296]}]\n\n\n\nlearn.blurr_predict([\"I really liked the movie\", \"I really hated the movie\"])\n\n[{'label': 'pos',\n  'score': 0.9718672633171082,\n  'class_index': 1,\n  'class_labels': ['neg', 'pos'],\n  'probs': [0.028132745996117592, 0.9718672633171082]},\n {'label': 'pos',\n  'score': 0.5788970589637756,\n  'class_index': 1,\n  'class_labels': ['neg', 'pos'],\n  'probs': [0.42110294103622437, 0.5788970589637756]}]\n\n\n\n\nThough not useful in sequence classification, we will also add a blurr_generate method to Learner that uses Hugging Face’s PreTrainedModel.generate for text generation tasks.\nFor the full list of arguments you can pass in see here. You can also check out their “How To Generate” notebook for more information about how it all works.\n\nsource\n\n\n\n\n\n Learner.blurr_generate (items, key='generated_texts', **kwargs)\n\nUses the built-in generate method to generate the text (see here for a list of arguments you can pass in)\n\nsource\n\n\n\n\n Learner.blurr_generate (items, key='generated_texts', **kwargs)\n\nUses the built-in generate method to generate the text (see here for a list of arguments you can pass in)\n\n\nUsing fast.ai Learner.export and load_learner\n\nexport_fname = \"seq_class_learn_export\"\n\n\nlearn.export(fname=f\"{export_fname}.pkl\")\n\n\ninf_learn = load_learner(fname=f\"{export_fname}.pkl\")\ninf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n\n[{'label': 'neg',\n  'score': 0.8900553584098816,\n  'class_index': 0,\n  'class_labels': ['neg', 'pos'],\n  'probs': [0.8900553584098816, 0.1099446639418602]}]"
  },
  {
    "objectID": "text.modeling.core.html#high-level-api",
    "href": "text.modeling.core.html#high-level-api",
    "title": "Modeling",
    "section": "High-level API",
    "text": "High-level API\n\nmodel_cls = AutoModelForSequenceClassification\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\ndls = dblock.dataloaders(imdb_df, bs=4)\n\n\nsource\n\nBlearner\n\n Blearner (dls:fastai.data.core.DataLoaders,\n           hf_model:transformers.modeling_utils.PreTrainedModel,\n           base_model_cb:__main__.BaseModelCallback=<class\n           '__main__.BaseModelCallback'>, loss_func:callable|None=None,\n           opt_func=<function Adam>, lr=0.001, splitter:callable=<function\n           trainable_params>, cbs=None, metrics=None, path=None,\n           model_dir='models', wd=None, wd_bn_bias=False, train_bn=True,\n           moms=(0.95, 0.85, 0.95), default_cbs:bool=True)\n\nGroup together a model, some dls and a loss_func to handle training\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndls\n\n\nDataLoaders containing data for each dataset needed for model\n\n\nhf_model\nPreTrainedModel\n\nYour pretrained Hugging Face transformer\n\n\nbase_model_cb\nBaseModelCallback\nBaseModelCallback\nYour BaseModelCallback\n\n\nReturns\nLearner\n\n\n\n\n\nInstead of constructing our low-level Learner, we can use the Blearner class which provides sensible defaults for training\n\nlearn = Blearner(dls, hf_model, metrics=[accuracy])\n\n\nlearn.fit_one_cycle(1, lr_max=1e-3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.253714\n      0.305421\n      0.866667\n      00:13\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=500)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      Haha, what a great little movie! Wayne Crawford strikes again, or rather this was his first big strike, a deliriously entertaining little ball of manic kitsch energy masquerading as a psycho killer movie. It's actually a **brilliant** satire on post-hippie American culture in flyover country, though the movie was actually filmed independently in Miami. It defies any kind of studio oriented convention or plot device that I can think of: SOMETIMES AUNT MARTHA DOES DREADFUL THINGS may not be a ver\n      pos\n      pos\n    \n    \n      1\n      Most would agree that the character of Wolverine is one of the most intriguing characters in comic book history. I'm no Marvel expert, but I did grow up with the adventures of the X-Men and definitely approved of Hugh Jackman's now widely known portrayal of the scruffy Logan. I enjoyed the first X-Men, found the sequel too heavy and messy and liked the third one as comic book entertainment. All through the three movies, I probably enjoyed Jackman more than anything else. I figured the idea of m\n      neg\n      neg\n    \n  \n\n\n\n\nlearn.blurr_predict(\"This was a really good movie\")\n\n[{'label': 'pos',\n  'score': 0.9749817848205566,\n  'class_index': 1,\n  'class_labels': ['neg', 'pos'],\n  'probs': [0.02501819096505642, 0.9749817848205566]}]\n\n\n\nlearn.export(fname=f\"{export_fname}.pkl\")\ninf_learn = load_learner(fname=f\"{export_fname}.pkl\")\ninf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n\n[{'label': 'neg',\n  'score': 0.7373340129852295,\n  'class_index': 0,\n  'class_labels': ['neg', 'pos'],\n  'probs': [0.7373340129852295, 0.2626659572124481]}]\n\n\n\nsource\n\n\nBlearnerForSequenceClassification\n\n BlearnerForSequenceClassification (dls:fastai.data.core.DataLoaders,\n                                    hf_model:transformers.modeling_utils.P\n                                    reTrainedModel, base_model_cb:__main__\n                                    .BaseModelCallback=<class\n                                    '__main__.BaseModelCallback'>,\n                                    loss_func:callable|None=None,\n                                    opt_func=<function Adam>, lr=0.001,\n                                    splitter:callable=<function\n                                    trainable_params>, cbs=None,\n                                    metrics=None, path=None,\n                                    model_dir='models', wd=None,\n                                    wd_bn_bias=False, train_bn=True,\n                                    moms=(0.95, 0.85, 0.95),\n                                    default_cbs:bool=True)\n\nGroup together a model, some dls and a loss_func to handle training\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndls\n\nDataLoaders containing data for each dataset needed for model\n\n\nhf_model\nPreTrainedModel\n\n\n\n\nWe also introduce a classification task specific Blearner that get you your DataBlock, DataLoaders, and BLearner in one line of code!\n\n\nExamples\n\nUsing Mid-level API building blocks\n\nlearn = BlearnerForSequenceClassification.from_data(\n    imdb_df, \"distilroberta-base\", text_attr=\"text\", label_attr=\"label\", dl_kwargs={\"bs\": 4}\n)\n\n\nlearn.fit_one_cycle(1, lr_max=1e-3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      f1_score\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.289666\n      0.233302\n      0.920188\n      0.915000\n      00:13\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=500)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      Watching Stranger Than Fiction director Marc Forster's The Kite Runner is the cinematic equivalent of eating your vegetables because this art-house epic rated PG-13 is good for your movie-going diet. No, this isn't the kind of movie that I like to slouch on the couch and eyeball at the end of a tough day. The Kite Runner isn't your typical mainstream movie designed to entertain you and make you forget about your troubles. First, no celebrity stars appear in it. Second, nothing is cut and dried,\n      1\n      1\n    \n    \n      1\n      As an ancient movie fan, I had heard much about the controversial movie CALIGULA assessed ambiguously as one of the most realistic epics by some and as one of the most disgusting porn movies by others. I decided to see it in the entire uncut version to evaluate it myself hoping to find something positive that would make justice to the many accusations towards the film. I sat down in my chair one autumn evening and started to watch. The beginning quotation from the New Testament shocked me a bit\n      0\n      0\n    \n  \n\n\n\n\nlearn.predict(\"This was a really good movie\")\n\n[{'label': '1',\n  'score': 0.9277380108833313,\n  'class_index': 1,\n  'class_labels': [0, 1],\n  'probs': [0.07226195186376572, 0.9277380108833313]}]\n\n\n\nlearn.export(fname=f\"{export_fname}.pkl\")\ninf_learn = load_learner(fname=f\"{export_fname}.pkl\")\ninf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n\n[{'label': '0',\n  'score': 0.5971986651420593,\n  'class_index': 0,\n  'class_labels': [0, 1],\n  'probs': [0.5971986651420593, 0.4028013050556183]}]\n\n\n\n\nUsing Low-level API building blocks\nThanks to the TextDataLoader, there isn’t really anything you have to do to use plain ol’ PyTorch or fast.ai Datasets and DataLoaders with Blurr. Let’s take a look at fine-tuning a model against Glue’s MRPC dataset …\n\nBuild your Hugging Face objects\n\nmodel_cls = AutoModelForSequenceClassification\n\npretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\n\n\nPreprocess your data\n\nfrom datasets import load_dataset\nfrom blurr.text.data.core import preproc_hf_dataset\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")\n\nDownloading and preparing dataset glue/mrpc (download: 1.43 MiB, generated: 1.43 MiB, post-processed: Unknown size, total: 2.85 MiB) to /home/runner/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\nDataset glue downloaded and prepared to /home/runner/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n\n\nDownloading builder script:   0%|          | 0.00/7.78k [00:00<?, ?B/s]Downloading builder script: 28.8kB [00:00, 17.6MB/s]                   \nDownloading metadata:   0%|          | 0.00/4.47k [00:00<?, ?B/s]Downloading metadata: 28.7kB [00:00, 19.6MB/s]                   \nDownloading data files:   0%|          | 0/3 [00:00<?, ?it/s]\nDownloading data: 0.00B [00:00, ?B/s]Downloading data: 6.22kB [00:00, 4.47MB/s]\nDownloading data files:  33%|###3      | 1/3 [00:00<00:01,  1.10it/s]\nDownloading data: 0.00B [00:00, ?B/s]\nDownloading data: 53.5kB [00:00, 338kB/s]\nDownloading data: 280kB [00:00, 975kB/s] Downloading data: 1.05MB [00:00, 2.53MB/s]\nDownloading data files:  67%|######6   | 2/3 [00:02<00:01,  1.12s/it]\nDownloading data: 0.00B [00:00, ?B/s]\nDownloading data: 45.2kB [00:00, 290kB/s]\nDownloading data: 254kB [00:00, 856kB/s] Downloading data: 441kB [00:00, 1.31MB/s]\nDownloading data files: 100%|##########| 3/3 [00:03<00:00,  1.14s/it]Downloading data files: 100%|##########| 3/3 [00:03<00:00,  1.12s/it]\nGenerating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]Generating train split:  47%|####7     | 1724/3668 [00:00<00:00, 17236.40 examples/s]Generating train split:  96%|#########5| 3506/3668 [00:00<00:00, 17575.26 examples/s]                                                                                     Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]                                                                           Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]                                                                        0%|          | 0/3 [00:00<?, ?it/s]100%|##########| 3/3 [00:00<00:00, 929.66it/s]\n\n\n\ndef tokenize_function(example):\n    return hf_tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n\nLoading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-2a4493b3e0d7eec3.arrow\nLoading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-429f84b2ba09bf45.arrow\nLoading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-38abcb2a8785e400.arrow\n\n\n\n\nBuild your DataLoaders\n\nlabel_names = raw_datasets[\"train\"].features[\"label\"].names\n\ntrn_dl = TextDataLoader(\n    tokenized_datasets[\"train\"],\n    hf_arch=hf_arch,\n    hf_config=hf_config,\n    hf_tokenizer=hf_tokenizer,\n    hf_model=hf_model,\n    preproccesing_func=preproc_hf_dataset,\n    batch_decode_kwargs={\"labels\": label_names},\n    shuffle=True,\n    batch_size=8,\n)\n\nval_dl = TextDataLoader(\n    tokenized_datasets[\"validation\"],\n    hf_arch=hf_arch,\n    hf_config=hf_config,\n    hf_tokenizer=hf_tokenizer,\n    hf_model=hf_model,\n    preproccesing_func=preproc_hf_dataset,\n    batch_decode_kwargs={\"labels\": label_names},\n    batch_size=16,\n)\n\ndls = DataLoaders(trn_dl, val_dl)\n\n\n\nDefine your Blearner\n\nlearn = BlearnerForSequenceClassification(dls, hf_model, loss_func=PreCalculatedCrossEntropyLoss())\n\n\n\nTrain\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=7.585775892948732e-05)\n\n\n\n\n\n\nlearn.fit_one_cycle(1, lr_max=1e-3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.522506\n      0.483814\n      00:13\n    \n  \n\n\n\n\nlearn.unfreeze()\nlearn.fit_one_cycle(2, lr_max=slice(1e-8, 1e-6))\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.522194\n      0.483406\n      00:26\n    \n    \n      1\n      0.503598\n      0.482703\n      00:28\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=500)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      Spansion products are to be available from both AMD and Fujitsu, AMD said. Spansion Flash memory solutions are available worldwide from AMD and Fujitsu.\n      equivalent\n      equivalent\n    \n    \n      1\n      However, EPA officials would not confirm the 20 percent figure. Only in the past few weeks have officials settled on the 20 percent figure.\n      not_equivalent\n      not_equivalent"
  },
  {
    "objectID": "text.modeling.core.html#tests",
    "href": "text.modeling.core.html#tests",
    "title": "Modeling",
    "section": "Tests",
    "text": "Tests\nThe tests below to ensure the core training code above works for all pretrained sequence classification models available in Hugging Face. These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\nNote: Feel free to modify the code below to test whatever pretrained classification models you are working with … and if any of your pretrained sequence classification models fail, please submit a github issue (or a PR if you’d like to fix it yourself)\n\n\n\n\n  \n    \n      \n      arch\n      tokenizer\n      model\n      result\n      error\n    \n  \n  \n    \n      0\n      albert\n      AlbertTokenizerFast\n      AlbertForSequenceClassification\n      PASSED\n      \n    \n    \n      1\n      bart\n      BartTokenizerFast\n      BartForSequenceClassification\n      PASSED\n      \n    \n    \n      2\n      bert\n      BertTokenizerFast\n      BertForSequenceClassification\n      PASSED\n      \n    \n    \n      3\n      big_bird\n      BigBirdTokenizerFast\n      BigBirdForSequenceClassification\n      PASSED\n      \n    \n    \n      4\n      bigbird_pegasus\n      PegasusTokenizerFast\n      BigBirdPegasusForSequenceClassification\n      PASSED\n      \n    \n    \n      5\n      ctrl\n      CTRLTokenizer\n      CTRLForSequenceClassification\n      PASSED\n      \n    \n    \n      6\n      camembert\n      CamembertTokenizerFast\n      CamembertForSequenceClassification\n      PASSED\n      \n    \n    \n      7\n      canine\n      CanineTokenizer\n      CanineForSequenceClassification\n      PASSED\n      \n    \n    \n      8\n      convbert\n      ConvBertTokenizerFast\n      ConvBertForSequenceClassification\n      PASSED\n      \n    \n    \n      9\n      deberta\n      DebertaTokenizerFast\n      DebertaForSequenceClassification\n      PASSED\n      \n    \n    \n      10\n      deberta_v2\n      DebertaV2TokenizerFast\n      DebertaV2ForSequenceClassification\n      PASSED\n      \n    \n    \n      11\n      distilbert\n      DistilBertTokenizerFast\n      DistilBertForSequenceClassification\n      PASSED\n      \n    \n    \n      12\n      electra\n      ElectraTokenizerFast\n      ElectraForSequenceClassification\n      PASSED\n      \n    \n    \n      13\n      flaubert\n      FlaubertTokenizer\n      FlaubertForSequenceClassification\n      PASSED\n      \n    \n    \n      14\n      funnel\n      FunnelTokenizerFast\n      FunnelForSequenceClassification\n      PASSED\n      \n    \n    \n      15\n      gpt2\n      GPT2TokenizerFast\n      GPT2ForSequenceClassification\n      PASSED\n      \n    \n    \n      16\n      gptj\n      GPT2TokenizerFast\n      GPTJForSequenceClassification\n      PASSED\n      \n    \n    \n      17\n      gpt_neo\n      GPT2TokenizerFast\n      GPTNeoForSequenceClassification\n      PASSED\n      \n    \n    \n      18\n      ibert\n      RobertaTokenizer\n      IBertForSequenceClassification\n      PASSED\n      \n    \n    \n      19\n      led\n      LEDTokenizerFast\n      LEDForSequenceClassification\n      PASSED\n      \n    \n    \n      20\n      longformer\n      LongformerTokenizerFast\n      LongformerForSequenceClassification\n      PASSED\n      \n    \n    \n      21\n      mbart\n      MBartTokenizerFast\n      MBartForSequenceClassification\n      PASSED\n      \n    \n    \n      22\n      mpnet\n      MPNetTokenizerFast\n      MPNetForSequenceClassification\n      PASSED\n      \n    \n    \n      23\n      mobilebert\n      MobileBertTokenizerFast\n      MobileBertForSequenceClassification\n      PASSED\n      \n    \n    \n      24\n      openai\n      OpenAIGPTTokenizerFast\n      OpenAIGPTForSequenceClassification\n      PASSED\n      \n    \n    \n      25\n      rembert\n      RemBertTokenizerFast\n      RemBertForSequenceClassification\n      PASSED\n      \n    \n    \n      26\n      roformer\n      RoFormerTokenizerFast\n      RoFormerForSequenceClassification\n      PASSED\n      \n    \n    \n      27\n      roberta\n      RobertaTokenizerFast\n      RobertaForSequenceClassification\n      PASSED\n      \n    \n    \n      28\n      squeezebert\n      SqueezeBertTokenizerFast\n      SqueezeBertForSequenceClassification\n      PASSED\n      \n    \n    \n      29\n      transfo_xl\n      TransfoXLTokenizer\n      TransfoXLForSequenceClassification\n      PASSED\n      \n    \n    \n      30\n      xlm\n      XLMTokenizer\n      XLMForSequenceClassification\n      PASSED\n      \n    \n    \n      31\n      xlm_roberta\n      XLMRobertaTokenizerFast\n      XLMRobertaForSequenceClassification\n      PASSED\n      \n    \n    \n      32\n      xlnet\n      XLNetTokenizerFast\n      XLNetForSequenceClassification\n      PASSED"
  },
  {
    "objectID": "text.data.seq2seq.core.html",
    "href": "text.data.seq2seq.core.html",
    "title": "Data",
    "section": "",
    "text": "pretrained_model_name = \"facebook/bart-large-cnn\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=BartForConditionalGeneration)\nhf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)\n\n('bart',\n transformers.models.bart.configuration_bart.BartConfig,\n transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,\n transformers.models.bart.modeling_bart.BartForConditionalGeneration)"
  },
  {
    "objectID": "text.data.seq2seq.core.html#preprocessing",
    "href": "text.data.seq2seq.core.html#preprocessing",
    "title": "Data",
    "section": "Preprocessing",
    "text": "Preprocessing\nStarting with version 2.0, BLURR provides a preprocessing base class that can be used to build seq2seq preprocessed datasets from pandas DataFrames or Hugging Face Datasets\n\nsource\n\nSeq2SeqPreprocessor\n\n Seq2SeqPreprocessor (hf_tokenizer:transformers.tokenization_utils_base.Pr\n                      eTrainedTokenizerBase, batch_size:int=1000,\n                      text_attr:str='text',\n                      max_input_tok_length:Optional[int]=None,\n                      target_text_attr:str='summary',\n                      max_target_tok_length:Optional[int]=None,\n                      is_valid_attr:Optional[str]='is_valid',\n                      tok_kwargs:dict={})\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nbatch_size\nint\n1000\nThe number of examples to process at a time\n\n\ntext_attr\nstr\ntext\nThe attribute holding the text\n\n\nmax_input_tok_length\nOptional\nNone\nThe maximum length (# of tokens) allowed for inputs. Will default to the max length allowed\n\n\nby the model if not provided\n\n\n\n\n\ntarget_text_attr\nstr\nsummary\nThe attribute holding the summary\n\n\nmax_target_tok_length\nOptional\nNone\nThe maximum length (# of tokens) allowed for targets\n\n\nis_valid_attr\nOptional\nis_valid\nThe attribute that should be created if your are processing individual training and validation\n\n\ndatasets into a single dataset, and will indicate to which each example is associated\n\n\n\n\n\ntok_kwargs\ndict\n{}\nTokenization kwargs that will be applied with calling the tokenizer"
  },
  {
    "objectID": "text.data.seq2seq.core.html#mid-level-api",
    "href": "text.data.seq2seq.core.html#mid-level-api",
    "title": "Data",
    "section": "Mid-level API",
    "text": "Mid-level API\nBase tokenization, batch transform, and DataBlock methods\n\nsource\n\nSeq2SeqTextInput\n\n Seq2SeqTextInput (x, **kwargs)\n\nThe base represenation of your inputs; used by the various fastai show methods\nA Seq2SeqTextInput object is returned from the decodes method of Seq2SeqBatchTokenizeTransform as a means to customize @typedispatched functions like DataLoaders.show_batch and Learner.show_results. The value will the your “input_ids”.\n\nsource\n\n\nSeq2SeqBatchTokenizeTransform\n\n Seq2SeqBatchTokenizeTransform (hf_arch:str,\n                                hf_config:transformers.configuration_utils\n                                .PretrainedConfig, hf_tokenizer:transforme\n                                rs.tokenization_utils_base.PreTrainedToken\n                                izerBase, hf_model:transformers.modeling_u\n                                tils.PreTrainedModel,\n                                include_labels:bool=True,\n                                ignore_token_id:int=-100,\n                                max_length:int=None,\n                                max_target_length:int=None,\n                                padding:Union[bool,str]=True,\n                                truncation:Union[bool,str]=True,\n                                is_split_into_words:bool=False,\n                                tok_kwargs={}, text_gen_kwargs={},\n                                **kwargs)\n\nHandles everything you need to assemble a mini-batch of inputs and targets, as well as decode the dictionary produced as a byproduct of the tokenization process in the encodes method.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_arch\nstr\n\nThe abbreviation/name of your Hugging Face transformer architecture (e.b., bert, bart, etc..)\n\n\nhf_config\nPretrainedConfig\n\nA specific configuration instance you want to use\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nhf_model\nPreTrainedModel\n\nA Hugging Face model\n\n\ninclude_labels\nbool\nTrue\nTo control whether the “labels” are included in your inputs. If they are, the loss will be calculated in\n\n\nthe model’s forward function and you can simply use PreCalculatedLoss as your Learner’s loss function to use it\n\n\n\n\n\nignore_token_id\nint\n-100\nThe token ID that should be ignored when calculating the loss\n\n\nmax_length\nint\nNone\nTo control the length of the padding/truncation of the input sequence. It can be an integer or None,\n\n\n\nin which case it will default to the maximum length the model can accept. If the model has no specific maximum input length, truncation/padding to max_length is deactivated. See Everything you always wanted to know about padding and truncation | | max_target_length | int | None | To control the length of the padding/truncation of the target sequence. It can be an integer or None, in which case it will default to the maximum length the model can accept. If the model has no specific maximum input length, truncation/padding to max_length is deactivated. See Everything you always wanted to know about padding and truncation | | padding | Union | True | To control the padding applied to your hf_tokenizer during tokenization. If None, will default to False or 'do_not_pad'. See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation) | | truncation | Union | True | To controltruncationapplied to yourhf_tokenizerduring tokenization. If None, will default toFalseordo_not_truncate. See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation) | | is_split_into_words | bool | False | Theis_split_into_wordsargument applied to yourhf_tokenizerduring tokenization. Set this toTrueif your inputs are pre-tokenized (not numericalized) | | tok_kwargs | dict | {} | Any other keyword arguments you want included when using yourhf_tokenizerto tokenize your inputs | | text_gen_kwargs | dict | {} | Any keyword arguments to pass to thehf_model.generate` method | | kwargs | | | |\nWe create a subclass of BatchTokenizeTransform for summarization tasks to add decoder_input_ids and labels (if we want Hugging Face to calculate the loss for us) to our inputs during training. See here and here for more information on these additional inputs used in summarization, translation, and conversational training tasks. How they should look for particular architectures can be found by looking at those model’s forward function’s docs (See here for BART for example)\nNote also that labels is simply target_ids shifted to the right by one since the task to is to predict the next token based on the current (and all previous) decoder_input_ids.\nAnd lastly, we also update our targets to just be the input_ids of our target sequence so that fastai’s Learner.show_results works (again, almost all the fastai bits require returning a single tensor to work).\n\nsource\n\n\nSeq2SeqBatchDecodeTransform\n\n Seq2SeqBatchDecodeTransform (input_return_type:type=<class\n                              'blurr.text.data.core.TextInput'>,\n                              hf_arch:str=None,\n                              hf_config:PretrainedConfig=None,\n                              hf_tokenizer:PreTrainedTokenizerBase=None,\n                              hf_model:PreTrainedModel=None, **kwargs)\n\nA class used to cast your inputs as input_return_type for fastai show methods\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_return_type\ntype\nTextInput\nUsed by typedispatched show methods\n\n\nhf_arch\nstr\nNone\nThe abbreviation/name of your Hugging Face transformer architecture (not required if passing in an instance of BatchTokenizeTransform to before_batch_tfm)\n\n\nhf_config\nPretrainedConfig\nNone\nA Hugging Face configuration object (not required if passing in an instance of BatchTokenizeTransform to before_batch_tfm)\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\nNone\nA Hugging Face tokenizer (not required if passing in an instance of BatchTokenizeTransform to before_batch_tfm)\n\n\nhf_model\nPreTrainedModel\nNone\nA Hugging Face model (not required if passing in an instance of BatchTokenizeTransform to before_batch_tfm)\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\ndefault_text_gen_kwargs\n\n default_text_gen_kwargs (hf_config, hf_model, task=None)\n\n\ndefault_text_gen_kwargs(hf_config, hf_model)\n\n{'max_length': 142,\n 'min_length': 56,\n 'do_sample': False,\n 'early_stopping': True,\n 'num_beams': 4,\n 'temperature': 1.0,\n 'top_k': 50,\n 'top_p': 1.0,\n 'repetition_penalty': 1.0,\n 'bad_words_ids': None,\n 'bos_token_id': 0,\n 'pad_token_id': 1,\n 'eos_token_id': 2,\n 'length_penalty': 2.0,\n 'no_repeat_ngram_size': 3,\n 'encoder_no_repeat_ngram_size': 0,\n 'num_return_sequences': 1,\n 'decoder_start_token_id': 2,\n 'use_cache': True,\n 'num_beam_groups': 1,\n 'diversity_penalty': 0.0,\n 'output_attentions': False,\n 'output_hidden_states': False,\n 'output_scores': False,\n 'return_dict_in_generate': False,\n 'forced_bos_token_id': 0,\n 'forced_eos_token_id': 2,\n 'remove_invalid_values': False}\n\n\n\nsource\n\n\nSeq2SeqTextBlock\n\n Seq2SeqTextBlock (hf_arch:str=None,\n                   hf_config:transformers.configuration_utils.PretrainedCo\n                   nfig=None, hf_tokenizer:transformers.tokenization_utils\n                   _base.PreTrainedTokenizerBase=None, hf_model:transforme\n                   rs.modeling_utils.PreTrainedModel=None, batch_tokenize_\n                   tfm:Optional[blurr.text.data.core.BatchTokenizeTransfor\n                   m]=None, batch_decode_tfm:Optional[blurr.text.data.core\n                   .BatchDecodeTransform]=None, max_length:int=None,\n                   max_target_length=None, padding:Union[bool,str]=True,\n                   truncation:Union[bool,str]=True,\n                   input_return_type=<class '__main__.Seq2SeqTextInput'>,\n                   dl_type=<class 'fastai.text.data.SortedDL'>,\n                   batch_tokenize_kwargs:dict={},\n                   batch_decode_kwargs:dict={}, tok_kwargs={},\n                   text_gen_kwargs={}, **kwargs)\n\nThe core TransformBlock to prepare your inputs for training in Blurr with fastai’s DataBlock API\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_arch\nstr\nNone\nThe abbreviation/name of your Hugging Face transformer architecture (not required if passing in an\n\n\ninstance of BatchTokenizeTransform to before_batch_tfm)\n\n\n\n\n\nhf_config\nPretrainedConfig\nNone\nA Hugging Face configuration object (not required if passing in an\n\n\ninstance of BatchTokenizeTransform to before_batch_tfm)\n\n\n\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\nNone\nA Hugging Face tokenizer (not required if passing in an\n\n\ninstance of BatchTokenizeTransform to before_batch_tfm)\n\n\n\n\n\nhf_model\nPreTrainedModel\nNone\nA Hugging Face model (not required if passing in an\n\n\ninstance of BatchTokenizeTransform to before_batch_tfm)\n\n\n\n\n\nbatch_tokenize_tfm\nOptional\nNone\nThe before_batch_tfm you want to use to tokenize your raw data on the fly\n\n\n(defaults to an instance of BatchTokenizeTransform)\n\n\n\n\n\nbatch_decode_tfm\nOptional\nNone\nThe batch_tfm you want to decode your inputs into a type that can be used in the fastai show methods,\n\n\n(defaults to BatchDecodeTransform)\n\n\n\n\n\nmax_length\nint\nNone\nTo control the length of the padding/truncation for the input sequence. It can be an integer or None,\n\n\n\nin which case it will default to the maximum length the model can accept. If the model has no specific maximum input length, truncation/padding to max_length is deactivated. See Everything you always wanted to know about padding and truncation | | max_target_length | NoneType | None | To control the length of the padding/truncation for the target sequence. It can be an integer or None, in which case it will default to the maximum length the model can accept. If the model has no specific maximum input length, truncation/padding to max_length is deactivated. See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-y | | padding | Union | True | To control the padding applied to your hf_tokenizer during tokenization. If None, will default to False or 'do_not_pad'. See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation) | | truncation | Union | True | To controltruncationapplied to yourhf_tokenizerduring tokenization. If None, will default toFalseordo_not_truncate. See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation) | | input_return_type | _TensorMeta | Seq2SeqTextInput | The return type your decoded inputs should be cast too (used by methods such asshow_batch) | | dl_type | type | SortedDL | The type ofDataLoaderyou want created (defaults toSortedDL) | | batch_tokenize_kwargs | dict | {} | Any keyword arguments you want applied to yourbatch_tokenize_tfm| | batch_decode_kwargs | dict | {} | Any keyword arguments you want applied to yourbatch_decode_tfm(will be set as a fastaibatch_tfms`) | | tok_kwargs | dict | {} | Any keyword arguments you want your Hugging Face tokenizer to use during tokenization | | text_gen_kwargs | dict | {} | Any keyword arguments you want to have applied with generating text (default: default_text_gen_kwargs) | | kwargs | | | |\n\n\nshow_batch"
  },
  {
    "objectID": "text.data.question_answering.html",
    "href": "text.data.question_answering.html",
    "title": "Data",
    "section": "",
    "text": "What we're running with at the time this documentation was generated:\ntorch: 1.9.0+cu102\nfastai: 2.7.9\ntransformers: 4.21.2"
  },
  {
    "objectID": "text.data.question_answering.html#setup",
    "href": "text.data.question_answering.html#setup",
    "title": "Data",
    "section": "Setup",
    "text": "Setup\nWe’ll use a subset of squad_v2 to demonstrate how to configure your blurr code for extractive question answering\n\nraw_datasets = load_dataset(\"squad_v2\", split=[\"train[:1000]\", \"validation[:200]\"])\n\nReusing dataset squad_v2 (/home/wgilliam/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n\n\n\n\n\n\nraw_train_ds, raw_valid_ds = raw_datasets[0], raw_datasets[1]\n\n\nraw_train_df = pd.DataFrame(raw_train_ds)\nraw_valid_df = pd.DataFrame(raw_valid_ds)\n\nraw_train_df[\"is_valid\"] = False\nraw_valid_df[\"is_valid\"] = True\n\nprint(len(raw_train_df))\nprint(len(raw_valid_df))\n\n1000\n200\n\n\n\nraw_train_df.head(2)\n\n\n\n\n\n  \n    \n      \n      id\n      title\n      context\n      question\n      answers\n      is_valid\n    \n  \n  \n    \n      0\n      56be85543aeaaa14008c9063\n      Beyoncé\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      When did Beyonce start becoming popular?\n      {'text': ['in the late 1990s'], 'answer_start': [269]}\n      False\n    \n    \n      1\n      56be85543aeaaa14008c9065\n      Beyoncé\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      What areas did Beyonce compete in when she was growing up?\n      {'text': ['singing and dancing'], 'answer_start': [207]}\n      False\n    \n  \n\n\n\n\n\nraw_valid_df.head(2)\n\n\n\n\n\n  \n    \n      \n      id\n      title\n      context\n      question\n      answers\n      is_valid\n    \n  \n  \n    \n      0\n      56ddde6b9a695914005b9628\n      Normans\n      The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10...\n      In what country is Normandy located?\n      {'text': ['France', 'France', 'France', 'France'], 'answer_start': [159, 159, 159, 159]}\n      True\n    \n    \n      1\n      56ddde6b9a695914005b9629\n      Normans\n      The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10...\n      When were the Normans in Normandy?\n      {'text': ['10th and 11th centuries', 'in the 10th and 11th centuries', '10th and 11th centuries'...\n      True\n    \n  \n\n\n\n\n\nsquad_df = pd.concat([raw_train_df, raw_valid_df])\nlen(squad_df)\n\n1200\n\n\n\nsquad_df[\"ans_start_char_idx\"] = squad_df.answers.apply(lambda v: v[\"answer_start\"][0] if len(v[\"answer_start\"]) > 0 else \"0\")\nsquad_df[\"answer_text\"] = squad_df.answers.apply(lambda v: v[\"text\"][0] if len(v[\"text\"]) > 0 else \"\")\nsquad_df[\"ans_end_char_idx\"] = squad_df[\"ans_start_char_idx\"].astype(int) + squad_df[\"answer_text\"].str.len()\n\nprint(len(squad_df))\nsquad_df[squad_df.is_valid == True].head(2)\n\n1200\n\n\n\n\n\n\n  \n    \n      \n      id\n      title\n      context\n      question\n      answers\n      is_valid\n      ans_start_char_idx\n      answer_text\n      ans_end_char_idx\n    \n  \n  \n    \n      0\n      56ddde6b9a695914005b9628\n      Normans\n      The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10...\n      In what country is Normandy located?\n      {'text': ['France', 'France', 'France', 'France'], 'answer_start': [159, 159, 159, 159]}\n      True\n      159\n      France\n      165\n    \n    \n      1\n      56ddde6b9a695914005b9629\n      Normans\n      The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10...\n      When were the Normans in Normandy?\n      {'text': ['10th and 11th centuries', 'in the 10th and 11th centuries', '10th and 11th centuries'...\n      True\n      94\n      10th and 11th centuries\n      117\n    \n  \n\n\n\n\n\nmodel_cls = AutoModelForQuestionAnswering\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"roberta-base\"  #'xlm-mlm-ende-1024'\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\nmax_seq_len = 128\nvocab = dict(enumerate(range(max_seq_len)))"
  },
  {
    "objectID": "text.data.question_answering.html#preprocessing",
    "href": "text.data.question_answering.html#preprocessing",
    "title": "Data",
    "section": "Preprocessing",
    "text": "Preprocessing\nWith version 2.0.0 of BLURR, we include a Preprocessor for question answering that can either truncate texts or else chunk long documents into multiple examples.\nNote: Unlike other NLP tasks in BLURR, extractive question answering requires preprocessing in order to convert our raw start/end character indices into start/end token indices unless your dataset includes the later. Token indicies, rather than character indices, will be used as our targets and are dependent on your tokenizer of choice.\n\nsource\n\nQAPreprocessor\n\n QAPreprocessor (hf_tokenizer:transformers.tokenization_utils_base.PreTrai\n                 nedTokenizerBase, batch_size:int=1000,\n                 id_attr:Optional[str]=None, ctx_attr:str='context',\n                 qst_attr:str='question', ans_attr:str='answer_text',\n                 ans_start_char_idx:str='ans_start_char_idx',\n                 ans_end_char_idx:str='ans_end_char_idx',\n                 is_valid_attr:Optional[str]='is_valid',\n                 tok_kwargs:dict={'return_overflowing_tokens': True})\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nbatch_size\nint\n1000\nThe number of examples to process at a time\n\n\nid_attr\nOptional\nNone\nThe unique identifier in the dataset. If not specified and “return_overflowing_tokens”: True, an “_id” attribute\n\n\nwill be added to your dataset with its value a unique, sequential integer, assigned to each record\n\n\n\n\n\nctx_attr\nstr\ncontext\nThe attribute in your dataset that contains the context (where the answer is included) (default: ‘context’)\n\n\nqst_attr\nstr\nquestion\nThe attribute in your dataset that contains the question being asked (default: ‘question’)\n\n\nans_attr\nstr\nanswer_text\nThe attribute in your dataset that contains the actual answer (default: ‘answer_text’)\n\n\nans_start_char_idx\nstr\nans_start_char_idx\nThe attribute in your dataset that contains the actual answer (default: ‘answer_text’)\n\n\nans_end_char_idx\nstr\nans_end_char_idx\nThe attribute in your dataset that contains the actual answer (default: ‘answer_text’)\n\n\nis_valid_attr\nOptional\nis_valid\nThe attribute that should be created if your are processing individual training and validation\n\n\ndatasets into a single dataset, and will indicate to which each example is associated\n\n\n\n\n\ntok_kwargs\ndict\n{‘return_overflowing_tokens’: True}\nTokenization kwargs that will be applied with calling the tokenizer (default: {“return_overflowing_tokens”: True})\n\n\n\n\nHow to preprocess your data\n\ntok_kwargs = {\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 64}\npreprocessor = QAPreprocessor(hf_tokenizer, id_attr=\"id\", tok_kwargs=tok_kwargs)\nproc_df = preprocessor.process_df(squad_df)\n\nprint(len(proc_df))\nproc_df.head(4)\n\n3560\n\n\n\n\n\n\n  \n    \n      \n      id\n      title\n      context\n      question\n      answers\n      is_valid\n      ans_start_char_idx\n      answer_text\n      ans_end_char_idx\n      proc_question\n      proc_context\n      ans_start_token_idx\n      ans_end_token_idx\n      is_answerable\n    \n  \n  \n    \n      0\n      56be85543aeaaa14008c9063\n      Beyoncé\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      When did Beyonce start becoming popular?\n      {'text': ['in the late 1990s'], 'answer_start': [269]}\n      False\n      269\n      in the late 1990s\n      286\n      When did Beyonce start becoming popular?\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      84\n      89\n      True\n    \n    \n      1\n      56be85543aeaaa14008c9063\n      Beyoncé\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      When did Beyonce start becoming popular?\n      {'text': ['in the late 1990s'], 'answer_start': [269]}\n      False\n      269\n      in the late 1990s\n      286\n      When did Beyonce start becoming popular?\n      in Houston, Texas, she performed in various singing and dancing competitions as a child, and ro...\n      32\n      37\n      True\n    \n    \n      2\n      56be85543aeaaa14008c9063\n      Beyoncé\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      When did Beyonce start becoming popular?\n      {'text': ['in the late 1990s'], 'answer_start': [269]}\n      False\n      269\n      in the late 1990s\n      286\n      When did Beyonce start becoming popular?\n      group became one of the world's best-selling girl groups of all time. Their hiatus saw the rele...\n      0\n      0\n      False\n    \n    \n      3\n      56be85543aeaaa14008c9065\n      Beyoncé\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      What areas did Beyonce compete in when she was growing up?\n      {'text': ['singing and dancing'], 'answer_start': [207]}\n      False\n      207\n      singing and dancing\n      226\n      What areas did Beyonce compete in when she was growing up?\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      77\n      80\n      True\n    \n  \n\n\n\n\n\nsampled_df = proc_df.sample(n=10)\nfor row_idx, row in sampled_df.iterrows():\n    test_example = row\n\n    inputs = hf_tokenizer(row.proc_question, row.proc_context)\n\n    if test_example.is_answerable:\n        # print(test_example.answer_text)\n        test_eq(\n            test_example.answer_text,\n            hf_tokenizer.decode(inputs[\"input_ids\"][test_example.ans_start_token_idx : test_example.ans_end_token_idx]).strip(),\n        )\n    else:\n        test_eq(test_example.ans_start_token_idx, 0)\n        test_eq(test_example.ans_end_token_idx, 0)\n\nIf you want to remove texts longer than your model will hold (and include only answerable contexts)\n\npreprocessor = QAPreprocessor(hf_tokenizer, tok_kwargs={\"return_overflowing_tokens\": False, \"max_length\": max_seq_len})\nproc2_df = preprocessor.process_df(squad_df)\nproc2_df = proc2_df[(proc2_df.ans_end_token_idx < max_seq_len) & (proc2_df.is_answerable)]\n\nprint(len(proc2_df))\nproc2_df.head(2)\n\n763\n\n\n\n\n\n\n  \n    \n      \n      id\n      title\n      context\n      question\n      answers\n      is_valid\n      ans_start_char_idx\n      answer_text\n      ans_end_char_idx\n      proc_question\n      proc_context\n      ans_start_token_idx\n      ans_end_token_idx\n      is_answerable\n    \n  \n  \n    \n      0\n      56be85543aeaaa14008c9063\n      Beyoncé\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      When did Beyonce start becoming popular?\n      {'text': ['in the late 1990s'], 'answer_start': [269]}\n      False\n      269\n      in the late 1990s\n      286\n      When did Beyonce start becoming popular?\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      84\n      89\n      True\n    \n    \n      1\n      56be85543aeaaa14008c9065\n      Beyoncé\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      What areas did Beyonce compete in when she was growing up?\n      {'text': ['singing and dancing'], 'answer_start': [207]}\n      False\n      207\n      singing and dancing\n      226\n      What areas did Beyonce compete in when she was growing up?\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      77\n      80\n      True"
  },
  {
    "objectID": "text.data.question_answering.html#mid-level-api",
    "href": "text.data.question_answering.html#mid-level-api",
    "title": "Data",
    "section": "Mid-level API",
    "text": "Mid-level API\n\nsource\n\nQATextInput\n\n QATextInput (x, **kwargs)\n\nThe base represenation of your inputs; used by the various fastai show methods\n\nsource\n\n\nQABatchTokenizeTransform\n\n QABatchTokenizeTransform (hf_arch:str,\n                           hf_config:transformers.configuration_utils.Pret\n                           rainedConfig, hf_tokenizer:transformers.tokeniz\n                           ation_utils_base.PreTrainedTokenizerBase, hf_mo\n                           del:transformers.modeling_utils.PreTrainedModel\n                           , include_labels:bool=True,\n                           ignore_token_id=-100, max_length:int=None,\n                           padding:Union[bool,str]=True,\n                           truncation:Union[bool,str]='only_second',\n                           is_split_into_words:bool=False,\n                           tok_kwargs:dict={}, **kwargs)\n\nHandles everything you need to assemble a mini-batch of inputs and targets, as well as decode the dictionary produced as a byproduct of the tokenization process in the encodes method.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_arch\nstr\n\nThe abbreviation/name of your Hugging Face transformer architecture (e.b., bert, bart, etc..)\n\n\nhf_config\nPretrainedConfig\n\nA specific configuration instance you want to use\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nhf_model\nPreTrainedModel\n\nA Hugging Face model\n\n\ninclude_labels\nbool\nTrue\nTo control whether the “labels” are included in your inputs. If they are, the loss will be calculated in\n\n\nthe model’s forward function and you can simply use PreCalculatedLoss as your Learner’s loss function to use it\n\n\n\n\n\nignore_token_id\nint\n-100\nThe token ID that should be ignored when calculating the loss\n\n\nmax_length\nint\nNone\nTo control the length of the padding/truncation. It can be an integer or None,\n\n\n\nin which case it will default to the maximum length the model can accept. If the model has no specific maximum input length, truncation/padding to max_length is deactivated. See Everything you always wanted to know about padding and truncation | | padding | Union | True | To control the padding applied to your hf_tokenizer during tokenization. If None, will default to False or 'do_not_pad'. See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation) | | truncation | Union | only_second | To controltruncationapplied to yourhf_tokenizerduring tokenization. If None, will default toFalseordo_not_truncate. See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation) | | is_split_into_words | bool | False | Theis_split_into_wordsargument applied to yourhf_tokenizerduring tokenization. Set this toTrueif your inputs are pre-tokenized (not numericalized) | | tok_kwargs | dict | {} | Any other keyword arguments you want included when using yourhf_tokenizer` to tokenize your inputs. | | kwargs | | | |"
  },
  {
    "objectID": "text.data.question_answering.html#examples",
    "href": "text.data.question_answering.html#examples",
    "title": "Data",
    "section": "Examples",
    "text": "Examples\nThe following eamples demonstrate several approaches to construct your DataBlock for question answering tasks using the mid-level API\n\nUsing the mid-level API\n\nBatch-Time Tokenization\n\nStep 1: Get your Hugging Face objects\n\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"distilroberta-base\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=AutoModelForQuestionAnswering)\n\nmax_seq_len = 128\nvocab = dict(enumerate(range(max_seq_len)))\n\n\n\nStep 2: Preprocess dataset\n\ntok_kwargs = {\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 24}\npreprocessor = QAPreprocessor(hf_tokenizer, id_attr=\"id\", tok_kwargs=tok_kwargs)\nproc_df = preprocessor.process_df(squad_df)\n\nproc_df.head(1)\n\n\n\n\n\n  \n    \n      \n      id\n      title\n      context\n      question\n      answers\n      is_valid\n      ans_start_char_idx\n      answer_text\n      ans_end_char_idx\n      proc_question\n      proc_context\n      ans_start_token_idx\n      ans_end_token_idx\n      is_answerable\n    \n  \n  \n    \n      0\n      56be85543aeaaa14008c9063\n      Beyoncé\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      When did Beyonce start becoming popular?\n      {'text': ['in the late 1990s'], 'answer_start': [269]}\n      False\n      269\n      in the late 1990s\n      286\n      When did Beyonce start becoming popular?\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      84\n      89\n      True\n    \n  \n\n\n\n\n\n\nStep 3: Create your DataBlock\n\nbefore_batch_tfm = QABatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_seq_len)\n\nblocks = (\n    TextBlock(batch_tokenize_tfm=before_batch_tfm, input_return_type=QATextInput),\n    CategoryBlock(vocab=vocab),\n    CategoryBlock(vocab=vocab),\n)\n\ndblock = DataBlock(\n    blocks=blocks,\n    get_x=lambda x: (x.proc_question, x.proc_context),\n    get_y=[ColReader(\"ans_start_token_idx\"), ColReader(\"ans_end_token_idx\")],\n    splitter=ColSplitter(),\n    n_inp=1,\n)\n\n\n\nStep 4: Build your DataLoaders\n\ndls = dblock.dataloaders(proc_df, bs=4)\nlen(dls.train), len(dls.valid)\n\n(590, 94)\n\n\n\nb = dls.one_batch()\nlen(b), len(b[0]), len(b[1]), len(b[2])\n\n(3, 8, 4, 4)\n\n\n\nb[0][\"input_ids\"].shape, b[0][\"attention_mask\"].shape, b[1].shape, b[2].shape\n\n(torch.Size([4, 128]), torch.Size([4, 128]), torch.Size([4]), torch.Size([4]))\n\n\n\nb[0][\"start_positions\"], b[0][\"end_positions\"]\n\n(TensorCategory([ 0,  0, 85,  0], device='cuda:1'),\n TensorCategory([ 0,  0, 87,  0], device='cuda:1'))\n\n\nThe show_batch method above allows us to create a more interpretable view of our question/answer data.\n\ndls.show_batch(dataloaders=dls, max_n=4)\n\n\n\n  \n    \n      \n      text\n      found\n      start/end\n      answer\n    \n  \n  \n    \n      0\n      Beyonce has been awarded how many Grammy nominations? ously in Love, B'Day and I Am... Sasha Fierce have all won Best Contemporary R&B Album. Beyoncé set the record for the most Grammy awards won by a female artist in one night in 2010 when she won six awards, breaking the tie she previously held with Alicia Keys, Norah Jones, Alison Krauss, and Amy Winehouse, with Adele equaling this in 2012. Following her role in Dreamgirls she was nominated for Best Original Song for \"Listen\" and Best Actress at the Golden Globe Awards, and Outstanding Actress\n      False\n      (0, 0)\n      \n    \n    \n      1\n      Who did Beyonce record the lead single with in the movie \"The Fighting Temptations\"? cé starred opposite Cuba Gooding, Jr., in the musical comedy The Fighting Temptations as Lilly, a single mother whom Gooding's character falls in love with. The film received mixed reviews from critics but grossed $30 million in the U.S. Beyoncé released \"Fighting Temptation\" as the lead single from the film's soundtrack album, with Missy Elliott, MC Lyte, and Free which was also used to promote the film. Another of Beyoncé's contributions to the soundtrack, \"\n      True\n      (97, 100)\n      Missy Elliott\n    \n    \n      2\n      What did Bryan Lessard name after Beyoncé?'s \"Say My Name\" and discussed his relationship with women. In January 2012, research scientist Bryan Lessard named Scaptia beyonceae, a species of horse fly found in Northern Queensland, Australia after Beyoncé due to the fly's unique golden hairs on its abdomen. In July 2014, a Beyoncé exhibit was introduced into the \"Legends of Rock\" section of the Rock and Roll Hall of Fame. The black leotard from the \"Single Ladies\" video and her outfit from the Super Bowl half time performance are among several pieces housed at\n      True\n      (45, 50)\n      a species of horse fly\n    \n    \n      3\n      How many awards did Beyonce take home with her at the 57th Grammy Awards? ogue magazine was unveiled online, Beyoncé as the cover star, becoming the first African-American artist and third African-American woman in general to cover the September issue. She headlined the 2015 Made in America festival in early September and also the Global Citizen Festival later that month. Beyoncé made an uncredited featured appearance on the track \"Hymn for the Weekend\" by British rock band Coldplay, on their seventh studio album A Head Full of Dreams (2015), which saw release in December. On January 7, 2016,\n      False\n      (0, 0)\n      \n    \n  \n\n\n\n\n\n\nPassing extra information\nAs mentioned in the data.core module documentation, BLURR now also allows you to pass extra information alongside your inputs in the form of a dictionary. If we are splitting long documents into chunks but want to predict/aggregation by example (rather than by chunk), we’ll need to include a unique identifier for each example. When we look at modeling.question_answer module, we’ll see how the question answering bits can use such an Id for this purpose.\n\nStep 1: Get your Hugging Face objects\n\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=AutoModelForQuestionAnswering)\n\nmax_seq_len = 128\nvocab = dict(enumerate(range(max_seq_len)))\n\n\n\nStep 2: Preprocess dataset\n\npreprocessor = QAPreprocessor(\n    hf_tokenizer, id_attr=\"id\", tok_kwargs={\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 64}\n)\n\nproc_df = preprocessor.process_df(squad_df)\nproc_df.head(1)\n\n\n\n\n\n  \n    \n      \n      id\n      title\n      context\n      question\n      answers\n      is_valid\n      ans_start_char_idx\n      answer_text\n      ans_end_char_idx\n      proc_question\n      proc_context\n      ans_start_token_idx\n      ans_end_token_idx\n      is_answerable\n    \n  \n  \n    \n      0\n      56be85543aeaaa14008c9063\n      Beyoncé\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      When did Beyonce start becoming popular?\n      {'text': ['in the late 1990s'], 'answer_start': [269]}\n      False\n      269\n      in the late 1990s\n      286\n      When did Beyonce start becoming popular?\n      Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an America...\n      75\n      79\n      True\n    \n  \n\n\n\n\n\n\nStep 2: Create your DataBlock\n\nbefore_batch_tfm = QABatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_seq_len)\n\nblocks = (\n    TextBlock(batch_tokenize_tfm=before_batch_tfm, input_return_type=QATextInput),\n    CategoryBlock(vocab=vocab),\n    CategoryBlock(vocab=vocab),\n)\n\n# since its preprocessed, we include an \"text\" key with the values of our question and context\ndef get_x(item):\n    return {\"text\": (item.proc_question, item.proc_context), \"id\": item.id}\n\n\ndblock = DataBlock(\n    blocks=blocks,\n    get_x=get_x,\n    get_y=[ItemGetter(\"ans_start_token_idx\"), ItemGetter(\"ans_end_token_idx\")],\n    splitter=ColSplitter(),\n    n_inp=1,\n)\n\n\n\nStep 3: Build your DataLoaders\n\ndls = dblock.dataloaders(proc_df, bs=4)\nlen(dls.train), len(dls.valid)\n\n(733, 108)\n\n\n\nb = dls.one_batch()\nlen(b), len(b[0]), len(b[1]), len(b[2])\n\n(3, 10, 4, 4)\n\n\n\nb[0].keys()\n\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'offset_mapping', 'id', 'cls_index', 'p_mask', 'start_positions', 'end_positions'])\n\n\n\nb[0][\"input_ids\"].shape, b[0][\"attention_mask\"].shape, b[1].shape, b[2].shape\n\n(torch.Size([4, 128]), torch.Size([4, 128]), torch.Size([4]), torch.Size([4]))\n\n\nWe can see that any additional data is now located in the inputs dictionary\n\nb[0][\"id\"]\n\n['56be8bab3aeaaa14008c90a1',\n '56d4cde92ccc5a1400d83239',\n '56bea8463aeaaa14008c91ac',\n '56becc903aeaaa14008c94a1']\n\n\n\ndls.show_batch(dataloaders=dls, max_n=4)\n\n\n\n  \n    \n      \n      text\n      found\n      start/end\n      answer\n    \n  \n  \n    \n      0\n      who was the first record label to give the girls a record deal? ped and danced on the talent show circuit in houston. after seeing the group, r & b producer arne frager brought them to his northern california studio and placed them in star search, the largest talent show on national tv at the time. girl's tyme failed to win, and beyonce later said the song they performed was not good. in 1995 beyonce's father resigned from his job to manage the group. the move reduced beyonce's family's income by half, and her parents were forced to move into separated apartments. mathew\n      False\n      (0, 0)\n      \n    \n    \n      1\n      who said that chopin set out \" into the wide world, with no very clearly defined aim, forever? \" cki, \" into the wide world, with no very clearly defined aim, forever. \" with woyciechowski, he headed for austria, intending to go on to italy. later that month, in warsaw, the november 1830 uprising broke out, and woyciechowski returned to poland to enlist. chopin, now alone in vienna, was nostalgic for his homeland, and wrote to a friend, \" i curse the moment of my departure. \" when in september 1831 he learned, while\n      False\n      (0, 0)\n      \n    \n    \n      2\n      what short poem spoke of frederic's popularity as a child? yk and his family moved to a building, which still survives, adjacent to the kazimierz palace. during this period, fryderyk was sometimes invited to the belweder palace as playmate to the son of the ruler of russian poland, grand duke constantine ; he played the piano for the duke and composed a march for him. julian ursyn niemcewicz, in his dramatic eclogue, \" nasze przebiegi \" ( \" our discourses \", 1818 ), attested to \" little chopin's \" popularity\n      True\n      (101, 107)\n      nasze przebiegi\n    \n    \n      3\n      which national event caused beyonce to produce \" demand a plan? \" in a campaign video released on 15 may 2013, where she, along with cameron diaz, john legend and kylie minogue, described inspiration from their mothers, while a number of other artists celebrated personal inspiration from other women, leading to a call for submission of photos of women of viewers'inspiration from which a selection was shown at the concert. beyonce said about her mother tina knowles that her gift was \" finding the best qualities in every human being. \" with help of the crowdfunding platform catapult, visitors of the concert could choose between several projects promoting education\n      False\n      (0, 0)"
  },
  {
    "objectID": "text.data.core.html",
    "href": "text.data.core.html",
    "title": "Data",
    "section": "",
    "text": "What we're running with at the time this documentation was generated:\ntorch: 1.9.0+cu102\nfastai: 2.7.9\ntransformers: 4.21.2"
  },
  {
    "objectID": "text.data.core.html#setup",
    "href": "text.data.core.html#setup",
    "title": "Data",
    "section": "Setup",
    "text": "Setup\nWe’ll use a subset of imdb to demonstrate how to configure your BLURR for sequence classification tasks\n\nraw_datasets = load_dataset(\"imdb\", split=[\"train\", \"test\"])\n\nraw_datasets[0] = raw_datasets[0].add_column(\"is_valid\", [False] * len(raw_datasets[0]))\nraw_datasets[1] = raw_datasets[1].add_column(\"is_valid\", [True] * len(raw_datasets[1]))\n\nfinal_ds = concatenate_datasets([raw_datasets[0].shuffle().select(range(1000)), raw_datasets[1].shuffle().select(range(200))])\n\nimdb_df = pd.DataFrame(final_ds)\nimdb_df.head()\n\nReusing dataset imdb (/home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      label\n      is_valid\n    \n  \n  \n    \n      0\n      What an overlooked 80's soundtrack. I imagine John Travolta sang some of the songs but in watching the movie it did seem to personify everything that was 80s cheese. Clearly movies that rely on mechanical bulls, bartenders and immature relationships were in style. The best was his lousy Texas accent. Compare that to Friday Night Lights.I suggest watching Cocktail and Stir Crazy to start really getting into the dumbing down of film. Also, as a side note Made in America with Ted Danson and Whoopie Goldberg is an awesomely bad movie. I was so shocked to realize I had never watched it. One mor...\n      1\n      False\n    \n    \n      1\n      An archaeologist (Casper Van Dien) stumbles accidentally upon an ancient, 40 foot mummy, well preserved underground in the Nevada desert. They are determined to keep this a secret and call in a Jewish translator to assist in figuring out the history of it. The mummy, as explained at the beginning, is the son of a fallen angel and is one of several giants that apparently existed in \"those days\". In order to save his son from a devastating flood which was predicted to kill everything, he mummifies his son, burying him with several servants for centuries - planning to awaken him years from th...\n      0\n      False\n    \n    \n      2\n      Sudden Impact is a two pronged story. Harry is targeted by the mob who want to kill him and Harry is very glad to return the favour and show them how it's done. This little war puts Harry on suspension which he doesn't care about but he goes away on a little vacation. Now the second part of the story. Someone is killing some punks and Harry gets dragged into this situation where he meets Jennifer spencer a woman with a secret that the little tourist town wants to keep quiet. The police Chief is not a subtle man and he warns Harry to not get involved or cause any trouble. This is Harry Call...\n      1\n      False\n    \n    \n      3\n      It is a superb Swedish film .. it was the first Swedish film I've seen .. it is simple & deep .. what a great combination!.<br /><br />Michael Nyqvist did a great performance as a famous conductor who seeks peace in his hometown.<br /><br />Frida Hallgren was great as his inspirational girlfriend to help him to carry on & never give up.<br /><br />The fight between the conductor and the hypocrite priest who loses his battle with Michael when his wife confronts him And defends Michael's noble cause to help his hometown people finding their own peace in music.<br /><br />The only thing that ...\n      1\n      False\n    \n    \n      4\n      The plot is about a female nurse, named Anna, is caught in the middle of a world-wide chaos as flesh-eating zombies begin rising up and taking over the world and attacking the living. She escapes into the streets and is rescued by a black police officer. So far, so good! I usually enjoy horror movies, but this piece of film doesn't deserve to be called horror. It's not even thrilling, just ridiculous.Even \"the Flintstones\" or \"Kukla, Fran and Ollie\" will give you more excitement. It's like watching a bunch of bloodthirsty drunkards not being able to get into a shopping mall to by more liqu...\n      0\n      False\n    \n  \n\n\n\n\n\nlabels = raw_datasets[0].features[\"label\"].names\nlabels\n\n['neg', 'pos']\n\n\n\nmodel_cls = AutoModelForSequenceClassification\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"roberta-base\"  # \"bert-base-multilingual-cased\"\nn_labels = len(labels)\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n    pretrained_model_name, model_cls=model_cls, config_kwargs={\"num_labels\": n_labels}\n)\n\nhf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)\n\n('roberta',\n transformers.models.roberta.configuration_roberta.RobertaConfig,\n transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast,\n transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification)"
  },
  {
    "objectID": "text.data.core.html#preprocessing",
    "href": "text.data.core.html#preprocessing",
    "title": "Data",
    "section": "Preprocessing",
    "text": "Preprocessing\nStarting with version 2.0, BLURR provides a preprocessing base class that can be used to build task specific pre-processed datasets from pandas DataFrames or Hugging Face Datasets\n\nsource\n\nPreprocessor\n\n Preprocessor (hf_tokenizer:transformers.tokenization_utils_base.PreTraine\n               dTokenizerBase, batch_size:int=1000, text_attr:str='text',\n               text_pair_attr:str=None, is_valid_attr:str='is_valid',\n               tok_kwargs:dict={})\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nbatch_size\nint\n1000\nThe number of examples to process at a time\n\n\ntext_attr\nstr\ntext\nThe attribute holding the text\n\n\ntext_pair_attr\nstr\nNone\nThe attribute holding the text_pair\n\n\nis_valid_attr\nstr\nis_valid\nThe attribute that should be created if your are processing individual training and validation\ndatasets into a single dataset, and will indicate to which each example is associated\n\n\ntok_kwargs\ndict\n{}\nTokenization kwargs that will be applied with calling the tokenizer\n\n\n\n\nsource\n\n\nClassificationPreprocessor\n\n ClassificationPreprocessor (hf_tokenizer:transformers.tokenization_utils_\n                             base.PreTrainedTokenizerBase,\n                             batch_size:int=1000,\n                             is_multilabel:bool=False, id_attr:str=None,\n                             text_attr:str='text',\n                             text_pair_attr:str=None,\n                             label_attrs:str|list[str]='label',\n                             is_valid_attr:str='is_valid',\n                             label_mapping:list[str]=None,\n                             tok_kwargs:dict={})\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nbatch_size\nint\n1000\nThe number of examples to process at a time\n\n\nis_multilabel\nbool\nFalse\nWhether the dataset should be processed for multi-label; if True, will ensure label_attrs are\nconverted to a value of either 0 or 1 indiciating the existence of the class in the example\n\n\nid_attr\nstr\nNone\nThe unique identifier in the dataset\n\n\ntext_attr\nstr\ntext\nThe attribute holding the text\n\n\ntext_pair_attr\nstr\nNone\nThe attribute holding the text_pair\n\n\nlabel_attrs\nstr | list[str]\nlabel\nThe attribute holding the label(s) of the example\n\n\nis_valid_attr\nstr\nis_valid\nThe attribute that should be created if your are processing individual training and validation\ndatasets into a single dataset, and will indicate to which each example is associated\n\n\nlabel_mapping\nlist[str]\nNone\nA list indicating the valid labels for the dataset (optional, defaults to the unique set of labels\nfound in the full dataset)\n\n\ntok_kwargs\ndict\n{}\nTokenization kwargs that will be applied with calling the tokenizer\n\n\n\nStarting with version 2.0, BLURR provides a sequence classification preprocessing class that can be used to preprocess DataFrames or Hugging Face Datasets.\nThis class can be used for preprocessing both multiclass and multilabel classification datasets, and includes a proc_{your_text_attr} and proc_{your_text_pair_attr} (optional) attributes containing your modified text as a result of tokenization (e.g., if you specify a max_length the proc_{your_text_attr} may contain truncated text).\nNote: This class works for both slow and fast tokenizers\n\nUsing a DataFrame\n\npreprocessor = ClassificationPreprocessor(hf_tokenizer, label_mapping=labels, tok_kwargs={\"max_length\": 24})\n\nproc_df = preprocessor.process_df(imdb_df)\nproc_df.columns, len(proc_df)\nproc_df.head(2)\n\n\n\n\n\n  \n    \n      \n      proc_text\n      text\n      label\n      is_valid\n      label_name\n      text_start_char_idx\n      text_end_char_idx\n    \n  \n  \n    \n      0\n      What an overlooked 80's soundtrack. I imagine John Travolta sang some of the songs but in watching\n      What an overlooked 80's soundtrack. I imagine John Travolta sang some of the songs but in watching the movie it did seem to personify everything that was 80s cheese. Clearly movies that rely on mechanical bulls, bartenders and immature relationships were in style. The best was his lousy Texas accent. Compare that to Friday Night Lights.I suggest watching Cocktail and Stir Crazy to start really getting into the dumbing down of film. Also, as a side note Made in America with Ted Danson and Whoopie Goldberg is an awesomely bad movie. I was so shocked to realize I had never watched it. One mor...\n      1\n      False\n      pos\n      0\n      98\n    \n    \n      1\n      An archaeologist (Casper Van Dien) stumbles accidentally upon an ancient, 40 foot mummy, well\n      An archaeologist (Casper Van Dien) stumbles accidentally upon an ancient, 40 foot mummy, well preserved underground in the Nevada desert. They are determined to keep this a secret and call in a Jewish translator to assist in figuring out the history of it. The mummy, as explained at the beginning, is the son of a fallen angel and is one of several giants that apparently existed in \"those days\". In order to save his son from a devastating flood which was predicted to kill everything, he mummifies his son, burying him with several servants for centuries - planning to awaken him years from th...\n      0\n      False\n      neg\n      0\n      93\n    \n  \n\n\n\n\n\n\nUsing a Hugging Face Dataset\n\npreprocessor = ClassificationPreprocessor(hf_tokenizer, label_mapping=labels)\n\nproc_ds = preprocessor.process_hf_dataset(final_ds)\nproc_ds\n\nDataset({\n    features: ['proc_text', 'text', 'label', 'is_valid', 'label_name', 'text_start_char_idx', 'text_end_char_idx'],\n    num_rows: 1200\n})"
  },
  {
    "objectID": "text.data.core.html#mid-level-api",
    "href": "text.data.core.html#mid-level-api",
    "title": "Data",
    "section": "Mid-level API",
    "text": "Mid-level API\nBase tokenization, batch transform, and DataBlock methods\n\nsource\n\nTextInput\n\n TextInput (x, **kwargs)\n\nThe base represenation of your inputs; used by the various fastai show methods\nA TextInput object is returned from the decodes method of BatchDecodeTransform as a means to customize @typedispatched functions like DataLoaders.show_batch and Learner.show_results. The value will the your “input_ids”.\n\nsource\n\n\nBatchTokenizeTransform\n\n BatchTokenizeTransform (hf_arch:str, hf_config:PretrainedConfig,\n                         hf_tokenizer:PreTrainedTokenizerBase,\n                         hf_model:PreTrainedModel,\n                         include_labels:bool=True,\n                         ignore_token_id:int=-100, max_length:int=None,\n                         padding:bool|str=True, truncation:bool|str=True,\n                         is_split_into_words:bool=False,\n                         tok_kwargs:dict={}, **kwargs)\n\nHandles everything you need to assemble a mini-batch of inputs and targets, as well as decode the dictionary produced as a byproduct of the tokenization process in the encodes method.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_arch\nstr\n\nThe abbreviation/name of your Hugging Face transformer architecture (e.b., bert, bart, etc..)\n\n\nhf_config\nPretrainedConfig\n\nA specific configuration instance you want to use\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nhf_model\nPreTrainedModel\n\nA Hugging Face model\n\n\ninclude_labels\nbool\nTrue\nTo control whether the “labels” are included in your inputs. If they are, the loss will be calculated in\nthe model’s forward function and you can simply use PreCalculatedLoss as your Learner’s loss function to use it\n\n\nignore_token_id\nint\n-100\nThe token ID that should be ignored when calculating the loss\n\n\nmax_length\nint\nNone\nTo control the length of the padding/truncation. It can be an integer or None,\nin which case it will default to the maximum length the model can accept.\nIf the model has no specific maximum input length, truncation/padding to max_length is deactivated.\nSee Everything you always wanted to know about padding and truncation\n\n\npadding\nbool | str\nTrue\nTo control the padding applied to your hf_tokenizer during tokenization.\nIf None, will default to ‘False’ or ‘do_not_pad’.\nSee Everything you always wanted to know about padding and truncation\n\n\ntruncation\nbool | str\nTrue\nTo control truncation applied to your hf_tokenizer during tokenization.\nIf None, will default to ‘False’ or ‘do_not_truncate’.\nSee Everything you always wanted to know about padding and truncation\n\n\nis_split_into_words\nbool\nFalse\nThe is_split_into_words argument applied to your hf_tokenizer during tokenization.\nSet this to ‘True’ if your inputs are pre-tokenized (not numericalized) \\\n\n\ntok_kwargs\ndict\n{}\nAny other keyword arguments you want included when using your hf_tokenizer to tokenize your inputs\n\n\nkwargs\n\n\n\n\n\n\nInspired by this article, BatchTokenizeTransform inputs can come in as raw text, a list of words (e.g., tasks like Named Entity Recognition (NER), where you want to predict the label of each token), or as a dictionary that includes extra information you want to use during post-processing.\nOn-the-fly Batch-Time Tokenization:\nPart of the inspiration for this derives from the mechanics of Hugging Face tokenizers, in particular it can return a collated mini-batch of data given a list of sequences. As such, the collating required for our inputs can be done during tokenization before our batch transforms run in a before_batch_tfms transform (where we get a list of examples)! This allows users of BLURR to have everything done dynamically at batch-time without prior preprocessing with at least four potential benefits: 1. Less code 2. Faster mini-batch creation 3. Less RAM utilization and time spent tokenizing beforehand (this really helps with very large datasets) 4. Flexibility\n\nsource\n\n\nBatchDecodeTransform\n\n BatchDecodeTransform (input_return_type:type=<class\n                       '__main__.TextInput'>, hf_arch:str=None,\n                       hf_config:PretrainedConfig=None,\n                       hf_tokenizer:PreTrainedTokenizerBase=None,\n                       hf_model:PreTrainedModel=None, **kwargs)\n\nA class used to cast your inputs as input_return_type for fastai show methods\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_return_type\ntype\nTextInput\nUsed by typedispatched show methods\n\n\nhf_arch\nstr\nNone\nThe abbreviation/name of your Hugging Face transformer architecture (not required if passing in an instance of BatchTokenizeTransform to before_batch_tfm)\n\n\nhf_config\nPretrainedConfig\nNone\nA Hugging Face configuration object (not required if passing in an instance of BatchTokenizeTransform to before_batch_tfm)\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\nNone\nA Hugging Face tokenizer (not required if passing in an instance of BatchTokenizeTransform to before_batch_tfm)\n\n\nhf_model\nPreTrainedModel\nNone\nA Hugging Face model (not required if passing in an instance of BatchTokenizeTransform to before_batch_tfm)\n\n\nkwargs\n\n\n\n\n\n\nAs of fastai 2.1.5, before batch transforms no longer have a decodes method … and so, I’ve introduced a standard batch transform here, BatchDecodeTransform, (one that occurs “after” the batch has been created) that will do the decoding for us.\n\nsource\n\n\nblurr_sort_func\n\n blurr_sort_func (example, hf_tokenizer:transformers.tokenization_utils_ba\n                  se.PreTrainedTokenizerBase,\n                  is_split_into_words:bool=False, tok_kwargs:dict={})\n\nThis method is used by the SortedDL to ensure your dataset is sorted after tokenization\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nexample\n\n\n\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nis_split_into_words\nbool\nFalse\nThe is_split_into_words argument applied to your hf_tokenizer during tokenization.\nSet this to ‘True’ if your inputs are pre-tokenized (not numericalized)\n\n\ntok_kwargs\ndict\n{}\nAny other keyword arguments you want to include during tokenization\n\n\n\n\nsource\n\n\nTextBlock\n\n TextBlock (hf_arch:str=None,\n            hf_config:transformers.configuration_utils.PretrainedConfig=No\n            ne, hf_tokenizer:transformers.tokenization_utils_base.PreTrain\n            edTokenizerBase=None,\n            hf_model:transformers.modeling_utils.PreTrainedModel=None,\n            include_labels:bool=True, ignore_token_id=-100,\n            batch_tokenize_tfm:__main__.BatchTokenizeTransform=None,\n            batch_decode_tfm:__main__.BatchDecodeTransform=None,\n            max_length:int=None, padding:bool|str=True,\n            truncation:bool|str=True, is_split_into_words:bool=False,\n            input_return_type:type=<class '__main__.TextInput'>,\n            dl_type:fastai.data.load.DataLoader=None,\n            batch_tokenize_kwargs:dict={}, batch_decode_kwargs:dict={},\n            tok_kwargs:dict={}, text_gen_kwargs:dict={}, **kwargs)\n\nThe core TransformBlock to prepare your inputs for training in Blurr with fastai’s DataBlock API\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_arch\nstr\nNone\nThe abbreviation/name of your Hugging Face transformer architecture (not required if passing in an\ninstance of BatchTokenizeTransform to before_batch_tfm)\n\n\nhf_config\nPretrainedConfig\nNone\nA Hugging Face configuration object (not required if passing in an\ninstance of BatchTokenizeTransform to before_batch_tfm)\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\nNone\nA Hugging Face tokenizer (not required if passing in an\ninstance of BatchTokenizeTransform to before_batch_tfm)\n\n\nhf_model\nPreTrainedModel\nNone\nA Hugging Face model (not required if passing in an\ninstance of BatchTokenizeTransform to before_batch_tfm)\n\n\ninclude_labels\nbool\nTrue\nTo control whether the “labels” are included in your inputs. If they are, the loss will be calculated in\nthe model’s forward function and you can simply use PreCalculatedLoss as your Learner’s loss function to use it\n\n\nignore_token_id\nint\n-100\nThe token ID that should be ignored when calculating the loss\n\n\nbatch_tokenize_tfm\nBatchTokenizeTransform\nNone\nThe before_batch_tfm you want to use to tokenize your raw data on the fly\n(defaults to an instance of BatchTokenizeTransform)\n\n\nbatch_decode_tfm\nBatchDecodeTransform\nNone\nThe batch_tfm you want to decode your inputs into a type that can be used in the fastai show methods,\n(defaults to BatchDecodeTransform)\n\n\nmax_length\nint\nNone\nTo control the length of the padding/truncation. It can be an integer or None,\nin which case it will default to the maximum length the model can accept. If the model has no\nspecific maximum input length, truncation/padding to max_length is deactivated.\nSee Everything you always wanted to know about padding and truncation\n\n\npadding\nbool | str\nTrue\nTo control the ‘padding’ applied to your hf_tokenizer during tokenization.\nIf None, will default to ‘False’ or ‘do_not_pad’.\nSee Everything you always wanted to know about padding and truncation\n\n\ntruncation\nbool | str\nTrue\nTo control ‘truncation’ applied to your hf_tokenizer during tokenization.\nIf None, will default to ‘False’ or ‘do_not_truncate’.\nSee Everything you always wanted to know about padding and truncation\n\n\nis_split_into_words\nbool\nFalse\nThe is_split_into_words argument applied to your hf_tokenizer during tokenization.\nSet this to True if your inputs are pre-tokenized (not numericalized)\n\n\ninput_return_type\ntype\nTextInput\nThe return type your decoded inputs should be cast too (used by methods such as show_batch)\n\n\ndl_type\nDataLoader\nNone\nThe type of DataLoader you want created (defaults to SortedDL)\n\n\nbatch_tokenize_kwargs\ndict\n{}\nAny keyword arguments you want applied to your batch_tokenize_tfm\n\n\nbatch_decode_kwargs\ndict\n{}\nAny keyword arguments you want applied to your batch_decode_tfm (will be set as a fastai batch_tfms)\n\n\ntok_kwargs\ndict\n{}\nAny keyword arguments you want your Hugging Face tokenizer to use during tokenization\n\n\ntext_gen_kwargs\ndict\n{}\nAny keyword arguments you want to have applied with generating text\n\n\nkwargs\n\n\n\n\n\n\nA basic DataBlock for our inputs, TextBlock is designed with sensible defaults to minimize user effort in defining their transforms pipeline. It handles setting up your BatchTokenizeTransform and BatchDecodeTransform transforms regardless of data source (e.g., this will work with files, DataFrames, whatever).\nNote: You must either pass in your own instance of a BatchTokenizeTransform class or the Hugging Face objects returned from BLURR.get_hf_objects (e.g.,architecture, config, tokenizer, and model). The other args are optional.\nWe also include a blurr_sort_func that works with SortedDL to properly sort based on the number of tokens in each example."
  },
  {
    "objectID": "text.data.core.html#utility-classes-and-methods",
    "href": "text.data.core.html#utility-classes-and-methods",
    "title": "Data",
    "section": "Utility classes and methods",
    "text": "Utility classes and methods\nThese methods are use internally for getting blurr transforms associated to your DataLoaders\n\nsource\n\nget_blurr_tfm\n\n get_blurr_tfm (tfms_list:fastcore.transform.Pipeline,\n                tfm_class:fastcore.transform.Transform=<class\n                '__main__.BatchTokenizeTransform'>)\n\nGiven a fastai DataLoaders batch transforms, this method can be used to get at a transform instance used in your Blurr DataBlock\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntfms_list\nPipeline\n\nA list of transforms (e.g., dls.after_batch, dls.before_batch, etc…)\n\n\ntfm_class\nTransform\nBatchTokenizeTransform\nThe transform to find\n\n\n\n\nsource\n\n\nfirst_blurr_tfm\n\n first_blurr_tfm (dls:fastai.data.core.DataLoaders,\n                  tfms:list[fastcore.transform.Transform]=[<class\n                  '__main__.BatchTokenizeTransform'>, <class\n                  '__main__.BatchDecodeTransform'>])\n\nThis convenience method will find the first Blurr transform required for methods such as show_batch and show_results. The returned transform should have everything you need to properly decode and ‘show’ your Hugging Face inputs/targets\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndls\nDataLoaders\n\nYour fast.ai `DataLoaders\n\n\ntfms\nlist[Transform]\n[<class ‘main.BatchTokenizeTransform’>, <class ‘main.BatchDecodeTransform’>]\nThe Blurr transforms to look for in order"
  },
  {
    "objectID": "text.data.core.html#mid-level-examples",
    "href": "text.data.core.html#mid-level-examples",
    "title": "Data",
    "section": "Mid-level Examples",
    "text": "Mid-level Examples\nThe following eamples demonstrate several approaches to construct your DataBlock for sequence classication tasks using the mid-level API.\n\nBatch-Time Tokenization\n\nStep 1: Get your Hugging Face objects.\nThere are a bunch of ways we can get at the four Hugging Face elements we need (e.g., architecture name, tokenizer, config, and model). We can just create them directly, or we can use one of the helper methods available via NLP.\n\nmodel_cls = AutoModelForSequenceClassification\n\npretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\n\n\nStep 2: Create your DataBlock\n\nblocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, batch_tokenize_kwargs={\"labels\": labels}), CategoryBlock)\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(\"label\"), splitter=ColSplitter())\n\n\n\nStep 3: Build your DataLoaders\n\ndls = dblock.dataloaders(imdb_df, bs=4)\n\n\nb = dls.one_batch()\nlen(b), len(b[0][\"input_ids\"]), b[0][\"input_ids\"].shape, len(b[1])\n\n(2, 4, torch.Size([4, 512]), 4)\n\n\n\nb[0]\n\n{'input_ids': tensor([[   0, 5102, 3764,  ..., 1530,   36,    2],\n         [   0,   22,  250,  ..., 5422,  278,    2],\n         [   0, 9342, 1864,  ...,   80,    6,    2],\n         [   0,  318,   47,  ..., 5320,  853,    2]], device='cuda:1'),\n 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 1, 1, 1]], device='cuda:1'),\n 'labels': TensorCategory([1, 0, 1, 1], device='cuda:1')}\n\n\nLet’s take a look at the actual types represented by our batch\n\nexplode_types(b)\n\n{tuple: [dict, fastai.torch_core.TensorCategory]}\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      ANCHORS AWEIGH sees two eager young sailors, Joe Brady (Gene Kelly) and Clarence Doolittle/Brooklyn (Frank Sinatra), get a special four-day shore leave. Eager to get to the girls, particularly Joe's Lola, neither Joe nor Brooklyn figure on the interruption of little Navy-mad Donald (Dean Stockwell) and his Aunt Susie (Kathryn Grayson). Unexperienced in the ways of females and courting, Brooklyn quickly enlists Joe to help him win Aunt Susie over. Along the way, however, Joe finds himself fallin\n      pos\n    \n    \n      1\n      WARNING: POSSIBLE SPOILERS (Not that you should care. Also, sorry for the caps.)<br /><br />Starting with an unnecessarily dramatic voice that's all the more annoying for talking nonsense, it goes on with nonsense and unnecessary drama. That's badly but accurately put.<br /><br />We know space travel is a risky enterprise. There's a complicated system with a lot of potential for malfunctions, radiation, stress-related symptoms etc, and unexpected things are bound to happen in largely unknown en\n      neg\n    \n  \n\n\n\n\n\n\nUsing a preprocessed dataset\nPreprocessing your raw data is the more traditional approach to using Transformers. It is required, for example, when you want to work with documents longer than your model will allow. A preprocessed dataset is used in the same way a non-preprocessed dataset is.\n\nStep 1a: Get your Hugging Face objects.\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\n\n\nStep 1b. Preprocess dataset\n\npreprocessor = ClassificationPreprocessor(hf_tokenizer, label_mapping=labels)\nproc_ds = preprocessor.process_hf_dataset(final_ds)\nproc_ds\n\nDataset({\n    features: ['proc_text', 'text', 'label', 'is_valid', 'label_name', 'text_start_char_idx', 'text_end_char_idx'],\n    num_rows: 1200\n})\n\n\n\n\nStep 2: Create your DataBlock\n\nblocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, batch_tokenize_kwargs={\"labels\": labels}), CategoryBlock)\ndblock = DataBlock(blocks=blocks, get_x=ItemGetter(\"proc_text\"), get_y=ItemGetter(\"label\"), splitter=RandomSplitter())\n\n\n\nStep 3: Build your DataLoaders\n\ndls = dblock.dataloaders(proc_ds, bs=4)\n\n\ndls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      I saw this film at the Adelaide Film Festival '07 and was thoroughly intrigued for all 106 minutes. I like documentaries, but often find them dragging with about 25 minutes to go. Forbidden Lie$ powered on though, never losing my interest.<br /><br />The film's subject is Norma Khoury, a Jordanian woman who found fame and fortune in 2001 with the publication of her book Forbidden Love, a biographical story of sorts concerning a Muslim friend of hers who was murdered by her family for having a r\n      pos\n    \n    \n      1\n      ANCHORS AWEIGH sees two eager young sailors, Joe Brady (Gene Kelly) and Clarence Doolittle/Brooklyn (Frank Sinatra), get a special four-day shore leave. Eager to get to the girls, particularly Joe's Lola, neither Joe nor Brooklyn figure on the interruption of little Navy-mad Donald (Dean Stockwell) and his Aunt Susie (Kathryn Grayson). Unexperienced in the ways of females and courting, Brooklyn quickly enlists Joe to help him win Aunt Susie over. Along the way, however, Joe finds himself fallin\n      pos\n    \n  \n\n\n\n\n\n\nPassing extra information\nAs of v.2, BLURR now also allows you to pass extra information alongside your inputs in the form of a dictionary. If you use this approach, you must assign your text(s) to the text attribute of the dictionary. This is a useful approach when splitting long documents into chunks, but wanting to score/predict by example rather than chunk (for example in extractive question answering tasks).\nNote: A good place to access to this extra information during training/validation is in the before_batch method of a Callback.\n\nblocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, batch_tokenize_kwargs={\"labels\": labels}), CategoryBlock)\n\n\ndef get_x(item):\n    return {\"text\": item.text, \"another_val\": \"testing123\"}\n\n\ndblock = DataBlock(blocks=blocks, get_x=get_x, get_y=ColReader(\"label\"), splitter=ColSplitter())\n\n\ndls = dblock.dataloaders(imdb_df, bs=4)\n\n\nb = dls.one_batch()\nlen(b), len(b[0][\"input_ids\"]), b[0][\"input_ids\"].shape, len(b[1])\n\n(2, 4, torch.Size([4, 512]), 4)\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      ANCHORS AWEIGH sees two eager young sailors, Joe Brady (Gene Kelly) and Clarence Doolittle/Brooklyn (Frank Sinatra), get a special four-day shore leave. Eager to get to the girls, particularly Joe's Lola, neither Joe nor Brooklyn figure on the interruption of little Navy-mad Donald (Dean Stockwell) and his Aunt Susie (Kathryn Grayson). Unexperienced in the ways of females and courting, Brooklyn quickly enlists Joe to help him win Aunt Susie over. Along the way, however, Joe finds himself fallin\n      pos\n    \n    \n      1\n      I've rented and watched this movie for the 1st time on DVD without reading any reviews about it. So, after 15 minutes of watching I've noticed that something is wrong with this movie; it's TERRIBLE! I mean, in the trailers it looked scary and serious!<br /><br />I think that Eli Roth (Mr. Director) thought that if all the characters in this film were stupid, the movie would be funny...(So stupid, it's funny...? WRONG!) He should watch and learn from better horror-comedies such as:\"Fright Night\"\n      neg"
  },
  {
    "objectID": "text.data.core.html#low-level-api",
    "href": "text.data.core.html#low-level-api",
    "title": "Data",
    "section": "Low-level API",
    "text": "Low-level API\nFor working with PyTorch and/or fast.ai Datasets & DataLoaders, the low-level API allows you to get back fast.ai specific features such as show_batch, show_results, etc… when using plain ol’ PyTorch Datasets, Hugging Face Datasets, etc…\n\nsource\n\nTextBatchCreator\n\n TextBatchCreator (hf_arch:str,\n                   hf_config:transformers.configuration_utils.PretrainedCo\n                   nfig, hf_tokenizer:transformers.tokenization_utils_base\n                   .PreTrainedTokenizerBase,\n                   hf_model:transformers.modeling_utils.PreTrainedModel,\n                   data_collator:type=None)\n\nA class that can be assigned to a TfmdDL.create_batch method; used to in Blurr’s low-level API to create batches that can be used in the Blurr library\n\nsource\n\n\nTextDataLoader\n\n TextDataLoader (dataset:torch.utils.data.dataset.Dataset|Datasets,\n                 hf_arch:str, hf_config:PretrainedConfig,\n                 hf_tokenizer:PreTrainedTokenizerBase,\n                 hf_model:PreTrainedModel,\n                 batch_creator:TextBatchCreator=None,\n                 batch_decode_tfm:BatchDecodeTransform=None,\n                 input_return_type:type=<class '__main__.TextInput'>,\n                 preproccesing_func:Callable=None,\n                 batch_decode_kwargs:dict={}, bs:int=64,\n                 shuffle:bool=False, num_workers:int=None,\n                 verbose:bool=False, do_setup:bool=True, pin_memory=False,\n                 timeout=0, batch_size=None, drop_last=False,\n                 indexed=None, n=None, device=None,\n                 persistent_workers=False, pin_memory_device='', wif=None,\n                 before_iter=None, after_item=None, before_batch=None,\n                 after_batch=None, after_iter=None, create_batches=None,\n                 create_item=None, create_batch=None, retain=None,\n                 get_idxs=None, sample=None, shuffle_fn=None,\n                 do_batch=None)\n\nA transformed DataLoader that works with Blurr. From the fastai docs: A TfmDL is described as “a DataLoader that creates Pipeline from a list of Transforms for the callbacks after_item, before_batch and after_batch. As a result, it can decode or show a processed batch.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataset\ntorch.utils.data.dataset.Dataset | Datasets\n\nA standard PyTorch Dataset\n\n\nhf_arch\nstr\n\nThe abbreviation/name of your Hugging Face transformer architecture (not required if passing in an\ninstance of BatchTokenizeTransform to before_batch_tfm)\n\n\nhf_config\nPretrainedConfig\n\nA Hugging Face configuration object (not required if passing in an\ninstance of BatchTokenizeTransform to before_batch_tfm)\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer (not required if passing in an instance of BatchTokenizeTransform to before_batch_tfm)\n\n\nhf_model\nPreTrainedModel\n\nA Hugging Face model (not required if passing in an instance of BatchTokenizeTransform to before_batch_tfm)\n\n\nbatch_creator\nTextBatchCreator\nNone\nAn instance of BlurrBatchCreator or equivalent (defaults to BlurrBatchCreator)\n\n\nbatch_decode_tfm\nBatchDecodeTransform\nNone\nThe batch_tfm used to decode Blurr batches (defaults to BatchDecodeTransform)\n\n\ninput_return_type\ntype\nTextInput\nUsed by typedispatched show methods\n\n\npreproccesing_func\nCallable\nNone\n(optional) A preprocessing function that will be applied to your dataset\n\n\nbatch_decode_kwargs\ndict\n{}\nKeyword arguments to be applied to your batch_decode_tfm\n\n\nbs\nint\n64\n\n\n\nshuffle\nbool\nFalse\n\n\n\nnum_workers\nint\nNone\n\n\n\nverbose\nbool\nFalse\n\n\n\ndo_setup\nbool\nTrue\n\n\n\npin_memory\nbool\nFalse\n\n\n\ntimeout\nint\n0\n\n\n\nbatch_size\nNoneType\nNone\n\n\n\ndrop_last\nbool\nFalse\n\n\n\nindexed\nNoneType\nNone\n\n\n\nn\nNoneType\nNone\n\n\n\ndevice\nNoneType\nNone\n\n\n\npersistent_workers\nbool\nFalse\n\n\n\npin_memory_device\nstr\n\n\n\n\nwif\nNoneType\nNone\n\n\n\nbefore_iter\nNoneType\nNone\n\n\n\nafter_item\nNoneType\nNone\n\n\n\nbefore_batch\nNoneType\nNone\n\n\n\nafter_batch\nNoneType\nNone\n\n\n\nafter_iter\nNoneType\nNone\n\n\n\ncreate_batches\nNoneType\nNone\n\n\n\ncreate_item\nNoneType\nNone\n\n\n\ncreate_batch\nNoneType\nNone\n\n\n\nretain\nNoneType\nNone\n\n\n\nget_idxs\nNoneType\nNone\n\n\n\nsample\nNoneType\nNone\n\n\n\nshuffle_fn\nNoneType\nNone\n\n\n\ndo_batch\nNoneType\nNone"
  },
  {
    "objectID": "text.data.core.html#low-level-examples",
    "href": "text.data.core.html#low-level-examples",
    "title": "Data",
    "section": "Low-level Examples",
    "text": "Low-level Examples\nThe following example demonstrates how to use the low-level API with standard PyTorch/Hugging Face/fast.ai Datasets and DataLoaders.\n\nStep 1: Build your datasets\n\nraw_datasets = load_dataset(\"glue\", \"mrpc\")\n\nReusing dataset glue (/home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n\n\n\n\n\n\ndef tokenize_function(example):\n    return hf_tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n\n\n\n\n\n\n\n\n\n\n\n\nStep 2: Dataset pre-processing (optional)\n\nsource\n\npreproc_hf_dataset\n\n preproc_hf_dataset\n                     (dataset:torch.utils.data.dataset.Dataset|fastai.data\n                     .core.Datasets, hf_tokenizer:transformers.tokenizatio\n                     n_utils_base.PreTrainedTokenizerBase,\n                     hf_model:transformers.modeling_utils.PreTrainedModel)\n\nThis method can be used to preprocess most Hugging Face Datasets for use in Blurr and other training libraries\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndataset\ntorch.utils.data.dataset.Dataset | Datasets\nA standard PyTorch Dataset or fast.ai Datasets\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\nA Hugging Face tokenizer\n\n\nhf_model\nPreTrainedModel\nA Hugging Face model\n\n\n\n\n\n\nStep 3: Build your DataLoaders.\nUse BlurrDataLoader to build Blurr friendly dataloaders from your datasets. Passing {'labels': label_names} to your batch_tfm_kwargs will ensure that your lable/target names will be displayed in methods like show_batch and show_results (just as it works with the mid-level API)\n\nlabel_names = raw_datasets[\"train\"].features[\"label\"].names\n\ntrn_dl = TextDataLoader(\n    tokenized_datasets[\"train\"],\n    hf_arch,\n    hf_config,\n    hf_tokenizer,\n    hf_model,\n    preproccesing_func=preproc_hf_dataset,\n    batch_decode_kwargs={\"labels\": label_names},\n    shuffle=True,\n    batch_size=8,\n)\n\nval_dl = TextDataLoader(\n    tokenized_datasets[\"validation\"],\n    hf_arch,\n    hf_config,\n    hf_tokenizer,\n    hf_model,\n    preproccesing_func=preproc_hf_dataset,\n    batch_decode_kwargs={\"labels\": label_names},\n    batch_size=16,\n)\n\ndls = DataLoaders(trn_dl, val_dl)\n\n\nb = dls.one_batch()\nb[0][\"input_ids\"].shape\n\ntorch.Size([8, 65])\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2, trunc_at=800)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      The technology-laced Nasdaq Composite Index.IXIC inched down 1 point, or 0.11 percent, to 1,650. The broad Standard & Poor's 500 Index.SPX inched up 3 points, or 0.32 percent, to 970.\n      not_equivalent\n    \n    \n      1\n      His 1996 Chevrolet Tahoe was found abandoned June 25 in a Virginia Beach, Va., parking lot. His sport utility vehicle was found June 25, abandoned without its license plates in Virginia Beach, Va.\n      equivalent"
  },
  {
    "objectID": "text.data.core.html#tests",
    "href": "text.data.core.html#tests",
    "title": "Data",
    "section": "Tests",
    "text": "Tests\nThe tests below to ensure the core DataBlock code above works for all pretrained sequence classification models available in Hugging Face. These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\nNote: Feel free to modify the code below to test whatever pretrained classification models you are working with … and if any of your pretrained sequence classification models fail, please submit a github issue (or a PR if you’d like to fix it yourself)\n\n\n\n\n  \n    \n      \n      arch\n      tokenizer\n      model_name\n      result\n      error\n    \n  \n  \n    \n      0\n      albert\n      AlbertTokenizerFast\n      hf-internal-testing/tiny-albert\n      PASSED\n      \n    \n    \n      1\n      bart\n      BartTokenizerFast\n      hf-internal-testing/tiny-random-bart\n      PASSED\n      \n    \n    \n      2\n      bert\n      BertTokenizerFast\n      hf-internal-testing/tiny-bert\n      PASSED\n      \n    \n    \n      3\n      big_bird\n      BigBirdTokenizerFast\n      google/bigbird-roberta-base\n      PASSED\n      \n    \n    \n      4\n      bigbird_pegasus\n      PegasusTokenizerFast\n      google/bigbird-pegasus-large-arxiv\n      PASSED\n      \n    \n    \n      5\n      ctrl\n      CTRLTokenizer\n      hf-internal-testing/tiny-random-ctrl\n      PASSED\n      \n    \n    \n      6\n      camembert\n      CamembertTokenizerFast\n      camembert-base\n      PASSED\n      \n    \n    \n      7\n      canine\n      CanineTokenizer\n      hf-internal-testing/tiny-random-canine\n      PASSED\n      \n    \n    \n      8\n      convbert\n      ConvBertTokenizerFast\n      YituTech/conv-bert-base\n      PASSED\n      \n    \n    \n      9\n      deberta\n      DebertaTokenizerFast\n      hf-internal-testing/tiny-deberta\n      PASSED\n      \n    \n    \n      10\n      deberta_v2\n      DebertaV2TokenizerFast\n      hf-internal-testing/tiny-random-deberta-v2\n      PASSED\n      \n    \n    \n      11\n      distilbert\n      DistilBertTokenizerFast\n      hf-internal-testing/tiny-random-distilbert\n      PASSED\n      \n    \n    \n      12\n      electra\n      ElectraTokenizerFast\n      hf-internal-testing/tiny-electra\n      PASSED\n      \n    \n    \n      13\n      fnet\n      FNetTokenizerFast\n      google/fnet-base\n      PASSED\n      \n    \n    \n      14\n      flaubert\n      FlaubertTokenizer\n      hf-internal-testing/tiny-random-flaubert\n      PASSED\n      \n    \n    \n      15\n      funnel\n      FunnelTokenizerFast\n      hf-internal-testing/tiny-random-funnel\n      PASSED\n      \n    \n    \n      16\n      gpt2\n      GPT2TokenizerFast\n      hf-internal-testing/tiny-random-gpt2\n      PASSED\n      \n    \n    \n      17\n      gptj\n      GPT2TokenizerFast\n      anton-l/gpt-j-tiny-random\n      PASSED\n      \n    \n    \n      18\n      gpt_neo\n      GPT2TokenizerFast\n      hf-internal-testing/tiny-random-gpt_neo\n      PASSED\n      \n    \n    \n      19\n      ibert\n      RobertaTokenizer\n      kssteven/ibert-roberta-base\n      PASSED\n      \n    \n    \n      20\n      led\n      LEDTokenizerFast\n      hf-internal-testing/tiny-random-led\n      PASSED\n      \n    \n    \n      21\n      longformer\n      LongformerTokenizerFast\n      hf-internal-testing/tiny-random-longformer\n      PASSED\n      \n    \n    \n      22\n      mbart\n      MBartTokenizerFast\n      hf-internal-testing/tiny-random-mbart\n      PASSED\n      \n    \n    \n      23\n      mpnet\n      MPNetTokenizerFast\n      hf-internal-testing/tiny-random-mpnet\n      PASSED\n      \n    \n    \n      24\n      mobilebert\n      MobileBertTokenizerFast\n      hf-internal-testing/tiny-random-mobilebert\n      PASSED\n      \n    \n    \n      25\n      openai\n      OpenAIGPTTokenizerFast\n      openai-gpt\n      PASSED\n      \n    \n    \n      26\n      reformer\n      ReformerTokenizerFast\n      google/reformer-crime-and-punishment\n      PASSED\n      \n    \n    \n      27\n      rembert\n      RemBertTokenizerFast\n      google/rembert\n      PASSED\n      \n    \n    \n      28\n      roformer\n      RoFormerTokenizerFast\n      junnyu/roformer_chinese_sim_char_ft_small\n      PASSED\n      \n    \n    \n      29\n      roberta\n      RobertaTokenizerFast\n      roberta-base\n      PASSED\n      \n    \n    \n      30\n      squeezebert\n      SqueezeBertTokenizerFast\n      squeezebert/squeezebert-uncased\n      PASSED\n      \n    \n    \n      31\n      transfo_xl\n      TransfoXLTokenizer\n      hf-internal-testing/tiny-random-transfo-xl\n      PASSED\n      \n    \n    \n      32\n      xlm\n      XLMTokenizer\n      xlm-mlm-en-2048\n      PASSED\n      \n    \n    \n      33\n      xlm_roberta\n      XLMRobertaTokenizerFast\n      xlm-roberta-base\n      PASSED\n      \n    \n    \n      34\n      xlnet\n      XLNetTokenizerFast\n      xlnet-base-cased\n      PASSED\n      \n    \n  \n\n\n\nThe text.data.core module contains the fundamental bits for all data preprocessing tasks"
  },
  {
    "objectID": "text.data.token_classification.html",
    "href": "text.data.token_classification.html",
    "title": "Data",
    "section": "",
    "text": "We’ll use a subset of conll2003 to demonstrate how to configure your blurr code for token classification\n\nraw_datasets = load_dataset(\"conll2003\")\nraw_datasets\n\nReusing dataset conll2003 (/home/wgilliam/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3453\n    })\n})\n\n\nWe need to get a list of the distinct entities we want to predict. If they are represented as list in their raw/readable form in another attribute/column in our dataset, we could use something like this to build a sorted list of distinct values as such: labels = sorted(list(set([lbls for sublist in germ_eval_df.labels.tolist() for lbls in sublist]))).\nFortunately, the conll2003 dataset allows us to get at this list directly using the code below.\n\nprint(raw_datasets[\"train\"].features[\"chunk_tags\"].feature.names[:20])\nprint(raw_datasets[\"train\"].features[\"ner_tags\"].feature.names[:20])\nprint(raw_datasets[\"train\"].features[\"pos_tags\"].feature.names[:20])\n\n['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP']\n['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS']\n\n\n\nlabels = raw_datasets[\"train\"].features[\"ner_tags\"].feature.names\nlabels\n\n['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n\n\n\nconll2003_df = pd.DataFrame(raw_datasets[\"train\"])\n\n\nmodel_cls = AutoModelForTokenClassification\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"roberta-base\"  # \"bert-base-multilingual-cased\"\nn_labels = len(labels)\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n    pretrained_model_name, model_cls=model_cls, config_kwargs={\"num_labels\": n_labels}\n)\n\nhf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)\n\n('roberta',\n transformers.models.roberta.configuration_roberta.RobertaConfig,\n transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast,\n transformers.models.roberta.modeling_roberta.RobertaForTokenClassification)"
  },
  {
    "objectID": "text.data.token_classification.html#preprocessing",
    "href": "text.data.token_classification.html#preprocessing",
    "title": "Data",
    "section": "Preprocessing",
    "text": "Preprocessing\nStarting with version 2.0, BLURR provides a token classification preprocessing class that can be used to preprocess DataFrames or Hugging Face Datasets. We also introduce a novel way of handling long documents for this task that ensures tokens associated to a word is not split up in “chunked” documents. See below for an example.\n\nsource\n\nTokenClassPreprocessor\n\n TokenClassPreprocessor (hf_tokenizer:transformers.tokenization_utils_base\n                         .PreTrainedTokenizerBase,\n                         chunk_examples:bool=False, word_stride:int=2,\n                         ignore_token_id:int=-100,\n                         label_names:Optional[List[str]]=None,\n                         batch_size:int=1000, id_attr:Optional[str]=None,\n                         word_list_attr:str='tokens',\n                         label_list_attr:str='labels',\n                         is_valid_attr:Optional[str]='is_valid',\n                         slow_word_ids_func:Optional[Callable]=None,\n                         tok_kwargs:dict={})\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nchunk_examples\nbool\nFalse\nSet to True if the preprocessor should chunk examples that exceed max_length\n\n\nword_stride\nint\n2\nLike “stride” except for words (not tokens)\n\n\nignore_token_id\nint\n-100\nThe token ID that should be ignored when calculating the loss\n\n\nlabel_names\nOptional\nNone\nThe label names (if not specified, will build from DataFrame)\n\n\nbatch_size\nint\n1000\nThe number of examples to process at a time\n\n\nid_attr\nOptional\nNone\nThe unique identifier in the dataset\n\n\nword_list_attr\nstr\ntokens\nThe attribute holding the list of words\n\n\nlabel_list_attr\nstr\nlabels\nThe attribute holding the list of labels (one for each word in word_list_attr)\n\n\nis_valid_attr\nOptional\nis_valid\nThe attribute that should be created if your are processing individual training and validation\n\n\ndatasets into a single dataset, and will indicate to which each example is associated\n\n\n\n\n\nslow_word_ids_func\nOptional\nNone\nIf using a slow tokenizer, users will need to prove a slow_word_ids_func that accepts a\n\n\n\ntokenizzer, example index, and a batch encoding as arguments and in turn returnes the equavlient of fast tokenizer’s word_ids | | tok_kwargs | dict | {} | Tokenization kwargs that will be applied with calling the tokenizer |\n\nlabels are Ids\n\npreprocessor = TokenClassPreprocessor(\n    hf_tokenizer,\n    chunk_examples=True,\n    word_stride=2,\n    label_names=labels,\n    id_attr=\"id\",\n    word_list_attr=\"tokens\",\n    label_list_attr=\"ner_tags\",\n    tok_kwargs={\"max_length\": 8},\n)\nproc_df = preprocessor.process_df(conll2003_df)\n\nprint(len(proc_df))\nprint(preprocessor.label_names)\nproc_df.head(4)\n\n61298\n['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n\n\n\n\n\n\n  \n    \n      \n      proc_tokens\n      proc_ner_tags\n      id\n      tokens\n      pos_tags\n      chunk_tags\n      ner_tags\n    \n  \n  \n    \n      0\n      [EU, rejects, German, call, to, boycott]\n      [3, 0, 7, 0, 0, 0]\n      0\n      [EU, rejects, German, call, to, boycott, British, lamb, .]\n      [22, 42, 16, 21, 35, 37, 16, 21, 7]\n      [11, 21, 11, 12, 21, 22, 11, 12, 0]\n      [3, 0, 7, 0, 0, 0, 7, 0, 0]\n    \n    \n      1\n      [to, boycott, British, lamb, .]\n      [0, 0, 7, 0, 0]\n      0\n      [EU, rejects, German, call, to, boycott, British, lamb, .]\n      [22, 42, 16, 21, 35, 37, 16, 21, 7]\n      [11, 21, 11, 12, 21, 22, 11, 12, 0]\n      [3, 0, 7, 0, 0, 0, 7, 0, 0]\n    \n    \n      2\n      [Peter, Blackburn]\n      [1, 2]\n      1\n      [Peter, Blackburn]\n      [22, 22]\n      [11, 12]\n      [1, 2]\n    \n    \n      3\n      [BRUSSELS, 1996-08-22]\n      [5, 0]\n      2\n      [BRUSSELS, 1996-08-22]\n      [22, 11]\n      [11, 12]\n      [5, 0]\n    \n  \n\n\n\n\n\n\nlabels are entity names\n\nconll2003_labeled_df = conll2003_df.copy()\nconll2003_labeled_df.ner_tags = conll2003_labeled_df.ner_tags.apply(lambda v: [labels[lbl_id] for lbl_id in v])\nconll2003_labeled_df.head(5)\n\n\n\n\n\n  \n    \n      \n      id\n      tokens\n      pos_tags\n      chunk_tags\n      ner_tags\n    \n  \n  \n    \n      0\n      0\n      [EU, rejects, German, call, to, boycott, British, lamb, .]\n      [22, 42, 16, 21, 35, 37, 16, 21, 7]\n      [11, 21, 11, 12, 21, 22, 11, 12, 0]\n      [B-ORG, O, B-MISC, O, O, O, B-MISC, O, O]\n    \n    \n      1\n      1\n      [Peter, Blackburn]\n      [22, 22]\n      [11, 12]\n      [B-PER, I-PER]\n    \n    \n      2\n      2\n      [BRUSSELS, 1996-08-22]\n      [22, 11]\n      [11, 12]\n      [B-LOC, O]\n    \n    \n      3\n      3\n      [The, European, Commission, said, on, Thursday, it, disagreed, with, German, advice, to, consumers, to, shun, British, lamb, until, scientists, determine, whether, mad, cow, disease, can, be, transmitted, to, sheep, .]\n      [12, 22, 22, 38, 15, 22, 28, 38, 15, 16, 21, 35, 24, 35, 37, 16, 21, 15, 24, 41, 15, 16, 21, 21, 20, 37, 40, 35, 21, 7]\n      [11, 12, 12, 21, 13, 11, 11, 21, 13, 11, 12, 13, 11, 21, 22, 11, 12, 17, 11, 21, 17, 11, 12, 12, 21, 22, 22, 13, 11, 0]\n      [O, B-ORG, I-ORG, O, O, O, O, O, O, B-MISC, O, O, O, O, O, B-MISC, O, O, O, O, O, O, O, O, O, O, O, O, O, O]\n    \n    \n      4\n      4\n      [Germany, 's, representative, to, the, European, Union, 's, veterinary, committee, Werner, Zwingmann, said, on, Wednesday, consumers, should, buy, sheepmeat, from, countries, other, than, Britain, until, the, scientific, advice, was, clearer, .]\n      [22, 27, 21, 35, 12, 22, 22, 27, 16, 21, 22, 22, 38, 15, 22, 24, 20, 37, 21, 15, 24, 16, 15, 22, 15, 12, 16, 21, 38, 17, 7]\n      [11, 11, 12, 13, 11, 12, 12, 11, 12, 12, 12, 12, 21, 13, 11, 12, 21, 22, 11, 13, 11, 1, 13, 11, 17, 11, 12, 12, 21, 1, 0]\n      [B-LOC, O, O, O, O, B-ORG, I-ORG, O, O, O, B-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O]\n    \n  \n\n\n\n\n\npreprocessor = TokenClassPreprocessor(\n    hf_tokenizer, label_names=labels, id_attr=\"id\", word_list_attr=\"tokens\", label_list_attr=\"ner_tags\", tok_kwargs={\"max_length\": 8}\n)\nproc_df = preprocessor.process_df(conll2003_labeled_df)\n\nprint(len(proc_df))\nprint(preprocessor.label_names)\nproc_df.head(4)\n\n14041\n['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n\n\n\n\n\n\n  \n    \n      \n      proc_tokens\n      proc_ner_tags\n      id\n      tokens\n      pos_tags\n      chunk_tags\n      ner_tags\n    \n  \n  \n    \n      0\n      [EU, rejects, German, call, to, boycott]\n      [B-ORG, O, B-MISC, O, O, O]\n      0\n      [EU, rejects, German, call, to, boycott, British, lamb, .]\n      [22, 42, 16, 21, 35, 37, 16, 21, 7]\n      [11, 21, 11, 12, 21, 22, 11, 12, 0]\n      [B-ORG, O, B-MISC, O, O, O, B-MISC, O, O]\n    \n    \n      1\n      [Peter, Blackburn]\n      [B-PER, I-PER]\n      1\n      [Peter, Blackburn]\n      [22, 22]\n      [11, 12]\n      [B-PER, I-PER]\n    \n    \n      2\n      [BRUSSELS, 1996-08-22]\n      [B-LOC, O]\n      2\n      [BRUSSELS, 1996-08-22]\n      [22, 11]\n      [11, 12]\n      [B-LOC, O]\n    \n    \n      3\n      [The, European, Commission, said, on, Thursday]\n      [O, B-ORG, I-ORG, O, O, O]\n      3\n      [The, European, Commission, said, on, Thursday, it, disagreed, with, German, advice, to, consumers, to, shun, British, lamb, until, scientists, determine, whether, mad, cow, disease, can, be, transmitted, to, sheep, .]\n      [12, 22, 22, 38, 15, 22, 28, 38, 15, 16, 21, 35, 24, 35, 37, 16, 21, 15, 24, 41, 15, 16, 21, 21, 20, 37, 40, 35, 21, 7]\n      [11, 12, 12, 21, 13, 11, 11, 21, 13, 11, 12, 13, 11, 21, 22, 11, 12, 17, 11, 21, 17, 11, 12, 12, 21, 22, 22, 13, 11, 0]\n      [O, B-ORG, I-ORG, O, O, O, O, O, O, B-MISC, O, O, O, O, O, B-MISC, O, O, O, O, O, O, O, O, O, O, O, O, O, O]"
  },
  {
    "objectID": "text.data.token_classification.html#labeling-strategies",
    "href": "text.data.token_classification.html#labeling-strategies",
    "title": "Data",
    "section": "Labeling strategies",
    "text": "Labeling strategies\n\nsource\n\nBaseLabelingStrategy\n\n BaseLabelingStrategy (hf_tokenizer:transformers.tokenization_utils_base.P\n                       reTrainedTokenizerBase,\n                       label_names:Optional[List[str]],\n                       non_entity_label:str='O', ignore_token_id:int=-100)\n\nInitialize self. See help(type(self)) for accurate signature.\nHere we include a BaseLabelingStrategy abstract class and several different strategies for assigning labels to your tokenized inputs. The “only first token” and “B/I” labeling strategies are discussed in the “Token Classification” section in part 7 of the Hugging Face’s Transformers course.\n\nsource\n\n\nBILabelingStrategy\n\n BILabelingStrategy (hf_tokenizer:transformers.tokenization_utils_base.Pre\n                     TrainedTokenizerBase,\n                     label_names:Optional[List[str]],\n                     non_entity_label:str='O', ignore_token_id:int=-100)\n\nIf using B/I labels, the first token assoicated to a given word gets the “B” label while all other tokens related to that same word get “I” labels. If “I” labels don’t exist, this strategy behaves like the OnlyFirstTokenLabelingStrategy. Works where labels are Ids or strings (in the later case we’ll use the label_names to look up it’s Id)\n\nsource\n\n\nSameLabelLabelingStrategy\n\n SameLabelLabelingStrategy (hf_tokenizer:transformers.tokenization_utils_b\n                            ase.PreTrainedTokenizerBase,\n                            label_names:Optional[List[str]],\n                            non_entity_label:str='O',\n                            ignore_token_id:int=-100)\n\nEvery token associated with a given word is associated with the word’s label. Works where labels are Ids or strings (in the later case we’ll use the label_names to look up it’s Id)\n\nsource\n\n\nOnlyFirstTokenLabelingStrategy\n\n OnlyFirstTokenLabelingStrategy (hf_tokenizer:transformers.tokenization_ut\n                                 ils_base.PreTrainedTokenizerBase,\n                                 label_names:Optional[List[str]],\n                                 non_entity_label:str='O',\n                                 ignore_token_id:int=-100)\n\nOnly the first token of word is associated with the label (all other subtokens with the ignore_index_id). Works where labels are Ids or strings (in the later case we’ll use the label_names to look up it’s Id)\n\n\nReconstructing inputs/labels\nThe utility methods below allow blurr users to reconstruct the original word/label associations from the input_ids/label associations. For example, these are used in our token classification show_batch method below.\n\n# TESTS for align_labels_with_tokens()\nfor idx in range(3):\n    raw_word_list = conll2003_df.iloc[idx][\"tokens\"]\n    raw_label_list = conll2003_df.iloc[idx][\"ner_tags\"]\n\n    be = hf_tokenizer(raw_word_list, is_split_into_words=True)\n    input_ids = be[\"input_ids\"]\n    targ_ids = [-100 if (word_id == None) else raw_label_list[word_id] for word_id in be.word_ids()]\n\n    tok_labels = get_token_labels_from_input_ids(hf_tokenizer, input_ids, targ_ids, labels)\n\n    for tok_label, targ_id in zip(tok_labels, [label_id for label_id in targ_ids if label_id != -100]):\n        test_eq(tok_label[1], labels[targ_id])\n\n\nsource\n\n\nget_token_labels_from_input_ids\n\n get_token_labels_from_input_ids (hf_tokenizer:transformers.tokenization_u\n                                  tils_base.PreTrainedTokenizerBase,\n                                  input_ids:List[int],\n                                  token_label_ids:List[int],\n                                  vocab:List[str],\n                                  ignore_token_id:int=-100,\n                                  ignore_token:str='[xIGNx]')\n\nGiven a list of input IDs, the label ID associated to each, and the labels vocab, this method will return a list of tuples whereby each tuple defines the “token” and its label name. For example: [(‘ĠWay’, B-PER), (‘de’, B-PER), (‘ĠGill’, I-PER), (‘iam’, I-PER), (‘Ġloves’), (‘ĠHug’, B-ORG), (‘ging’, B-ORG), (‘ĠFace’, I-ORG)]\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\ninput_ids\nList\n\nList of input_ids for the tokens in a single piece of processed text\n\n\ntoken_label_ids\nList\n\nList of label indexs for each token\n\n\nvocab\nList\n\nList of label names from witch the label indicies can be used to find the name of the label\n\n\nignore_token_id\nint\n-100\nThe token ID that should be ignored when calculating the loss\n\n\nignore_token\nstr\n[xIGNx]\nThe token used to identifiy ignored tokens (default: [xIGNx])\n\n\nReturns\nList\n\n\n\n\n\n\n# TESTS for align_labels_with_words()\nfor idx in range(5):\n    raw_word_list = conll2003_df.iloc[idx][\"tokens\"]\n    raw_label_list = conll2003_df.iloc[idx][\"ner_tags\"]\n\n    be = hf_tokenizer(raw_word_list, is_split_into_words=True)\n    input_ids = be[\"input_ids\"]\n    targ_ids = [-100 if (word_id == None) else raw_label_list[word_id] for word_id in be.word_ids()]\n\n    tok_labels = get_token_labels_from_input_ids(hf_tokenizer, input_ids, targ_ids, labels)\n    word_labels = get_word_labels_from_token_labels(hf_arch, hf_tokenizer, tok_labels)\n\n    for word_label, raw_word, raw_label_id in zip(word_labels, raw_word_list, raw_label_list):\n        test_eq(word_label[0], raw_word)\n        test_eq(word_label[1], labels[raw_label_id])\n\n\nsource\n\n\nget_word_labels_from_token_labels\n\n get_word_labels_from_token_labels (hf_arch:str, hf_tokenizer:transformers\n                                    .tokenization_utils_base.PreTrainedTok\n                                    enizerBase, tok_labels)\n\nGiven a list of tuples where each tuple defines a token and its label, return a list of tuples whereby each tuple defines the “word” and its label. Method assumes that model inputs are a list of words, and in conjunction with the align_labels_with_tokens method, allows the user to reconstruct the orginal raw inputs and labels.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nhf_arch\nstr\n\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\nA Hugging Face tokenizer\n\n\ntok_labels\n\nA list of tuples, where each represents a token and its label (e.g., [(‘ĠHug’, B-ORG), (‘ging’, B-ORG), (‘ĠFace’, I-ORG), …])\n\n\nReturns\nList"
  },
  {
    "objectID": "text.data.token_classification.html#mid-level-api",
    "href": "text.data.token_classification.html#mid-level-api",
    "title": "Data",
    "section": "Mid-level API",
    "text": "Mid-level API\n\nsource\n\nTokenTensorCategory\n\n TokenTensorCategory (x, **kwargs)\n\nA Tensor which support subclass pickling, and maintains metadata when casting or after methods\n\nsource\n\n\nTokenCategorize\n\n TokenCategorize (vocab:List[str]=None, ignore_token:str='[xIGNx]',\n                  ignore_token_id:int=-100)\n\nReversible transform of a list of category string to vocab id\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nvocab\nList\nNone\nThe unique list of entities (e.g., B-LOC) (default: CategoryMap(vocab))\n\n\nignore_token\nstr\n[xIGNx]\nThe token used to identifiy ignored tokens (default: xIGNx)\n\n\nignore_token_id\nint\n-100\nThe token ID that should be ignored when calculating the loss (default: CrossEntropyLossFlat().ignore_index)\n\n\n\nTokenCategorize modifies the fastai Categorize transform in a couple of ways.\nFirst, it allows your targets to consist of a Category per token, and second, it uses the idea of an ignore_token_id to mask subtokens that don’t need a prediction. For example, the target of special tokens (e.g., pad, cls, sep) are set to ignore_token_id as are subsequent sub-tokens of a given token should more than 1 sub-token make it up.\n\nsource\n\n\nTokenCategoryBlock\n\n TokenCategoryBlock (vocab:Optional[List[str]]=None,\n                     ignore_token:str='[xIGNx]', ignore_token_id:int=-100)\n\nTransformBlock for per-token categorical targets\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nvocab\nOptional\nNone\nThe unique list of entities (e.g., B-LOC) (default: CategoryMap(vocab))\n\n\nignore_token\nstr\n[xIGNx]\nThe token used to identifiy ignored tokens (default: xIGNx)\n\n\nignore_token_id\nint\n-100\nThe token ID that should be ignored when calculating the loss (default: CrossEntropyLossFlat().ignore_index)\n\n\n\n\nsource\n\n\nTokenClassTextInput\n\n TokenClassTextInput (x, **kwargs)\n\nThe base represenation of your inputs; used by the various fastai show methods\nAgain, we define a custom class, TokenClassTextInput, for the @typedispatched methods to use so that we can override how token classification inputs/targets are assembled, as well as, how the data is shown via methods like show_batch and show_results.\n\nsource\n\n\nTokenClassBatchTokenizeTransform\n\n TokenClassBatchTokenizeTransform (hf_arch:str,\n                                   hf_config:transformers.configuration_ut\n                                   ils.PretrainedConfig, hf_tokenizer:tran\n                                   sformers.tokenization_utils_base.PreTra\n                                   inedTokenizerBase, hf_model:transformer\n                                   s.modeling_utils.PreTrainedModel,\n                                   include_labels:bool=True,\n                                   ignore_token_id:int=-100, labeling_stra\n                                   tegy_cls:__main__.BaseLabelingStrategy=\n                                   <class '__main__.OnlyFirstTokenLabeling\n                                   Strategy'>, target_label_names:Optional\n                                   [List[str]]=None,\n                                   non_entity_label:str='O',\n                                   max_length:Optional[int]=None,\n                                   padding:Union[bool,str]=True,\n                                   truncation:Union[bool,str]=True,\n                                   is_split_into_words:bool=True, slow_wor\n                                   d_ids_func:Optional[Callable]=None,\n                                   tok_kwargs:dict={}, **kwargs)\n\nHandles everything you need to assemble a mini-batch of inputs and targets, as well as decode the dictionary produced as a byproduct of the tokenization process in the encodes method.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_arch\nstr\n\nThe abbreviation/name of your Hugging Face transformer architecture (e.b., bert, bart, etc..)\n\n\nhf_config\nPretrainedConfig\n\nA specific configuration instance you want to use\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nhf_model\nPreTrainedModel\n\nA Hugging Face model\n\n\ninclude_labels\nbool\nTrue\nTo control whether the “labels” are included in your inputs. If they are, the loss will be calculated in\n\n\nthe model’s forward function and you can simply use PreCalculatedLoss as your Learner’s loss function to use it\n\n\n\n\n\nignore_token_id\nint\n-100\nThe token ID that should be ignored when calculating the loss\n\n\nlabeling_strategy_cls\nBaseLabelingStrategy\nOnlyFirstTokenLabelingStrategy\nThe labeling strategy you want to apply when associating labels with word tokens\n\n\ntarget_label_names\nOptional\nNone\nthe target label names\n\n\nnon_entity_label\nstr\nO\nthe label for non-entity\n\n\nmax_length\nOptional\nNone\nTo control the length of the padding/truncation. It can be an integer or None,\n\n\n\nin which case it will default to the maximum length the model can accept. If the model has no specific maximum input length, truncation/padding to max_length is deactivated. See Everything you always wanted to know about padding and truncation | | padding | Union | True | To control the padding applied to your hf_tokenizer during tokenization. If None, will default to False or 'do_not_pad'. See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation) | | truncation | Union | True | To controltruncationapplied to yourhf_tokenizerduring tokenization. If None, will default toFalseordo_not_truncate. See [Everything you always wanted to know about padding and truncation](https://huggingface.co/transformers/preprocessing.html#everything-you-always-wanted-to-know-about-padding-and-truncation) | | is_split_into_words | bool | True | Theis_split_into_wordsargument applied to yourhf_tokenizerduring tokenization. Set this toTrueif your inputs are pre-tokenized (not numericalized) | | slow_word_ids_func | Optional | None | If using a slow tokenizer, users will need to prove aslow_word_ids_functhat accepts a tokenizzer, example index, and a batch encoding as arguments and in turn returnes the equavlient of fast tokenizer'sword_ids`| | tok_kwargs | dict | {} | Any other keyword arguments you want included when using yourhf_tokenizer` to tokenize your inputs | | kwargs | | | |\nTokenClassBatchTokenizeTransform is used to exclude any of the target’s tokens we don’t want to include in the loss calcuation (e.g. padding, cls, sep, etc…).\nNote also that we default is_split_into_words = True since token classification tasks expect a list of words and labels for each word."
  },
  {
    "objectID": "text.data.token_classification.html#examples",
    "href": "text.data.token_classification.html#examples",
    "title": "Data",
    "section": "Examples",
    "text": "Examples\n\nUsing the mid-level API\n\nBatch-Time Tokenization\n\nStep 1: Get your Hugging Face objects.\n\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"distilroberta-base\"\nn_labels = len(labels)\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n    pretrained_model_name, model_cls=AutoModelForTokenClassification, config_kwargs={\"num_labels\": n_labels}\n)\n\nhf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)\n\n('roberta',\n transformers.models.roberta.configuration_roberta.RobertaConfig,\n transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast,\n transformers.models.roberta.modeling_roberta.RobertaForTokenClassification)\n\n\n\n\nStep 2: Create your DataBlock\n\nbatch_tok_tfm = TokenClassBatchTokenizeTransform(\n    hf_arch, hf_config, hf_tokenizer, hf_model, labeling_strategy_cls=BILabelingStrategy, target_label_names=labels\n)\nblocks = (TextBlock(batch_tokenize_tfm=batch_tok_tfm, input_return_type=TokenClassTextInput), TokenCategoryBlock(vocab=labels))\n\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"tokens\"), get_y=ColReader(\"ner_tags\"), splitter=RandomSplitter())\n\n\n\nStep 3: Build your DataLoaders\n\ndls = dblock.dataloaders(conll2003_df, bs=4)\n\n\nb = dls.one_batch()\n\n\nlen(b), b[0][\"input_ids\"].shape, b[1].shape\n\n(2, torch.Size([4, 156]), torch.Size([4, 156]))\n\n\n\ndls.show_batch(dataloaders=dls, max_n=5, trunc_at=20)\n\n\n\n  \n    \n      \n      word / target label\n    \n  \n  \n    \n      0\n      [('MARKET', 'O'), ('TALK', 'O'), ('-', 'O'), ('USDA', 'B-ORG'), ('net', 'O'), ('change', 'O'), ('in', 'O'), ('weekly', 'O'), ('export', 'O'), ('commitments', 'O'), ('for', 'O'), ('the', 'O'), ('week', 'O'), ('ended', 'O'), ('August', 'O'), ('22', 'O'), (',', 'O'), ('includes', 'O'), ('old', 'O'), ('crop', 'O')]\n    \n    \n      1\n      [('Slough', 'B-ORG'), (\"'s\", 'O'), ('chairman', 'O'), ('Sir', 'O'), ('Nigel', 'B-PER'), ('Mobbs', 'I-PER'), ('added', 'O'), ('to', 'O'), ('the', 'O'), ('bullish', 'O'), ('mood', 'O'), ('in', 'O'), ('the', 'O'), ('sector', 'O'), (',', 'O'), ('saying', 'O'), ('in', 'O'), ('a', 'O'), ('statement', 'O'), ('that', 'O')]\n    \n    \n      2\n      [('The', 'O'), ('government-owned', 'O'), ('al-Ingaz', 'B-ORG'), ('al-Watani', 'I-ORG'), ('said', 'O'), ('the', 'O'), ('smugglers', 'O'), ('were', 'O'), ('caught', 'O'), ('in', 'O'), ('Banat', 'B-LOC'), ('in', 'O'), ('the', 'O'), ('eastern', 'O'), ('state', 'O'), ('of', 'O'), ('Kassala', 'B-LOC'), (',', 'O'), ('on', 'O'), ('the', 'O')]\n    \n    \n      3\n      [('\"', 'O'), ('The', 'O'), ('ultimatum', 'O'), ('(', 'O'), ('to', 'O'), ('storm', 'O'), ('Grozny', 'B-LOC'), (')', 'O'), ('is', 'O'), ('no', 'O'), ('longer', 'O'), ('an', 'O'), ('issue', 'O'), (',', 'O'), ('\"', 'O'), ('he', 'O'), ('said', 'O'), ('quoting', 'O'), ('Ischinger', 'B-PER'), (',', 'O')]\n    \n  \n\n\n\n\n\n\nPassing extra infromation\n\nStep 1b: Get your Hugging Face objects.\n\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"distilroberta-base\"\nn_labels = len(labels)\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n    pretrained_model_name, model_cls=AutoModelForTokenClassification, config_kwargs={\"num_labels\": n_labels}\n)\n\nhf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)\n\n('roberta',\n transformers.models.roberta.configuration_roberta.RobertaConfig,\n transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast,\n transformers.models.roberta.modeling_roberta.RobertaForTokenClassification)\n\n\n\n\nStep 1b. Preprocess dataset\n\npreprocessor = TokenClassPreprocessor(\n    hf_tokenizer,\n    label_names=labels,\n    id_attr=\"id\",\n    word_list_attr=\"tokens\",\n    label_list_attr=\"ner_tags\",\n    tok_kwargs={\"max_length\": 128},\n)\nproc_df = preprocessor.process_df(conll2003_df)\nproc_df.head(2)\n\n\n\n\n\n  \n    \n      \n      proc_tokens\n      proc_ner_tags\n      id\n      tokens\n      pos_tags\n      chunk_tags\n      ner_tags\n    \n  \n  \n    \n      0\n      [EU, rejects, German, call, to, boycott, British, lamb, .]\n      [3, 0, 7, 0, 0, 0, 7, 0, 0]\n      0\n      [EU, rejects, German, call, to, boycott, British, lamb, .]\n      [22, 42, 16, 21, 35, 37, 16, 21, 7]\n      [11, 21, 11, 12, 21, 22, 11, 12, 0]\n      [3, 0, 7, 0, 0, 0, 7, 0, 0]\n    \n    \n      1\n      [Peter, Blackburn]\n      [1, 2]\n      1\n      [Peter, Blackburn]\n      [22, 22]\n      [11, 12]\n      [1, 2]\n    \n  \n\n\n\n\n\n\nStep 2: Create your DataBlock\n\nbatch_tok_tfm = TokenClassBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, target_label_names=labels)\nblocks = (TextBlock(batch_tokenize_tfm=batch_tok_tfm, input_return_type=TokenClassTextInput), TokenCategoryBlock(vocab=labels))\n\n\ndef get_x(item):\n    return {\"id\": item.id, \"text\": item.proc_tokens}\n\n\ndblock = DataBlock(blocks=blocks, get_x=get_x, get_y=ColReader(\"proc_ner_tags\"), splitter=RandomSplitter())\n\n\n\nStep 3: Build your DataLoaders\n\ndls = dblock.dataloaders(proc_df, bs=4)\n\n\nb = dls.one_batch()\nb[0].keys()\n\ndict_keys(['input_ids', 'attention_mask', 'id', 'labels'])\n\n\n\nlen(b), b[0][\"input_ids\"].shape, b[1].shape\n\n(2, torch.Size([4, 130]), torch.Size([4, 130]))\n\n\n\ndls.show_batch(dataloaders=dls, max_n=5, trunc_at=20)\n\n\n\n  \n    \n      \n      word / target label\n    \n  \n  \n    \n      0\n      [('MARKET', 'O'), ('TALK', 'O'), ('-', 'O'), ('USDA', 'B-ORG'), ('net', 'O'), ('change', 'O'), ('in', 'O'), ('weekly', 'O'), ('export', 'O'), ('commitments', 'O'), ('for', 'O'), ('the', 'O'), ('week', 'O'), ('ended', 'O'), ('August', 'O'), ('22', 'O'), (',', 'O'), ('includes', 'O'), ('old', 'O'), ('crop', 'O')]\n    \n    \n      1\n      [('\"', 'O'), ('This', 'O'), ('finding', 'O'), ('is', 'O'), ('important', 'O'), ('because', 'O'), ('one', 'O'), ('of', 'O'), ('the', 'O'), ('jars', 'O'), ('still', 'O'), ('contains', 'O'), ('substances', 'O'), ('and', 'O'), ('materials', 'O'), ('used', 'O'), ('in', 'O'), ('the', 'O'), ('conservation', 'O'), ('of', 'O')]\n    \n    \n      2\n      [('\"', 'O'), ('We', 'O'), ('have', 'O'), ('always', 'O'), ('been', 'O'), ('concerned', 'O'), ('about', 'O'), ('barter', 'O'), ('deals', 'O'), ('with', 'O'), ('other', 'O'), ('countries', 'O'), (',', 'O'), ('viewing', 'O'), ('them', 'O'), ('as', 'O'), ('a', 'O'), ('disguised', 'O'), ('kind', 'O'), ('of', 'O')]\n    \n    \n      3\n      [('The', 'O'), ('officials', 'O'), ('had', 'O'), ('been', 'O'), ('positive', 'O'), ('about', 'O'), ('Kinkel', 'B-PER'), (\"'s\", 'O'), ('request', 'O'), ('on', 'O'), ('Wednesday', 'O'), ('that', 'O'), ('President', 'O'), ('Boris', 'B-PER'), ('Yeltsin', 'I-PER'), (\"'s\", 'O'), ('security', 'O'), ('chief', 'O'), ('Alexander', 'B-PER'), ('Lebed', 'I-PER')]"
  },
  {
    "objectID": "text.data.token_classification.html#tests",
    "href": "text.data.token_classification.html#tests",
    "title": "Data",
    "section": "Tests",
    "text": "Tests\nThe tests below to ensure the core DataBlock code above works for all pretrained token classification models available in Hugging Face. These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\nNote: Feel free to modify the code below to test whatever pretrained classification models you are working with … and if any of your pretrained token classification models fail, please submit a github issue (or a PR if you’d like to fix it yourself)\n\nraw_datasets = load_dataset(\"conll2003\")\nconll2003_df = pd.DataFrame(raw_datasets[\"train\"])\n\nlabels = raw_datasets[\"train\"].features[\"ner_tags\"].feature.names\n\nReusing dataset conll2003 (/home/wgilliam/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      arch\n      tokenizer\n      model_name\n      result\n      error\n    \n  \n  \n    \n      0\n      albert\n      AlbertTokenizerFast\n      hf-internal-testing/tiny-albert\n      PASSED\n      \n    \n    \n      1\n      bert\n      BertTokenizerFast\n      hf-internal-testing/tiny-bert\n      PASSED\n      \n    \n    \n      2\n      big_bird\n      BigBirdTokenizerFast\n      google/bigbird-roberta-base\n      PASSED\n      \n    \n    \n      3\n      camembert\n      CamembertTokenizerFast\n      camembert-base\n      PASSED\n      \n    \n    \n      4\n      convbert\n      ConvBertTokenizerFast\n      YituTech/conv-bert-base\n      PASSED\n      \n    \n    \n      5\n      deberta\n      DebertaTokenizerFast\n      hf-internal-testing/tiny-deberta\n      PASSED\n      \n    \n    \n      6\n      bert\n      BertTokenizerFast\n      sshleifer/tiny-distilbert-base-cased\n      PASSED\n      \n    \n    \n      7\n      electra\n      ElectraTokenizerFast\n      hf-internal-testing/tiny-electra\n      PASSED\n      \n    \n    \n      8\n      funnel\n      FunnelTokenizerFast\n      huggingface/funnel-small-base\n      PASSED\n      \n    \n    \n      9\n      gpt2\n      GPT2TokenizerFast\n      sshleifer/tiny-gpt2\n      PASSED\n      \n    \n    \n      10\n      layoutlm\n      LayoutLMTokenizerFast\n      hf-internal-testing/tiny-layoutlm\n      PASSED\n      \n    \n    \n      11\n      longformer\n      LongformerTokenizerFast\n      allenai/longformer-base-4096\n      PASSED\n      \n    \n    \n      12\n      mpnet\n      MPNetTokenizerFast\n      microsoft/mpnet-base\n      PASSED\n      \n    \n    \n      13\n      ibert\n      RobertaTokenizerFast\n      kssteven/ibert-roberta-base\n      PASSED\n      \n    \n    \n      14\n      mobilebert\n      MobileBertTokenizerFast\n      google/mobilebert-uncased\n      PASSED\n      \n    \n    \n      15\n      rembert\n      RemBertTokenizerFast\n      google/rembert\n      PASSED\n      \n    \n    \n      16\n      roformer\n      RoFormerTokenizerFast\n      junnyu/roformer_chinese_sim_char_ft_small\n      PASSED\n      \n    \n    \n      17\n      roberta\n      RobertaTokenizerFast\n      roberta-base\n      PASSED\n      \n    \n    \n      18\n      squeezebert\n      SqueezeBertTokenizerFast\n      squeezebert/squeezebert-uncased\n      PASSED\n      \n    \n    \n      19\n      xlm_roberta\n      XLMRobertaTokenizerFast\n      xlm-roberta-base\n      PASSED\n      \n    \n    \n      20\n      xlnet\n      XLNetTokenizerFast\n      xlnet-base-cased\n      PASSED"
  },
  {
    "objectID": "text.modeling.seq2seq.translation.html",
    "href": "text.modeling.seq2seq.translation.html",
    "title": "Modeling",
    "section": "",
    "text": "The objective in translation is to generate a representation of a given text in another style. For example, we may want to translate German into English or modern English into old English.\n\ndataset = load_dataset(\"wmt16\", \"de-en\", split=\"train\")\ndataset = dataset.shuffle(seed=32).select(range(1200))\nwmt_df = pd.DataFrame(dataset[\"translation\"], columns=[\"de\", \"en\"])\nlen(wmt_df)\nwmt_df.head(2)\n\n\n\n\n\n\n\n\n\n\nDownloading and preparing dataset wmt16/de-en (download: 1.57 GiB, generated: 1.28 GiB, post-processed: Unknown size, total: 2.85 GiB) to /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerating examples from: %s europarl_v7\nGenerating examples from: %s commoncrawl\nGenerating examples from: %s newscommentary_v11\n\n\n\n\n\nGenerating examples from: %s newstest2015\n\n\n\n\n\nGenerating examples from: %s newstest2016\nDataset wmt16 downloaded and prepared to /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f. Subsequent calls will reuse this data.\n\n\n\n\n\n\n  \n    \n      \n      de\n      en\n    \n  \n  \n    \n      0\n      Tada se dio stanovništva preselio uz samu obalu - Pristan, gdje je i nastao Novi grad početkom XX vijeka.\n      In that period the majority of the population moved close to the seaside, where the first sea port was founded at the beginning of the 20th century, and later a new city was built.\n    \n    \n      1\n      \"Dieses Video ist nicht verfügbar loger\" bitch, daß das Böse, der sein Video auf YouTube hochgeladen hatte nearsyx?\n      \"This video is no loger available\" that evil bitch, who had uploaded his video on youtube nearsyx?\n    \n  \n\n\n\n\n\npretrained_model_name = \"Helsinki-NLP/opus-mt-de-en\"\nmodel_cls = AutoModelForSeq2SeqLM\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\nhf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)\n\nhttps://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmppp9i08el\n\n\n\n\n\nstoring https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json in cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\ncreating metadata file for /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\nloading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\nModel config MarianConfig {\n  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"swish\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"MarianMTModel\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bad_words_ids\": [\n    [\n      58100\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 512,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 58100,\n  \"decoder_vocab_size\": 58101,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_length\": 512,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"marian\",\n  \"normalize_before\": false,\n  \"normalize_embedding\": false,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 58100,\n  \"scale_embedding\": true,\n  \"share_encoder_decoder_embeddings\": true,\n  \"static_position_embeddings\": true,\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 58101\n}\n\nhttps://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmpes7wybva\n\n\n\n\n\nstoring https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/tokenizer_config.json in cache at /home/wgilliam/.cache/huggingface/transformers/3bb44a3386cfbb9cb18134066610daf2447a07f2f56a14bed4ef1ffee714851c.ab636688faaa6513d9a830ea57bdb7081f0dda90f9de5e3c857a239f0cc406e7\ncreating metadata file for /home/wgilliam/.cache/huggingface/transformers/3bb44a3386cfbb9cb18134066610daf2447a07f2f56a14bed4ef1ffee714851c.ab636688faaa6513d9a830ea57bdb7081f0dda90f9de5e3c857a239f0cc406e7\nloading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\nModel config MarianConfig {\n  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"swish\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"MarianMTModel\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bad_words_ids\": [\n    [\n      58100\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 512,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 58100,\n  \"decoder_vocab_size\": 58101,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_length\": 512,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"marian\",\n  \"normalize_before\": false,\n  \"normalize_embedding\": false,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 58100,\n  \"scale_embedding\": true,\n  \"share_encoder_decoder_embeddings\": true,\n  \"static_position_embeddings\": true,\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 58101\n}\n\nhttps://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/source.spm not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmpmmic75d1\n\n\n\n\n\nstoring https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/source.spm in cache at /home/wgilliam/.cache/huggingface/transformers/97f9ac1f9bf6b0e421cdf322cd4243cf20650839545200bf6b513ad03c168c8c.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587\ncreating metadata file for /home/wgilliam/.cache/huggingface/transformers/97f9ac1f9bf6b0e421cdf322cd4243cf20650839545200bf6b513ad03c168c8c.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587\nhttps://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target.spm not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmp_780e_84\n\n\n\n\n\nstoring https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target.spm in cache at /home/wgilliam/.cache/huggingface/transformers/1c5dd1c09c6117b6da35a0bfc70dee4e4852bd9f1e019474ccd80f98014806b5.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79\ncreating metadata file for /home/wgilliam/.cache/huggingface/transformers/1c5dd1c09c6117b6da35a0bfc70dee4e4852bd9f1e019474ccd80f98014806b5.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79\nhttps://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmp9veehttl\n\n\n\n\n\nstoring https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/vocab.json in cache at /home/wgilliam/.cache/huggingface/transformers/135ba2ed81322da617731039edec94c1b10b121b5499ea1bcdd7e60040cf4913.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7\ncreating metadata file for /home/wgilliam/.cache/huggingface/transformers/135ba2ed81322da617731039edec94c1b10b121b5499ea1bcdd7e60040cf4913.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/source.spm from cache at /home/wgilliam/.cache/huggingface/transformers/97f9ac1f9bf6b0e421cdf322cd4243cf20650839545200bf6b513ad03c168c8c.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target.spm from cache at /home/wgilliam/.cache/huggingface/transformers/1c5dd1c09c6117b6da35a0bfc70dee4e4852bd9f1e019474ccd80f98014806b5.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/135ba2ed81322da617731039edec94c1b10b121b5499ea1bcdd7e60040cf4913.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target_vocab.json from cache at None\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/3bb44a3386cfbb9cb18134066610daf2447a07f2f56a14bed4ef1ffee714851c.ab636688faaa6513d9a830ea57bdb7081f0dda90f9de5e3c857a239f0cc406e7\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/special_tokens_map.json from cache at None\nloading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\nModel config MarianConfig {\n  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"swish\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"MarianMTModel\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bad_words_ids\": [\n    [\n      58100\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 512,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 58100,\n  \"decoder_vocab_size\": 58101,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_length\": 512,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"marian\",\n  \"normalize_before\": false,\n  \"normalize_embedding\": false,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 58100,\n  \"scale_embedding\": true,\n  \"share_encoder_decoder_embeddings\": true,\n  \"static_position_embeddings\": true,\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 58101\n}\n\nhttps://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/wgilliam/.cache/huggingface/transformers/tmp4evxfupq\n\n\n\n\n\nstoring https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin in cache at /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514\ncreating metadata file for /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514\nloading weights file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514\nAll model checkpoint weights were used when initializing MarianMTModel.\n\nAll the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-de-en.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n\n\n('marian',\n transformers.models.marian.tokenization_marian.MarianTokenizer,\n transformers.models.marian.configuration_marian.MarianConfig,\n transformers.models.marian.modeling_marian.MarianMTModel)\n\n\n\nblocks = (Seq2SeqTextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"de\"), get_y=ColReader(\"en\"), splitter=RandomSplitter())\n\n\ndls = dblock.dataloaders(wmt_df, bs=2)\n\n\nb = dls.one_batch()\n\n\nlen(b), b[0][\"input_ids\"].shape, b[1].shape\n\n(2, torch.Size([2, 168]), torch.Size([2, 140]))\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=250, target_trunc_at=250)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      \"In▁Erwägung▁nachstehender▁Gründe▁sollte das▁Europäische▁Parlament▁keinerlei▁Doppelmoral tolerieren. Indessen und um▁politischen Druck auf▁Journalisten▁auszuüben, die▁Korruptionsfälle aufdecken, die in▁Verbindung mit▁hochrangigen▁Beamten und▁regieren\n      'whereas the European Parliament shall not accept double standards; whereas, in order to put political pressure on journalists disclosing corruption cases linked to high-ranking officials and ruling party politicians, the Government administration in\n    \n    \n      1\n      Es▁ist▁jetzt▁wirklich an der Zeit,▁daß nicht▁nur in▁bezug auf den▁Jahreswirtschaftsbericht und die▁wirtschaftspolitischen▁Leitlinien,▁nein,▁auch in▁bezug auf die▁gesamten▁Fragen zum▁Verfahren zur▁Feststellung des▁übermäßigen▁Defizits und▁auch in▁bezu\n      It really is time for the European Parliament to be given a codecision right that is consistent with the further democratic development of this European Union; that right must apply not just to the annual economic report and the economic policy guide\n    \n  \n\n\n\n\n\n\nseq2seq_metrics = {\"bleu\": {\"returns\": \"bleu\"}, \"meteor\": {\"returns\": \"meteor\"}, \"sacrebleu\": {\"returns\": \"score\"}}\n\nmodel = BaseModelWrapper(hf_model)\nlearn_cbs = [BaseModelCallback]\nfit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n\nlearn = Learner(\n    dls,\n    model,\n    opt_func=partial(Adam),\n    loss_func=PreCalculatedCrossEntropyLoss(),  # CrossEntropyLossFlat()\n    cbs=learn_cbs,\n    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n)\n\n# learn = learn.to_native_fp16() #.to_fp16()\nlearn.freeze()\n\n\n\n\n\n\n\n\n\n\n[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n\n\n\n\n\n\nlearn.summary()\n\n\nb = dls.one_batch()\npreds = learn.model(b[0])\n\nlen(preds), preds[\"loss\"].shape, preds[\"logits\"].shape\n\n(3, torch.Size([]), torch.Size([2, 140, 58101]))\n\n\n\nlen(b), len(b[0]), b[0][\"input_ids\"].shape, len(b[1]), b[1].shape\n\n(2, 3, torch.Size([2, 168]), 2, torch.Size([2, 140]))\n\n\n\nprint(len(learn.opt.param_groups))\n\n3\n\n\n\nlearn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\nSuggestedLRs(minimum=3.981071640737355e-05, steep=6.309573450380412e-07, valley=5.248074739938602e-05, slide=7.585775892948732e-05)\n\n\n\n\n\n\nlearn.fit_one_cycle(1, lr_max=4e-5, cbs=fit_cbs)\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      bleu\n      meteor\n      sacrebleu\n      time\n    \n  \n  \n    \n      0\n      2.088453\n      2.097524\n      0.295524\n      0.543777\n      28.882930\n      00:58\n    \n  \n\n\n\n\n\n\nAnd here we create a @typedispatched implementation of Learner.show_results.\n\nlearn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=500)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      ▁Schließen die▁vorgeschlagenen▁Anwendungszwecke▁Empfehlungen über die▁Bekämpfung von oder den▁Schutz▁gegen▁Organismen ein, die▁unter den in der▁vorgesehenen▁Anwendungsregion▁herrschenden▁Bedingungen in▁bezug auf▁Landwirtschaft,▁Pflanzenschutz und Umwelt -▁einschließlich der▁Witterungsverhältnisse - nach den▁Erfahrungen und dem▁wissenschaftlichen▁Erkenntnisstand nicht▁als▁schädlich▁gelten, oder▁ist▁davon▁auszugehen,▁daß die▁anderen▁Wirkungen▁unter▁diesen▁Bedingungen den▁beabsichtigten▁Zweck nicht\n      Where relevant, yield response when the product is used and reduction of loss in storage must be quantitatively and/or qualitatively similar to those resulting from the use of suitable reference products. If no suitable reference product exists, the plant protection product must be shown to give a consistent and defined quantitative and/or qualitative benefit in terms of yield response and reduction of loss in storage under the agricultural, plant health and environmental (including climatic) co\n      [Where the proposed uses include recommendations on the control of or protection against organisms which are not considered to be harmful under the conditions prevailing in the intended application region in respect of agriculture, plant health and the environment, including climatic conditions, in the light of experience and scientific knowledge, or where it is assumed that the other effects do not meet the intended purpose under such conditions, no authorisation shall be granted for such uses., That is why we have listened to you and asked you to introduce a further transparent consultation procedure on the Anti-Counterfeiting Agreement (ACTA) to ensure that the European Parliament and the citizens represented by this Parliament are regularly and comprehensively informed about the progress of the negotiations, while respecting the confidentiality clauses that you have just explained to us about the agreement.]\n    \n  \n\n\n\n\n\n\nWe add here Learner.blurr_translate method to bring the results inline with the format returned via Hugging Face’s pipeline method\n\ntest_de = \"Ich trinke gerne Bier\"\n\n\noutputs = learn.blurr_generate(test_de, key=\"translation_texts\", num_return_sequences=3)\noutputs\n\n[{'translation_texts': ['I like to drink beer',\n   'I like to drink beer.',\n   'I like drinking beer']}]\n\n\n\nsource\n\n\n\n\n\n Learner.blurr_translate (inp, **kwargs)\n\n\nlearn.blurr_translate(test_de, num_return_sequences=3)\n\n[{'translation_texts': ['I like to drink beer',\n   'I like to drink beer.',\n   'I like drinking beer']}]\n\n\n\n\nUsing fast.ai Learner.export and load_learner\n\nexport_fname = \"translation_export\"\n\n\nlearn.metrics = None\nlearn.export(fname=f\"{export_fname}.pkl\")\n\n\ninf_learn = load_learner(fname=f\"{export_fname}.pkl\")\ninf_learn.blurr_translate(test_de)\n\n[{'translation_texts': 'I like to drink beer'}]"
  },
  {
    "objectID": "text.modeling.seq2seq.translation.html#high-level-api",
    "href": "text.modeling.seq2seq.translation.html#high-level-api",
    "title": "Modeling",
    "section": "High-level API",
    "text": "High-level API\n\nsource\n\nBlearnerForTranslation\n\n BlearnerForTranslation (dls:fastai.data.core.DataLoaders,\n                         hf_model:transformers.modeling_utils.PreTrainedMo\n                         del, base_model_cb:blurr.text.modeling.core.BaseM\n                         odelCallback=<class\n                         'blurr.text.modeling.core.BaseModelCallback'>,\n                         loss_func:callable|None=None, opt_func=<function\n                         Adam>, lr=0.001, splitter:callable=<function\n                         trainable_params>, cbs=None, metrics=None,\n                         path=None, model_dir='models', wd=None,\n                         wd_bn_bias=False, train_bn=True, moms=(0.95,\n                         0.85, 0.95), default_cbs:bool=True)\n\nGroup together a model, some dls and a loss_func to handle training\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndls\n\nDataLoaders containing data for each dataset needed for model\n\n\nhf_model\nPreTrainedModel\n\n\n\n\n\nlearn = BlearnerForTranslation.from_data(\n    wmt_df,\n    \"Helsinki-NLP/opus-mt-de-en\",\n    src_lang_name=\"German\",\n    src_lang_attr=\"de\",\n    trg_lang_name=\"English\",\n    trg_lang_attr=\"en\",\n    dl_kwargs={\"bs\": 2},\n)\n\nloading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\nModel config MarianConfig {\n  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"swish\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"MarianMTModel\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bad_words_ids\": [\n    [\n      58100\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 512,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 58100,\n  \"decoder_vocab_size\": 58101,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_length\": 512,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"marian\",\n  \"normalize_before\": false,\n  \"normalize_embedding\": false,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 58100,\n  \"scale_embedding\": true,\n  \"share_encoder_decoder_embeddings\": true,\n  \"static_position_embeddings\": true,\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 58101\n}\n\nloading weights file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514\nAll model checkpoint weights were used when initializing MarianMTModel.\n\nAll the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-de-en.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\nloading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\nModel config MarianConfig {\n  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"swish\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"MarianMTModel\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bad_words_ids\": [\n    [\n      58100\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 512,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 58100,\n  \"decoder_vocab_size\": 58101,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_length\": 512,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"marian\",\n  \"normalize_before\": false,\n  \"normalize_embedding\": false,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 58100,\n  \"scale_embedding\": true,\n  \"share_encoder_decoder_embeddings\": true,\n  \"static_position_embeddings\": true,\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 58101\n}\n\nloading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\nModel config MarianConfig {\n  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"swish\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"MarianMTModel\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bad_words_ids\": [\n    [\n      58100\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 512,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 58100,\n  \"decoder_vocab_size\": 58101,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_length\": 512,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"marian\",\n  \"normalize_before\": false,\n  \"normalize_embedding\": false,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 58100,\n  \"scale_embedding\": true,\n  \"share_encoder_decoder_embeddings\": true,\n  \"static_position_embeddings\": true,\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 58101\n}\n\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/source.spm from cache at /home/wgilliam/.cache/huggingface/transformers/97f9ac1f9bf6b0e421cdf322cd4243cf20650839545200bf6b513ad03c168c8c.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target.spm from cache at /home/wgilliam/.cache/huggingface/transformers/1c5dd1c09c6117b6da35a0bfc70dee4e4852bd9f1e019474ccd80f98014806b5.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/vocab.json from cache at /home/wgilliam/.cache/huggingface/transformers/135ba2ed81322da617731039edec94c1b10b121b5499ea1bcdd7e60040cf4913.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/target_vocab.json from cache at None\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/tokenizer_config.json from cache at /home/wgilliam/.cache/huggingface/transformers/3bb44a3386cfbb9cb18134066610daf2447a07f2f56a14bed4ef1ffee714851c.ab636688faaa6513d9a830ea57bdb7081f0dda90f9de5e3c857a239f0cc406e7\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/special_tokens_map.json from cache at None\nloading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/config.json from cache at /home/wgilliam/.cache/huggingface/transformers/1854c5c3f3aeab11cfc4ef9f74e960e7bf2300332cd7cdbd83077f02499cdfab.b1412cdfcd82522fbf1b1559d2bb133e7c34f871e99859d46b74f1533daa4757\nModel config MarianConfig {\n  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n  \"_num_labels\": 3,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"swish\",\n  \"add_bias_logits\": false,\n  \"add_final_layer_norm\": false,\n  \"architectures\": [\n    \"MarianMTModel\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bad_words_ids\": [\n    [\n      58100\n    ]\n  ],\n  \"bos_token_id\": 0,\n  \"classif_dropout\": 0.0,\n  \"classifier_dropout\": 0.0,\n  \"d_model\": 512,\n  \"decoder_attention_heads\": 8,\n  \"decoder_ffn_dim\": 2048,\n  \"decoder_layerdrop\": 0.0,\n  \"decoder_layers\": 6,\n  \"decoder_start_token_id\": 58100,\n  \"decoder_vocab_size\": 58101,\n  \"dropout\": 0.1,\n  \"encoder_attention_heads\": 8,\n  \"encoder_ffn_dim\": 2048,\n  \"encoder_layerdrop\": 0.0,\n  \"encoder_layers\": 6,\n  \"eos_token_id\": 0,\n  \"forced_eos_token_id\": 0,\n  \"id2label\": {\n    \"0\": \"LABEL_0\",\n    \"1\": \"LABEL_1\",\n    \"2\": \"LABEL_2\"\n  },\n  \"init_std\": 0.02,\n  \"is_encoder_decoder\": true,\n  \"label2id\": {\n    \"LABEL_0\": 0,\n    \"LABEL_1\": 1,\n    \"LABEL_2\": 2\n  },\n  \"max_length\": 512,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"marian\",\n  \"normalize_before\": false,\n  \"normalize_embedding\": false,\n  \"num_beams\": 4,\n  \"num_hidden_layers\": 6,\n  \"pad_token_id\": 58100,\n  \"scale_embedding\": true,\n  \"share_encoder_decoder_embeddings\": true,\n  \"static_position_embeddings\": true,\n  \"transformers_version\": \"4.18.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 58101\n}\n\nloading weights file https://huggingface.co/Helsinki-NLP/opus-mt-de-en/resolve/main/pytorch_model.bin from cache at /home/wgilliam/.cache/huggingface/transformers/939fa8e38fdeb206b841054406fe90638dbe4a602679798fc35126e90fe54e12.9f2385d4ebdde4e5e8ef144654a4666f40c8423a85f51590fecb88452aec1514\nAll model checkpoint weights were used when initializing MarianMTModel.\n\nAll the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-de-en.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n\n\n\nmetrics_cb = BlearnerForTranslation.get_metrics_cb()\nlearn.fit_one_cycle(1, lr_max=4e-5, cbs=[metrics_cb])\n\n[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      bleu\n      meteor\n      sacrebleu\n      time\n    \n  \n  \n    \n      0\n      2.014099\n      2.172663\n      0.307334\n      0.537191\n      29.823626\n      00:52\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)\n\n\n\n\n\n\n  \n    \n      \n      text\n      target\n      prediction\n    \n  \n  \n    \n      0\n      (IT) Herr▁Präsident, Herr▁Kommissar,▁meine▁Damen und Herren, so▁genau▁wie die▁Entschließung mit dem▁Titel \"Naturkatastrophen\", die von der▁Fraktion der▁Europäischen▁Volkspartei (Christdemokraten)▁vorgelegt wurde,▁ist,▁würde▁ich▁gerne▁trotzdem die▁Aufmerksamkeit auf▁einige▁Punkte▁lenken, die▁heute▁Abend▁angesprochen▁wurden, die▁aber nicht in der▁Entschließung zum▁Thema▁gemacht▁werden, und die▁Gegenstand▁meiner▁Änderungsvorschläge▁sind.\n      (IT) Mr President, Commissioner, ladies and gentlemen, as accurate as the resolution entitled 'Natural disasters', tabled by the Group of the European People's Party (Christian Democrats), is, I would nonetheless like to draw attention to some points\n      [(IT) Mr President, Commissioner, ladies and gentlemen, just as the resolution on natural disasters presented by the Group of the European People's Party (Christian Democrats), I would like to draw attention to some of the points raised this evening, which are not dealt with in the resolution, and which are the subject of my amendments., This Parliament has always been an example and a champion in the defence of human rights, and at this critical time it must prove that it is not doing a common cause with a corrupt dictator in full decline and that it will allow itself to be carried away by the collaboration of some Members who have always been manipulated by this dictatorship.]\n    \n  \n\n\n\n\ntest_de = \"Ich trinke gerne Bier\"\n\n\nlearn.blurr_translate(test_de)\n\n[{'translation_texts': 'I like to drink beer'}]\n\n\n\nexport_fname = \"translation_export\"\n\nlearn.metrics = None\nlearn = learn.to_fp32()\nlearn.export(fname=f\"{export_fname}.pkl\")\n\ninf_learn = load_learner(fname=f\"{export_fname}.pkl\")\ninf_learn.blurr_generate(test_de)\n\n[{'generated_texts': 'I like to drink beer'}]"
  },
  {
    "objectID": "text.modeling.seq2seq.translation.html#tests",
    "href": "text.modeling.seq2seq.translation.html#tests",
    "title": "Modeling",
    "section": "Tests",
    "text": "Tests\nThe purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained translation models below. These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\nNote: Feel free to modify the code below to test whatever pretrained summarization models you are working with … and if any of your pretrained translation models fail, please submit a github issue (or a PR if you’d like to fix it yourself)\n\ntry:\n    del learn\n    torch.cuda.empty_cache()\nexcept:\n    pass\n\n\n[model_type for model_type in NLP.get_models(task=\"ConditionalGeneration\") if (not model_type.startswith(\"TF\"))]\n\n['BartForConditionalGeneration',\n 'BigBirdPegasusForConditionalGeneration',\n 'BlenderbotForConditionalGeneration',\n 'BlenderbotSmallForConditionalGeneration',\n 'FSMTForConditionalGeneration',\n 'LEDForConditionalGeneration',\n 'M2M100ForConditionalGeneration',\n 'MBartForConditionalGeneration',\n 'MT5ForConditionalGeneration',\n 'PLBartForConditionalGeneration',\n 'PegasusForConditionalGeneration',\n 'ProphetNetForConditionalGeneration',\n 'Speech2TextForConditionalGeneration',\n 'T5ForConditionalGeneration',\n 'XLMProphetNetForConditionalGeneration']\n\n\n\npretrained_model_names = [\n    \"facebook/bart-base\",\n    \"facebook/wmt19-de-en\",  # FSMT\n    \"Helsinki-NLP/opus-mt-de-en\",  # MarianMT\n    #'sshleifer/tiny-mbart',\n    #'google/mt5-small',\n    \"t5-small\",\n]\n\n\ndataset = load_dataset(\"wmt16\", \"de-en\", split=\"train\")\ndataset = dataset.shuffle(seed=32).select(range(1200))\nwmt_df = pd.DataFrame(dataset[\"translation\"], columns=[\"de\", \"en\"])\nlen(wmt_df)\n\nReusing dataset wmt16 (/home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f)\nLoading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/wmt16/de-en/1.0.0/af3c5d746b307726d0de73ebe7f10545361b9cb6f75c83a1734c000e48b6264f/cache-8fc54b133c8c43b7.arrow\n\n\n1200\n\n\n\nmodel_cls = AutoModelForSeq2SeqLM\nbsz = 2\ninp_seq_sz = 128\ntrg_seq_sz = 128\n\ntest_results = []\nfor model_name in pretrained_model_names:\n    error = None\n\n    print(f\"=== {model_name} ===\\n\")\n\n    hf_tok_kwargs = {}\n    if model_name == \"sshleifer/tiny-mbart\":\n        hf_tok_kwargs[\"src_lang\"], hf_tok_kwargs[\"tgt_lang\"] = \"de_DE\", \"en_XX\"\n\n    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(model_name, model_cls=model_cls, tokenizer_kwargs=hf_tok_kwargs)\n\n    print(f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n\")\n\n    # 1. build your DataBlock\n    text_gen_kwargs = default_text_gen_kwargs(hf_config, hf_model, task=\"translation\")\n\n    def add_t5_prefix(inp):\n        return f\"translate German to English: {inp}\" if (hf_arch == \"t5\") else inp\n\n    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n        hf_arch,\n        hf_config,\n        hf_tokenizer,\n        hf_model,\n        padding=\"max_length\",\n        max_length=inp_seq_sz,\n        max_target_length=trg_seq_sz,\n        text_gen_kwargs=text_gen_kwargs,\n    )\n\n    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n    dblock = DataBlock(blocks=blocks, get_x=Pipeline([ColReader(\"de\"), add_t5_prefix]), get_y=ColReader(\"en\"), splitter=RandomSplitter())\n\n    dls = dblock.dataloaders(wmt_df, bs=bsz)\n    b = dls.one_batch()\n\n    # 2. build your Learner\n    seq2seq_metrics = {}\n\n    model = BaseModelWrapper(hf_model)\n    fit_cbs = [ShortEpochCallback(0.05, short_valid=True), Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n\n    learn = Learner(\n        dls,\n        model,\n        opt_func=ranger,\n        loss_func=PreCalculatedCrossEntropyLoss(),\n        cbs=[BaseModelCallback],\n        splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n    ).to_fp16()\n\n    learn.create_opt()\n    learn.freeze()\n\n    # 3. Run your tests\n    try:\n        print(\"*** TESTING DataLoaders ***\\n\")\n        test_eq(len(b), 2)\n        test_eq(len(b[0][\"input_ids\"]), bsz)\n        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, inp_seq_sz]))\n        test_eq(len(b[1]), bsz)\n\n        #         print('*** TESTING One pass through the model ***')\n        #         preds = learn.model(b[0])\n        #         test_eq(preds[1].shape[0], bsz)\n        #         test_eq(preds[1].shape[2], hf_config.vocab_size)\n\n        print(\"*** TESTING Training/Results ***\")\n        learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n\n        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"PASSED\", \"\"))\n        learn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)\n    except Exception as err:\n        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"FAILED\", err))\n    finally:\n        # cleanup\n        del learn\n        torch.cuda.empty_cache()\n\n\n\n\n\n  \n    \n      \n      arch\n      tokenizer\n      model_name\n      result\n      error\n    \n  \n  \n    \n      0\n      bart\n      BartTokenizerFast\n      BartForConditionalGeneration\n      PASSED\n      \n    \n    \n      1\n      fsmt\n      FSMTTokenizer\n      FSMTForConditionalGeneration\n      PASSED\n      \n    \n    \n      2\n      marian\n      MarianTokenizer\n      MarianMTModel\n      PASSED\n      \n    \n    \n      3\n      t5\n      T5TokenizerFast\n      T5ForConditionalGeneration\n      PASSED"
  },
  {
    "objectID": "text.modeling.token_classification.html",
    "href": "text.modeling.token_classification.html",
    "title": "Modeling",
    "section": "",
    "text": "We’ll use a subset of conll2003 to demonstrate how to configure your BLURR code for token classification\nNote: Make sure you set the config.num_labels attribute to the number of labels your model is predicting. The model will update its last layer accordingly as la transfer learning.\n\nraw_datasets = load_dataset(\"conll2003\")\n\nlabels = raw_datasets[\"train\"].features[\"ner_tags\"].feature.names\nprint(f\"Labels: {labels}\")\n\nconll2003_df = pd.DataFrame(raw_datasets[\"train\"])\nconll2003_df.head()\n\nReusing dataset conll2003 (/home/wgilliam/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n\n\n\n\n\nLabels: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n\n\n\n\n\n\n  \n    \n      \n      id\n      tokens\n      pos_tags\n      chunk_tags\n      ner_tags\n    \n  \n  \n    \n      0\n      0\n      [EU, rejects, German, call, to, boycott, British, lamb, .]\n      [22, 42, 16, 21, 35, 37, 16, 21, 7]\n      [11, 21, 11, 12, 21, 22, 11, 12, 0]\n      [3, 0, 7, 0, 0, 0, 7, 0, 0]\n    \n    \n      1\n      1\n      [Peter, Blackburn]\n      [22, 22]\n      [11, 12]\n      [1, 2]\n    \n    \n      2\n      2\n      [BRUSSELS, 1996-08-22]\n      [22, 11]\n      [11, 12]\n      [5, 0]\n    \n    \n      3\n      3\n      [The, European, Commission, said, on, Thursday, it, disagreed, with, German, advice, to, consumers, to, shun, British, lamb, until, scientists, determine, whether, mad, cow, disease, can, be, transmitted, to, sheep, .]\n      [12, 22, 22, 38, 15, 22, 28, 38, 15, 16, 21, 35, 24, 35, 37, 16, 21, 15, 24, 41, 15, 16, 21, 21, 20, 37, 40, 35, 21, 7]\n      [11, 12, 12, 21, 13, 11, 11, 21, 13, 11, 12, 13, 11, 21, 22, 11, 12, 17, 11, 21, 17, 11, 12, 12, 21, 22, 22, 13, 11, 0]\n      [0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n    \n    \n      4\n      4\n      [Germany, 's, representative, to, the, European, Union, 's, veterinary, committee, Werner, Zwingmann, said, on, Wednesday, consumers, should, buy, sheepmeat, from, countries, other, than, Britain, until, the, scientific, advice, was, clearer, .]\n      [22, 27, 21, 35, 12, 22, 22, 27, 16, 21, 22, 22, 38, 15, 22, 24, 20, 37, 21, 15, 24, 16, 15, 22, 15, 12, 16, 21, 38, 17, 7]\n      [11, 11, 12, 13, 11, 12, 12, 11, 12, 12, 12, 12, 21, 13, 11, 12, 21, 22, 11, 13, 11, 1, 13, 11, 17, 11, 12, 12, 21, 1, 0]\n      [5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0]\n    \n  \n\n\n\n\n\nmodel_cls = AutoModelForTokenClassification\nhf_logging.set_verbosity_error()\n\npretrained_model_name = \"roberta-base\"\nconfig = AutoConfig.from_pretrained(pretrained_model_name)\n\nconfig.num_labels = len(labels)\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls, config=config)\nhf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)\n\n('roberta',\n transformers.models.roberta.configuration_roberta.RobertaConfig,\n transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast,\n transformers.models.roberta.modeling_roberta.RobertaForTokenClassification)\n\n\n\ntest_eq(hf_config.num_labels, len(labels))\n\n\nbatch_tok_tfm = TokenClassBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model)\nblocks = (TextBlock(batch_tokenize_tfm=batch_tok_tfm, input_return_type=TokenClassTextInput), TokenCategoryBlock(vocab=labels))\n\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"tokens\"), get_y=ColReader(\"ner_tags\"), splitter=RandomSplitter())\n\n\ndls = dblock.dataloaders(conll2003_df, bs=4)\n\n\nb = dls.one_batch()\n\n\ndls.show_batch(dataloaders=dls, max_n=2)\n\n\n\n  \n    \n      \n      word / target label\n    \n  \n  \n    \n      0\n      [('15', 'O'), ('-', 'O'), ('Christian', 'B-PER'), ('Cullen', 'I-PER'), (',', 'O'), ('14', 'O'), ('-', 'O'), ('Jeff', 'B-PER'), ('Wilson', 'I-PER'), (',', 'O'), ('13', 'O'), ('-', 'O'), ('Walter', 'B-PER'), ('Little', 'I-PER'), (',', 'O'), ('12', 'O'), ('-', 'O'), ('Frank', 'B-PER'), ('Bunce', 'I-PER'), (',', 'O'), ('11', 'O'), ('-', 'O'), ('Glen', 'B-PER'), ('Osborne', 'I-PER'), (';', 'O'), ('10', 'O'), ('-', 'O'), ('Andrew', 'B-PER'), ('Mehrtens', 'I-PER'), (',', 'O'), ('9', 'O'), ('-', 'O'), ('Justin', 'B-PER'), ('Marshall', 'I-PER'), (';', 'O'), ('8', 'O'), ('-', 'O'), ('Zinzan', 'B-PER'), ('Brooke', 'I-PER'), (',', 'O'), ('7', 'O'), ('-', 'O'), ('Josh', 'B-PER'), ('Kronfeld', 'I-PER'), (',', 'O'), ('6', 'O'), ('-', 'O'), ('Michael', 'B-PER'), ('Jones', 'I-PER'), (',', 'O'), ('5', 'O'), ('-', 'O'), ('Ian', 'B-PER'), ('Jones', 'I-PER'), (',', 'O'), ('4', 'O'), ('-', 'O'), ('Robin', 'B-PER'), ('Brooke', 'I-PER'), (',', 'O'), ('3', 'O'), ('-', 'O'), ('Olo', 'B-PER'), ('Brown', 'I-PER'), (',', 'O'), ('2', 'O'), ('-', 'O'), ('Sean', 'B-PER'), ('Fitzpatrick', 'I-PER'), ('(', 'O'), ('captain', 'O'), (')', 'O'), (',', 'O'), ('1', 'O'), ('-', 'O'), ('Craig', 'B-PER'), ('Dowd', 'I-PER'), ('.', 'O')]\n    \n    \n      1\n      [('A', 'O'), ('super', 'O'), ('piece', 'O'), ('of', 'O'), ('fielding', 'O'), ('by', 'O'), ('Lewis', 'B-PER'), (',', 'O'), ('dropped', 'O'), ('as', 'O'), ('a', 'O'), ('disciplinary', 'O'), ('measure', 'O'), ('after', 'O'), ('arriving', 'O'), ('only', 'O'), ('35', 'O'), ('minutes', 'O'), ('before', 'O'), ('the', 'O'), ('start', 'O'), ('on', 'O'), ('the', 'O'), ('fourth', 'O'), ('morning', 'O'), (',', 'O'), ('provided', 'O'), ('the', 'O'), ('only', 'O'), ('bright', 'O'), ('spot', 'O'), ('for', 'O'), ('England', 'B-LOC'), ('as', 'O'), ('the', 'O'), ('touring', 'O'), ('team', 'O'), ('batted', 'O'), ('on', 'O'), ('to', 'O'), ('reach', 'O'), ('413', 'O'), ('for', 'O'), ('five', 'O'), ('at', 'O'), ('the', 'O'), ('interval', 'O'), (',', 'O'), ('a', 'O'), ('lead', 'O'), ('of', 'O'), ('87', 'O'), ('.', 'O')]"
  },
  {
    "objectID": "text.modeling.token_classification.html#mid-level-api",
    "href": "text.modeling.token_classification.html#mid-level-api",
    "title": "Modeling",
    "section": "Mid-level API",
    "text": "Mid-level API\nIn this section, we’ll add helpful metrics for token classification tasks\n\nsource\n\ncalculate_token_class_metrics\n\n calculate_token_class_metrics (pred_toks, targ_toks, metric_key)\n\n\nsource\n\n\nTokenClassMetricsCallback\n\n TokenClassMetricsCallback (tok_metrics=['accuracy', 'precision',\n                            'recall', 'f1'], **kwargs)\n\nA fastai friendly callback that includes accuracy, precision, recall, and f1 metrics using the seqeval library. Additionally, this metric knows how to not include your ‘ignore_token’ in it’s calculations.\nSee here for more information on seqeval.\n\n\nExample\n\nTraining\n\nmodel = BaseModelWrapper(hf_model)\nlearn_cbs = [BaseModelCallback]\nfit_cbs = [TokenClassMetricsCallback()]\n\nlearn = Learner(dls, model, opt_func=partial(Adam), loss_func=PreCalculatedCrossEntropyLoss(), cbs=learn_cbs, splitter=blurr_splitter)\n\nlearn.freeze()\n\n\nlearn.summary()\n\n\nb = dls.one_batch()\npreds = learn.model(b[0])\nlen(preds), type(preds), preds.keys()\n\n(2,\n transformers.modeling_outputs.TokenClassifierOutput,\n odict_keys(['loss', 'logits']))\n\n\n\nlen(b), len(b[0]), b[0][\"input_ids\"].shape, len(b[1]), b[1].shape\n\n(2, 3, torch.Size([4, 88]), 4, torch.Size([4, 88]))\n\n\n\n# b[0][\"labels\"].shape\npreds.logits.shape\n\ntorch.Size([4, 88, 9])\n\n\n\nprint(preds.logits.view(-1, preds.logits.shape[-1]).shape, b[1].view(-1).shape)\ntest_eq(preds.logits.view(-1, preds.logits.shape[-1]).shape[0], b[1].view(-1).shape[0])\n\ntorch.Size([352, 9]) torch.Size([352])\n\n\n\nprint(len(learn.opt.param_groups))\n\n3\n\n\n\nlearn.unfreeze()\nlearn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n\n\n\n\n\n\n\n\nSuggestedLRs(minimum=0.0009120108559727668, steep=6.30957365501672e-05, valley=0.00013182566908653826, slide=4.365158383734524e-05)\n\n\n\n\n\n\nlearn.fit_one_cycle(1, lr_max=3e-5, moms=(0.8, 0.7, 0.8), cbs=fit_cbs)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      precision\n      recall\n      f1\n      time\n    \n  \n  \n    \n      0\n      0.065990\n      0.049054\n      0.989001\n      0.941656\n      0.930676\n      0.936134\n      03:12\n    \n  \n\n\n\n\nprint(learn.token_classification_report)\n\n              precision    recall  f1-score   support\n\n         LOC       0.97      0.95      0.96      1439\n        MISC       0.89      0.87      0.88       737\n         ORG       0.91      0.89      0.90      1241\n         PER       0.97      0.98      0.97      1300\n\n   micro avg       0.94      0.93      0.94      4717\n   macro avg       0.93      0.92      0.93      4717\nweighted avg       0.94      0.93      0.94      4717\n\n\n\n\n\nShowing results\nBelow we’ll add in additional functionality to more intuitively show the results of our model.\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=10)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      token / target label / predicted label\n    \n  \n  \n    \n      0\n      [('MARKET', 'O', 'O'), ('TALK', 'O', 'O'), ('-', 'O', 'O'), ('USDA', 'B-ORG', 'B-ORG'), ('net', 'O', 'O'), ('change', 'O', 'O'), ('in', 'O', 'O'), ('weekly', 'O', 'O'), ('export', 'O', 'O'), ('commitments', 'O', 'O')]\n    \n    \n      1\n      [('Innocent', 'B-PER', 'B-PER'), ('Butare', 'I-PER', 'I-PER'), (',', 'O', 'O'), ('executive', 'O', 'O'), ('secretary', 'O', 'O'), ('of', 'O', 'O'), ('the', 'O', 'O'), ('Rally', 'B-ORG', 'B-ORG'), ('for', 'I-ORG', 'I-ORG'), ('the', 'I-ORG', 'I-ORG')]\n    \n  \n\n\n\n\n\nPrediction\nThe default Learner.predict method returns a prediction per subtoken, including the special tokens for each architecture’s tokenizer. Starting with version 2.0 of BLURR, we bring token prediction in-line with Hugging Face’s token classification pipeline, both in terms of supporting the same aggregation strategies via Blurr’s TokenAggregationStrategies class, and also the output via BLURR’s @patched Learner method, blurr_predict_tokens.\n\nsource\n\n\n\nTokenAggregationStrategies\n\n TokenAggregationStrategies (hf_tokenizer:transformers.tokenization_utils_\n                             base.PreTrainedTokenizerBase,\n                             labels:List[str], non_entity_label:str='O')\n\nProvides the equivalanet of Hugging Face’s token classification pipeline’s aggregation_strategy support across various token classication tasks (e.g, NER, POS, chunking, etc…)\n\nsource\n\n\nLearner.blurr_predict_tokens\n\n Learner.blurr_predict_tokens (items:Union[str,List[str]],\n                               aggregation_strategy:str='simple',\n                               non_entity_label:str='O',\n                               slow_word_ids_func:Optional[Callable]=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nitems\nUnion\n\nThe str (or list of strings) you want to get token classification predictions for\n\n\naggregation_strategy\nstr\nsimple\nHow entities are grouped and scored\n\n\nnon_entity_label\nstr\nO\nThe label used to idendity non-entity related words/tokens\n\n\nslow_word_ids_func\nOptional\nNone\nIf using a slow tokenizer, users will need to prove a slow_word_ids_func that accepts a\n\n\n\ntokenizzer, example index, and a batch encoding as arguments and in turn returnes the equavlient of fast tokenizer’s `word_ids`` |\n\nsource\n\n\nLearner.blurr_predict_tokens\n\n Learner.blurr_predict_tokens (items:Union[str,List[str]],\n                               aggregation_strategy:str='simple',\n                               non_entity_label:str='O',\n                               slow_word_ids_func:Optional[Callable]=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nitems\nUnion\n\nThe str (or list of strings) you want to get token classification predictions for\n\n\naggregation_strategy\nstr\nsimple\nHow entities are grouped and scored\n\n\nnon_entity_label\nstr\nO\nThe label used to idendity non-entity related words/tokens\n\n\nslow_word_ids_func\nOptional\nNone\nIf using a slow tokenizer, users will need to prove a slow_word_ids_func that accepts a\n\n\n\ntokenizzer, example index, and a batch encoding as arguments and in turn returnes the equavlient of fast tokenizer’s `word_ids`` |\n\nres = learn.blurr_predict_tokens(\n    items=[\"My name is Wayde and I live in San Diego and using Hugging Face\", \"Bayern Munich is a soccer team in Germany\"],\n    aggregation_strategy=\"max\",\n)\n\nprint(len(res))\nprint(res[1])\n\n2\n[{'entity_group': 'ORG', 'score': 0.9952805638313293, 'word': 'Bayern Munich', 'start': 0, 'end': 13}, {'entity_group': 'LOC', 'score': 0.9980798959732056, 'word': 'Germany', 'start': 34, 'end': 41}]\n\n\n\ntxt = \"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\"\ntxt2 = \"I wish covid was over so I could go to Germany and watch Bayern Munich play in the Bundesliga.\"\n\n\nres = learn.blurr_predict_tokens(txt)\nprint(res)\n\n[[{'entity_group': 'PER', 'score': 0.8786835372447968, 'word': 'Wayde Gilliam', 'start': 15, 'end': 28}, {'entity_group': 'PER', 'score': 0.30589407682418823, 'word': 'oh', 'start': 34, 'end': 36}, {'entity_group': 'ORG', 'score': 0.31899651885032654, 'word': 'meow', 'start': 36, 'end': 40}, {'entity_group': 'LOC', 'score': 0.1332944929599762, 'word': '.', 'start': 44, 'end': 45}, {'entity_group': 'LOC', 'score': 0.9964601397514343, 'word': 'California', 'start': 56, 'end': 66}, {'entity_group': 'LOC', 'score': 0.13329452276229858, 'word': '.', 'start': 66, 'end': 67}]]\n\n\n\nresults = learn.blurr_predict_tokens([txt, txt2])\nfor res in results:\n    print(f\"{res}\\n\")\n\n[{'entity_group': 'PER', 'score': 0.8786835372447968, 'word': 'Wayde Gilliam', 'start': 15, 'end': 28}, {'entity_group': 'PER', 'score': 0.30589407682418823, 'word': 'oh', 'start': 34, 'end': 36}, {'entity_group': 'ORG', 'score': 0.31899651885032654, 'word': 'meow', 'start': 36, 'end': 40}, {'entity_group': 'LOC', 'score': 0.1332944929599762, 'word': '.', 'start': 44, 'end': 45}, {'entity_group': 'LOC', 'score': 0.9964601397514343, 'word': 'California', 'start': 56, 'end': 66}, {'entity_group': 'LOC', 'score': 0.13329452276229858, 'word': '.', 'start': 66, 'end': 67}]\n\n[{'entity_group': 'LOC', 'score': 0.9927727580070496, 'word': 'Germany', 'start': 39, 'end': 46}, {'entity_group': 'ORG', 'score': 0.9933880269527435, 'word': 'Bayern Munich', 'start': 57, 'end': 70}, {'entity_group': 'MISC', 'score': 0.9065296053886414, 'word': 'Bundesliga', 'start': 83, 'end': 93}, {'entity_group': 'ORG', 'score': 0.12906739115715027, 'word': '.', 'start': 93, 'end': 94}]\n\n\n\n\nInference\n\nexport_fname = \"tok_class_learn_export\"\n\n\nlearn.export(fname=f\"{export_fname}.pkl\")\ninf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n\nresults = inf_learn.blurr_predict_tokens([txt, txt2])\nfor res in results:\n    print(f\"{res}\\n\")\n\n[{'entity_group': 'PER', 'score': 0.8786836713552475, 'word': 'Wayde Gilliam', 'start': 15, 'end': 28}, {'entity_group': 'PER', 'score': 0.30589422583580017, 'word': 'oh', 'start': 34, 'end': 36}, {'entity_group': 'ORG', 'score': 0.31899629533290863, 'word': 'meow', 'start': 36, 'end': 40}, {'entity_group': 'LOC', 'score': 0.1332944929599762, 'word': '.', 'start': 44, 'end': 45}, {'entity_group': 'LOC', 'score': 0.9964601397514343, 'word': 'California', 'start': 56, 'end': 66}, {'entity_group': 'LOC', 'score': 0.13329453766345978, 'word': '.', 'start': 66, 'end': 67}]\n\n[{'entity_group': 'LOC', 'score': 0.9927727580070496, 'word': 'Germany', 'start': 39, 'end': 46}, {'entity_group': 'ORG', 'score': 0.9933880269527435, 'word': 'Bayern Munich', 'start': 57, 'end': 70}, {'entity_group': 'MISC', 'score': 0.9065297245979309, 'word': 'Bundesliga', 'start': 83, 'end': 93}, {'entity_group': 'ORG', 'score': 0.12906737625598907, 'word': '.', 'start': 93, 'end': 94}]"
  },
  {
    "objectID": "text.modeling.token_classification.html#high-level-api",
    "href": "text.modeling.token_classification.html#high-level-api",
    "title": "Modeling",
    "section": "High-level API",
    "text": "High-level API\n\nsource\n\nBlearnerForTokenClassification\n\n BlearnerForTokenClassification (dls:fastai.data.core.DataLoaders,\n                                 hf_model:transformers.modeling_utils.PreT\n                                 rainedModel, base_model_cb:blurr.text.mod\n                                 eling.core.BaseModelCallback=<class 'blur\n                                 r.text.modeling.core.BaseModelCallback'>,\n                                 loss_func:callable|None=None,\n                                 opt_func=<function Adam>, lr=0.001,\n                                 splitter:callable=<function\n                                 trainable_params>, cbs=None,\n                                 metrics=None, path=None,\n                                 model_dir='models', wd=None,\n                                 wd_bn_bias=False, train_bn=True,\n                                 moms=(0.95, 0.85, 0.95),\n                                 default_cbs:bool=True)\n\nGroup together a model, some dls and a loss_func to handle training\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndls\n\nDataLoaders containing data for each dataset needed for model\n\n\nhf_model\nPreTrainedModel\n\n\n\n\n\n\nExample\n\nDefine your Blearner\n\nhf_logging.set_verbosity_error()\n\nlearn = BlearnerForTokenClassification.from_data(\n    conll2003_df,\n    \"distilroberta-base\",\n    tokens_attr=\"tokens\",\n    token_labels_attr=\"ner_tags\",\n    labels=labels,\n    dl_kwargs={\"bs\": 2},\n)\n\nlearn.unfreeze()\n\n\nlearn.dls.show_batch(dataloaders=learn.dls, max_n=2)\n\n\n\n  \n    \n      \n      word / target label\n    \n  \n  \n    \n      0\n      [('MARKET', 'O'), ('TALK', 'O'), ('-', 'O'), ('USDA', 'B-ORG'), ('net', 'O'), ('change', 'O'), ('in', 'O'), ('weekly', 'O'), ('export', 'O'), ('commitments', 'O'), ('for', 'O'), ('the', 'O'), ('week', 'O'), ('ended', 'O'), ('August', 'O'), ('22', 'O'), (',', 'O'), ('includes', 'O'), ('old', 'O'), ('crop', 'O'), ('and', 'O'), ('new', 'O'), ('crop', 'O'), (',', 'O'), ('were', 'O'), (':', 'O'), ('wheat', 'O'), ('up', 'O'), ('595,400', 'O'), ('tonnes', 'O'), ('old', 'O'), (',', 'O'), ('nil', 'O'), ('new', 'O'), (';', 'O'), ('corn', 'O'), ('up', 'O'), ('1,900', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('319,600', 'O'), ('new', 'O'), (';', 'O'), ('soybeans', 'O'), ('down', 'O'), ('12,300', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('300,800', 'O'), ('new', 'O'), (';', 'O'), ('upland', 'O'), ('cotton', 'O'), ('up', 'O'), ('50,400', 'O'), ('bales', 'O'), ('new', 'O'), (',', 'O'), ('nil', 'O'), ('old', 'O'), (';', 'O'), ('soymeal', 'O'), ('54,800', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('100,600', 'O'), ('new', 'O'), (',', 'O'), ('soyoil', 'O'), ('nil', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('75,000', 'O'), ('new', 'O'), (';', 'O'), ('barley', 'O'), ('up', 'O'), ('1,700', 'O'), ('old', 'O'), (',', 'O'), ('nil', 'O'), ('new', 'O'), (';', 'O'), ('sorghum', 'O'), ('6,200', 'O'), ('old', 'O'), (',', 'O'), ('up', 'O'), ('156,700', 'O'), ('new', 'O'), (';', 'O'), ('pima', 'O'), ('cotton', 'O'), ('up', 'O'), ('4,000', 'O'), ('bales', 'O'), ('old', 'O'), (',', 'O'), ('nil', 'O'), ('new', 'O'), (';', 'O'), ('rice', 'O'), ('up', 'O'), ('49,900', 'O'), ('old', 'O'), (',', 'O'), ('nil', 'O'), ('new', 'O'), ('...', 'O')]\n    \n    \n      1\n      [('The', 'O'), ('Pirates', 'B-ORG'), (',', 'O'), ('who', 'O'), ('conceded', 'O'), ('earlier', 'O'), ('this', 'O'), ('week', 'O'), ('they', 'O'), ('would', 'O'), ('be', 'O'), ('forced', 'O'), ('to', 'O'), ('trim', 'O'), ('salary', 'O'), ('from', 'O'), ('next', 'O'), ('season', 'O'), (\"'s\", 'O'), ('payroll', 'O'), (',', 'O'), ('received', 'O'), ('Ron', 'B-PER'), ('Wright', 'I-PER'), (',', 'O'), ('a', 'O'), ('first', 'O'), ('baseman', 'O'), ('at', 'O'), ('Double-A', 'O'), ('Greenville', 'B-ORG'), (';', 'O'), ('Corey', 'B-PER'), ('Pointer', 'I-PER'), (',', 'O'), ('a', 'O'), ('pitcher', 'O'), ('at', 'O'), ('Class-A', 'O'), ('Eugene', 'B-ORG'), (',', 'O'), ('and', 'O'), ('a', 'O'), ('player', 'O'), ('to', 'O'), ('be', 'O'), ('named', 'O'), ('.', 'O')]\n    \n  \n\n\n\n\n\nTrain\n\nlearn.fit_one_cycle(1, lr_max=3e-5, moms=(0.8, 0.7, 0.8), cbs=[BlearnerForTokenClassification.get_metrics_cb()])\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      precision\n      recall\n      f1\n      time\n    \n  \n  \n    \n      0\n      0.066553\n      0.050842\n      0.988192\n      0.934066\n      0.930526\n      0.932293\n      03:59\n    \n  \n\n\n\n\nlearn.show_results(learner=learn, max_n=2, trunc_at=10)\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      token / target label / predicted label\n    \n  \n  \n    \n      0\n      [('Innocent', 'B-PER', 'B-PER'), ('Butare', 'I-PER', 'I-PER'), (',', 'O', 'O'), ('executive', 'O', 'O'), ('secretary', 'O', 'O'), ('of', 'O', 'O'), ('the', 'O', 'O'), ('Rally', 'B-ORG', 'B-ORG'), ('for', 'I-ORG', 'I-ORG'), ('the', 'I-ORG', 'I-ORG')]\n    \n    \n      1\n      [('\"', 'O', 'O'), ('I', 'O', 'O'), ('do', 'O', 'O'), (\"n't\", 'O', 'O'), ('know', 'O', 'O'), ('what', 'O', 'O'), ('the', 'O', 'O'), ('source', 'O', 'O'), ('of', 'O', 'O'), ('the', 'O', 'O')]\n    \n  \n\n\n\n\nprint(learn.token_classification_report)\n\n              precision    recall  f1-score   support\n\n         LOC       0.95      0.96      0.95      1401\n        MISC       0.87      0.89      0.88       676\n         ORG       0.91      0.89      0.90      1372\n         PER       0.98      0.97      0.97      1301\n\n   micro avg       0.93      0.93      0.93      4750\n   macro avg       0.93      0.93      0.93      4750\nweighted avg       0.93      0.93      0.93      4750\n\n\n\n\n\nPrediction\n\ntxt = \"Hi! My name is Wayde Gilliam from ohmeow.com. I live in California.\"\ntxt2 = \"I wish covid was over so I could watch Lewandowski score some more goals for Bayern Munich in the Bundesliga.\"\n\n\nresults = learn.predict([txt, txt2])\nfor res in results:\n    print(f\"{res}\\n\")\n\n[{'entity_group': 'PER', 'score': 0.9960938096046448, 'word': 'Way', 'start': 15, 'end': 18}, {'entity_group': 'PER', 'score': 0.9659706950187683, 'word': 'de Gilliam', 'start': 18, 'end': 28}, {'entity_group': 'ORG', 'score': 0.4243549704551697, 'word': 'ohmeow', 'start': 34, 'end': 40}, {'entity_group': 'LOC', 'score': 0.9980984330177307, 'word': 'California', 'start': 56, 'end': 66}]\n\n[{'entity_group': 'PER', 'score': 0.9737088978290558, 'word': 'Lewandowski', 'start': 39, 'end': 50}, {'entity_group': 'ORG', 'score': 0.983256071805954, 'word': 'Bayern Munich', 'start': 77, 'end': 90}, {'entity_group': 'MISC', 'score': 0.957284688949585, 'word': 'Bundesliga', 'start': 98, 'end': 108}]"
  },
  {
    "objectID": "text.modeling.token_classification.html#tests",
    "href": "text.modeling.token_classification.html#tests",
    "title": "Modeling",
    "section": "Tests",
    "text": "Tests\nThe tests below to ensure the token classification training code above works for all pretrained token classification models available in Hugging Face. These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\nNote: Feel free to modify the code below to test whatever pretrained token classification models you are working with … and if any of your pretrained token classification models fail, please submit a github issue (or a PR if you’d like to fix it yourself)\n\nraw_datasets = load_dataset(\"conll2003\")\nlabels = raw_datasets[\"train\"].features[\"ner_tags\"].feature.names\nconll2003_df = pd.DataFrame(raw_datasets[\"train\"])\n\nReusing dataset conll2003 (/home/wgilliam/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      arch\n      tokenizer\n      model_name\n      result\n      error\n    \n  \n  \n    \n      0\n      albert\n      AlbertTokenizerFast\n      AlbertForTokenClassification\n      PASSED\n      \n    \n    \n      1\n      bert\n      BertTokenizerFast\n      BertForTokenClassification\n      PASSED\n      \n    \n    \n      2\n      big_bird\n      BigBirdTokenizerFast\n      BigBirdForTokenClassification\n      PASSED\n      \n    \n    \n      3\n      camembert\n      CamembertTokenizerFast\n      CamembertForTokenClassification\n      PASSED\n      \n    \n    \n      4\n      convbert\n      ConvBertTokenizerFast\n      ConvBertForTokenClassification\n      PASSED\n      \n    \n    \n      5\n      deberta\n      DebertaTokenizerFast\n      DebertaForTokenClassification\n      PASSED\n      \n    \n    \n      6\n      bert\n      BertTokenizerFast\n      BertForTokenClassification\n      PASSED\n      \n    \n    \n      7\n      electra\n      ElectraTokenizerFast\n      ElectraForTokenClassification\n      PASSED\n      \n    \n    \n      8\n      funnel\n      FunnelTokenizerFast\n      FunnelForTokenClassification\n      PASSED\n      \n    \n    \n      9\n      gpt2\n      GPT2TokenizerFast\n      GPT2ForTokenClassification\n      PASSED\n      \n    \n    \n      10\n      layoutlm\n      LayoutLMTokenizerFast\n      LayoutLMForTokenClassification\n      PASSED\n      \n    \n    \n      11\n      longformer\n      LongformerTokenizerFast\n      LongformerForTokenClassification\n      PASSED\n      \n    \n    \n      12\n      mpnet\n      MPNetTokenizerFast\n      MPNetForTokenClassification\n      PASSED\n      \n    \n    \n      13\n      ibert\n      RobertaTokenizerFast\n      IBertForTokenClassification\n      PASSED\n      \n    \n    \n      14\n      mobilebert\n      MobileBertTokenizerFast\n      MobileBertForTokenClassification\n      PASSED\n      \n    \n    \n      15\n      rembert\n      RemBertTokenizerFast\n      RemBertForTokenClassification\n      PASSED\n      \n    \n    \n      16\n      roformer\n      RoFormerTokenizerFast\n      RoFormerForTokenClassification\n      PASSED\n      \n    \n    \n      17\n      roberta\n      RobertaTokenizerFast\n      RobertaForTokenClassification\n      PASSED\n      \n    \n    \n      18\n      squeezebert\n      SqueezeBertTokenizerFast\n      SqueezeBertForTokenClassification\n      PASSED\n      \n    \n    \n      19\n      xlm_roberta\n      XLMRobertaTokenizerFast\n      XLMRobertaForTokenClassification\n      PASSED\n      \n    \n    \n      20\n      xlnet\n      XLNetTokenizerFast\n      XLNetForTokenClassification\n      PASSED"
  },
  {
    "objectID": "text.data.seq2seq.summarization.html",
    "href": "text.data.seq2seq.summarization.html",
    "title": "Data",
    "section": "",
    "text": "We’ll use a subset of cnn_dailymail to demonstrate how to configure your BLURR for summarization tasks\n\nraw_datasets = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=[\"train\", \"validation\"])\nraw_datasets\n\nReusing dataset cnn_dailymail (/home/wgilliam/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n\n\n\n\n\n[Dataset({\n     features: ['article', 'highlights', 'id'],\n     num_rows: 287113\n }),\n Dataset({\n     features: ['article', 'highlights', 'id'],\n     num_rows: 13368\n })]\n\n\n\nprint(raw_datasets[0][0].keys())\nprint(raw_datasets[0][0][\"highlights\"])\n\nprint(raw_datasets[1][0].keys())\nprint(raw_datasets[1][0][\"highlights\"])\n\ndict_keys(['article', 'highlights', 'id'])\nSyrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\nObama sends a letter to the heads of the House and Senate .\nObama to seek congressional approval on military action against Syria .\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .\ndict_keys(['article', 'highlights', 'id'])\nAccident happens in Santa Ynez, California, near where Crosby lives .\nThe jogger suffered multiple fractures; his injuries are not believed to be life-threatening .\n\n\n\nraw_train_ds = raw_datasets[0].shuffle(seed=42).select(range(1000))\nraw_valid_ds = raw_datasets[1].shuffle(seed=42).select(range(200))\n\nlen(raw_train_ds) + len(raw_valid_ds)\n\nLoading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-516bef66c83f0d37.arrow\nLoading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-e7e93c0052828394.arrow\n\n\n1200\n\n\n\nraw_train_df = pd.DataFrame(raw_train_ds)\nraw_valid_df = pd.DataFrame(raw_valid_ds)\n\nraw_train_df.head(2)\n\n\n\n\n\n  \n    \n      \n      article\n      highlights\n      id\n    \n  \n  \n    \n      0\n      A protester in Ferguson was arrested during a demonstration on Thursday night - and live-tweeted her entire experience. Brittany Ferrell, a nursing student at the University of Missouri-Saint Louis, was one of 13 people detained by officers in the conflicted Missouri city for 'noise disruption'. The detention has sparked an investigation by the American Civil Liberties Union as lawyers accuse officers of overstretching their powers. Scroll down for video . Arrested: This is Brittany Ferrell, the nursing student and protester who live-tweeted her arrest in Ferguson . Tweeting in handcuffs, ...\n      Brittany Ferrell, nursing student, was arrested with 12 people on Thursday .\\nThey were calling on police take responsibility for Michael Brown's death .\\nMs Ferrell tweeted as she was arrested, piled in a small wagon with 7 others .\\nThey were accused of 'noise disruption', put in orange jumpsuits and cuffed .\\nOfficers now being investigated, lawyers claim they 'overstretched powers'\n      1e01f238418c31d4e9093f6334e0232babeb639a\n    \n    \n      1\n      A day after confirming it had lost the ability to display Instagram images, Twitter has rolled out its own library of retro filters for its Android and iPhone apps. The eight filters are the usual suspects we've come to expect from mobile photo apps, including desaturated, black and white and high contrast. There are auto-adjust and cropping options, as well as a helpful grid view that lets you see what each filter will look like at once. \"The latest versions of Twitter for iPhone and Twitter for Android introduce a few new ways to enhance the images you tweet,\" said Twitter senior designe...\n      Twitter has added photo filters to its Android and iOS mobile apps .\\nThe addition will help Twitter compete against Facebook-owned Instagram .\\nThis is the first time the social network has offered image editing tools .\n      6f89645bff243fe9ce2a0509e5ca01912abf0d10\n    \n  \n\n\n\n\n\npretrained_model_name = \"sshleifer/distilbart-cnn-6-6\"\nmodel_cls = AutoModelForSeq2SeqLM\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\nhf_arch, type(hf_tokenizer), type(hf_config), type(hf_model)\n\n('bart',\n transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,\n transformers.models.bart.configuration_bart.BartConfig,\n transformers.models.bart.modeling_bart.BartForConditionalGeneration)"
  },
  {
    "objectID": "text.data.seq2seq.summarization.html#preprocessing",
    "href": "text.data.seq2seq.summarization.html#preprocessing",
    "title": "Data",
    "section": "Preprocessing",
    "text": "Preprocessing\nStarting with version 2.0, BLURR provides a preprocessing base class that can be used to build task specific pre-processed datasets from pandas DataFrames or Hugging Face Datasets\n\nsource\n\nSummarizationPreprocessor\n\n SummarizationPreprocessor (hf_tokenizer:transformers.tokenization_utils_b\n                            ase.PreTrainedTokenizerBase,\n                            batch_size:int=1000,\n                            id_attr:Optional[str]=None,\n                            text_attr:str='text',\n                            max_input_tok_length:Optional[int]=None,\n                            target_text_attr:str='summary',\n                            max_target_tok_length:Optional[int]=None,\n                            min_summary_char_length:Optional[int]=None,\n                            is_valid_attr:Optional[str]='is_valid',\n                            tok_kwargs:dict={})\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nhf_tokenizer\nPreTrainedTokenizerBase\n\nA Hugging Face tokenizer\n\n\nbatch_size\nint\n1000\nThe number of examples to process at a time\n\n\nid_attr\nOptional\nNone\nThe unique identifier in the dataset\n\n\ntext_attr\nstr\ntext\nThe attribute holding the text\n\n\nmax_input_tok_length\nOptional\nNone\nThe maximum length (# of tokens) allowed for inputs. Will default to the max length allowed\n\n\nby the model if not provided\n\n\n\n\n\ntarget_text_attr\nstr\nsummary\nThe attribute holding the summary\n\n\nmax_target_tok_length\nOptional\nNone\nThe maximum length (# of tokens) allowed for targets\n\n\nmin_summary_char_length\nOptional\nNone\nIf not “None”, any examples where “target_text_attr” is < “min_summary_char_length” will be removed\n\n\nis_valid_attr\nOptional\nis_valid\nThe attribute that should be created if your are processing individual training and validation\n\n\ndatasets into a single dataset, and will indicate to which each example is associated\n\n\n\n\n\ntok_kwargs\ndict\n{}\nTokenization kwargs that will be applied with calling the tokenizer\n\n\n\nThis class can be used for preprocessing summarization tasks, and includes a proc_{your_text_attr} and proc_{target_text_attr} attributes containing your modified input and target texts as a result of tokenization (e.g., if you specify a max_length the proc_{your_text_attr} may contain truncated text).\n\nUsing a DataFrame\n\npreprocessor = SummarizationPreprocessor(\n    hf_tokenizer,\n    id_attr=\"id\",\n    text_attr=\"article\",\n    target_text_attr=\"highlights\",\n    max_input_tok_length=128,\n    max_target_tok_length=30,\n    min_summary_char_length=10,\n)\nproc_df = preprocessor.process_df(raw_train_df, raw_valid_df)\nproc_df.columns, len(proc_df)\nproc_df.head(2)\n\n\n\n\n\n  \n    \n      \n      proc_highlights\n      proc_article\n      article\n      highlights\n      id\n      is_valid\n      article_start_char_idx\n      article_end_char_idx\n      highlights_start_char_idx\n      highlights_end_char_idx\n    \n  \n  \n    \n      0\n      Brittany Ferrell, nursing student, was arrested with 12 people on Thursday .\\nThey were calling on police take responsibility for Michael Brown's death\n      A protester in Ferguson was arrested during a demonstration on Thursday night - and live-tweeted her entire experience. Brittany Ferrell, a nursing student at the University of Missouri-Saint Louis, was one of 13 people detained by officers in the conflicted Missouri city for 'noise disruption'. The detention has sparked an investigation by the American Civil Liberties Union as lawyers accuse officers of overstretching their powers. Scroll down for video . Arrested: This is Brittany Ferrell, the nursing student and protester who live-tweeted her arrest in Ferguson . Tweeting in handcuffs, ...\n      A protester in Ferguson was arrested during a demonstration on Thursday night - and live-tweeted her entire experience. Brittany Ferrell, a nursing student at the University of Missouri-Saint Louis, was one of 13 people detained by officers in the conflicted Missouri city for 'noise disruption'. The detention has sparked an investigation by the American Civil Liberties Union as lawyers accuse officers of overstretching their powers. Scroll down for video . Arrested: This is Brittany Ferrell, the nursing student and protester who live-tweeted her arrest in Ferguson . Tweeting in handcuffs, ...\n      Brittany Ferrell, nursing student, was arrested with 12 people on Thursday .\\nThey were calling on police take responsibility for Michael Brown's death .\\nMs Ferrell tweeted as she was arrested, piled in a small wagon with 7 others .\\nThey were accused of 'noise disruption', put in orange jumpsuits and cuffed .\\nOfficers now being investigated, lawyers claim they 'overstretched powers'\n      1e01f238418c31d4e9093f6334e0232babeb639a\n      False\n      0\n      648\n      0\n      150\n    \n    \n      1\n      Twitter has added photo filters to its Android and iOS mobile apps .\\nThe addition will help Twitter compete against Facebook-owned Instagram .\\nThis\n      A day after confirming it had lost the ability to display Instagram images, Twitter has rolled out its own library of retro filters for its Android and iPhone apps. The eight filters are the usual suspects we've come to expect from mobile photo apps, including desaturated, black and white and high contrast. There are auto-adjust and cropping options, as well as a helpful grid view that lets you see what each filter will look like at once. \"The latest versions of Twitter for iPhone and Twitter for Android introduce a few new ways to enhance the images you tweet,\" said Twitter senior designe...\n      A day after confirming it had lost the ability to display Instagram images, Twitter has rolled out its own library of retro filters for its Android and iPhone apps. The eight filters are the usual suspects we've come to expect from mobile photo apps, including desaturated, black and white and high contrast. There are auto-adjust and cropping options, as well as a helpful grid view that lets you see what each filter will look like at once. \"The latest versions of Twitter for iPhone and Twitter for Android introduce a few new ways to enhance the images you tweet,\" said Twitter senior designe...\n      Twitter has added photo filters to its Android and iOS mobile apps .\\nThe addition will help Twitter compete against Facebook-owned Instagram .\\nThis is the first time the social network has offered image editing tools .\n      6f89645bff243fe9ce2a0509e5ca01912abf0d10\n      False\n      0\n      635\n      0\n      147"
  },
  {
    "objectID": "text.data.seq2seq.summarization.html#examples",
    "href": "text.data.seq2seq.summarization.html#examples",
    "title": "Data",
    "section": "Examples",
    "text": "Examples\n\nUsing the mid-level API\n\nBatch-Time Tokenization\n\nStep 1: Get your Hugging Face objects.\n\npretrained_model_name = \"facebook/bart-large-cnn\"\nmodel_cls = AutoModelForSeq2SeqLM\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\n\n\nStep 2: Create your DataBlock\nTwo lines! Notice we pass in noop for our targets (e.g. our summaries) because the batch transform will take care of both out inputs and targets.\n\nblocks = (Seq2SeqTextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"article\"), get_y=ColReader(\"highlights\"), splitter=RandomSplitter())\n\n\n# dblock.summary(cnndm_df)\n\n\n\nStep 3: Build your DataLoaders\n\ndls = dblock.dataloaders(raw_train_df, bs=4)\n\n\nb = dls.one_batch()\n\n\nlen(b), b[0][\"input_ids\"].shape, b[0][\"labels\"].shape, b[1].shape\n\n(2, torch.Size([4, 1024]), torch.Size([4, 152]), torch.Size([4, 152]))\n\n\n\nb[0][\"labels\"][0], b[1][0]\n\n(tensor([    0,   270,  3905,  2950,   516,     9,   908,    25,    37,  5586,\n           940,  2355,   375,   479, 50118,  9167,   703,    15,     5,   276,\n           183,  1284,  2922, 11137,  4457,    30,   299,   940,  2355,  3504,\n            11,   188,   469,   479,     2,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100], device='cuda:1'),\n tensor([    0,   270,  3905,  2950,   516,     9,   908,    25,    37,  5586,\n           940,  2355,   375,   479, 50118,  9167,   703,    15,     5,   276,\n           183,  1284,  2922, 11137,  4457,    30,   299,   940,  2355,  3504,\n            11,   188,   469,   479,     2,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n          -100,  -100], device='cuda:1'))\n\n\n\ndls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=1000, target_trunc_at=250)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      <s> By. Daily Mail Reporter. PUBLISHED:. 08:16 EST, 14 May 2012. |. UPDATED:. 22:07 EST, 14 May 2012. Barack Obama's latest campaign gambit follows a familiar line of attack as it uses Mitt Romney's private equity past to cast the Republican candidate as  greedy, job-killing corporate titan with little concern for the working class. The President is not the first of Mr Romney's opponents to try and paint the former governor of Massachusetts as a heartless uber-capitalist - even his Republican rivals used the same tactic during the heated primary battle. But Mr Obama's campaign seems to have been particularly unoriginal - as his attack ad is almost identical to one produced by Ted Kennedy for his Senate campaign against Mr Romney in 1994, featuring unemployed workers complaining about Bain Capital, the firm founded by Mr Romney. The timing of the Obama assault on private equity is also unfortunate, as on Monday night the President attended a fundraiser hosted by Democratic supporter Ham\n      President follows familiar line of attack as he highlights private equity past.\\nAd released on the same day Obama attended fundraiser hosted by top private equity boss in New York.\n    \n    \n      1\n      <s> (CNN) -- Voters in North Carolina, Indiana and Ohio on Tuesday kick off five straight weeks of primary contests that could give us a clearer indication of whether establishment Republicans have the upper hand against the tea party movement for control of the party. The results could back up recent tough talk from Senate GOP leader Mitch McConnell, who predicted big wins for incumbents facing primary challenges from the right, saying, \"I think we are going to crush them everywhere.\" And they may have a major impact in determining whether Republicans retake the majority in the Senate. Since the birth of the tea party movement in 2009, primary challenges from the right have produced major headlines and headaches for the GOP and hurt the party's chances of winning back the Senate from Democrats in the past two election cycles. Candidates backed by the tea party movement and other grass-roots conservatives effectively cost the GOP five winnable Senate elections the last two cycles in Ne\n      Establishment Republicans are fighting back more strongly against challenges from the right.\\nWith a number of vulnerable Democrats in the Senate, GOP thinks it can win control.\\nNorth Carolina primary seen as a key test of establishment-vs.-tea party\n    \n  \n\n\n\n\n\n\nUsing a preprocessed dataset\n\nStep 1a: Get your Hugging Face objects.\n\npretrained_model_name = \"sshleifer/distilbart-cnn-6-6\"\nmodel_cls = AutoModelForSeq2SeqLM\n\nhf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n\n\n\nStep 1b. Preprocess dataset\n\npreprocessor = SummarizationPreprocessor(\n    hf_tokenizer,\n    id_attr=\"id\",\n    text_attr=\"article\",\n    target_text_attr=\"highlights\",\n    max_input_tok_length=128,\n    max_target_tok_length=30,\n    min_summary_char_length=10,\n)\nproc_df = preprocessor.process_df(raw_train_df, raw_valid_df)\n\n\n\nStep 2: Create your DataBlock\n\nblocks = (Seq2SeqTextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), noop)\ndblock = DataBlock(blocks=blocks, get_x=ColReader(\"proc_article\"), get_y=ColReader(\"proc_highlights\"), splitter=ColSplitter())\n\n\n\nStep 3: Build your DataLoaders\n\ndls = dblock.dataloaders(proc_df, bs=4)\n\n\ndls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n\n\n\n  \n    \n      \n      text\n      target\n    \n  \n  \n    \n      0\n      <s> Washington (CNN) -- A post-mortem Sunday of the mid-term elections provided little evidence that Democrats and Republicans will work together to address major issues such as deficit reduction any better than they have in recent years. Republicans interviewed on talk shows promised congressional investigations, an all-out effort to repeal health care reform, and steadfast opposition to any form of higher taxes. Democrats, meanwhile, said the losses they suffered in the congressional elections reflected voter dissatisfaction with lingering high unemployment in the slow recovery from economic recession, rather than an outright repudiation of their policies. Republicans won more than 60 seats formerly held by Democrats to take majority control of </s>\n      GOP targets health care reform, government spending.\\n\"Are we willing to work with him?\" Cantor says of President Obama.\\nObama says\n    \n    \n      1\n      <s> Scientists believe they have discovered how to'switch off' autoimmune diseases, prompting hope the breakthrough could pave the way for a new treatment for multiple sclerosis. Researchers at the University of Bristol, who describe the work as an 'important breakthrough', say it could improve the lives of millions around the world. The study reveals how to stop cells from attacking healthy body tissue. The team discovered how cells convert from being aggressive to protecting against disease, rather than the body's immune system destroying its own tissue by mistake. Scientists at the University of Bristol have discovered how to'switch off' autoimmune diseases, which they hope will pave the way for new </s>\n      Team at Bristol University have described their work as a 'breakthrough'\\nDiscovered a way to stop cells from attacking healthy body tissue.\\n"
  },
  {
    "objectID": "text.data.seq2seq.summarization.html#tests",
    "href": "text.data.seq2seq.summarization.html#tests",
    "title": "Data",
    "section": "Tests",
    "text": "Tests\nThe purpose of the following tests is to ensure as much as possible, that the core DataBlock code above works for the pretrained summarization models below. These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\nNote: Feel free to modify the code below to test whatever pretrained summarization models you are working with … and if any of your pretrained summarization models fail, please submit a github issue (or a PR if you’d like to fix it yourself)\n\n[model_type for model_type in NLP.get_models(task=\"ConditionalGeneration\") if (not model_type.startswith(\"TF\"))]\n\n['BartForConditionalGeneration',\n 'BigBirdPegasusForConditionalGeneration',\n 'BlenderbotForConditionalGeneration',\n 'BlenderbotSmallForConditionalGeneration',\n 'FSMTForConditionalGeneration',\n 'LEDForConditionalGeneration',\n 'M2M100ForConditionalGeneration',\n 'MBartForConditionalGeneration',\n 'MT5ForConditionalGeneration',\n 'PegasusForConditionalGeneration',\n 'ProphetNetForConditionalGeneration',\n 'Speech2TextForConditionalGeneration',\n 'T5ForConditionalGeneration',\n 'XLMProphetNetForConditionalGeneration']\n\n\n\npretrained_model_names = [\n    \"facebook/bart-base\",\n    \"facebook/blenderbot_small-90M\",\n    \"allenai/led-base-16384\",\n    \"google/mt5-small\",\n    \"google/pegasus-cnn_dailymail\",\n    \"t5-small\",\n    \"microsoft/prophetnet-large-uncased\",\n    \"microsoft/xprophetnet-large-wiki100-cased\",  # XLMProphetNet\n]\n\n\npath = Path(\"./\")\ncnndm_df = pd.read_csv(path / \"cnndm_sample.csv\")\n\n\nmodel_cls = AutoModelForSeq2SeqLM\nbsz = 2\nseq_sz = 256\ntrg_seq_sz = 40\n\ntest_results = []\nfor model_name in pretrained_model_names:\n    error = None\n\n    print(f\"=== {model_name} ===\\n\")\n\n    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(model_name, model_cls=model_cls)\n    print(f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\n\")\n\n    # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n    if hf_tokenizer.pad_token is None:\n        hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n        hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n        hf_model.resize_token_embeddings(len(hf_tokenizer))\n\n    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n        hf_arch, hf_config, hf_tokenizer, hf_model, padding=\"max_length\", max_length=seq_sz, max_target_length=trg_seq_sz\n    )\n\n    def add_t5_prefix(inp):\n        return f\"summarize: {inp}\" if (hf_arch == \"t5\") else inp\n\n    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n    dblock = DataBlock(\n        blocks=blocks, get_x=Pipeline([ColReader(\"article\"), add_t5_prefix]), get_y=ColReader(\"highlights\"), splitter=RandomSplitter()\n    )\n\n    dls = dblock.dataloaders(cnndm_df, bs=bsz)\n    b = dls.one_batch()\n\n    try:\n        print(\"*** TESTING DataLoaders ***\\n\")\n        test_eq(len(b), 2)\n        test_eq(len(b[0][\"input_ids\"]), bsz)\n        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, seq_sz]))\n        test_eq(len(b[1]), bsz)\n        test_eq(b[1].shape, torch.Size([bsz, trg_seq_sz]))\n\n        if hasattr(hf_tokenizer, \"add_prefix_space\") and hf_arch not in [\"led\"]:\n            test_eq(hf_tokenizer.add_prefix_space, True)\n\n        test_results.append((hf_arch, type(hf_tokenizer).__name__, model_name, \"PASSED\", \"\"))\n        dls.show_batch(dataloaders=dls, max_n=2, input_trunc_at=1000)\n\n    except Exception as err:\n        test_results.append((hf_arch, type(hf_tokenizer).__name__, model_name, \"FAILED\", err))\n\n\n\n\n\n  \n    \n      \n      arch\n      tokenizer\n      model_name\n      result\n      error\n    \n  \n  \n    \n      0\n      bart\n      BartTokenizerFast\n      facebook/bart-base\n      PASSED\n      \n    \n    \n      1\n      blenderbot_small\n      BlenderbotSmallTokenizer\n      facebook/blenderbot_small-90M\n      PASSED\n      \n    \n    \n      2\n      led\n      LEDTokenizerFast\n      allenai/led-base-16384\n      PASSED\n      \n    \n    \n      3\n      mt5\n      T5TokenizerFast\n      google/mt5-small\n      PASSED\n      \n    \n    \n      4\n      pegasus\n      PegasusTokenizerFast\n      google/pegasus-cnn_dailymail\n      PASSED\n      \n    \n    \n      5\n      t5\n      T5TokenizerFast\n      t5-small\n      PASSED\n      \n    \n    \n      6\n      prophetnet\n      ProphetNetTokenizer\n      microsoft/prophetnet-large-uncased\n      PASSED\n      \n    \n    \n      7\n      xlm_prophetnet\n      XLMProphetNetTokenizer\n      microsoft/xprophetnet-large-wiki100-cased\n      PASSED"
  }
]